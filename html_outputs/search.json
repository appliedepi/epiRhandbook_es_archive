[{"path":"index.html","id":"section","chapter":"","heading":"","text":"","code":""},{"path":"index.html","id":"r-para-epidemiología-aplicada-y-salud-pública","chapter":"","heading":"R para epidemiología aplicada y salud pública","text":"Utilización: Este manual ha sido utilizado más de 1 millón de veces por 300.000 personas en todo el mundo.Objetivo: Servir como breve guía de referencia para escribir código en R (en línea y versión sin conexión con ejemplos detallados que aborden problemas epidemiológicos.¿Está empezando con R? Pruebe nuestros tutoriales interactivos gratuitos o el curso de introducción sincrónico, utilizado por los CDC de EE.UU., la OMS, y más de 75 agencias de salud y programas de formación de Epi de campo.\nIdiomas: Inglés, Vietnamita (Tiếng Việt), Turco (Türkçe)\n \nEscrito y traducido por profesionales de la epidemiología, para profesionales de la epidemiologíaSomos epi’s de campo de todo el mundo, escribiendo en nuestro tiempo libre para ofrecer este recurso la comunidad. Tu apoyo y comentarios son muy bienvenidos:Envía un email contact@appliedepi.org, un tweet @appliedepi, o en LinkedInEnvía problemas nuestro Repositorio Github","code":""},{"path":"index.html","id":"how-to-use-this-handbook","chapter":"","heading":"Cómo utilizar este manual","text":"Navega por las páginas del índice o utiliza el cuadro de búsquedaClica en los iconos “Copy” para copiar el códigoPuedes seguir paso paso las lecciones utilizando nuestros [datos de ejemplo][Download handbook data]Versión sin conexiónConsulta las instrucciones en la página de Descargar el Manual y los datos.","code":""},{"path":"index.html","id":"acknowledgements","chapter":"","heading":"Agradecimientos","text":"Este manual ha sido elaborado mediante la colaboración de profesionales de la epidemiología de todo el mundo, basándonos en nuestra experiencia en organismos sanitarios locales, estatales, provinciales y nacionales, la Organización Mundial de la Salud (OMS), Médicos Sin Fronteras (MSF), sistemas hospitalarios e instituciones académicas.Este manual es un producto aprobado por ninguna organización específica. Aunque nos esforzamos por ser precisos, ofrecemos ninguna garantía sobre el contenido de este libro.","code":""},{"path":"index.html","id":"colaboradores","chapter":"","heading":"Colaboradores","text":"Redactor jefe: Neale BatraEquipo central del proyecto: Neale Batra, Alex Spina, Amrish Baidjoe, Pat Keating, Henry Laurenson-Schafer, Finlay CampbellAutores: Neale Batra, Alex Spina, Paula Blomquist, Finlay Campbell, Henry Laurenson-Schafer, Isaac Florence, Natalie Fischer, Aminata Ndiaye, Liza Coyer, Jonathan Polonsky, Yurie Izawa, Chris Bailey, Daniel Molling, Isha Berry, Emma Buajitti, Mathilde Mousset, Sara Hollis, Wen LinRevisores: Pat Keating, Annick Lenglet, Margot Charette, Danielly Xavier, Esther Kukielka, Michelle Sloan, Aybüke Koyuncu, Rachel Burke, Kate Kelsey, Berhe Etsay, John Rossow, Mackenzie Zendt, James Wright, Laura Haskins, Flavio Finger, Tim Taylor, Jae Hyoung Tim Lee, Brianna Bradley, Wayne Enanoria, Manual Albela Miranda, Molly Mantus, Pattama Ulrich, Joseph Timothy, Adam Vaughan, Olivia Varsaneux, Lionel Monteiro, Joao MuiangaEquipo de traducción al español: Juan Carlos Fernández-Merino, Juan Francisco Monteagudo, Ximena Tolosa, Luis Hernando Aguilar Ramirez, Ignacio Castro Aguirre, Esther Kukielka, Cristina Torró, Ana Fernández-Ayuso.Illustraciones: Calder Fong","code":""},{"path":"index.html","id":"financiación-y-apoyo","chapter":"","heading":"Financiación y apoyo","text":"Este libro ha sido principalmente un esfuerzo voluntario que ha requerido miles de horas de trabajo.\nEl manual recibió apoyo financiaciero de TEPHINET, la red mundial de Programas de Formación en Epidemiología de Campo (FETP) través de una subvención para el desarrollo de capacidades de emergencia COVID-19.La Red de Antiguos Alumnos de (EAN) proporcionó apoyo administrativo, con un agradecimiento especial Annika Wendland. EPIET es el Programa Europeo de Formación en Epidemiología de Intervención.Un agradecimiento especial Médicos Sin Fronteras (MSF) Centro Operativo de Ámsterdam (OCA) por su apoyo durante la elaboración de este manual.Esta publicación fue respaldada por el Acuerdo de Cooperación número NU2GGH001873, financiado por los Centros para el Control y la Prevención de Enfermedades través de TEPHINET, un programa de Task Force Global Health. Su contenido es responsabilidad exclusiva de los autores y representa necesariamente las opiniones oficiales de los Centros para el Control y la Prevención de Enfermedades, el Departamento de Salud y Servicios Humanos, Task Force Global Health, Inc. o TEPHINET.","code":""},{"path":"index.html","id":"inspiración","chapter":"","heading":"Inspiración","text":"Hay multitud de tutoriales y viñetas que aportaron conocimientos para el desarrollo del contenido del manual y se acreditan en sus respectivas páginas.De manera más general, las siguientes fuentes han servido de inspiración para este manual:El proyecto “R4Epis” (una colaboración entre MSF y RECON)R Epidemics Consortium (RECON)El libro R Data Science (R4DS), en español en este enlacebookdown: Creación de libros y documentos técnicos con R MarkdownNetlify alberga este sitio web","code":""},{"path":"index.html","id":"terms-of-use-and-contribution","chapter":"","heading":"Condiciones de uso y contribución","text":"","code":""},{"path":"index.html","id":"licencia","chapter":"","heading":"Licencia","text":"Esta obra está bajo una Licencia Internacional Creative Commons Attribution-NonCommercial-ShareAlike 4.0.Los cursos académicos y los programas de formación en epidemiología pueden utilizar este manual con sus estudiantes. Si tienes preguntas sobre el uso que se le va dar, envía un correo electrónico epiRhandbook@gmail.com.","code":""},{"path":"index.html","id":"cita-sugerida","chapter":"","heading":"Cita sugerida","text":"Batra, Neale, et al. Manual de R para Epidemiología. 2021. ","code":""},{"path":"index.html","id":"contribución","chapter":"","heading":"Contribución","text":"Si quieres hacer una contribución de contenido, por favor, ponte en contacto con nosotros primero través de Github o por correo electrónico. Estamos implementando un calendario de actualizaciones y estamos creando una guía para colaboradores.Ten en cuenta que el proyecto epiRhandbook se publica con un Código de Conducta del Colaborador . Al contribuir este proyecto, te comprometes respetar sus términos.","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-and-technical-notes","chapter":"1 Notas editoriales y técnicas","heading":"1 Notas editoriales y técnicas","text":"En esta página describimos la filosofía, el estilo y las decisiones editoriales elegidas para la elaboración de este manual.","code":""},{"path":"editorial-and-technical-notes.html","id":"approach-and-style","chapter":"1 Notas editoriales y técnicas","heading":"1.1 Enfoque y estilo","text":"El público potencial de este libro es amplio. Seguramente será utilizado tanto por personas muy noveles con R, como por usuarios experimentados buscando los mejores consejos y prácticas. Por lo tanto, este debe ser accesible y conciso la vez. Por ello, nuestro enfoque fue proporcionar la información suficiente para que alguien muy nuevo en R pueda aplicar y seguir el código.Otros puntos:Se trata de un libro de referencia de códigos acompañado de ejemplos relativamente breves, de un libro de texto completo sobre R o ciencia de datosEste es un manual de R para su uso dentro de la epidemiología aplicada - un manual sobre los métodos o ciencia de la epidemiología aplicadaSe trata de un documento vivo: los paquetes de R óptimos para una tarea determinada cambian menudo, por lo que agradecemos que exista debate sobre cuáles son los más empleados en el manual","code":""},{"path":"editorial-and-technical-notes.html","id":"paquetes-de-r","chapter":"1 Notas editoriales y técnicas","heading":"Paquetes de R","text":"Muchas opcionesUno de los aspectos más difíciles de aprender en R es saber qué paquete utilizar para una tarea determinada. Es muy común pelearse con una tarea para luego darse cuenta de que ¡hay un paquete de R que hace todo eso en una línea de código!.En este manual, tratamos de ofrecerte al menos dos maneras de completar cada tarea: un método probado y comprobado (probablemente en R base o tidyverse) y un paquete especial de R que está hecho medida para ese propósito. Queremos que tengas un par de opciones en caso de que puedas descargar un paquete determinado o de que éste te funcione.la hora de elegir los paquetes utilizar, hemos dado prioridad los paquetes y enfoques de R que han sido probados y aprobados por la comunidad, que minimizan el número de paquetes utilizados en una sesión de trabajo típica, que son estables (cambian con frecuencia) y que realizan la tarea de forma sencilla y limpia.En general, este manual da prioridad los paquetes y funciones de R de tidyverse. Tidyverse es una colección de paquetes de R diseñados para ciencia de datos que comparten la gramática y estructuras de datos subyacentes. Todos los paquetes tidyverse pueden instalarse o cargarse través del paquete tidyverse. Más información en el sitio web de tidyverse.Cuando es aplicable, también ofrecemos opciones de código usando R base - los paquetes y funciones que vienen con R en la instalación. Esto se debe que somos conscientes de que parte de la audiencia de este libro podría tener una buena conexión internet para descargar paquetes adicionales.Vinculación explícita de las funciones los paquetesEs frustrante cuando en algunos tutoriales de R, se muestra una función (en código), pero se sabe bien de qué paquete es. En este libro intentamos evitar esta situación.En el texto explicativo, los nombres de los paquetes se escriben en negrita (por ejemplo, dplyr) y las funciones se escriben así: mutate(). Nos esforzaremos en dejar claro el paquete del que proviene una función, ya sea haciendo referencia al paquete en el texto o especificando el paquete en el código mediante esta sintaxis: dplyr::mutate(). Puede parecer redundante, pero lo hacemos propósito.Consulta la página sobre fundamentos de R para saber más sobre los paquetes y las funciones.","code":""},{"path":"editorial-and-technical-notes.html","id":"código-de-estilo","chapter":"1 Notas editoriales y técnicas","heading":"Código de estilo","text":"En el manual, utilizamos con frecuencia “líneas nuevas”, haciendo que nuestro código parezca “largo”. Lo hacemos por varias razones:De esta forma se pueden escribir comentarios explicativos con #, los cuales están situados adyacentes cada línea de códigoEn general, el código más largo (en vertical) es más fácil de leerEs más fácil de leer en una pantalla estrecha (es necesario desplazarse lateralmente)Con las sangrías, puede ser más fácil saber qué argumentos pertenecen cada funciónComo resultado, el código que podría estar escrito:…pero se escribe así:El código de R generalmente se ve afectado por nuevas líneas o sangrías. Al escribir el código, si se inicia una nueva línea después de una coma, se aplicarán patrones de sangría automáticos.También utilizamos muchos espacios (por ejemplo, n = 1 en lugar de n=1) porque es más fácil de leer. ¡Sé amable con la gente que lee tu código!","code":"\nlinelist %>% \n  group_by(hospital) %>%  # filas agrupadas por hospital\n  slice_max(date, n = 1, with_ties = F) # si hay un empate (de fecha), tomar la primera fila\nlinelist %>% \n  group_by(hospital) %>% # group rows by hospital\n  slice_max(\n    date,                # mantener la fila por grupo con el valor máximo de la fecha \n    n = 1,               # mantener sólo la fila más alta\n    with_ties = F)       # si hay un empate (de fecha), tomar la primera fila"},{"path":"editorial-and-technical-notes.html","id":"nomenclatura","chapter":"1 Notas editoriales y técnicas","heading":"Nomenclatura","text":"En este manual, generalmente hacemos referencia “columnas” y “filas” en lugar de “variables” y “observaciones”. Como se explica en este manual sobre “datos ordenados”, la mayoría de los conjuntos de datos estadísticos epidemiológicos se componen estructuralmente de filas, columnas y valores.Las variables contienen los valores que miden el mismo atributo subyacente (como el grupo de edad, el resultado o la fecha de inicio). Las observaciones contienen todos los valores medidos en la misma unidad (por ejemplo, una persona, un lugar o una muestra de laboratorio). Por lo tanto, estos aspectos pueden ser más difíciles de definir de forma tangible.En los conjuntos de datos “ordenados”, cada columna es una variable, cada fila es una observación y cada celda es un único valor. Sin embargo, algunos conjuntos de datos que se encuentran se ajustan este molde: unos datos de formato “amplio” puede tener una variable dividida en varias columnas (véase un ejemplo en la página Pivotar datos). Del mismo modo, las observaciones pueden estar divididas en varias filas.La mayor parte de este manual trata sobre la gestión y la transformación de datos, por lo que las referencias las estructuras de datos concretas de filas y columnas son más relevantes que las observaciones y las variables más abstractas. Las excepciones se dan sobre todo en las páginas sobre análisis de datos, en las que verás más referencias las variables y las observaciones.","code":""},{"path":"editorial-and-technical-notes.html","id":"nota","chapter":"1 Notas editoriales y técnicas","heading":"Nota","text":"types notes may encounter handbook:NOTA: Esto es una notaCONSEJO: Esto es un consejo.PRECAUCIÓN: Esto es una nota de precaución.PELIGRO Esto es un aviso (warning).","code":""},{"path":"editorial-and-technical-notes.html","id":"editorial-decisions","chapter":"1 Notas editoriales y técnicas","heading":"1.2 Decisiones editoriales","text":"continuación, hacemos un seguimiento de las decisiones editoriales importantes en torno la elección de paquetes y funciones. Si estás de acuerdo o quieres ofrecer una nueva herramienta para que la consideremos, únete o inicia una conversación en nuestra página de Github.Tabla de paquetes, funciones y otras decisiones editoriales","code":""},{"path":"editorial-and-technical-notes.html","id":"major-revisions","chapter":"1 Notas editoriales y técnicas","heading":"1.3 Revisiones importantes","text":"","code":""},{"path":"editorial-and-technical-notes.html","id":"session-info-r-rstudio-packages","chapter":"1 Notas editoriales y técnicas","heading":"1.4 Información de la sesión (R, RStudio, paquetes)","text":"continuación se presenta la información sobre las versiones de R, RStudio y los paquetes de R utilizados en esta versión del Manual.","code":"\nsessioninfo::session_info()## ─ Session info ───────────────────────────────────────────────────────────────────────────────────────\n##  setting  value\n##  version  R version 4.2.1 (2022-06-23 ucrt)\n##  os       Windows 10 x64 (build 22000)\n##  system   x86_64, mingw32\n##  ui       RStudio\n##  language (EN)\n##  collate  English_United States.utf8\n##  ctype    English_United States.utf8\n##  tz       Europe/Berlin\n##  date     2022-11-22\n##  rstudio  2022.07.1+554 Spotted Wakerobin (desktop)\n##  pandoc   2.18 @ C:/Program Files/RStudio/bin/quarto/bin/tools/ (via rmarkdown)\n## \n## ─ Packages ───────────────────────────────────────────────────────────────────────────────────────────\n##  ! package              * version    date (UTC) lib source\n##    abind                * 1.4-5      2016-07-21 [1] CRAN (R 4.2.0)\n##    ada                    2.0-5      2016-05-13 [1] CRAN (R 4.2.2)\n##    adagio                 0.8.5      2022-10-03 [1] CRAN (R 4.2.1)\n##    ade4                   1.7-20     2022-11-01 [1] CRAN (R 4.2.2)\n##    anytime                0.3.9      2020-08-27 [1] CRAN (R 4.2.1)\n##    ape                  * 5.6-2      2022-03-02 [1] CRAN (R 4.2.1)\n##    aplot                  0.1.7      2022-09-06 [1] CRAN (R 4.2.1)\n##    apyramid             * 0.1.2      2022-08-26 [1] Github (R4EPI/apyramid@c4114cc)\n##    assertive.base         0.0-9      2021-02-08 [1] CRAN (R 4.2.2)\n##    assertive.properties   0.0-5      2022-04-21 [1] CRAN (R 4.2.2)\n##    assertive.types        0.0-3      2016-12-30 [1] CRAN (R 4.2.2)\n##    assertthat             0.2.1      2019-03-21 [1] CRAN (R 4.2.1)\n##    aweek                * 1.0.2      2021-01-04 [1] CRAN (R 4.2.1)\n##    backports              1.4.1      2021-12-13 [1] CRAN (R 4.2.0)\n##    base64enc              0.1-3      2015-07-28 [1] CRAN (R 4.2.0)\n##    bayestestR           * 0.13.0     2022-09-18 [1] CRAN (R 4.2.1)\n##    bit                  * 4.0.4      2020-08-04 [1] CRAN (R 4.2.1)\n##    bit64                  4.0.5      2020-08-30 [1] CRAN (R 4.2.1)\n##    blob                   1.2.3      2022-04-10 [1] CRAN (R 4.2.1)\n##    bookdown               0.28       2022-08-09 [1] CRAN (R 4.2.1)\n##    boot                 * 1.3-28     2021-05-03 [2] CRAN (R 4.2.1)\n##    broom                * 1.0.1      2022-08-29 [1] CRAN (R 4.2.1)\n##    broom.helpers          1.9.0      2022-09-23 [1] CRAN (R 4.2.1)\n##    bslib                  0.4.0      2022-07-16 [1] CRAN (R 4.2.1)\n##    cachem                 1.0.6      2021-08-19 [1] CRAN (R 4.2.1)\n##    callr                  3.7.2      2022-08-22 [1] CRAN (R 4.2.1)\n##    car                    3.1-0      2022-06-15 [1] CRAN (R 4.2.1)\n##    carData                3.0-5      2022-01-06 [1] CRAN (R 4.2.1)\n##    cellranger             1.1.0      2016-07-27 [1] CRAN (R 4.2.1)\n##    class                  7.3-20     2022-01-16 [2] CRAN (R 4.2.1)\n##    classInt               0.4-7      2022-06-10 [1] CRAN (R 4.2.1)\n##    cli                    3.4.1      2022-09-23 [1] CRAN (R 4.2.1)\n##    clipr                  0.8.0      2022-02-22 [1] CRAN (R 4.2.1)\n##    clock                  0.6.1      2022-07-18 [1] CRAN (R 4.2.1)\n##    cmprsk                 2.2-11     2022-01-06 [1] CRAN (R 4.2.2)\n##    coarseDataTools        0.6-6      2021-12-09 [1] CRAN (R 4.2.1)\n##    coda                   0.19-4     2020-09-30 [1] CRAN (R 4.2.1)\n##    codetools              0.2-18     2020-11-04 [2] CRAN (R 4.2.1)\n##    colorspace             2.0-3      2022-02-21 [1] CRAN (R 4.2.1)\n##    commonmark             1.8.0      2022-03-09 [1] CRAN (R 4.2.1)\n##    correlation          * 0.8.2      2022-08-09 [1] CRAN (R 4.2.1)\n##    corrr                * 0.4.4      2022-08-16 [1] CRAN (R 4.2.1)\n##    cowplot              * 1.1.1      2020-12-30 [1] CRAN (R 4.2.1)\n##    crayon                 1.5.2      2022-09-29 [1] CRAN (R 4.2.1)\n##    crosstalk              1.2.0      2021-11-04 [1] CRAN (R 4.2.1)\n##    curl                   4.3.2      2021-06-23 [1] CRAN (R 4.2.1)\n##    data.table           * 1.14.2     2021-09-27 [1] CRAN (R 4.2.1)\n##    datawizard           * 0.6.1      2022-09-25 [1] CRAN (R 4.2.1)\n##    DBI                  * 1.1.3      2022-06-18 [1] CRAN (R 4.2.1)\n##    dbplyr                 2.2.1      2022-06-27 [1] CRAN (R 4.2.1)\n##    deldir                 1.0-6      2021-10-23 [1] CRAN (R 4.2.0)\n##    Deriv                  4.1.3      2021-02-24 [1] CRAN (R 4.2.1)\n##    devtools               2.4.4      2022-07-20 [1] CRAN (R 4.2.1)\n##    DiagrammeR           * 1.0.9      2022-03-05 [1] CRAN (R 4.2.1)\n##    dichromat              2.0-0.1    2022-05-02 [1] CRAN (R 4.2.0)\n##    digest                 0.6.29     2021-12-01 [1] CRAN (R 4.2.1)\n##    distcrete            * 1.0.3      2017-11-23 [1] CRAN (R 4.2.1)\n##    distributional         0.3.1      2022-09-02 [1] CRAN (R 4.2.2)\n##    doBy                 * 4.6.13     2022-05-02 [1] CRAN (R 4.2.1)\n##    doParallel             1.0.17     2022-02-07 [1] CRAN (R 4.2.2)\n##    downlit                0.4.2      2022-07-05 [1] CRAN (R 4.2.1)\n##    dplyr                * 1.0.10     2022-09-01 [1] CRAN (R 4.2.1)\n##    dsr                  * 0.2.2      2019-08-23 [1] Github (cran/dsr@f5e1c3f)\n##    DT                   * 0.24       2022-08-09 [1] CRAN (R 4.2.1)\n##    e1071                  1.7-11     2022-06-07 [1] CRAN (R 4.2.1)\n##    easystats            * 0.5.2      2022-08-30 [1] CRAN (R 4.2.1)\n##    ecmwfr               * 1.4.0      2022-08-17 [1] CRAN (R 4.2.2)\n##    effectsize           * 0.7.0.5    2022-08-10 [1] CRAN (R 4.2.1)\n##    ellipsis               0.3.2      2021-04-29 [1] CRAN (R 4.2.1)\n##    Epi                  * 2.47       2022-06-26 [1] CRAN (R 4.2.2)\n##    epicontacts          * 1.2.0      2022-11-20 [1] Github (reconhub/epicontacts@c5cd648)\n##    epidict                0.0.0.9001 2022-09-29 [1] Github (R4EPI/epidict@9cf5a53)\n##    EpiEstim             * 2.2-4      2021-01-07 [1] CRAN (R 4.2.1)\n##    epikit               * 0.1.4      2022-09-29 [1] Github (R4EPI/epikit@f2f6c6c)\n##    EpiNow2              * 1.3.2      2020-12-14 [1] CRAN (R 4.2.1)\n##    epitabulate            0.0.0.9007 2022-09-29 [1] Github (R4EPI/epitabulate@fa6338c)\n##    epitrix              * 0.2.2      2019-01-15 [1] CRAN (R 4.2.1)\n##    etm                    1.1.1      2020-09-08 [1] CRAN (R 4.2.2)\n##    evaluate               0.16       2022-08-09 [1] CRAN (R 4.2.1)\n##    evd                    2.3-6.1    2022-07-04 [1] CRAN (R 4.2.2)\n##    fabletools           * 0.3.2      2021-11-29 [1] CRAN (R 4.2.2)\n##    FactoClass             1.2.7      2018-10-01 [1] CRAN (R 4.2.2)\n##    fansi                  1.0.3      2022-03-24 [1] CRAN (R 4.2.1)\n##    farver                 2.1.1      2022-07-06 [1] CRAN (R 4.2.1)\n##    fastLink             * 0.6.0      2020-04-29 [1] CRAN (R 4.2.2)\n##    fastmap                1.1.0      2021-01-25 [1] CRAN (R 4.2.1)\n##    feasts               * 0.3.0      2022-09-01 [1] CRAN (R 4.2.2)\n##    ff                   * 4.0.7      2022-05-06 [1] CRAN (R 4.2.2)\n##    fitdistrplus           1.1-8      2022-03-10 [1] CRAN (R 4.2.1)\n##    flexdashboard        * 0.6.0      2022-08-05 [1] CRAN (R 4.2.1)\n##    flextable            * 0.8.2      2022-09-26 [1] CRAN (R 4.2.1)\n##    forcats              * 0.5.2      2022-08-19 [1] CRAN (R 4.2.1)\n##    foreach                1.5.2      2022-02-02 [1] CRAN (R 4.2.1)\n##    forecast             * 8.18       2022-10-02 [1] CRAN (R 4.2.2)\n##    foreign                0.8-82     2022-01-16 [2] CRAN (R 4.2.1)\n##    formatR                1.12       2022-03-31 [1] CRAN (R 4.2.1)\n##    formattable          * 0.2.1      2021-01-07 [1] CRAN (R 4.2.2)\n##    Formula              * 1.2-4      2020-10-16 [1] CRAN (R 4.2.0)\n##    fracdiff               1.5-2      2022-10-31 [1] CRAN (R 4.2.2)\n##    frailtypack          * 3.5.0      2021-12-20 [1] CRAN (R 4.2.1)\n##    fs                   * 1.5.2      2021-12-08 [1] CRAN (R 4.2.1)\n##    futile.logger          1.4.3      2016-07-10 [1] CRAN (R 4.2.1)\n##    futile.options         1.0.1      2018-04-20 [1] CRAN (R 4.2.0)\n##    future                 1.28.0     2022-09-02 [1] CRAN (R 4.2.1)\n##    future.apply           1.9.1      2022-09-07 [1] CRAN (R 4.2.1)\n##    gargle                 1.2.0      2021-07-02 [1] CRAN (R 4.2.1)\n##    gdtools                0.2.4      2022-02-14 [1] CRAN (R 4.2.1)\n##    generics               0.1.3      2022-07-05 [1] CRAN (R 4.2.1)\n##    ggExtra              * 0.10.0     2022-03-23 [1] CRAN (R 4.2.1)\n##    ggforce              * 0.4.1      2022-10-04 [1] CRAN (R 4.2.2)\n##    ggfun                  0.0.7      2022-08-31 [1] CRAN (R 4.2.1)\n##    gghighlight          * 0.3.3      2022-06-06 [1] CRAN (R 4.2.1)\n##    ggnewscale           * 0.4.7      2022-03-25 [1] CRAN (R 4.2.1)\n##    ggplot2              * 3.4.0      2022-11-04 [1] CRAN (R 4.2.2)\n##    ggplotify              0.1.0      2021-09-02 [1] CRAN (R 4.2.1)\n##    ggpubr               * 0.5.0      2022-11-16 [1] CRAN (R 4.2.1)\n##    ggrepel              * 0.9.1      2021-01-15 [1] CRAN (R 4.2.1)\n##    ggsignif               0.6.4      2022-10-13 [1] CRAN (R 4.2.2)\n##    ggtext                 0.1.2      2022-09-16 [1] CRAN (R 4.2.2)\n##    ggtree               * 3.4.4      2022-09-27 [1] Bioconductor\n##    ggupset              * 0.3.0      2020-05-05 [1] CRAN (R 4.2.2)\n##    globals                0.16.1     2022-08-28 [1] CRAN (R 4.2.1)\n##    glue                   1.6.2      2022-02-24 [1] CRAN (R 4.2.1)\n##    googledrive            2.0.0      2021-07-08 [1] CRAN (R 4.2.1)\n##    googlesheets4          1.0.0      2021-07-21 [1] CRAN (R 4.2.1)\n##    grates                 0.3.0      2021-10-21 [1] CRAN (R 4.2.1)\n##    gridExtra              2.3        2017-09-09 [1] CRAN (R 4.2.1)\n##    gridGraphics           0.5-1      2020-12-13 [1] CRAN (R 4.2.1)\n##    gridtext               0.1.5      2022-09-16 [1] CRAN (R 4.2.2)\n##    gt                     0.7.0      2022-08-25 [1] CRAN (R 4.2.1)\n##    gtable                 0.3.1      2022-09-01 [1] CRAN (R 4.2.1)\n##    gtools                 3.9.3      2022-07-11 [1] CRAN (R 4.2.2)\n##    gtsummary            * 1.6.2      2022-09-30 [1] CRAN (R 4.2.2)\n##    haven                  2.5.1      2022-08-22 [1] CRAN (R 4.2.1)\n##    here                 * 1.0.1      2020-12-13 [1] CRAN (R 4.2.1)\n##    highcharter          * 0.9.4      2022-01-03 [1] CRAN (R 4.2.2)\n##    highr                  0.9        2021-04-16 [1] CRAN (R 4.2.1)\n##    hms                    1.1.2      2022-08-19 [1] CRAN (R 4.2.1)\n##    htmltools              0.5.3      2022-07-18 [1] CRAN (R 4.2.1)\n##    htmlwidgets            1.5.4      2021-09-08 [1] CRAN (R 4.2.1)\n##    httpuv                 1.6.6      2022-09-08 [1] CRAN (R 4.2.1)\n##    httr                   1.4.4      2022-08-17 [1] CRAN (R 4.2.1)\n##    i2extras             * 0.1.2      2021-07-08 [1] CRAN (R 4.2.1)\n##    igraph                 1.3.5      2022-09-22 [1] CRAN (R 4.2.1)\n##    imputeTS             * 3.3        2022-09-09 [1] CRAN (R 4.2.2)\n##    incidence              1.7.3      2020-11-04 [1] CRAN (R 4.2.1)\n##    incidence2           * 1.2.3      2021-11-07 [1] CRAN (R 4.2.1)\n##    inline                 0.3.19     2021-05-31 [1] CRAN (R 4.2.1)\n##    insight              * 0.18.4     2022-09-20 [1] CRAN (R 4.2.1)\n##    ipred                  0.9-13     2022-06-02 [1] CRAN (R 4.2.1)\n##    isoband                0.2.5      2021-07-13 [1] CRAN (R 4.2.1)\n##    iterators              1.0.14     2022-02-05 [1] CRAN (R 4.2.1)\n##    janitor              * 2.1.0      2021-01-05 [1] CRAN (R 4.2.1)\n##    jpeg                   0.1-9      2021-07-24 [1] CRAN (R 4.2.0)\n##    jquerylib              0.1.4      2021-04-26 [1] CRAN (R 4.2.1)\n##    jsonlite               1.8.0      2022-02-22 [1] CRAN (R 4.2.1)\n##    kableExtra           * 1.3.4      2021-02-20 [1] CRAN (R 4.2.1)\n##    KernSmooth             2.23-20    2021-05-03 [2] CRAN (R 4.2.1)\n##    km.ci                  0.5-6      2022-04-06 [1] CRAN (R 4.2.2)\n##    KMsurv                 0.1-5      2012-12-03 [1] CRAN (R 4.2.0)\n##    knitr                  1.40       2022-08-24 [1] CRAN (R 4.2.1)\n##    labeling               0.4.2      2020-10-20 [1] CRAN (R 4.2.0)\n##    labelled               2.10.0     2022-09-14 [1] CRAN (R 4.2.1)\n##    lambda.r               1.2.4      2019-09-18 [1] CRAN (R 4.2.1)\n##    later                  1.3.0      2021-08-18 [1] CRAN (R 4.2.1)\n##    lattice                0.20-45    2021-09-22 [2] CRAN (R 4.2.1)\n##    lava                   1.6.10     2021-09-02 [1] CRAN (R 4.2.1)\n##    lazyeval               0.2.2      2019-03-15 [1] CRAN (R 4.2.1)\n##    leafem                 0.2.0      2022-04-16 [1] CRAN (R 4.2.1)\n##    leaflet                2.1.1      2022-03-23 [1] CRAN (R 4.2.1)\n##    leaflet.providers      1.9.0      2019-11-09 [1] CRAN (R 4.2.1)\n##    leafsync               0.1.0      2019-03-05 [1] CRAN (R 4.2.1)\n##    lifecycle              1.0.3      2022-10-07 [1] CRAN (R 4.2.2)\n##    linelist             * 0.0.1      2022-05-13 [1] CRAN (R 4.2.1)\n##    listenv                0.8.0      2019-12-05 [1] CRAN (R 4.2.1)\n##    lmtest               * 0.9-40     2022-03-21 [1] CRAN (R 4.2.1)\n##    loo                    2.5.1      2022-03-24 [1] CRAN (R 4.2.1)\n##    lpSolve                5.6.17     2022-10-10 [1] CRAN (R 4.2.1)\n##    lubridate            * 1.8.0      2021-10-07 [1] CRAN (R 4.2.1)\n##    lwgeom                 0.2-9      2022-10-01 [1] CRAN (R 4.2.1)\n##    magrittr             * 2.0.3      2022-03-30 [1] CRAN (R 4.2.1)\n##    markdown               1.1        2019-08-07 [1] CRAN (R 4.2.1)\n##    MASS                 * 7.3-57     2022-04-22 [2] CRAN (R 4.2.1)\n##    matchmaker             0.1.1      2020-02-21 [1] CRAN (R 4.2.1)\n##    Matrix               * 1.5-1      2022-09-13 [1] CRAN (R 4.2.1)\n##    MatrixModels           0.5-1      2022-09-11 [1] CRAN (R 4.2.1)\n##    matrixStats            0.62.0     2022-04-19 [1] CRAN (R 4.2.1)\n##    mcmc                   0.9-7      2020-03-21 [1] CRAN (R 4.2.1)\n##    MCMCpack               1.6-3      2022-04-13 [1] CRAN (R 4.2.1)\n##    memoise                2.0.1      2021-11-26 [1] CRAN (R 4.2.1)\n##    mgcv                   1.8-40     2022-03-29 [2] CRAN (R 4.2.1)\n##    mice                 * 3.15.0     2022-11-19 [1] CRAN (R 4.2.1)\n##    microbenchmark         1.4.9      2021-11-09 [1] CRAN (R 4.2.1)\n##    mime                   0.12       2021-09-28 [1] CRAN (R 4.2.0)\n##    miniUI                 0.1.1.1    2018-05-18 [1] CRAN (R 4.2.1)\n##    mitools                2.4        2019-04-26 [1] CRAN (R 4.2.1)\n##    modelbased           * 0.8.5      2022-08-18 [1] CRAN (R 4.2.1)\n##    modelr                 0.1.8      2020-05-19 [1] CRAN (R 4.2.1)\n##    munsell                0.5.0      2018-06-12 [1] CRAN (R 4.2.1)\n##    naniar               * 0.6.1      2021-05-14 [1] CRAN (R 4.2.1)\n##    networkD3            * 0.4        2017-03-18 [1] CRAN (R 4.2.2)\n##    nlme                   3.1-157    2022-03-25 [2] CRAN (R 4.2.1)\n##    nnet                   7.3-17     2022-01-16 [2] CRAN (R 4.2.1)\n##    numDeriv               2016.8-1.1 2019-06-06 [1] CRAN (R 4.2.0)\n##    officer              * 0.4.4      2022-09-09 [1] CRAN (R 4.2.1)\n##    OpenStreetMap        * 0.3.4      2019-05-31 [1] CRAN (R 4.2.1)\n##    openxlsx               4.2.5      2021-12-14 [1] CRAN (R 4.2.1)\n##    outbreaks              1.9.0      2020-09-28 [1] CRAN (R 4.2.1)\n##    pacman                 0.5.1      2019-03-11 [1] CRAN (R 4.2.1)\n##    parallelly             1.32.1     2022-07-21 [1] CRAN (R 4.2.1)\n##    parameters           * 0.18.2     2022-08-10 [1] CRAN (R 4.2.1)\n##    parsedate              1.3.0      2022-02-13 [1] CRAN (R 4.2.1)\n##    patchwork            * 1.1.2      2022-08-19 [1] CRAN (R 4.2.1)\n##    performance          * 0.9.2      2022-08-10 [1] CRAN (R 4.2.1)\n##    PerformanceAnalytics * 2.0.4      2020-02-06 [1] CRAN (R 4.2.2)\n##    PHEindicatormethods  * 1.4.1      2022-08-08 [1] CRAN (R 4.2.2)\n##    pillar                 1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n##    pkgbuild               1.3.1      2021-12-20 [1] CRAN (R 4.2.1)\n##    pkgconfig              2.0.3      2019-09-22 [1] CRAN (R 4.2.1)\n##    pkgload                1.3.0      2022-06-27 [1] CRAN (R 4.2.1)\n##    plotly               * 4.10.0     2021-10-09 [1] CRAN (R 4.2.1)\n##    plotrix                3.8-2      2021-09-08 [1] CRAN (R 4.2.0)\n##    plyr                   1.8.7      2022-03-24 [1] CRAN (R 4.2.1)\n##    png                    0.1-7      2013-12-03 [1] CRAN (R 4.2.0)\n##    polyclip               1.10-4     2022-10-20 [1] CRAN (R 4.2.1)\n##    polyCub                0.8.0      2021-01-27 [1] CRAN (R 4.2.2)\n##    prettyunits            1.1.1      2020-01-24 [1] CRAN (R 4.2.1)\n##    processx               3.7.0      2022-07-07 [1] CRAN (R 4.2.1)\n##    prodlim                2019.11.13 2019-11-17 [1] CRAN (R 4.2.1)\n##    profvis                0.3.7      2020-11-02 [1] CRAN (R 4.2.1)\n##    progressr              0.11.0     2022-09-02 [1] CRAN (R 4.2.1)\n##    projections          * 0.5.4      2021-04-22 [1] CRAN (R 4.2.1)\n##    promises               1.2.0.1    2021-02-11 [1] CRAN (R 4.2.1)\n##    proxy                  0.4-27     2022-06-09 [1] CRAN (R 4.2.1)\n##    ps                     1.7.1      2022-06-18 [1] CRAN (R 4.2.1)\n##    purrr                * 0.3.4      2020-04-17 [1] CRAN (R 4.2.1)\n##    quadprog               1.5-8      2019-11-20 [1] CRAN (R 4.2.0)\n##    Quandl                 2.11.0     2021-08-11 [1] CRAN (R 4.2.2)\n##    quantmod             * 0.4.20     2022-04-29 [1] CRAN (R 4.2.2)\n##    quantreg               5.94       2022-07-20 [1] CRAN (R 4.2.1)\n##    R.methodsS3            1.8.2      2022-06-13 [1] CRAN (R 4.2.0)\n##    R.oo                   1.25.0     2022-06-12 [1] CRAN (R 4.2.0)\n##    R.utils                2.12.0     2022-06-28 [1] CRAN (R 4.2.1)\n##    R6                     2.5.1      2021-08-19 [1] CRAN (R 4.2.1)\n##    raster                 3.5-29     2022-08-14 [1] CRAN (R 4.2.1)\n##    RColorBrewer         * 1.1-3      2022-04-03 [1] CRAN (R 4.2.0)\n##    Rcpp                 * 1.0.9      2022-07-08 [1] CRAN (R 4.2.1)\n##  D RcppParallel           5.1.5      2022-01-05 [1] CRAN (R 4.2.1)\n##    readr                * 2.1.2      2022-01-30 [1] CRAN (R 4.2.1)\n##    readxl               * 1.4.1      2022-08-17 [1] CRAN (R 4.2.1)\n##    RecordLinkage        * 0.4-12.4   2022-11-08 [1] CRAN (R 4.2.2)\n##    remotes                2.4.2      2021-11-30 [1] CRAN (R 4.2.1)\n##    report               * 0.5.5      2022-08-22 [1] CRAN (R 4.2.1)\n##    repr                   1.1.4      2022-01-04 [1] CRAN (R 4.2.1)\n##    reprex                 2.0.1      2021-08-05 [1] CRAN (R 4.2.1)\n##    reshape2               1.4.4      2020-04-09 [1] CRAN (R 4.2.1)\n##    rgdal                  1.5-32     2022-05-09 [1] CRAN (R 4.2.1)\n##    rio                  * 0.5.29     2021-11-22 [1] CRAN (R 4.2.1)\n##  D rJava                  1.0-6      2021-12-10 [1] CRAN (R 4.2.0)\n##    rlang                  1.0.6      2022-09-24 [1] CRAN (R 4.2.1)\n##    rlist                  0.4.6.2    2021-09-03 [1] CRAN (R 4.2.2)\n##    rmarkdown              2.16       2022-08-24 [1] CRAN (R 4.2.1)\n##    rootSolve              1.8.2.3    2021-09-29 [1] CRAN (R 4.2.0)\n##    rpart                  4.1.16     2022-01-24 [2] CRAN (R 4.2.1)\n##    rprojroot              2.0.3      2022-04-02 [1] CRAN (R 4.2.1)\n##    RSQLite              * 2.2.18     2022-10-04 [1] CRAN (R 4.2.2)\n##    rstan                  2.21.7     2022-09-08 [1] CRAN (R 4.2.1)\n##    rstatix              * 0.7.1      2022-11-09 [1] CRAN (R 4.2.2)\n##    rstudioapi             0.14       2022-08-22 [1] CRAN (R 4.2.1)\n##    runner                 0.4.2      2022-09-17 [1] CRAN (R 4.2.1)\n##    rvest                  1.0.2      2021-10-16 [1] CRAN (R 4.2.1)\n##    s2                     1.1.0      2022-07-18 [1] CRAN (R 4.2.1)\n##    sass                   0.4.2      2022-07-16 [1] CRAN (R 4.2.1)\n##    scales               * 1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n##    scatterplot3d          0.3-42     2022-09-08 [1] CRAN (R 4.2.1)\n##    see                  * 0.7.3      2022-09-20 [1] CRAN (R 4.2.1)\n##    SemiCompRisks        * 3.4        2021-02-03 [1] CRAN (R 4.2.2)\n##    sessioninfo            1.2.2      2021-12-06 [1] CRAN (R 4.2.1)\n##    sf                   * 1.0-8      2022-07-14 [1] CRAN (R 4.2.1)\n##    shiny                * 1.7.2      2022-07-19 [1] CRAN (R 4.2.1)\n##    sitrep               * 0.2.3      2022-09-29 [1] Github (r4epi/sitrep@75c86a7)\n##    skimr                * 2.1.4      2022-04-15 [1] CRAN (R 4.2.1)\n##    slider               * 0.2.2      2021-07-01 [1] CRAN (R 4.2.1)\n##    snakecase              0.11.0     2019-05-25 [1] CRAN (R 4.2.1)\n##    sp                   * 1.5-0      2022-06-05 [1] CRAN (R 4.2.1)\n##    SparseM                1.81       2021-02-18 [1] CRAN (R 4.2.0)\n##    spatstat.data          3.0-0      2022-10-21 [1] CRAN (R 4.2.2)\n##    spatstat.geom          3.0-3      2022-10-25 [1] CRAN (R 4.2.2)\n##    spatstat.utils         3.0-1      2022-10-19 [1] CRAN (R 4.2.2)\n##    spData               * 2.2.0      2022-08-31 [1] CRAN (R 4.2.1)\n##    spdep                * 1.2-7      2022-10-01 [1] CRAN (R 4.2.1)\n##    srvyr                * 1.1.1      2022-02-20 [1] CRAN (R 4.2.1)\n##    StanHeaders            2.21.0-7   2020-12-17 [1] CRAN (R 4.2.1)\n##    stars                * 0.5-6      2022-07-21 [1] CRAN (R 4.2.1)\n##    statmod                1.4.37     2022-08-12 [1] CRAN (R 4.2.1)\n##    stinepack              1.4        2018-07-30 [1] CRAN (R 4.2.0)\n##    stringdist           * 0.9.10     2022-11-07 [1] CRAN (R 4.2.2)\n##    stringi                1.7.8      2022-07-11 [1] CRAN (R 4.2.1)\n##    stringr              * 1.4.1      2022-08-20 [1] CRAN (R 4.2.1)\n##    survC1               * 1.0-3      2021-02-10 [1] CRAN (R 4.2.1)\n##    surveillance         * 1.20.3     2022-11-16 [1] CRAN (R 4.2.1)\n##    survey               * 4.1-1      2021-07-19 [1] CRAN (R 4.2.1)\n##    survival             * 3.3-1      2022-03-03 [2] CRAN (R 4.2.1)\n##    survminer            * 0.4.9      2021-03-09 [1] CRAN (R 4.2.2)\n##    survMisc               0.5.6      2022-04-07 [1] CRAN (R 4.2.2)\n##    svglite                2.1.0      2022-02-03 [1] CRAN (R 4.2.1)\n##    systemfonts            1.0.4      2022-02-11 [1] CRAN (R 4.2.1)\n##    terra                  1.6-7      2022-08-07 [1] CRAN (R 4.2.1)\n##    tibble               * 3.1.8      2022-07-22 [1] CRAN (R 4.2.1)\n##    tidyquant            * 1.0.6      2022-11-16 [1] CRAN (R 4.2.1)\n##    tidyr                * 1.2.1      2022-09-08 [1] CRAN (R 4.2.1)\n##    tidyselect             1.1.2      2022-02-21 [1] CRAN (R 4.2.1)\n##    tidytree               0.4.1      2022-09-26 [1] CRAN (R 4.2.1)\n##    tidyverse            * 1.3.2      2022-07-18 [1] CRAN (R 4.2.2)\n##    timeDate               4021.106   2022-09-30 [1] CRAN (R 4.2.1)\n##    tinytex                0.42       2022-09-27 [1] CRAN (R 4.2.1)\n##    tmap                 * 3.3-3      2022-03-02 [1] CRAN (R 4.2.1)\n##    tmaptools            * 3.1-1      2021-01-19 [1] CRAN (R 4.2.1)\n##    treeio               * 1.20.2     2022-08-14 [1] Bioconductor\n##    trending             * 0.0.3      2021-04-19 [1] CRAN (R 4.2.1)\n##    truncnorm              1.0-8      2018-02-27 [1] CRAN (R 4.2.1)\n##    tseries                0.10-52    2022-10-10 [1] CRAN (R 4.2.2)\n##    tsibble              * 1.1.2      2022-08-21 [1] CRAN (R 4.2.1)\n##    TTR                  * 0.24.3     2021-12-12 [1] CRAN (R 4.2.2)\n##    tweenr                 2.0.2      2022-09-06 [1] CRAN (R 4.2.1)\n##    tzdb                   0.3.0      2022-03-28 [1] CRAN (R 4.2.1)\n##    units                * 0.8-0      2022-02-05 [1] CRAN (R 4.2.1)\n##    UpSetR               * 1.4.0      2019-05-22 [1] CRAN (R 4.2.1)\n##    urca                   1.3-3      2022-08-29 [1] CRAN (R 4.2.2)\n##    urlchecker             1.0.1      2021-11-30 [1] CRAN (R 4.2.1)\n##    usethis                2.1.6      2022-05-25 [1] CRAN (R 4.2.1)\n##    utf8                   1.2.2      2021-07-24 [1] CRAN (R 4.2.1)\n##    uuid                   1.1-0      2022-04-19 [1] CRAN (R 4.2.0)\n##    vctrs                  0.5.1      2022-11-16 [1] CRAN (R 4.2.1)\n##    viridis              * 0.6.2      2021-10-13 [1] CRAN (R 4.2.1)\n##    viridisLite          * 0.4.1      2022-08-22 [1] CRAN (R 4.2.1)\n##    visdat                 0.5.3      2019-02-15 [1] CRAN (R 4.2.1)\n##    visNetwork           * 2.1.2      2022-09-29 [1] CRAN (R 4.2.1)\n##    vistime              * 1.2.3      2022-10-16 [1] CRAN (R 4.2.2)\n##    warp                   0.2.0      2020-10-21 [1] CRAN (R 4.2.1)\n##    webshot              * 0.5.3      2022-04-14 [1] CRAN (R 4.2.1)\n##    withr                  2.5.0      2022-03-03 [1] CRAN (R 4.2.1)\n##    wk                     0.6.0      2022-01-03 [1] CRAN (R 4.2.1)\n##    writexl              * 1.4.1      2022-10-18 [1] CRAN (R 4.2.2)\n##    xfun                   0.33       2022-09-12 [1] CRAN (R 4.2.1)\n##    XML                    3.99-0.10  2022-06-09 [1] CRAN (R 4.2.1)\n##    xml2                   1.3.3      2021-11-30 [1] CRAN (R 4.2.1)\n##    xtable               * 1.8-4      2019-04-21 [1] CRAN (R 4.2.1)\n##    xts                  * 0.12.2     2022-10-16 [1] CRAN (R 4.2.2)\n##    yaml                   2.3.5      2022-02-21 [1] CRAN (R 4.2.1)\n##    yardstick            * 1.1.0      2022-09-07 [1] CRAN (R 4.2.2)\n##    yulab.utils            0.0.5      2022-06-30 [1] CRAN (R 4.2.1)\n##    zip                    2.2.1      2022-09-08 [1] CRAN (R 4.2.1)\n##    zoo                  * 1.8-11     2022-09-17 [1] CRAN (R 4.2.1)\n## \n##  [1] C:/Users/neale/AppData/Local/R/win-library/4.2\n##  [2] C:/Program Files/R/R-4.2.1/library\n## \n##  D ── DLL MD5 mismatch, broken installation.\n## \n## ──────────────────────────────────────────────────────────────────────────────────────────────────────"},{"path":"download-handbook-and-data.html","id":"download-handbook-and-data","chapter":"2 Descargando el manual y los datos","heading":"2 Descargando el manual y los datos","text":"","code":""},{"path":"download-handbook-and-data.html","id":"download-offline-handbook","chapter":"2 Descargando el manual y los datos","heading":"2.1 Descargar el manual sin conexión","text":"Puedes descargar la versión sin conexión de este manual. Éste es un archivo HTML que puedes ver en tu navegador web sin acceder Internet. Si estás pensando en utilizar este manual sin conexión, debes tener en cuenta algunas cosas:Al abrir el archivo, las imágenes y el índice pueden tardar uno o dos minutos en cargarse.Este manual tiene un diseño ligeramente diferente: una página muy larga con el índice la izquierda. Para buscar términos específicos utiliza Ctrl+f (Cmd-f)Consulta la página de Paquetes recomendados para ayudarte instalar los paquetes de R adecuados antes de que pierdas la conectividad InternetInstala nuestro paquete R epirhandbook que contiene todos los datos del ejemplo (el proceso de instalación se describe continuación)Hay dos maneras de descargar el manual:","code":""},{"path":"download-handbook-and-data.html","id":"utilizando-el-enlace-de-descarga","chapter":"2 Descargando el manual y los datos","heading":"Utilizando el enlace de descarga","text":"Para acceder rápidamente, clica con el botón derecho en este enlace y selecciona “Guardar enlace como”.Si es un Mac, utiliza Cmd+clic. Si es un móvil, mantén clicado el enlace y selecciona “Guardar enlace”. El manual se descargará en el dispositivo. Si aparece una pantalla con código HTML sin procesar, asegúrate de haber seguido las instrucciones anteriores o prueba la opción 2.","code":""},{"path":"download-handbook-and-data.html","id":"utilizando-nuestro-paquete-r","chapter":"2 Descargando el manual y los datos","heading":"Utilizando nuestro paquete R","text":"Ofrecemos un paquete llamado epirhandbook. Este incluye la función download_book() que descarga el archivo del manual desde nuestro repositorio de Github tu ordenador.Este paquete también contiene una función get_data() que descarga todos los datos del ejemplo en tu ordenador.Ejecuta el siguiente código para instalar nuestro paquete R epirhandbook desde el repositorio de Github appliedepi. Este paquete está en CRAN, así que utiliza la función especial p_install_gh() para instalarlo desde Github.Ahora, puedes cargar el paquete para utilizarlo en la sesión actual de R:continuación, ejecuta la función del paquete download_book() (con los paréntesis vacíos) para descargar el manual en tu ordenador. Suponiendo que estés en RStudio, aparecerá una ventana que te permitirá seleccionar una ubicación para guardarlo.","code":"\n# instala la última versión del paquete Epi R Handbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# carga el paquete para utilizarlo\npacman::p_load(epirhandbook)\n# descarga el manual offline en tu computadora\ndownload_book()"},{"path":"download-handbook-and-data.html","id":"download-data-to-follow-along","chapter":"2 Descargando el manual y los datos","heading":"2.2 Descarga los datos para seguir el manual","text":"Para “seguir” las páginas del manual, puedes descargar los datos y los resultados de los ejemplos.","code":""},{"path":"download-handbook-and-data.html","id":"utiliza-nuestro-paquete-para-r","chapter":"2 Descargando el manual y los datos","heading":"Utiliza nuestro paquete para R","text":"El método más sencillo para descargar todos los datos es instalar nuestro paquete epirhandbook. Contiene una función get_data() que guarda todos los datos del ejemplo en una carpeta de tu elección en tu ordenador.Para instalar nuestro paquete epirhandbook, ejecuta el siguiente código. Este paquete está en CRAN, así que utiliza la función p_install_gh() para instalarlo. La entrada hace referencia nuestra organización de Github (“appliedepi”) y al paquete epirhandbook.epirhandbook package.Ahora, carga el paquete para utilizarlo en tu sesión actual de R:continuación, utiliza la función get_data() del paquete para descargar los datos de ejemplo en tu ordenador. Ejecuta get_data(“”) para obtener todos los datos de ejemplo, o escribe un nombre de archivo específico y una extensión entre comillas para recuperar sólo un archivo.Los datos ya se han descargado con el paquete, y sólo hay que transferirlos una carpeta del ordenador. Aparecerá una ventana emergente para seleccionar la ubicación de la carpeta de almacenamiento. Te sugerimos que crees una nueva carpeta de “datos”, ya que hay unos 30 archivos (incluidos los datos de ejemplo y los resultados de ejemplo).Una vez que hayas utilizado get_data() para guardar un archivo en tu ordenador, tendrás que importarlo R. Consulta la página de importación y exportación para más detalles.Si lo deseas, puedes revisar todos los datos utilizados en este manual en la carpeta “data” de nuestro repositorio de Github.","code":"\n# instala la última versión del paquete Epi R Handbook\npacman::p_install_gh(\"appliedepi/epirhandbook\")\n# carga el paquete para utilizarlo\npacman::p_load(epirhandbook)\n# descarga todos los datos de ejemplos en tu computadora\nget_data(\"all\")\n\n# descarga solo los datos del ejemplo listado limpio\nget_data(file = \"linelist_cleaned.rds\")\n# descarga solo un archivo específoco en tu computadora\nget_data(\"linelist_cleaned.rds\")"},{"path":"download-handbook-and-data.html","id":"descargar-uno-por-uno","chapter":"2 Descargando el manual y los datos","heading":"Descargar uno por uno","text":"Esta opción implica la descarga de los datos archivo por archivo desde nuestro repositorio de Github través de un enlace o un comando de R específico para el archivo. Algunos tipos de archivos permiten un botón de descarga, mientras que otros pueden descargarse mediante un comando de R.","code":""},{"path":"download-handbook-and-data.html","id":"linelist","chapter":"2 Descargando el manual y los datos","heading":"Linelist","text":"Se trata de un brote de ébola ficticio, ampliado por el equipo del manual partir de los datos ebola_sim de las prácticas del paquete Outbreaks.Clica para descargar Linelist (con los casos) “en bruto” -raw- (.xlsx). Este listado de casos “en bruto” es una hoja de cálculo de Excel con datos desordenados. Utilízala para seguir la página de limpieza de datos y funciones básicas.Clica para descargar Linelist (con los casos) “en bruto” -raw- (.xlsx). Este listado de casos “en bruto” es una hoja de cálculo de Excel con datos desordenados. Utilízala para seguir la página de limpieza de datos y funciones básicas.Clica para descargar Linelist “en limpio”. Utiliza este archivo para todas las demás páginas de este manual que utilizan el listado de casos. Un archivo .rds es un tipo de archivo específico de R que conserva los tipos de columnas. Esto asegura que sólo tendrás que hacer una limpieza mínima después de importar los datos R.Clica para descargar Linelist “en limpio”. Utiliza este archivo para todas las demás páginas de este manual que utilizan el listado de casos. Un archivo .rds es un tipo de archivo específico de R que conserva los tipos de columnas. Esto asegura que sólo tendrás que hacer una limpieza mínima después de importar los datos R.Otros archivos relacionados:Clica para descargar el listado de casos “en limpio” como archivo Excel.Clica para descargar el listado de casos “en limpio” como archivo Excel.Parte de la página de limpieza utiliza un “diccionario de limpieza” (archivo .csv). Puedes cargarlo directamente en R ejecutando los siguientes comandos:Parte de la página de limpieza utiliza un “diccionario de limpieza” (archivo .csv). Puedes cargarlo directamente en R ejecutando los siguientes comandos:","code":"\npacman::p_load(rio) # install/load the rio package\n\n# importa el archivo directamente desde Github\ncleaning_dict <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/case_linelists/cleaning_dict.csv\")"},{"path":"download-handbook-and-data.html","id":"data_malaria","chapter":"2 Descargando el manual y los datos","heading":"Recuento de datos de malaria","text":"Estos datos son recuentos ficticios de casos de malaria por grupos de edad, centro y día. Un archivo .rds es un tipo de archivo específico de R que conserva los tipos de columnas. Esto asegura que sólo tendrás que hacer una limpieza mínima después de importar los datos R.Clica para descargar los datos del recuento de casos de malaria (archivo .rds)","code":""},{"path":"download-handbook-and-data.html","id":"datos-en-escala-likert","chapter":"2 Descargando el manual y los datos","heading":"Datos en escala Likert","text":"Se trata de datos ficticios de una encuesta tipo Likert, utilizados en la página sobre Pirámides de población y escalas de Likert. Puedes cargar estos datos directamente en R ejecutando los siguientes comandos:","code":"\npacman::p_load(rio) # instala/carga el paquete rio\n\n# importa el fichero directamente de Github\nlikert_data <- import(\"https://raw.githubusercontent.com/appliedepi/epirhandbook_eng/master/data/likert_data.csv\")"},{"path":"download-handbook-and-data.html","id":"flexdashboard","chapter":"2 Descargando el manual y los datos","heading":"Flexdashboard","text":"continuación se encuentran los enlaces al archivo asociado la página sobre Dashboards con R Markdown:Para descargar el código de R Markdown para el dashboard (panel de control) del brote, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.Para descargar el código de R Markdown para el dashboard (panel de control) del brote, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.Para descargar el código HTML del dashboard, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.Para descargar el código HTML del dashboard, clica con el botón derecho en este enlace (Cmd+clic para Mac) y luego “Guardar enlace como”.","code":""},{"path":"download-handbook-and-data.html","id":"rastreo-de-contactos","chapter":"2 Descargando el manual y los datos","heading":"Rastreo de contactos","text":"La página de rastreo de contactos muestra el análisis de los datos de rastreo de contactos, utilizando como ejemplo datos de Go.Data. Los datos utilizados en la página pueden descargarse como archivos .rds clicando en los siguientes enlaces:Clica para descargar los datos de la investigación de casos (archivo .rds)Clica para descargar los datos de registro de los contactos (archivo .rds)Clica para descargar los datos de seguimiento de los contactos (archivo .rds)NOTA: Los datos de rastreo de contactos estructurados de otro software (por ejemplo, KoBo, DHIS2 Tracker, CommCare) pueden tener un aspecto diferente. Si quieres contribuir con una muestra de datos alternativos o con contenido para esta página, por favor, ponte en contacto, con nosotros.CONSEJO: Si estás utilizando Go.Data y quieres conectarte tu instancia de la API, consulta la página de importación y exportación (sección API) y la Comunidad de Prácticas de Go.Data.","code":""},{"path":"download-handbook-and-data.html","id":"sig-gis","chapter":"2 Descargando el manual y los datos","heading":"SIG (GIS)","text":"Los archivos geográficos tipo shapefile tienen varios archivos subcomponentes, cada uno con una extensión de archivo diferente. Un archivo tendrá la extensión “.shp”, pero otros tienen la extensión “.dbf”, “.prj”, etc.La página de Conceptos básicos de los SIG contiene enlaces al sitio web de Humanitarian Data Exchange, donde se pueden descargar los shapefiles directamente como archivos comprimidos.Por ejemplo, los datos de los puntos de las instalaciones sanitarias se pueden descargar de aquí. Descarga “hotosm_sierra_leone_health_facilities_points_shp.zip”. Una vez guardado en tu ordenador, “descomprime” la carpeta. Ahí vas encontrar varios archivos con diferentes extensiones (por ejemplo, “.shp”, “.prj”, “.shx”) todos ellos deben guardarse en la misma carpeta. continuación, para importar en R, proporciona la ruta completa y el nombre del archivo “.shp” st_read() del paquete sf (como se describe en la página de Conceptos básicos de los SIG).Si sigues la opción 1 para descargar todos los datos de ejemplo (través de nuestro paquete epirhandbook), todos los shapefiles están incluidos en el paquete.También puedes descargar los shapefiles de la carpeta “data” de R Handbook Github (véase la subcarpeta “gis”). Sin embargo, ten en cuenta que tendrás que descargar cada subfichero individualmente en tu ordenador. En Github, clica en cada archivo individualmente y descárgalo clicando en el botón “Download”. continuación, puedes ver cómo el shapefile “sle_adm3” consta de muchos archivos, cada uno de los cuales tendría que ser descargado de Github.","code":""},{"path":"download-handbook-and-data.html","id":"árboles-filogenéticos","chapter":"2 Descargando el manual y los datos","heading":"Árboles filogenéticos","text":"Mira la página sobre árboles filogenéticos. El archivo Newick con el árbol filogenético construido partir de la secuenciación del genoma completo de 299 muestras de Shigella sonnei y los datos de las muestras correspondientes (convertidos en un archivo de texto). Las muestras belgas y los datos resultantes han sido proporcionados amablemente por el NRC belga para Salmonella y Shigella en el marco de un proyecto dirigido por un fellow del programa ECDC EUPHEM, y también se publicarán en un manuscrito. Los datos internacionales están disponibles en bases de datos públicas (ncbi) y han sido publicados previamente.Para descargar el archivo del árbol filogenético “Shigella_tree.txt”, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.Para descargar el archivo del árbol filogenético “Shigella_tree.txt”, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.Para descargar el archivo “sample_data_Shigella_tree.csv” con información adicional sobre cada muestra, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.Para descargar el archivo “sample_data_Shigella_tree.csv” con información adicional sobre cada muestra, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”.Para ver el nuevo árbol de subconjuntos creado, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”. El archivo .txt se descargará en tu ordenador.Para ver el nuevo árbol de subconjuntos creado, clica con el botón derecho en este enlace (Cmd+clic para Mac) y selecciona “Guardar enlace como”. El archivo .txt se descargará en tu ordenador.Tras la descarga, se pueden importar los archivos .txt con la función read.tree() del paquete ape, como se explica en la página.","code":"\nape::read.tree(\"Shigella_tree.txt\")"},{"path":"download-handbook-and-data.html","id":"estandarización","chapter":"2 Descargando el manual y los datos","heading":"Estandarización","text":"Consulta la página de tasas estandarizadas. Puedes cargar los datos directamente desde nuestro repositorio de Github en Internet en tu sesión de R con los siguientes comandos:","code":"\n# instala/carga el paquete rio\npacman::p_load(rio) \n\n##############\n# Country A\n##############\n# importa demographics del país A directamente desde Github\nA_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics.csv\")\n\n# importa defunciones del país A directamente desde Github\nA_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryA.csv\")\n\n##############\n# Country B\n##############\n# importa demographics del país B directamente desde Github\nB_demo <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/country_demographics_2.csv\")\n\n# importa defunciones del país B directamente desde Github\nB_deaths <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/deaths_countryB.csv\")\n\n\n##########################\n# Población de referencia#\n##########################\n# importa demographics del país B directamente desde Github\nstandard_pop_data <- import(\"https://github.com/appliedepi/epirhandbook_eng/raw/master/data/standardization/world_standard_population_by_sex.csv\")"},{"path":"download-handbook-and-data.html","id":"data_outbreak","chapter":"2 Descargando el manual y los datos","heading":"Series temporales y detección de brotes","text":"Véase la página sobre series temporales y detección de brotes. Utilizamos los casos de campylobacter notificados en Alemania entre 2002 y 2011, disponibles en el paquete R surveillance. (nb. este conjunto de datos ha sido adaptado del original, en el sentido de que se han eliminado 3 meses de datos de finales de 2011 para fines de demostración).Clica para descargar Campylobacter en Alemania (.xlsx)También utilizamos datos climáticos de Alemania de 2002 2011 (temperatura en grados centígrados y lluvia caída en milímetros). Estos datos se descargaron de los datos del reanálisis por satélite Copernicus de la UE utilizando el paquete ecmwfr. Tendrás que descargarlos todos e importarlos con stars::read_stars() como se explica en la página de series temporales.Clica para descargar el tiempo de Alemania 2002 (archivo .nc)Clica para descargar el tiempo de Alemania 2003 (archivo .nc)Clica para descargar el tiempo en Alemania 2004 (archivo .nc)Clica para descargar el tiempo en Alemania 2005 (archivo .nc)Clica para descargar el tiempo en Alemania 2006 (archivo .nc)Clica para descargar el tiempo de Alemania 2007 (archivo .nc)Clica para descargar el tiempo de Alemania 2008 (archivo .nc)Clica para descargar el tiempo en Alemania 2009 (archivo .nc)Clica para descargar el tiempo en Alemania 2010 (archivo .nc)Clica para descargar el tiempo en Alemania 2011 (archivo .nc)","code":""},{"path":"download-handbook-and-data.html","id":"data_survey","chapter":"2 Descargando el manual y los datos","heading":"Análisis de encuestas","text":"Para el capítulo sobre análisis de encuestas utilizamos datos ficticios de encuestas de mortalidad basados en las plantillas de encuestas de MSF OCA. Estos datos ficticios se generaron como parte del proyecto “R4Epis”.Clica para descargar los datos de la encuesta ficticia (.xlsx)Clica para descargar el diccionario de datos de la encuesta ficticia (.xlsx)Clica para descargar los datos de la población de la encuesta ficticia (.xlsx)","code":""},{"path":"download-handbook-and-data.html","id":"data_shiny","chapter":"2 Descargando el manual y los datos","heading":"Shiny","text":"El capítulo sobre Dashboards con Shiny demuestra la construcción de una sencilla aplicación para mostrar datos sobre la malaria.Para descargar los archivos R que producen la aplicación Shiny:Puedes clicar aquí para descargar el archivo app.R que contiene tanto la interfaz de usuario como el código del servidor para la aplicación Shiny.Puedes clicar aquí para descargar el archivo facility_count_data.rds que contiene datos sobre la malaria para la aplicación Shiny. Ten en cuenta que puede ser necesario almacenarlo dentro de una carpeta “data” para que las rutas de los archivos () funcionen correctamente.Puedes clicar aquí para descargar el archivo global.R que debe ejecutarse antes de que se abra la aplicación, como se explica en dicho capítulo.Puedes clicar aquí para descargar el archivo plot_epicurve.R que es originado por global.R. Ten en cuenta que puede necesitar almacenarlo dentro de una carpeta “funcs” para que las rutas de los archivos () funcionen correctamente.","code":""},{"path":"r-basics.html","id":"r-basics","chapter":"3 Fundamentos de R","heading":"3 Fundamentos de R","text":"Bienvenido.Esta página repasa los aspectos esenciales de R. pretende ser un tutorial exhaustivo, pero proporciona los fundamentos y puede ser útil para refrescar la memoria. La sección de Recursos para el aprendizaje enlaza con tutoriales más completos.Partes de esta página han sido adaptadas con permiso del proyecto R4Epis.Consulta la página sobre Transición R para obtener consejos sobre cómo cambiar R desde STATA, SAS o Excel.","code":""},{"path":"r-basics.html","id":"why-use-r","chapter":"3 Fundamentos de R","heading":"3.1 ¿Por qué utilizar R?","text":"Como se indica en el sitio web de R project, éste es un lenguaje de programación y un entorno para la computación estadística y gráficos. Es muy versátil, ampliable y dirigido por la comunidad.CosteEl uso de R es gratuito. Hay una fuerte ética en la comunidad de material libre y de código abierto.ReproducibilidadLa gestión y el análisis de los datos través de un lenguaje de programación (en comparación con Excel u otra herramienta principalmente manual) mejora la reproducibilidad, facilita la detección de errores y alivia la carga de trabajo.ComunidadLa comunidad de usuarios de R es enorme y colaborativa. Cada día se desarrollan nuevos paquetes y herramientas para abordar problemas cotidianos, que son examinados por la comunidad de usuarios. Por ejemplo, R-Ladies es una asociación mundial cuya misión es promover la diversidad de género en la comunidad de R, siendo una de las mayores asociaciones de usuarios de R. Es probable que tengas un grupo cerca.","code":""},{"path":"r-basics.html","id":"key-terms","chapter":"3 Fundamentos de R","heading":"3.2 Términos clave","text":"RStudio - RStudio es una interfaz gráfica de usuario (GUI) para facilitar el uso de R. Lee más en la sección RStudio.Objetos - Todo lo que se almacena en R - conjuntos de datos, variables, una lista de nombres de pueblos, un número total de población, incluso resultados como gráficos - son objetos los que se les asigna un nombre y pueden ser referenciados en comandos posteriores. Lee más en la sección Objetos.Funciones - Una función es una operación de código que acepta entradas y devuelve una salida transformada. Lee más en la sección Funciones.Paquetes - Un paquete de R es un conjunto de funciones que se pueden compartir. Lee más en la sección Paquetes.Scripts - Un script es el archivo de documento que contiene tus comandos. Lee más en la sección Scripts","code":""},{"path":"r-basics.html","id":"learning","chapter":"3 Fundamentos de R","heading":"3.3 Recursos para aprender","text":"","code":""},{"path":"r-basics.html","id":"recursos-en-rstudio","chapter":"3 Fundamentos de R","heading":"Recursos en RStudio","text":"Documentación de ayudaBusca en la pestaña “Help” de RStudio la documentación sobre los paquetes de R y funciones específicas. Esto está dentro del panel que también contiene Archivos, Gráficos y Paquetes (normalmente en el panel inferior derecho). También puedes escribir el nombre de un paquete o función en la consola de R después de un signo de interrogación para abrir la página de ayuda correspondiente. incluyas paréntesis.Por ejemplo: ?filter o ?diagrammeR.Tutoriales interactivosHay varias formas de aprender R de forma interactiva dentro de RStudio.El propio RStudio ofrece un Tutorial que se encuentra en el paquete de R learnr. Simplemente instala este paquete y abre un tutorial través de la nueva pestaña “Tutorial” en el panel superior derecho de RStudio (que también contiene las pestañas Environment e History).El paquete de R swirl ofrece cursos interactivos en la consola de R. Instala y carga este paquete, luego ejecuta el comando swirl() (paréntesis vacío) en la consola de R. Verá que aparecen indicaciones en la consola. Responde escribiendo en la consola. Te guiará través de un curso de tu elección.","code":""},{"path":"r-basics.html","id":"hojas-de-referencia","chapter":"3 Fundamentos de R","heading":"Hojas de referencia","text":"Hay muchas “hojas de referencias o trucos” (Cheatsheets) en PDF disponibles en el sitio web de RStudio, por ejemplo:Factores con el paquete forcatsFechas y horarios con el paquete lubridateCadenas con el paquete stringrOperaciones iterativas con el paquete purrrImportación de datosTransformación de datos con el paquete dplyrR Markdown (para crear documentos como PDF, Word, Powerpoint…)Shiny (para crear aplicaciones web interactivas)Visualización de datos con el paquete ggplot2Cartografía (GIS)Mapas interactivos con el paquete leafletPython con R (paquete reticulate)En este enlace puedes encontrar un recurso en línea, específicamente para los usuarios de Excel","code":""},{"path":"r-basics.html","id":"twitter","chapter":"3 Fundamentos de R","heading":"Twitter","text":"R tiene una vibrante comunidad en Twitter en la que puedes aprender trucos, atajos y noticias: sigue estas cuentas:Síguenos! @epiRhandbookR Function Day @rfuntionaday (Es un recurso increíble)R para ciencia de datos @rstats4dsRStudio @RStudioTrucos de RStudio @rstudiotipsR-Bloggers @RbloggersR-ladies @RLadiesGlobalHadley Wickham @hadleywickhamTambién:#epitwitter y #rstats","code":""},{"path":"r-basics.html","id":"recursos-gratuitos-en-línea","chapter":"3 Fundamentos de R","heading":"Recursos gratuitos en línea","text":"Un texto definitivo es el libro R Data Science de Garrett Grolemund y Hadley WickhamEl sitio web del proyecto R4Epis tiene como objetivo “desarrollar herramientas estandarizadas de limpieza de datos, análisis y elaboración de informes para cubrir los tipos comunes de brotes y estudios realizados en la población en un entorno de respuesta de emergencia de MSF”. Se pueden encontrar materiales de formación sobre los fundamentos de R, plantillas para informes de RMarkdown sobre brotes y encuestas, y tutoriales para ayudar configurarlos.","code":""},{"path":"r-basics.html","id":"idiomas-distintos-del-inglés","chapter":"3 Fundamentos de R","heading":"Idiomas distintos del inglés","text":"Materiales de RStudio en EspañolR Data Science en españolIntroduction à R et au tidyverse (Francais)","code":""},{"path":"r-basics.html","id":"Installation","chapter":"3 Fundamentos de R","heading":"3.4 Instalación","text":"","code":""},{"path":"r-basics.html","id":"r-y-rstudio","chapter":"3 Fundamentos de R","heading":"R y RStudio","text":"Cómo instalar RVisita este sitio web https://www.r-project.org/ y descarga la última versión de R adecuada tu ordenador.Cómo instalar RStudioVisita este sitio web https://rstudio.com/products/rstudio/download/ y descarga la última versión gratuita de RStudio para escritorio adecuada para tu ordenador.Permisos Ten en cuenta que debes instalar R y RStudio en una unidad donde tengas permisos de lectura y escritura. De lo contrario, la capacidad para instalar paquetes de R (algo frecuente) se verá afectada. Si tienes problemas, intenta abrir RStudio con el botón derecho en el icono y seleccionando “Ejecutar como administrador”. Puedes encontrar otros consejos en la página R en unidades de red.Cómo actualizar R y RStudioTu versión de R se muestra al inicio de la consola de R. También puede ejecutar sessionInfo().Para actualizar R, puedes ir al sitio web mencionado anteriormente y vuelva instalar R. También puede utilizar el paquete installr (en Windows) ejecutando installr::updateR(). Esto abrirá cuadros de diálogo para ayudarle descargar la última versión de R y actualizar sus paquetes la nueva versión de R. Puedes encontrar más detalles en la documentación de installr.Ten en cuenta que la versión antigua de R seguirá existiendo en tu ordenador. Puedes ejecutar temporalmente una versión anterior (una “instalación” más antigua) de R clicando en “Herramientas” -> “Opciones globales” en RStudio y eligiendo una versión de R. Esto puede ser útil si quieres utilizar un paquete que ha sido actualizado para funcionar en la versión más reciente de R.Para actualizar RStudio, puede ir la página web anterior y volver descargar RStudio. Otra opción es clicar en “Ayuda” -> “Buscar actualizaciones” dentro de RStudio, pero esto puede mostrar las últimas actualizaciones.Para ver qué versiones de R, RStudio o paquetes se utilizaron cuando se hizo este Manual, consulta la página de Notas técnicas y editoriales.","code":""},{"path":"r-basics.html","id":"otros-programas-que-puedes-necesitar-instalar","chapter":"3 Fundamentos de R","heading":"Otros programas que puedes necesitar instalar","text":"TinyTeX (para compilar un documento RMarkdown en PDF)Pandoc (para compilar documentos RMarkdown)RTools (para construir paquetes para R)phantomjs (para guardar imágenes fijas de redes animadas, como cadenas de transmisión)","code":""},{"path":"r-basics.html","id":"tinytex","chapter":"3 Fundamentos de R","heading":"TinyTex","text":"TinyTex es una distribución LaTeX personalizada, útil cuando se trata de producir PDFs desde R. Ver https://yihui.org/tinytex/ para más información.Para instalar TinyTex desde R:","code":"\ninstall.packages('tinytex')\ntinytex::install_tinytex()\n# para desinstalar TinyTeX, ejecuta tinytex::uninstall_tinytex()"},{"path":"r-basics.html","id":"pandoc","chapter":"3 Fundamentos de R","heading":"Pandoc","text":"Pandoc es un conversor de documentos, un software separado de R. Viene incluido con RStudio y debería ser necesario descargarlo. Ayuda en el proceso de conversión de documentos Rmarkdown formatos como pdf y añade funcionalidades complejas.","code":""},{"path":"r-basics.html","id":"rtools","chapter":"3 Fundamentos de R","heading":"RTools","text":"RTools es una colección de software para construir paquetes para RSe instala desde este sitio web:https://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"r-basics.html","id":"phantomjs","chapter":"3 Fundamentos de R","heading":"phantomjs","text":"Esto se utiliza menudo para hacer “capturas de pantalla” de las páginas web. Por ejemplo, cuando se hace una cadena de transmisión con el paquete epicontacts, se produce un archivo HTML que es interactivo y dinámico. Si deseas una imagen estática, puede ser útil utilizar el paquete [webshot** para automatizar este proceso. Para ello se necesita el programa externo “phantomjs”. Puedes instalar phantomjs través del paquete webshot** con el comando webshot::install_phantomjs().]. Aprende convertir los valores faltantes al importar datos en la página sobre Importación y exportación.","code":""},{"path":"r-basics.html","id":"matemáticos-y-estadísticos","chapter":"3 Fundamentos de R","heading":"Matemáticos y estadísticos","text":"Todos los operadores y funciones de esta página están disponibles automáticamente en R base.","code":""},{"path":"r-basics.html","id":"operadores-matemáticos","chapter":"3 Fundamentos de R","heading":"Operadores matemáticos","text":"Se utilizan menudo para realizar sumas, divisiones, crear nuevas columnas, etc. continuación se muestran los operadores matemáticos más comunes en R. es importante poner espacios alrededor de los operadores.","code":""},{"path":"r-basics.html","id":"funciones-matemáticas","chapter":"3 Fundamentos de R","heading":"Funciones matemáticas","text":"Nota: para round() los dígits = especifican el número de decimales. Utiliza signif() para redondear un número de cifras significativas.","code":""},{"path":"r-basics.html","id":"notación-científica","chapter":"3 Fundamentos de R","heading":"Notación científica","text":"La probabilidad de que se utilice la notación científica depende del valor de la opción scipen.De la documentación de ?options: scipen es una penalización que se aplica cuando se decide obtener valores numéricos en notación fija o exponencial. Los valores positivos se inclinan hacia la notación fija y los negativos hacia la notación científica: se preferirá la notación fija menos que tenga más dígitos que ‘scipen’.Si se establece en un número bajo (por ejemplo, 0) estará “activada” siempre. Para “desactivar” la notación científica en tu sesión de R, configúrela con un número muy alto, por ejemplo:","code":"\n# turn off scientific notation\noptions(scipen=999)"},{"path":"r-basics.html","id":"redondeo","chapter":"3 Fundamentos de R","heading":"Redondeo","text":"PELIGRO: round() utiliza el “redondeo del banquero” que redondea hacia arriba desde un 0,5 sólo si el número superior es par. Utiliza round_half_up() de janitor para redondear consistentemente las mitades hacia arriba al número entero más cercano. Aquí tienes esta explicación","code":"\n# utilizar la función de redondeo adecuada para tu trabajo\nround(c(2.5, 3.5))## [1] 2 4\njanitor::round_half_up(c(2.5, 3.5))## [1] 3 4"},{"path":"r-basics.html","id":"funciones-estadísticas","chapter":"3 Fundamentos de R","heading":"Funciones estadísticas","text":"PRECAUCIÓN: Las funciones que aparecen continuación incluyen por defecto los valores faltantes en los cálculos. Los valores faltantes darán como resultado una salida de NA, menos que se especifique el argumento na.rm = TRUE. Esto se puede escribir de forma abreviada como na.rm = T.Notas:*quantile(): x es el vector numérico examinar, y probs = es un vector numérico con probabilidades entre 0 y 1.0, por ejemplo c(0.5, 0.8, 0.85)*quantile(): x es el vector numérico examinar, y probs = es un vector numérico con probabilidades entre 0 y 1.0, por ejemplo c(0.5, 0.8, 0.85)**summary(): da un resumen estadístico sobre un vector numérico incluyendo la media, mediana y percentiles más comunes**summary(): da un resumen estadístico sobre un vector numérico incluyendo la media, mediana y percentiles más comunesPELIGRO: Si proporciona un vector de números una de las funciones anteriores, asegúrese de envolver los números dentro de c().","code":"\n# Si se suministran números sin procesar a una función, envuélvalos en c()\nmean(1, 6, 12, 10, 5, 0)    # !!! INCORRECTO !!!  ## [1] 1\nmean(c(1, 6, 12, 10, 5, 0)) # CORRECTO## [1] 5.666667"},{"path":"r-basics.html","id":"otras-funciones-útiles","chapter":"3 Fundamentos de R","heading":"Otras funciones útiles","text":"","code":""},{"path":"r-basics.html","id":"in","chapter":"3 Fundamentos de R","heading":"%in%","text":"Un operador muy útil para comparar valores, y para evaluar rápidamente si un valor está dentro de un vector o dataframe.Para preguntar si un valor está %% en un vector, pon un signo de exclamación (!) delante de la declaración lógica:%% es muy útil cuando se utiliza la función case_when() de dplyr. Se puede definir un vector previamente y referenciarlo después. Por ejemplo:Nota: Si quieres detectar una cadena parcial, quizás usando str_detect() de stringr, aceptará un vector de caracteres como c(\"1\", \"Yes\", \"yes\", \"y\"). En su lugar, se le debe dar una expresión regular - una cadena condensada con barras , como “1|Yes|yes|y”. Por ejemplo, str_detect(hospitalized, \"1|Yes|yes|y\"). Consulta la página sobre Caracteres y cadenas para obtener más información.Puedes convertir un vector de caracteres en una expresión regular con este comando:","code":"\nmy_vector <- c(\"a\", \"b\", \"c\", \"d\")\n\"a\" %in% my_vector## [1] TRUE\n\"h\" %in% my_vector## [1] FALSE\n# para negar, pon una exclamación delante\n!\"a\" %in% my_vector## [1] FALSE\n!\"h\" %in% my_vector## [1] TRUE\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\n\nlinelist <- linelist %>% \n  mutate(child_hospitaled = case_when(\n    hospitalized %in% affirmative & age < 18 ~ \"Hospitalized Child\",\n    TRUE                                      ~ \"Not\"))\naffirmative <- c(\"1\", \"Yes\", \"YES\", \"yes\", \"y\", \"Y\", \"oui\", \"Oui\", \"Si\")\naffirmative## [1] \"1\"   \"Yes\" \"YES\" \"yes\" \"y\"   \"Y\"   \"oui\" \"Oui\" \"Si\"\n# condense to \naffirmative_str_search <- paste0(affirmative, collapse = \"|\")  # option with base R\naffirmative_str_search <- str_c(affirmative, collapse = \"|\")   # option with stringr package\n\naffirmative_str_search## [1] \"1|Yes|YES|yes|y|Y|oui|Oui|Si\""},{"path":"r-basics.html","id":"errors-warnings","chapter":"3 Fundamentos de R","heading":"3.5 Errores & avisos","text":"En esta sección se explica:La diferencia entre errores y avisos (warnings)Consejos generales de sintaxis para escribir código RCódigo de asistenciaEn las página de Errores comunes y de Obtener ayuda se pueden encontrar los errores y avisos más comunes, así como consejos para la resolución de problemas.","code":""},{"path":"r-basics.html","id":"error-vs-aviso","chapter":"3 Fundamentos de R","heading":"Error vs aviso","text":"Cuando se ejecuta un comando, la Consola de R puede mostrarte mensajes de aviso o error en texto rojo.Una aviso significa que R ha completado su comando, pero ha tenido que dar pasos adicionales o ha producido una salida inusual de la que deberías estar al tanto.Una aviso significa que R ha completado su comando, pero ha tenido que dar pasos adicionales o ha producido una salida inusual de la que deberías estar al tanto.Un error significa que R pudo completar su comando.Un error significa que R pudo completar su comando.Busca pistas:El mensaje de error/advertencia suele incluir un número de línea donde está el problema.El mensaje de error/advertencia suele incluir un número de línea donde está el problema.Si un objeto “es desconocido” o “se encuentra”, quizás lo hayas escrito mal, hayas olvidado llamar un paquete con library(), o hayas olvidado volver ejecutar tu script después de hacer cambios.Si un objeto “es desconocido” o “se encuentra”, quizás lo hayas escrito mal, hayas olvidado llamar un paquete con library(), o hayas olvidado volver ejecutar tu script después de hacer cambios.Si todo lo demás falla, copia el mensaje de error en Google junto con algunos términos clave; lo más probable es que alguien le haya pasado lo mismo y ¡ya haya resuelto el problema!.","code":""},{"path":"r-basics.html","id":"consejos-generales-de-sintaxis","chapter":"3 Fundamentos de R","heading":"Consejos generales de sintaxis","text":"Algunas cosas que hay que recordar al escribir comandos en R, para evitar errores y advertencias:Cierra siempre los paréntesis - consejo: cuenta el número de paréntesis de apertura “(” y de cierre “)” de cada trozo de códigoEvita los espacios en los nombres de columnas y objetos. Utiliza barras bajas ( _ ) o puntos ( . ) en su lugarNo olvides separar los argumentos de una función con comasR distingue entre mayúsculas y minúsculas, lo que significa que Variable_A es diferente de variable_A","code":""},{"path":"r-basics.html","id":"código-de-asistencia","chapter":"3 Fundamentos de R","heading":"Código de asistencia","text":"Cualquier script (RMarkdown o de otro tipo) te dará pistas cuando hayas cometido un error. Por ejemplo, si te olvidaste de escribir una coma donde se necesita, o de cerrar un paréntesis, RStudio levantará una bandera en esa línea, la derecha del script, para avisarte.","code":""},{"path":"transition-to-r.html","id":"transition-to-r","chapter":"4 Transición a R","heading":"4 Transición a R","text":"continuación, te ofrecemos algunos consejos y recursos que resultan útiles si te estás pasando R.R se introdujo finales de la década de 1990 y desde entonces su alcance ha crecido de forma espectacular. Sus capacidades son tan amplias que las alternativas comerciales han reaccionado los desarrollos de R para seguir siendo competitivas. (lee este artículo que compara R, SPSS, SAS, STATA y Python).Además, R es mucho más fácil de aprender que hace 10 años. Antes, R tenía fama de ser difícil para los principiantes. Ahora es mucho más fácil, con interfaces de usuario amigables como RStudio, código intuitivo como tidyverse, y muchos recursos tutoriales.¡te dejes intimidar, ven descubrir el mundo de R!","code":""},{"path":"transition-to-r.html","id":"from-excel","chapter":"4 Transición a R","heading":"4.1 Desde Excel","text":"La transición de Excel directamente R es un objetivo muy alcanzable. Puede parecer desalentador, ¡pero puedes hacerlo!Es cierto que alguien con grandes conocimientos de Excel puede realizar actividades muy avanzadas sólo con Excel, incluso utilizando herramientas de scripting como VBA. Excel se utiliza en todo el mundo y es una herramienta esencial para la epidemiología. Sin embargo, complementarlo con R puede mejorar y ampliar drásticamente tus flujos de trabajo.","code":""},{"path":"transition-to-r.html","id":"beneficios","chapter":"4 Transición a R","heading":"Beneficios","text":"Descubrirás que el uso de R ofrece inmensos beneficios en cuanto ahorro de tiempo, análisis más consistentes y precisos, reproducibilidad, posibilidad de compartir y una corrección de errores más rápida. Como cualquier software nuevo, hay una “curva de aprendizaje” en la que hay que invertir tiempo para familiarizarse. Los dividendos serán significativos y se te abrirá un inmenso abanico de nuevas posibilidades con R.Excel es un software muy conocido que permite que un principiante pueda realizar análisis y visualizaciones simples con “apuntar y clicar” de manera sencilla. En comparación, puede llevar un par de semanas sentirse cómodo con las funciones y la interfaz de R. Sin embargo, R ha evolucionado en los últimos años para ser mucho más amigable con los principiantes.Muchos flujos de trabajo de Excel se basan en la memoria y en la repetición, por lo que hay muchas posibilidades de error. Además, generalmente la limpieza de datos, la metodología de análisis y las ecuaciones utilizadas están ocultas la vista. un nuevo colega le puede llevar mucho tiempo aprender lo que hace un libro de Excel y cómo resolver problemas que surjan. Con R, todos los pasos se escriben explícitamente en el script y pueden verse, editarse, corregirse y aplicarse fácilmente otros conjuntos de datos.Para comenzar tu transición de Excel R debes ajustar tu mentalidad en algunos aspectos importantes:","code":""},{"path":"transition-to-r.html","id":"datos-ordenados-tidy-data","chapter":"4 Transición a R","heading":"Datos ordenados (tidy data)","text":"Debes utilizar datos “ordenados” (tidy), legibles por la máquina en lugar de datos desordenados “legibles por el ser humano”. Estos son los tres requisitos principales que los datos “ordenados” deben cumplir, como se explica en este tutorial sobre datos “ordenados” en R:Cada variable debe tener su propia columnaCada observación debe tener su propia filaCada valor debe tener su propia celdaPara los usuarios de Excel: piensa en el papel que desempeñan las “tablas” de Excel para estandarizar los datos y hacer que el formato sea más predecible.Un ejemplo de datos “ordenados” sería el listado de casos utilizado en este manual: cada variable está contenida en una columna, cada observación (un caso) tiene su propia fila y cada valor está en una sola celda. continuación, puede ver las primeras 50 filas del listado:La principal razón por la que nos encontramos con datos ordenados es porque muchas hojas de cálculo en Excel están diseñadas para dar prioridad la lectura fácil por parte de los humanos, la lectura fácil por parte de las máquinas/el software.Para ayudarte ver la diferencia, continuación se presentan algunos ejemplos ficticios de datos ordenados, los cuales dan prioridad la legibilidad humana sobre la legibilidad-mecánica:Problemas: En la hoja de cálculo de arriba, hay celdas combinadas que son fácilmente digeridas por R. está claro qué fila debe utilizarse para la “cabecera”. la derecha hay un diccionario basado en colores y los valores de las celdas están representados por colores, lo que tampoco es fácilmente interpretado por R (¡ni por los humanos que padecen daltonismo!). Además, se combinan diferentes informaciones en una celda (varias organizaciones asociadas que trabajan en un área, o el estado “TBC” en la misma celda que “Partner D”).Problemas:* En la hoja de cálculo anterior, hay numerosas filas y columnas vacías adicionales dentro de los datos, lo que provocará dolores de cabeza la hora de limpiarlos con R. Además, las coordenadas GPS están repartidas en dos filas para un centro de tratamiento determinado. Y, una nota adicional, ¡las coordenadas GPS están en dos formatos diferentes!Los datos “ordenados” pueden ser tan legibles para el ojo humano, pero facilitan mucho la limpieza y el análisis de los datos. Los datos ordenados pueden almacenarse en varios formatos, por ejemplo, “largos” o “anchos” (véase la página sobre Pivotar datos), pero se siguen observando los principios anteriores.","code":""},{"path":"transition-to-r.html","id":"funciones","chapter":"4 Transición a R","heading":"Funciones","text":"Puede que la palabra “función” en R sea nueva, pero el concepto existe también en Excel y se le conoce como fórmulas. Las fórmulas en Excel también requieren una sintaxis precisa (por ejemplo, la colocación de puntos y comas y paréntesis). Lo único que hay que hacer es aprender algunas funciones nuevas y cómo funcionan en R.","code":""},{"path":"transition-to-r.html","id":"scripts","chapter":"4 Transición a R","heading":"Scripts","text":"En lugar de clicar en los botones y arrastrar las celdas, escribirás cada paso y procedimiento en un “script” (secuencia de órdenes). Los usuarios de Excel pueden estar familiarizados con las “macros VBA”, que también emplean un enfoque de scripting (secuencia de comandos VBA).El script de R consiste en instrucciones paso paso. Esto permite que cualquier colega pueda leer el script y ver fácilmente los pasos que dado. Esto también ayuda depurar errores o cálculos inexactos. Consulta la sección sobre scripts del capítulo Fundamentos de R para ver algunos ejemplos.Este es un ejemplo de un script en R:","code":""},{"path":"transition-to-r.html","id":"recursos-en-la-migración-excel-a-r","chapter":"4 Transición a R","heading":"Recursos en la migración Excel a R","text":"Aquí hay algunos enlaces tutoriales que te ayudarán en la transición R desde Excel:R vs. ExcelR vs. ExcelCurso de RStudio en R para usuarios de ExcelCurso de RStudio en R para usuarios de Excel","code":""},{"path":"transition-to-r.html","id":"interacción-r-excel","chapter":"4 Transición a R","heading":"Interacción R-Excel","text":"R tiene formas robustas de importar libros de Excel, trabajar con los datos, exportar/guardar archivos de Excel y trabajar con los detalles de las hojas de Excel.Es cierto que algunos de los formatos más estéticos de Excel pueden perderse en la traducción (por ejemplo, la cursiva, el texto lateral, etc.). Si tu flujo de trabajo requiere que pases documentos de un lado otro entre R y Excel conservando el formato original de Excel, prueba paquetes como openxlsx.","code":""},{"path":"transition-to-r.html","id":"from-stata","chapter":"4 Transición a R","heading":"4.2 Desde Stata","text":"Llegando R desde StataA muchas personas en el campo de la epidemiología se les enseña primero usar Stata, y puede parecer desalentador pasar R. Sin embargo, si eres un usuario habitual de Stata, el salto R es ciertamente más manejable de lo que podrías pensar. Si bien hay algunas diferencias clave entre Stata y R en la forma en que se pueden crear y modificar los datos, así como en la forma en que se implementan las funciones de análisis - después de aprender estas diferencias clave serás capaz de adaptar tus habilidades.continuación, se presentan algunas traducciones clave entre Stata y R, que pueden ser útiles mientras revisas esta guía.Notas generalesDirectorio de trabajoImportación y visualización de datosManipulación básica de datosAnálisis descriptivoAunque esta lista ofrece una visión general de los fundamentos de la traducción de los comandos de Stata R, es exhaustiva. Hay muchos otros grandes recursos para los usuarios de Stata que podrían ser de interés en tu transición R:https://dss.princeton.edu/training/RStata.pdfhttps://clanfear.github.io/Stata_R_Equivalency/docs/r_stata_commands.htmlhttp://r4stats.com/books/r4stata/","code":""},{"path":"transition-to-r.html","id":"from-stata","chapter":"4 Transición a R","heading":"4.3 Desde SAS","text":"Pasar de SAS RSAS se utiliza habitualmente en las agencias de salud pública y en los campos de investigación académica. Aunque la transición un nuevo lenguaje suele ser un proceso sencillo, entender las diferencias clave entre SAS y R puede ayudarte empezar navegar por el nuevo lenguaje utilizando el lenguaje de partida. continuación se describen las principales traducciones en materia de gestión de datos y análisis descriptivo entre SAS y R.Notas generalesDirectorio de trabajoImportación y visualización de datosManipulación básica de datosAnálisis descriptivoAlgunos recursos útiles:R SAS SPSS Users (2011)SAS R, Second Edition (2014)","code":""},{"path":"transition-to-r.html","id":"from-stata","chapter":"4 Transición a R","heading":"4.4 Interoperabilidad de los datos","text":"Consulta la página de importación y exportación para obtener detalles sobre cómo el paquete rio puede importar y exportar los archivos .dta de STATA, los archivos .xpt y .sas7bdat de SAS, los archivos .por y .sav de SPSS, y muchos otros.","code":""},{"path":"suggested-packages-1.html","id":"suggested-packages-1","chapter":"5 Paquetes recomendados","heading":"5 Paquetes recomendados","text":"continuación se muestra lista de paquetes de R de utilidad para la realización de tareas frecuentes en epidemiología. Puedes copiar este código, ejecutarlo, y todos estos paquetes se instalarán desde CRAN y se cargarán para su uso en la sesión actual de R. Si un paquete ya está instalado, únicamente se cargará.Puedes modificar el código con símbolos # para excluir los paquetes que desees instalar.tener en cuenta:Instala primero el paquete pacman antes de ejecutar el código. Puedes hacerlo con install.packages(\"pacman\"). En este manual hacemos hincapié en p_load() de pacman, que instala el paquete si es necesario y lo carga para utilizarlo en la sesión actual de R. También puedes cargar paquetes ya instalados con library() de R base.Instala primero el paquete pacman antes de ejecutar el código. Puedes hacerlo con install.packages(\"pacman\"). En este manual hacemos hincapié en p_load() de pacman, que instala el paquete si es necesario y lo carga para utilizarlo en la sesión actual de R. También puedes cargar paquetes ya instalados con library() de R base.En el código siguiente, los paquetes que se incluyen al instalar/cargar otro paquete se indican con una sangría y un hash (#). Por ejemplo, ggplot2 aparece bajo tidyverse en forma de comentario.En el código siguiente, los paquetes que se incluyen al instalar/cargar otro paquete se indican con una sangría y un hash (#). Por ejemplo, ggplot2 aparece bajo tidyverse en forma de comentario.Si varios paquetes tienen funciones con el mismo nombre, puede ocurrir enmascaramiento cuando la función del paquete cargado más recientemente tiene prioridad. Lee más en la página de Fundamentos de R. Puedes gestionar estos conflictos con el paquete conflicted .Si varios paquetes tienen funciones con el mismo nombre, puede ocurrir enmascaramiento cuando la función del paquete cargado más recientemente tiene prioridad. Lee más en la página de Fundamentos de R. Puedes gestionar estos conflictos con el paquete conflicted .Consulta la sección de Fundamentos de R sobre paquetes para obtener más información sobre pacman y el enmascaramiento.Consulta la sección de Fundamentos de R sobre paquetes para obtener más información sobre pacman y el enmascaramiento.Para ver las versiones de R, RStudio y los paquetes de R utilizados durante la producción de este manual, consulta la página de notas editoriales y técnicas.","code":""},{"path":"suggested-packages-1.html","id":"packages-from-cran","chapter":"5 Paquetes recomendados","heading":"5.1 Paquetes desde CRAN","text":"","code":"\n######################################################\n# Listado de paquetes útiles para epidemiología en R #\n######################################################\n\n# Este código usa la función p_load() del paquete \"pacman\", \n# la cual instala el paquete si todavía no está instalado y en caso de no ser necesaria la instalación, procede a cargar el paquete. \n\n\n# Asegúrate que el paquete \"pacman\" está instalado\nif (!require(\"pacman\")) install.packages(\"pacman\")\n\n\n# Paquetes disponibles desde CRAN\n#################################\npacman::p_load(\n     \n     # Aprendiendo R\n     ###############\n     learnr,   # tutoriales interactivos en tu panel de R Studio\n     swirl,    # tutoriales interactivos en tu consola de R\n        \n     # Manejo de archivos y proyecto \n     ###############################\n     here,     # describir ruta de archivo dentro de la carpeta principal del proyecto\n     rio,      # importación/exportación de múltiples tipos de datos\n     openxlsx, # importación/exportación de libros con múltiples hojas de excel\n     \n     # Manejo e instalación de paquetes\n     ##################################\n     pacman,   # instalación/carga de paquetes\n     renv,     # manejo de versiones de paquetes para trabajar con grupos colaborativos.\n     remotes,  # instalación de paquetes desde github\n     \n     # Manejo general de datos\n     #########################\n     tidyverse,    # incluye múltiples paquetes para el tratamiento de datos en formato tidy y presentación de los mismos.\n          #dplyr,      # manejo de datos\n          #tidyr,      # manejo de datos\n          #ggplot2,    # visualización de datos\n          #stringr,    # trabajo con cadenas y caracteres\n          #forcats,    # trabajo con factores\n          #lubridate,  # trabajo con fechas\n          #purrr       # iteraciones y trabajo con listas\n     linelist,     # limpiar linelists\n     naniar,       # trabajo con valores perdidos\n     \n     # Estadística  \n     ############\n     janitor,      # tablas y limpieza de datos\n     gtsummary,    # hacer tablas descriptivas con valores estadísticos\n     rstatix,      # realización rápida de test estadísticos y tablas descriptivas\n     broom,        # pasar a formato tidy los resultados de las regresiones\n     lmtest,       # realizar test de likelihood-ratio\n     easystats,\n          # parameters, # alternativa para pasar a formato tidy los resultados de las regresiones \n          # see,        # alternativa para visualizar forest plots \n     \n     # Realización de modelos epidémicos\n     ###################################\n     epicontacts,  # analizar cadenas de transmisión\n     EpiNow2,      # estimación de Rt \n     EpiEstim,     # estimación de Rt\n     projections,  # proyecciones de incidencia\n     incidence2,   # hacer curvas epidémicas y manejar datos de incidencia\n     i2extras,     # Funciones extra para el paquete incidence2 \n     epitrix,      # funciones útiles para epidemiología\n     distcrete,    # Distribuciones discretas de demora o retardo\n     \n     # plots - general\n     #################\n     #ggplot2,         # incluido en tidyverse\n     cowplot,          # combinar plots  \n     # patchwork,      # alternativa para combinar plots    \n     RColorBrewer,     # escalas de color\n     ggnewscale,       # para añadir capas de color adicionales\n     \n     # plots - tipos específicos\n     ########################\n     DiagrammeR,       # diagramas empleando lenguaje DOT\n     incidence2,       # curvas epidémicas\n     gghighlight,      # destacar un subgrupo\n     ggrepel,          # etiquetas inteligentes (smart labels)\n     plotly,           # gráficos interactivos\n     gganimate,        # gráficos animados\n\n     \n     # gis\n     ######\n     sf,               # manejo de datos espaciales usando el formato Simple Features\n     tmap,             # producción sencilla de mapas, tanto estáticos como interactivos\n     OpenStreetMap,    # añadir una base con un mapa de OSM a un mapa en ggplot\n     spdep,            # estadística espacial\n     \n     # reportes rutinarios\n     #################\n     rmarkdown,        # producción de archivos PDF, Word, Powerpoint y HTML\n     reportfactory,    # auto-organización de los trabajos realizados en R Markdown \n     officer,          # powerpoints\n     \n     # dashboards\n     ############\n     flexdashboard,    # convierte código de R Markdown en un dashboard\n     shiny,            # aplicaciones web interactivas\n     \n     # tablas for para presentaciones\n     #########################\n     knitr,            # generación de reportes y tablas HTML con R Markdown \n     flextable,        # tablas HTML tables\n     #DT,              # tablas HTML (alternativa)\n     #gt,              # tablas HTML (alternativa)\n     #huxtable,        # tablas HTML (alternativa) \n     \n     # filogenética\n     ###############\n     ggtree,           # visualización and anotación de árboles\n     ape,              # análisis de filogenética y evolución\n     treeio            # visualización de archivos filogenéticos\n \n)"},{"path":"suggested-packages-1.html","id":"packages-from-github","chapter":"5 Paquetes recomendados","heading":"5.2 Paquetes desde Github","text":"continuación se muestran los comandos para instalar dos paquetes directamente desde los repositorios de Github.La versión de desarrollo de epicontacts tiene la capacidad de hacer árboles de transmisión con un eje temporal-xLa versión de desarrollo de epicontacts tiene la capacidad de hacer árboles de transmisión con un eje temporal-xEl paquete epirhandbook contiene todos los datos de ejemplo de este manual y puede utilizarse para descargar la versión sin conexión del manual.El paquete epirhandbook contiene todos los datos de ejemplo de este manual y puede utilizarse para descargar la versión sin conexión del manual.","code":"\n# Paquetes para descargar desde Github (no disponibles en CRAN)\n##########################################################\n\n# Version en desarrollo de epicontacts (para cadenas de transmisión con eje temporal en el eje x)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")\n\n# El paquete de este manual, el cual incluye todos los datos empleados en los ejemplos \npacman::p_install_gh(\"appliedepi/epirhandbook\")"},{"path":"r-projects.html","id":"r-projects","chapter":"6 Proyectos en R","heading":"6 Proyectos en R","text":"Un proyecto de R permite agrupar tu trabajo en una carpeta que contiene todos los archivos vínculados al mismo, facilitando su manejo. Dentro del proyecto, todos los scripts relevantes, los archivos de datos, las figuras/resultados y el historial se almacenan en subcarpetas y, lo que es más importante, el directorio de trabajo de dicho proyecto constituye la carpeta raíz del mismo.","code":""},{"path":"r-projects.html","id":"suggested-use","chapter":"6 Proyectos en R","heading":"6.1 Uso sugerido","text":"Una forma común, eficiente y sencilla de utilizar R es combinar 3 elementos. Un proyecto de trabajo concreto se aloja dentro de un proyecto R. Cada uno de los tres elementos anteriores se describe continuación.Un proyecto en RUn entorno de trabajo autónomo con carpetas para datos, scripts, salidas (outputs), etcEl paquete , el cual se utiliza para indicar las rutas relativas de los archivosLas rutas de los archivos se escriben en relación con la ubicación de la carpeta raíz del proyecto R - véase Importar y exportar para más informaciónEl paquete rio para importar/exportar -import() y export() manejan cualquier tipo de archivo por su extensión (por ejemplo, .csv, .xlsx, .png)","code":""},{"path":"r-projects.html","id":"creating-an-r-project","chapter":"6 Proyectos en R","heading":"6.2 Creación de un proyecto R","text":"Para crear un proyecto R, selecciona “New proyect” en el menú File (Archivo).Si quieres crear una nueva carpeta para el proyecto, selecciona “New directory” e indica dónde quieres crear la carpeta.Si deseas crear el proyecto dentro de una carpeta existente, cliquea en “Existing Directory” e indica la carpeta.Si quieres clonar un repositorio de Github, selecciona la tercera opción “Version Control” y luego “Git”. Consulta la página Control de versiones y colaboración con Git y Github para más detalles.El proyecto R que creado estará en una carpeta que contiene un archivo .Rproj. Este archivo es un acceso directo y probablemente la forma más directa de abrir tu proyecto. También puedes abrir un proyecto seleccionando “Open Project” en el menú File. Alternativamente, en el extremo superior derecho de RStudio verás un icono de R projects y un menú desplegable de proyectos disponibles.Para salir de un proyecto R, abre un nuevo proyecto o cierra el proyecto actual (Archivo - Cerrar proyecto).","code":""},{"path":"r-projects.html","id":"cambiar-de-proyecto","chapter":"6 Proyectos en R","heading":"Cambiar de proyecto","text":"Para cambiar entre proyectos, clica en el icono de R projects en el menú desplegable en la parte superior derecha de RStudio. Verás las opciones de Cerrar proyecto, Abrir proyecto y una lista de proyectos recientes.","code":""},{"path":"r-projects.html","id":"ajustes","chapter":"6 Proyectos en R","heading":"Ajustes","text":"Generalmente se aconseja que inicies RStudio cada vez con una “pizarra limpia” - es decir, con tu espacio de trabajo arrastrado de la sesión anterior. Esto significará que los objetos y resultados de una sesión persistirán en la siguiente sesión (deberás volver crearlos al ejecutar tus scripts). Esto es bueno, porque te obligará escribir mejores scripts y evitar errores largo plazo.Para configurar RStudio para que haga “borrón y cuenta nueva” cada vez que se inicie:Selecciona “Project Options” en el menú Tools (Herramientas).Selecciona “Project Options” en el menú Tools (Herramientas).En la pestaña “General”, configura RStudio para que restaure .RData en el espacio de trabajo al iniciar, y para que guarde el espacio de trabajo en .RData al salir.En la pestaña “General”, configura RStudio para que restaure .RData en el espacio de trabajo al iniciar, y para que guarde el espacio de trabajo en .RData al salir.","code":""},{"path":"r-projects.html","id":"organización","chapter":"6 Proyectos en R","heading":"Organización","text":"Es habitual tener subcarpetas en tu proyecto. Piensa en tener carpetas como “datos”, “scripts”, “figuras” y “presentaciones”. Puedes añadir carpetas de la forma típica en que añadirías una nueva carpeta en tu ordenador. Alternativamente, puedes ver en la página sobre interacciones con directorios para aprender crear nuevas carpetas con los comandos de R.","code":""},{"path":"r-projects.html","id":"control-de-versiones","chapter":"6 Proyectos en R","heading":"Control de versiones","text":"Considera utilizar un sistema de control de versiones. Podría ser algo tan simple como tener fechas en los nombres de los scripts (por ejemplo, “transmission_analysis_2020-10-03.R”) y una carpeta de “archivado”. También es buena idea tener un texto de cabecera agregando al comienzo de cada script una descripción, etiquetas, autores y un registro de cambios.Un método más complicado implicaría utilizar Github o una plataforma similar para el control de versiones. Consulta la página sobre Control de versiones y colaboración con Git y Github.Un consejo es que puedes realizas búsquedas en todo un proyecto o carpeta utilizando la herramienta “Buscar en archivos” (menú Edición). Puedes buscar e incluso reemplazar líneas de script en varios archivos.","code":""},{"path":"r-projects.html","id":"examples","chapter":"6 Proyectos en R","heading":"6.3 Ejemplos","text":"continuación se muestran algunos ejemplos de importación/exportación/guardado utilizando () desde un proyecto R. Lea más sobre el uso del paquete en la página de importación y exportación.Importación de linelist_raw.xlsx desde la carpeta “data” de tu proyecto RExportar linelist de objetos de R como “my_linelist.rds” la carpeta “clean” dentro de la carpeta “data” de tu proyecto R.Guardando el último gráfico creado como “epicurve_2021-02-15.png” dentro de la carpeta “epicurves” en la carpeta “outputs” de tu proyecto R.","code":"\nlinelist <- import(here(\"data\", \"linelist_raw.xlsx\"))\nexport(linelist, here(\"data\",\"clean\", \"my_linelist.rds\"))\nggsave(here(\"outputs\", \"epicurves\", \"epicurve_2021-02-15.png\"))"},{"path":"r-projects.html","id":"resources","chapter":"6 Proyectos en R","heading":"6.4 Recursos","text":"Página web de RStudio sobre uso de proyectos R","code":""},{"path":"import-and-export.html","id":"import-and-export","chapter":"7 Importación y exportación","heading":"7 Importación y exportación","text":"En esta página describimos las formas de localizar, importar y exportar\narchivos:Uso del paquete rio y las funciones import() y export() para importar muchos tipos de archivos.Uso del paquete rio y las funciones import() y export() para importar muchos tipos de archivos.Uso del paquete para localizar archivos relativos la raíz de un proyecto R - para evitar complicaciones de las rutas de los archivos que son específicas de un ordenadorUso del paquete para localizar archivos relativos la raíz de un proyecto R - para evitar complicaciones de las rutas de los archivos que son específicas de un ordenadorEscenarios específicos de importación, como:Escenarios específicos de importación, como:Hojas de ExcelHojas de ExcelEncabezados desordenados y filas que se saltan/son omitidasEncabezados desordenados y filas que se saltan/son omitidasDesde las hojas de GoogleDesde las hojas de GoogleA partir de datos publicados en sitios webA partir de datos publicados en sitios webCon las APICon las APIImportar el archivo más recienteImportar el archivo más recienteIntroducción manual de datosIntroducción manual de datosTipos de archivos específicos de R, como RDS y RDataTipos de archivos específicos de R, como RDS y RDataExportar/guardar archivos y gráficosExportar/guardar archivos y gráficos","code":""},{"path":"import-and-export.html","id":"overview","chapter":"7 Importación y exportación","heading":"7.1 Resumen","text":"Cuando importas unos “datos” en R, generalmente estás creando un nuevo objeto data frame en tu entorno de R y definiéndolo como un archivo importado (por ejemplo, Excel, CSV, TSV, RDS) que será guardado en tu disco en una determinada ruta/dirección.Puedes importar/exportar muchos tipos de archivos, incluidos los creados por otros programas estadísticos (SAS, STATA, SPSS). También puedes conectarte bases de datos relacionales.R tiene incluso sus propios formatos de datos:Un archivo RDS (.rds) almacena un único objeto R, como un dataframe. Son útiles para almacenar datos limpios, ya que mantienen los tipos de columnas de R. Lee más en esta sección.Un archivo RData (.Rdata) puede utilizarse para almacenar múltiples objetos, o incluso un espacio de trabajo R completo. Lee más en esta sección.","code":""},{"path":"import-and-export.html","id":"the-rio-package","chapter":"7 Importación y exportación","heading":"7.2 El paquete rio","text":"El paquete de R que recomendamos es: rio. El nombre “rio” es una abreviatura de “R /O” (input/output).Sus funciones import() y export() pueden manejar muchos tipos de archivos diferentes (por ejemplo, .xlsx, .csv, .rds, .tsv). Cuando se proporciona una ruta de archivo cualquiera de estas funciones (incluyendo la extensión del archivo como “.csv”), rio leerá la extensión y utilizará la herramienta correcta para importar o exportar el archivo.La alternativa al uso de rio es utilizar funciones de muchos otros paquetes, cada uno de los cuales es específico para un tipo de archivo. Por ejemplo, read.csv() (R base), read.xlsx() (paquete openxlsx), y write_csv() (paquete readr), etc. Estas alternativas pueden ser difíciles de recordar, mientras que usar import() y export() de rio es fácil.Las funciones import() y export() de rio utilizan el paquete y la función adecuados para un archivo determinado, basándose en su extensión. Al final de esta página puedes ver una tabla completa de los paquetes/funciones que utiliza rio en segundo plano. También puede utilizarse para importar archivos de STATA, SAS y SPSS, entre otras docenas de tipos de archivos.La importación/exportación de shapefiles requiere otros paquetes, como se detalla en la página sobre Conceptos básicos de los SIG (Sistemas de Información Geográfica).","code":""},{"path":"import-and-export.html","id":"here","chapter":"7 Importación y exportación","heading":"7.3 El paquete here","text":"El paquete y su función () facilitan la tarea de decirle R dónde encontrar y guardar tus archivos - en esencia, construye rutas de archivos.Utilizado junto con un proyecto R, te permite describir la ubicación de los archivos en tu proyecto R en relación con el directorio raíz de los proyectos de R (la carpeta de nivel superior). Esto es útil cuando el proyecto R puede ser compartido o accedido por múltiples personas/ordenadores. Evita las complicaciones debidas las rutas de archivos únicas en diferentes ordenadores (por ejemplo, \"C:/Users/Laura/Documents...\" al “comenzar” la ruta de archivos en un lugar común todos los usuarios (la raíz del proyecto R).Así es como funciona () dentro de un proyecto R:Cuando, dentro del proyecto R, se carga por primera vez el paquete , se coloca un pequeño archivo llamado “.” en la carpeta raíz de tu proyecto R como un “punto de referencia” o “ancla”Cuando, dentro del proyecto R, se carga por primera vez el paquete , se coloca un pequeño archivo llamado “.” en la carpeta raíz de tu proyecto R como un “punto de referencia” o “ancla”En tus scripts, para referenciar un archivo en las subcarpetas del proyecto R, se utiliza la función () para construir la ruta del archivo en relación con ese anclaEn tus scripts, para referenciar un archivo en las subcarpetas del proyecto R, se utiliza la función () para construir la ruta del archivo en relación con ese anclaPara construir la ruta de los archivos, escribe los nombres de las carpetas más allá de la raíz, entre comillas, separados por comas, y finalmente termina con el nombre y la extensión del archivo, como se muestra continuaciónPara construir la ruta de los archivos, escribe los nombres de las carpetas más allá de la raíz, entre comillas, separados por comas, y finalmente termina con el nombre y la extensión del archivo, como se muestra continuaciónLas rutas de () pueden utilizarse tanto para la importación como para la exportaciónLas rutas de () pueden utilizarse tanto para la importación como para la exportaciónPor ejemplo, continuación, la función import() recibe una ruta de archivo construida con ().El comando (\"data\", \"linelists\", \"ebola_linelist.xlsx\") en realidad está proporcionando la ruta completa del archivo que es única para el ordenador del usuario:Lo bueno es que el comando () puede ejecutarse en cualquier ordenador que acceda al proyecto R.CONSEJO: Si estás seguro de dónde está la raíz “.”, ejecuta la función () con los paréntesis vacíos.Lee más sobre el paquete en este enlace.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))\"C:/Users/Laura/Documents/my_R_project/data/linelists/ebola_linelist.xlsx\""},{"path":"import-and-export.html","id":"file-paths","chapter":"7 Importación y exportación","heading":"7.4 Rutas de los archivos","text":"Al importar o exportar datos, debes proporcionar una ruta de archivo. Puedes hacerlo de tres maneras:Recomendado: proporcionar una ruta de archivo “relativa” con el paquete hereProporcionar la ruta “completa” / “absoluta” del archivoSeleccionar manualmente los archivos","code":""},{"path":"import-and-export.html","id":"rutas-de-archivos-relativas","chapter":"7 Importación y exportación","heading":"Rutas de archivos “relativas”","text":"En R, las rutas de archivo “relativas” consisten en la ruta de archivo relativa la raíz de un proyecto R. Permiten rutas de archivo más simples que pueden funcionar en diferentes ordenadores (por ejemplo, si el proyecto R está en una unidad compartida o se envía por correo electrónico). Como se ha descrito anteriormente las rutas de archivo relativas se facilitan mediante el uso del paquete .continuación se muestra un ejemplo de una ruta de archivo relativa construida con (). Suponemos que el trabajo está en un proyecto R que contiene una subcarpeta “data” y dentro de ella una subcarpeta “linelists”, en la que está el archivo .xlsx de interés.","code":"\nlinelist <- import(here(\"data\", \"linelists\", \"ebola_linelist.xlsx\"))"},{"path":"import-and-export.html","id":"rutas-absolutas","chapter":"7 Importación y exportación","heading":"Rutas “absolutas”","text":"Las rutas absolutas o “completas” de los archivos pueden proporcionarse funciones como import(), pero son “frágiles”, ya que son únicas para el ordenador específico del usuario y, por tanto, se recomiendan.continuación se muestra un ejemplo de ruta absoluta de archivos, donde en el ordenador de Laura hay una carpeta “analysis”, una subcarpeta “data” y dentro de ésta una subcarpeta “linelists”, en la que se encuentra el archivo .xlsx de interés.Hay que tener en cuenta algunas cosas sobre las rutas absolutas de los archivos:Evita utilizar rutas absolutas de archivos, ya que el script funcionará si se ejecuta en un ordenador diferenteUtiliza barras inclinadas (/), como en el ejemplo anterior (nota: esto es el valor predeterminado para las rutas de archivos de Windows)Las rutas de archivos que comienzan con barras dobles (por ejemplo, “//…”) probablemente serán reconocidas por R y producirán un error. Considera la posibilidad de trasladar tu trabajo una unidad “con nombre” o que comience con una letra (por ejemplo, “J:” o “C:”). Consulta la página sobre interacciones con directorios para obtener más detalles sobre esta cuestión.Un escenario en el que las rutas absolutas de los archivos pueden ser apropiadas es cuando se quiere importar un archivo desde una unidad compartida que tiene la misma ruta de archivo completa para todos los usuarios.CONSEJO: Para convertir rápidamente las barras inclinadas \\ /, resalta el código de interés, usa Ctrl+f (en Windows), marca la casilla de opción para “En selección”, y luego usa la funcionalidad de reemplazo para convertirlos.","code":"\nlinelist <- import(\"C:/Users/Laura/Documents/analysis/data/linelists/ebola_linelist.xlsx\")"},{"path":"import-and-export.html","id":"selección-manual","chapter":"7 Importación y exportación","heading":"Selección manual","text":"Puedes importar datos manualmente mediante uno de estos métodos:En el panel de entorno de RStudio, cliquea en “Import Dataset”, y selecciona el tipo de datosCliquea en File / Import dataset / (selecciona el tipo de datos)Para codificar la selección manual, utiliza el comando de file.choose() (dejando los paréntesis vacíos) para provocar la aparición de una ventana emergente que permita al usuario seleccionar manualmente el archivo de su ordenador. Por ejemplo:CONSEJO: La ventana emergente puede aparecer DETRÁS de la ventana de RStudio.","code":"\n# Selección manual de un archivo. Cuando se ejecute este comando, aparecerá una ventana EMERGENTE.\n\n# La ruta del archivo seleccionado será suministrada al comando import().\n\nmy_data <- import(file.choose())"},{"path":"import-and-export.html","id":"import-data","chapter":"7 Importación y exportación","heading":"7.5 Importar datos","text":"Utilizar import() es bastante sencillo. Simplemente escribe la ruta del archivo (incluyendo el nombre y la extensión del archivo) entre comillas. Si utilizas () para construir la ruta del archivo, sigue las instrucciones anteriores. continuación se muestran algunos ejemplos:Para importar un archivo csv que se encuentra en tu “directorio de trabajo” o en la carpeta raíz del proyecto R:Para importar la primera hoja de un archivo de Excel que se encuentra en las subcarpetas “data” y “linelists” del proyecto R (la ruta del archivo construida con ()):Para importar un data frame (un archivo .rds) utilizando una ruta de archivo absoluta:","code":"\nlinelist <- import(\"linelist_cleaned.csv\")\nlinelist <- import(here(\"data\", \"linelists\", \"linelist_cleaned.xlsx\"))\nlinelist <- import(\"C:/Users/Laura/Documents/tuberculosis/data/linelists/linelist_cleaned.rds\")"},{"path":"import-and-export.html","id":"hojas-de-excel-específicas","chapter":"7 Importación y exportación","heading":"Hojas de Excel específicas","text":"Por defecto, si proporcionas un archivo de Excel (.xlsx) import(), se importará la primera hoja del libro. Si deseas importar una hoja específica, incluye el nombre de la hoja con el argumento =. Por ejemplo:Utilizando el método () para proporcionar una vía relativa import(), también podés importar una hoja específica añadiendo el argumento = después del paréntesis de cierre de la función ().Para exportar un dataframe de R una hoja de Excel específica y que el resto del archivo de Excel permanezca sin cambios, tendrás que importar, editar y exportar con un paquete alternativo destinado este fin, como openxlsx. Vea más información en la página sobre las interacciones con directorios o en esta página de github.Si tu libro de Excel es .xlsb (libro de Excel en formato binario) es posible que puedas importarlo con rio. Considera la posibilidad de volver guardarlo como .xlsx, o de utilizar un paquete como readxlsb, creado para este fin.","code":"\nmy_data <- import(\"my_excel_file.xlsx\", which = \"Sheetname\")# Demostración: importación de una hoja de Excel específica al utilizar rutas relativas con el paquete 'here'\nlinelist_raw <- import(here(\"data\", \"linelist.xlsx\"), which = \"Sheet1\")`  "},{"path":"import-and-export.html","id":"import_missing","chapter":"7 Importación y exportación","heading":"Valores faltantes","text":"Es posible que desees designar qué valor(es) de tus datos se debe(n) considerar como faltantes (missing values). Como se explica en la página sobre Valores faltantes, el valor en R para los valores faltantes es NA, pero tal vez los datos que vas importar utiliza 99, “Missing”, o simplemente el espacio de caracteres vacíos “” en su lugar.Utiliza el argumento na = en import() y proporciona el(los) valor(es) entre comillas (incluso si son números). Puedes especificar varios valores incluyéndolos dentro de un vector, utilizando c() como se muestra continuación.Aquí, el valor “99” en los datos importados se considera valor faltante y se convierte en NA en R.Aquí, cualquiera de los valores “Missing”, “” (celda vacía), o ” ” (un solo espacio) en los datos importados se convierten en NA en R.","code":"\nlinelist <- import(here(\"data\", \"my_linelist.xlsx\"), na = \"99\")\nlinelist <- import(here(\"data\", \"my_linelist.csv\"), na = c(\"Missing\", \"\", \" \"))"},{"path":"import-and-export.html","id":"saltar-filas","chapter":"7 Importación y exportación","heading":"Saltar filas","text":"Si querés evitar la importación de una fila de datos, puedes hacerlo con el argumento skip = utilizando import() de rio en un archivo .xlsx o .csv. Debes proporcionar el número de filas que deseas omitir.Desafortunadamente, skip = sólo acepta un valor entero, un rango (por ejemplo, “2:10” funciona). Para omitir la importación de filas específicas que son consecutivas desde el principio, considera la posibilidad de importar varias veces y utilizar bind_rows() de dplyr. Mira en el ejemplo siguiente cómo se omite sólo la fila 2.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\", skip = 1)  # no importa la fila de cabecera"},{"path":"import-and-export.html","id":"gestionar-una-segunda-fila-de-cabecera","chapter":"7 Importación y exportación","heading":"Gestionar una segunda fila de cabecera","text":"veces, tus datos pueden tener una segunda fila de cabecera, por ejemplo, si se trata de una fila de “diccionario de datos”, como se muestra continuación. Esta situación puede ser problemática porque puede hacer que todas las columnas se importen como de tipo “carácter”.continuación se muestra un ejemplo de este tipo de de datos (en el que la primera fila es el diccionario de datos).","code":""},{"path":"import-and-export.html","id":"eliminar-la-segunda-fila-de-la-cabecera","chapter":"7 Importación y exportación","heading":"Eliminar la segunda fila de la cabecera","text":"Para eliminar la segunda fila de la cabecera, tendrás que importar los datos dos veces.Importar los datos para almacenar los nombres correctos de las columnasImportar los datos de nuevo, saltándose las dos primeras filas (cabecera y segunda fila)\n3)Vincular los nombres correctos en el dataframe reducidoEl argumento exacto utilizado para vincular los nombres de las columnas correctas depende del tipo de archivo de datos (.csv, .tsv, .xlsx, etc.). Esto se debe que rio utiliza una función diferente para los distintos tipos de archivos (véase la tabla anterior).Para los archivos de Excel: (col_names =)Para archivos CSV: (col.names =)Opción alternativa - cambiar los nombres de las columnas utilizando un comando separado","code":"\n# importa por primera vez; almacena los nombres de las columnas\nlinelist_raw_names <- import(\"linelist_raw.xlsx\") %>% names()  # guarda los nombres de columna\n\n# importa por segunda vez; omite la fila 2, y asigna los nombres de las columnas al argumento col_names =\nlinelist_raw <- import(\"linelist_raw.xlsx\",\n                       skip = 2,\n                       col_names = linelist_raw_names\n                       ) \n# primera importación; almacena los nombres de las columnas\nlinelist_raw_names <- import(\"linelist_raw.csv\") %>% names() # save true column names\n\n# nota: el argumento para archivos csv es 'col.names = '\nlinelist_raw <- import(\"linelist_raw.csv\",\n                       skip = 2,\n                       col.names = linelist_raw_names\n                       ) \n# asigna/reescribe cabecesas usando la función 'colnames()' de R base\ncolnames(linelist_raw) <- linelist_raw_names"},{"path":"import-and-export.html","id":"hacer-un-diccionario-de-datos","chapter":"7 Importación y exportación","heading":"Hacer un diccionario de datos","text":"Bonus! Si tienes una segunda fila que es un diccionario de datos, puedes crear fácilmente un diccionario de datos propio partir de ella. Este consejo está adaptado de este post.","code":"\ndict <- linelist_2headers %>%             # linelist con como primera fila\n  head(1) %>%                             # mantener sólo los nombres de las columnas y la primera fila del diccionario \n  pivot_longer(cols = everything(),       # pivotar todas las columnas a formato largo\n               names_to = \"Column\",       # asignar nuevos nombres de columnas\n               values_to = \"Description\")"},{"path":"import-and-export.html","id":"combinar-las-dos-filas-de-la-cabecera","chapter":"7 Importación y exportación","heading":"Combinar las dos filas de la cabecera","text":"En algunos casos, cuando los datos crudos tienen dos filas de cabecera (o, más concretamente, la segunda fila de datos es una cabecera secundaria), es posible que desees “combinarlas” o añadir los valores de la segunda fila de cabecera la primera fila de cabecera.El comando siguiente definirá los nombres de las columnas del dataframe como la combinación del primer encabezado (verdadero) con el valor inmediatamente inferior (en la primera fila).","code":"\nnames(my_data) <- paste(names(my_data), my_data[1, ], sep = \"_\")"},{"path":"import-and-export.html","id":"hojas-de-google","chapter":"7 Importación y exportación","heading":"Hojas de Google","text":"Puedes importar datos de una hoja de cálculo de Google en línea con el paquete googlesheet4 y autenticando tu acceso al archivo.continuación, se importa y guarda una hoja de Google de demostración. Este comando puede solicitar la autentificación de tu cuenta de Google. Sigue las indicaciones y las ventanas emergentes de tu navegador web para conceder los paquetes de la API de Tidyverse permisos para editar, crear y eliminar sus hojas de cálculo en Google Drive.La hoja que aparece continuación es “visible para cualquiera con el enlace” y puedes intentar importarla.La hoja también puede importarse utilizando sólo el ID de la hoja, así es una url más corta:Otro paquete, googledrive ofrece funciones útiles para escribir, editar y eliminar hojas de Google. Por ejemplo, utilizando las funciones gs4_create() y sheet_write() que se encuentran en este paquete.Aquí hay otros tutoriales útiles en línea:tutorial básico de importación de hojas de Googletutorial más detalladointeracción entre googlesheets4 y tidyverse","code":"\npacman::p_load(\"googlesheets4\")\nGsheets_demo <- read_sheet(\"https://docs.google.com/spreadsheets/d/1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY/edit#gid=0\")\nGsheets_demo <- read_sheet(\"1scgtzkVLLHAe5a6_eFQEwkZcc14yFUx1KgOMZ4AKUfY\")"},{"path":"import-and-export.html","id":"multiple-files---import-export-split-combine","chapter":"7 Importación y exportación","heading":"7.6 Múltiples archivos - importar, exportar, dividir, combinar","text":"Consulta la página sobre Iteración, bucles y listas para ver ejemplos de cómo importar y combinar múltiples archivos, o múltiples archivos de Excel. Esa página también tiene ejemplos sobre cómo dividir un dataframe en partes y exportar cada uno por separado, o como hojas específicas en un archivo de Excel.","code":""},{"path":"import-and-export.html","id":"import_github","chapter":"7 Importación y exportación","heading":"7.7 Importar desde Github","text":"Importar datos directamente de Github R puede ser muy fácil o puede requerir algunos pasos - dependiendo del tipo de archivo. continuación se presentan algunos enfoques:","code":""},{"path":"import-and-export.html","id":"csv-files","chapter":"7 Importación y exportación","heading":"CSV files","text":"Es fácil importar un archivo .csv directamente desde Github R con un comando de R.Ve al repositorio de Github, localiza el archivo de interés y clica sobre élVe al repositorio de Github, localiza el archivo de interés y clica sobre élCliquea en el botón “Raw” (entonces verás los datos csv “crudos”, como se muestra continuación)Cliquea en el botón “Raw” (entonces verás los datos csv “crudos”, como se muestra continuación)Copia la URL (dirección web)Copia la URL (dirección web)Pega la URL entre comillas dentro del comando de R import()Pega la URL entre comillas dentro del comando de R import()","code":""},{"path":"import-and-export.html","id":"xlsx-files","chapter":"7 Importación y exportación","heading":"XLSX files","text":"Es posible que puedas ver los datos “en crudo” (raw) de algunos archivos (por ejemplo, .xlsx, .rds, .nwk, .shp)Ve al repositorio de Github, localica el archivo de interés y clica sobre élCliquea en el botón “Download”, como se muestra continuaciónGuarda el archivo en tu ordenador e impórtalo en R","code":""},{"path":"import-and-export.html","id":"shapefiles","chapter":"7 Importación y exportación","heading":"Shapefiles","text":"Los shapefiles tienen muchos archivos subcomponentes, cada uno con una extensión diferente. Un archivo tendrá la extensión “.shp”, pero otros tienen “.dbf”, “.prj”, etc. Para descargar un shapefile de Github, tendrás que descargar cada uno de los archivos subcomponentes individualmente, y guardarlos en la misma carpeta de tu ordenador. En Github, cliquea en cada archivo individualmente y descárgalos clicando en el botón “Download”.Una vez guardado en tu ordenador, puedes importar el archivo shape como se muestra en la página de Conceptos básicos de los SIG utilizando st_read() del paquete sf. Sólo tienes que proporcionar la ruta del archivo y el nombre del archivo “.shp”, siempre que los demás archivos relacionados estén en la misma carpeta de tu ordenador.continuación, se puede ver cómo el shapefile “sle_adm3” consta de muchos archivos, cada uno de los cuales debe descargarse de Github.","code":""},{"path":"import-and-export.html","id":"manual-data-entry","chapter":"7 Importación y exportación","heading":"7.8 Grabación manual de datos","text":"","code":""},{"path":"import-and-export.html","id":"entrada-por-filas","chapter":"7 Importación y exportación","heading":"Entrada por filas","text":"Utiliza la función tribble() del paquete tibble de tidyverse (referencia online de tibble).Observa que las cabeceras de las columnas comienzan con una tilde (~). Observa también que cada columna debe contener sólo un tipo de datos (carácter, numérico, etc.). Puedes utilizar tabulaciones, espacios y nuevas filas para que la entrada de datos sea más intuitiva y legible. Los espacios importan entre los valores, pero cada fila está representada por una nueva línea de código. Por ejemplo:Y ahora mostramos el nuevo conjunto de datos:","code":"\n# crea el dataset manualmente por filas\nmanual_entry_rows <- tibble::tribble(\n  ~colA, ~colB,\n  \"a\",   1,\n  \"b\",   2,\n  \"c\",   3\n  )"},{"path":"import-and-export.html","id":"entrada-por-columnas","chapter":"7 Importación y exportación","heading":"Entrada por columnas","text":"Dado que un dataframe consiste en vectores (columnas verticales), el enfoque básico para la creación manual de dataframes en R espera que definas cada columna y luego las unas. Esto puede ser contrario la intuición en epidemiología, ya que normalmente pensamos en nuestros datos como una observación por filas (como arriba).PRECAUCIÓN: Todos los vectores deben tener la misma longitud (el mismo número de valores).continuación, los vectores pueden unirse mediante la función data.frame():Y ahora mostramos el nuevo conjunto de datos:","code":"\n# define cada vector (columna vertical) por separado, cada uno con su propio nombre\nPatientID <- c(235, 452, 778, 111)\nTreatment <- c(\"Yes\", \"No\", \"Yes\", \"Yes\")\nDeath     <- c(1, 0, 1, 0)\n# combine the columns into a data frame, by referencing the vector names\nmanual_entry_cols <- data.frame(PatientID, Treatment, Death)"},{"path":"import-and-export.html","id":"pegar-desde-el-portapapeles","chapter":"7 Importación y exportación","heading":"Pegar desde el portapapeles","text":"Si copias los datos de otro lugar y los tienes en el portapapeles, puedes probar una de las dos formas siguientes:Con el paquete clipr, puedes utilizar read_clip_tbl() para importar como un dataframe, o simplemente read_clip() para importar como un vector de caracteres. En ambos casos, deja los paréntesis vacíos.También puedes exportar fácilmente al portapapeles de tu sistema con clipr. Consulta la sección siguiente sobre Exportación.Alternativamente, pueder utilizar la función read.table() de R base con file = \"clipboard\") para importar como un dataframe:","code":"\nlinelist <- clipr::read_clip_tbl()  # importar portapapeles actual como data frame\nlinelist <- clipr::read_clip()      # importar como vector de caracteres\ndf_from_clipboard <- read.table(\n  file = \"clipboard\",  # especifica esto como \"portapapeles\"\n  sep = \"t\",           # el separador puede ser un tabulador, o una coma, etc.\n  header=TRUE)         # si hay una fila de cabecera"},{"path":"import-and-export.html","id":"import-most-recent-file","chapter":"7 Importación y exportación","heading":"7.9 Importar el archivo más reciente","text":"menudo puedes recibir actualizaciones diarias de tus datos. En este caso, querrás escribir un código que importe el archivo más reciente. continuación presentamos dos maneras de abordar esto:Seleccionar el archivo en función de la fecha del nombre del archivoSeleccionar el archivo en función de los metadatos del archivo (última modificación)","code":""},{"path":"import-and-export.html","id":"fechas-en-el-nombre-del-archivo","chapter":"7 Importación y exportación","heading":"Fechas en el nombre del archivo","text":"Este enfoque se basa en tres premisas:Confías en las fechas en los nombres de los archivosLas fechas son numéricas y aparecen generalmente en el mismo formato (por ejemplo, año, mes y día)hay otros números en el nombre del archivoTe explicaremos paso paso y te mostraremos todos los pasos combinados al final.En primer lugar, utiliza dir() de R base para extraer sólo los nombres de los archivos de la carpeta de interés. Consulta la página sobre interacciones con directorios para obtener más detalles sobre dir(). En este ejemplo, la carpeta de interés es la carpeta “linelists” dentro de la carpeta “example” dentro de “data” dentro del proyecto R.Una vez que tengas este vector de nombres, puedes extraer las fechas de ellos aplicando str_extract() de stringr utilizando esta expresión regular. Este comando extrae cualquier número en el nombre del archivo (incluyendo cualquier otro carácter en el medio como guiones o barras). Puedes leer más sobre stringr en la página Caracteres y cadenas.Suponiendo que las fechas estén escritas en general con el mismo formato de fecha (por ejemplo, Año, Mes y Día) y que los años tengan 4 dígitos, puedes utilizar las funciones de conversión de lubridate (ymd(), dmy() o mdy()) para convertirlas en fechas. Para estas funciones, importan los guiones, espacios o barras, sino el orden de los números. Lee más en la página Trabajando con fechas.La función de R base wich.max() puede utilizarse para devolver la posición del índice (por ejemplo, 1ª, 2ª, 3ª, …) del valor máximo de la fecha. El último archivo se identifica correctamente como el sexto archivo - “case_linelist_2020-10-08.xlsx”.Si condensamos todos estos comandos, el código completo podría ser como el siguiente. Observa que el . en la última línea es un marcador de posición para el objeto canalizado en ese punto de la secuencia de pipes. En ese punto el valor es simplemente el número 6. Esto se coloca entre corchetes dobles para extraer el sexto elemento del vector de nombres de archivo producido por dir().Ahora puedes utilizar este nombre para terminar la ruta relativa del archivo, con ():Y ahora puedes importar el último archivo:","code":"\nlinelist_filenames <- dir(here(\"data\", \"example\", \"linelists\")) # obtiene los nombres de ficheros de la carpeta\nlinelist_filenames                                              # los muestra## [1] \"20201007linelist.csv\"          \"case_linelist_2020-10-02.csv\"  \"case_linelist_2020-10-03.csv\" \n## [4] \"case_linelist_2020-10-04.csv\"  \"case_linelist_2020-10-05.csv\"  \"case_linelist_2020-10-08.xlsx\"\n## [7] \"case_linelist20201006.csv\"\nlinelist_dates_raw <- stringr::str_extract(linelist_filenames, \"[0-9].*[0-9]\") # extract numbers and any characters in between\nlinelist_dates_raw  # print## [1] \"20201007\"   \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"20201006\"\nlinelist_dates_clean <- lubridate::ymd(linelist_dates_raw)\nlinelist_dates_clean## [1] \"2020-10-07\" \"2020-10-02\" \"2020-10-03\" \"2020-10-04\" \"2020-10-05\" \"2020-10-08\" \"2020-10-06\"\nindex_latest_file <- which.max(linelist_dates_clean)\nindex_latest_file## [1] 6\n# load packages\npacman::p_load(\n  tidyverse,         # gestión de datos\n  stringr,           # trabajar con cadenas/caracteres\n  lubridate,         # trabajar con fechas\n  rio,               # importar / exportar\n  here,              # rutas relativas \n  fs)                # interacciones de directorio\n\n# extraer el nombre del último archivo\nlatest_file <- dir(here(\"data\", \"example\", \"linelists\")) %>%  # nombres de archivos de la subcarpeta \"linelists\"    \n  str_extract(\"[0-9].*[0-9]\") %>%                  # extraer fechas (números)\n  ymd() %>%                                        # convertir los números en fechas (asumiendo el formato año-mes-día)\n  which.max() %>%                                 # obtener el índice de la fecha máxima (último archivo)\n  dir(here(\"data\", \"example\", \"linelists\"))[[.]]              #  devuelve el nombre del archivo del último linelist\n\nlatest_file  # mostrar el nombre del último archivo## [1] \"case_linelist_2020-10-08.xlsx\"\nhere(\"data\", \"example\", \"linelists\", latest_file) \n# import\nimport(here(\"data\", \"example\", \"linelists\", latest_file)) # importar "},{"path":"import-and-export.html","id":"utiliza-la-información-del-archivo","chapter":"7 Importación y exportación","heading":"Utiliza la información del archivo","text":"Si tus archivos tienen fechas en sus nombres (o te fías de esas fechas), puedes intentar extraer la última fecha de modificación de los metadatos del archivo. Utiliza las funciones del paquete fs para examinar la información de los metadatos de cada archivo, que incluye la fecha y hora de la última modificación y la ruta del archivo.continuación, proporcionamos la carpeta de interés dir_info() de fs. En este caso, la carpeta de interés está en el proyecto R en la carpeta “data”, la subcarpeta “example”, y su subcarpeta “linelists”. El resultado es un dataframe con una línea por cada archivo y columnas para modification_time, path, etc. Puedes ver un ejemplo visual de esto en la página sobre interacciones con directorios.Podemos ordenar este dataframe de archivos por la columna modification_time, y luego mantener sólo la fila superior (último archivo) con la función head() de R base. continuación, podemos extraer la ruta de este último archivo sólo con la función dplyr pull() en la columna path. Finalmente podemos pasar esta ruta de archivo import(). El archivo importado se guarda como latest_file.","code":"\nlatest_file <- dir_info(here(\"data\", \"example\", \"linelists\")) %>%  # recoger información de todos los archivos en el directorio\n  arrange(desc(modification_time)) %>%      # ordenar por tiempo de modificación\n  head(1) %>%                               # mantener sólo el archivo superior (más reciente)\n  pull(path) %>%                            # extraer sólo la ruta del archivo\n  import()                                  # importar el archivo"},{"path":"import-and-export.html","id":"import_api","chapter":"7 Importación y exportación","heading":"7.10 APIs","text":"Una “Interfaz de Programación Automatizada” (API) puede utilizarse para solicitar datos directamente de un sitio web. Las API son un conjunto de reglas que permiten que una aplicación de software interactúe con otra. El cliente (tu) envía una “solicitud” y recibe una “respuesta” con contenido. Los paquetes de R httr y jsonlite pueden facilitar este proceso.Cada sitio web habilitado para la API tendrá su propia documentación y detalles con los que hay que familiarizarse. Algunos sitios están disponibles públicamente y cualquiera puede acceder ellos. Otros, como las plataformas con ID de usuario y credenciales, requieren autenticación para acceder sus datos.Obviamente es necesario disponer de una conexión Internet para importar datos través de la API. Te daremos ejemplos breves de uso de las API para importar datos, y presentaremos enlaces otros recursos.Nota: recuerda que los datos pueden estar publicados* en un sitio web sin una API, que puede ser más fácil de recuperar. Por ejemplo, un archivo CSV publicado puede ser accesible simplemente proporcionando la URL del sitio import() como se describe en la sección sobre la importación desde Github.*","code":""},{"path":"import-and-export.html","id":"petición-http","chapter":"7 Importación y exportación","heading":"Petición HTTP","text":"El intercambio de la API se realiza normalmente través de una solicitud HTTP. HTTP es el Protocolo de Transferencia de Hipertexto, y es el formato subyacente de una solicitud/respuesta entre un cliente y un servidor. La entrada y la salida exactas pueden variar en función del tipo de API, pero el proceso es el mismo: una “Solicitud” (menudo Solicitud HTTP) del usuario, que suele contener una consulta, seguida de una “Respuesta”, que contiene información de estado sobre la solicitud y posiblemente el contenido solicitado.Estos son algunos de los componentes de una petición HTTP:La URL completa de la APIEl “Método” (o “Verbo”)Headers (Encabezados)Body (Cuerpo)El “método” de la petición HTTP es la acción que se quiere realizar. Los dos métodos HTTP más comunes son GET y POST, pero otros pueden ser PUT, DELETE, PATCH, etc. Cuando se importan datos R lo más probable es que se utilice GET.Después de la solicitud, tu ordenador recibirá una “respuesta” en un formato similar al que se envió, incluyendo la URL, el estado HTTP (¡status 200 es lo que quieres!), el tipo de archivo, el tamaño y el contenido deseado. continuación, tendrá que analizar esta respuesta y convertirla en un dataframe viable dentro de su entorno R.","code":""},{"path":"import-and-export.html","id":"paquetes","chapter":"7 Importación y exportación","heading":"Paquetes","text":"El paquete httr funciona bien para manejar peticiones HTTP en R. Requiere poco conocimiento previo de las APIs de la web y puede ser utilizado por personas menos familiarizadas con la terminología de desarrollo de software. Además, si la respuesta HTTP es .json, puede utilizar jsonlite para analizar la respuesta.","code":"\n# load packages\npacman::p_load(httr, jsonlite, tidyverse)"},{"path":"import-and-export.html","id":"datos-de-acceso-público","chapter":"7 Importación y exportación","heading":"Datos de acceso público","text":"continuación se muestra un ejemplo de solicitud HTTP, tomado de un tutorial de Trafford Data Lab. Este sitio tiene varios otros recursos para aprender y ejercicios de API.Escenario: Queremos importar una lista de establecimientos de comida rápida en la ciudad de Trafford, Reino Unido. Se puede acceder los datos desde la API de la Food Standards Agency (Agencia de Normas Alimentarias), que proporciona datos de calificación de higiene alimentaria para el Reino Unido.Estos son los parámetros de nuestra solicitud:Verbo HTTP: GETURL del punto de la API: http://api.ratings.food.gov.uk/EstablishmentsParámetros seleccionados: name, address, longitude, latitude, businessTypeId, ratingKey, localAuthorityIdCabeceras: “x-api-version”, 2Formato(s) de datos: JSON, XMLDocumentación: http://api.ratings.food.gov.uk/helpEl código R sería el siguiente:Ahora puedes limpiar y utilizar el dataframe response, que contiene una fila por establecimiento de comida rápida.","code":"\n# preparar la petición\npath <- \"http://api.ratings.food.gov.uk/Establishments\"\nrequest <- GET(url = path,\n             query = list(\n               localAuthorityId = 188,\n               BusinessTypeId = 7844,\n               pageNumber = 1,\n               pageSize = 5000),\n             add_headers(\"x-api-version\" = \"2\"))\n\n# Comprobar si hay error con el servidor (\"200\" es el correcto!)\nrequest$status_code\n\n# enviar la solicitud, analizar la respuesta y convertirla en un data frame\nresponse <- content(request, as = \"text\", encoding = \"UTF-8\") %>%\n  fromJSON(flatten = TRUE) %>%\n  pluck(\"establishments\") %>%\n  as_tibble()"},{"path":"import-and-export.html","id":"se-requiere-autenticación","chapter":"7 Importación y exportación","heading":"Se requiere autenticación","text":"Algunas APIs requieren autenticación - para que se demuestre quién eres y poder acceder datos restringidos. Para importar estos datos, es posible que tengas que utilizar primero un método POST para proporcionar un nombre de usuario, una contraseña o un código. Esto devolverá un token de acceso, que puede ser utilizado para posteriores solicitudes del método GET para obtener los datos deseados.continuación se muestra un ejemplo de consulta de datos de Go.Data, que es una herramienta de investigación de brotes. Go.Data utiliza una API para todas las interacciones entre la interfaz de la web y las aplicaciones de los smartphones utilizadas para la captura de datos. Go.Data se utiliza en todo el mundo. Se requiere autenticación, dado que los datos de los brotes son sensibles y sólo debes poder acceder los datos de tu brote.continuación se muestra un ejemplo de código R que utiliza httr y jsonlite para conectarse la API de Go.Data para importar datos sobre el seguimiento de los contactos de tu brote.PRECAUCIÓN: Si estás importando grandes cantidades de datos desde una API que requiere autenticación, es posible que se agote el tiempo de espera. Para evitarlo, recupera el access_token antes de cada solicitud GET de la API y prueba utilizar filtros o límites en la consulta. CONSEJO: La función fromJSON() del paquete jsonlite se ajuste completamente la primera vez que se ejecuta, por lo que es probable que todavía tengas elementos de la lista en tu tibble resultante. Tendrás que ajustar aún más ciertas variables, dependiendo de lo jerarquizado que esté tu .json. Para ver más información sobre esto, consulta la documentación del paquete jsonlite, como la función flatten(). Para más detalles, mira la documentación en el Explorador de LoopBack, la página de Rastreo de Contactos o los consejos de la API en el repositorio Github de Go.DataPuedes leer más sobre el paquete httr aquíEsta sección también se inspiró en este tutorial y este otro tutorial.","code":"\n# establecer credenciales para la autorización\nurl <- \"https://godatasampleURL.int/\"           # url correcta de Go.Data\nusername <- \"username\"                          # usuario Go.Data válido \npassword <- \"password\"                          # contraseña válida \noutbreak_id <- \"xxxxxx-xxxx-xxxx-xxxx-xxxxxxx\"  # ID de brote de Go.Data\n\n# obtener token de acceso\nurl_request <- paste0(url,\"api/oauth/token?access_token=123\") # definir URL base de la solicitud\n\n# preparar la petición\nresponse <- POST(\n  url = url_request,  \n  body = list(\n    username = username,    # utiliza el nombre de usuario/contraseña guardado  arriba para autorizar                               \n    password = password),                                       \n    encode = \"json\")\n\n# ejecutar la petición y analizar la respuesta\ncontent <-\n  content(response, as = \"text\") %>%\n  fromJSON(flatten = TRUE) %>%          # acoplar el JSON anidado\n  glimpse()\n\n# Guardar el token de acceso de la respuesta\naccess_token <- content$access_token    # guardar el token de acceso para permitir las siguientes llamadas a la API\n\n# importar contactos del brote\n# Utilizar el token de acceso \nresponse_contacts <- GET(\n  paste0(url,\"api/outbreaks/\",outbreak_id,\"/contacts\"),          # petición GET\n  add_headers(\n    Authorization = paste(\"Bearer\", access_token, sep = \" \")))\n\njson_contacts <- content(response_contacts, as = \"text\")         # # convertir JSON a texto\n\ncontacts <- as_tibble(fromJSON(json_contacts, flatten = TRUE))   # acoplar JSON a tibble"},{"path":"import-and-export.html","id":"export","chapter":"7 Importación y exportación","heading":"7.11 Exportar","text":"","code":""},{"path":"import-and-export.html","id":"con-el-paquete-rio","chapter":"7 Importación y exportación","heading":"Con el paquete rio","text":"Con rio, puedes utilizar la función export() de forma muy similar import(). Primero indica el nombre del objeto de R que deseas guardar (por ejemplo, linelist) y luego escribe entre comillas la ruta de acceso al archivo donde deseas guardarlo, incluyendo el nombre y la extensión de archivo deseados. Por ejemplo:Esto guarda el dataframe linelist como un archivo de Excel en el directorio de trabajo/carpeta raíz del proyecto R:Se puede guardar el mismo dataframe como un archivo csv cambiando la extensión. Por ejemplo, también lo guardamos en una ruta de archivo construida con ():","code":"\nexport(linelist, \"my_linelist.xlsx\") # lo guardará en el directorio de trabajo\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.csv\"))"},{"path":"import-and-export.html","id":"al-portapapeles","chapter":"7 Importación y exportación","heading":"Al portapapeles","text":"Para exportar un dataframe al “portapapeles” de tu ordenador (para luego pegarlo en otro software como Excel, Google Spreadsheets, etc.) puedes utilizar write_clip() del paquete clipr.","code":"\n# exporta el data frame linelist al portapapeles de tu sistema\nclipr::write_clip(linelist)"},{"path":"import-and-export.html","id":"import_rds","chapter":"7 Importación y exportación","heading":"7.12 Archivos RDS","text":"Además de .csv, .xlsx, etc., también puedes exportar/guardar dataframes de R como archivos .rds. Este es un formato de archivo específico de R, y es muy útil si sabes que vas trabajar con los datos exportados de nuevo en R.Los tipos de columnas se conservan, por lo que hay que volver hacer la limpieza cuando se importan (con un archivo Excel o incluso CSV esto puede ser un dolor de cabeza). También es un archivo más pequeño, lo que es útil para la exportación e importación si tu conjunto de datos es grande.Por ejemplo, si trabajas en un equipo de epidemiología y necesitas enviar archivos un equipo de SIG para la elaboración de mapas, y ellos también utilizan R, ¡sólo tienes que enviarles el archivo .rds! Así se conservan todos los tipos de columnas y ellos tienen menos trabajo que hacer.","code":"\nexport(linelist, here(\"data\", \"clean\", \"my_linelist.rds\"))"},{"path":"import-and-export.html","id":"import_rdata","chapter":"7 Importación y exportación","heading":"7.13 Archivos Rdata y listas de datos","text":"Los archivos .Rdata pueden almacenar múltiples objetos de R - por ejemplo, múltiples dataframes, resultados de modelos, listas, etc. Esto puede ser muy útil para consolidar o compartir muchos de tus datos para un proyecto determinado.En el siguiente ejemplo, se almacenan múltiples objetos R dentro del archivo exportado “my_objects.Rdata”:Nota: si estás intentando importar una lista, utiliza import_list() de rio para importarla con la estructura y el contenido originales completos.","code":"\nrio::export(my_list, my_dataframe, my_vector, \"my_objects.Rdata\")\nrio::import_list(\"my_list.Rdata\")"},{"path":"import-and-export.html","id":"saving-plots","chapter":"7 Importación y exportación","heading":"7.14 Guardar gráficos","text":"Las instrucciones sobre cómo guardar los gráficos, como los creados por ggplot(), se discuten en profundidad en la página de Conceptos básicos de ggplot.En resumen, ejecuta ggsave(\"my_plot_filepath_and_name.png\") después de obtener tu gráfico. Puedes proporcionar un gráfico guardado con plot = argumento, o sólo especificar la ruta de archivo de destino (con extensión de archivo) para guardar el gráfico mostrado más recientemente. También puedes controlar el ancho width =, la altura height =, las unidades units = y los puntos por pulgada dpi =.La forma de guardar un gráfico de red, como un árbol de transmisión, se aborda en la página Cadenas de transmisión.","code":""},{"path":"import-and-export.html","id":"resources-1","chapter":"7 Importación y exportación","heading":"7.15 Recursos","text":"El manual de importación y exportación de datos de RCapítulo de R 4 Data Science en español sobre la importación de datosdocumentación de ggsave()continuación se muestra una tabla, extraída de la viñeta online de rio. Para cada tipo de datos muestra: la extensión de archivo esperada, el paquete que rio utiliza para importar o exportar los datos, y si esta funcionalidad está incluida en la versión instalada de rio.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-data-and-core-functions","chapter":"8 Limpieza de datos y funciones básicas","heading":"8 Limpieza de datos y funciones básicas","text":"Esta página muestra los pasos más utilizados en el proceso de “limpieza” de datos, y también explica el uso de muchas funciones esenciales de gestión de datos en R.Para explicarlo, esta página comienza importando datos de un listado de casos crudo, y se avanza paso paso través del proceso de limpieza. En el código R, esto se manifiesta como una cadena de “tuberías”, que hacen referencia al operador “tuberías” %>% que pasa unos datos de una operación la siguiente.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"funciones-principales","chapter":"8 Limpieza de datos y funciones básicas","heading":"Funciones principales","text":"Este manual hace hincapié en el uso de las funciones de la familia de paquetes de R tidyverse. Las funciones esenciales que se muestran en esta página se enumeran continuación.Muchas de estas funciones pertenecen al paquete dplyr, que proporciona funciones “verbales” para resolver los retos de la manipulación de datos (el nombre hace una referencia unos alicates - plier - de dataframes). dplyr forma parte de la familia de paquetes de R tidyverse (que también incluye ggplot2, tidyr, stringr, tibble, purrr, magrittr y forcats, entre otros).Si quieres ver cómo se comparan estas funciones con los comandos de Stata o SAS, consulta la página sobre la transición R.Puedes encontrar una gestión de datos alternativa en el paquete R data.table con operadores como := y el uso frecuente de corchetes [ ]. Este enfoque y la sintaxis se explican brevemente en la página Data.Table.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nomenclatura-1","chapter":"8 Limpieza de datos y funciones básicas","heading":"Nomenclatura","text":"En este manual, generalmente hacemos referencia “columnas” y “filas” en lugar de “variables” y “observaciones”. Como se explica en este manual sobre “datos ordenados”, la mayoría de los conjuntos de datos estadísticos epidemiológicos se componen estructuralmente de filas, columnas y valores.Las variables contienen los valores que miden el mismo atributo subyacente (como el grupo de edad, el resultado o la fecha de inicio). Las observaciones contienen todos los valores medidos en la misma unidad (por ejemplo, una persona, un lugar o una muestra de laboratorio). Por lo tanto, estos aspectos pueden ser más difíciles de definir de forma tangible.En los conjuntos de datos “ordenados”, cada columna es una variable, cada fila es una observación y cada celda es un único valor. Sin embargo, algunos conjuntos de datos que se encuentran se ajustan este molde: unos datos de formato “amplio” pueden tener una variable dividida en varias columnas (véase un ejemplo en la página Pivotar datos). Del mismo modo, las observaciones pueden estar divididas en varias filas.La mayor parte de este manual trata sobre la gestión y la transformación de datos, por lo que las referencias las estructuras de datos concretas de filas y columnas son más relevantes que las observaciones y las variables más abstractas. Las excepciones se dan sobre todo en las páginas sobre análisis de datos, en las que verás más referencias las variables y las observaciones.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"cleaning-pipeline","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.1 Limpieza de tuberías","text":"Esta página recorre los pasos típicos de limpieza, añadiéndolos secuencialmente una cadena de tuberías de limpieza.En el análisis epidemiológico y el procesamiento de datos, los pasos de limpieza se realizan menudo de forma secuencial, enlazados entre sí. En R, esto se manifiesta menudo como una “tubería” de limpieza, en la que los datos en bruto se pasan o se “canalizan” de un paso de limpieza otro.Estas cadenas utilizan las funciones de dplyr y el operador %>% de magrittr. Esta tubería comienza con los datos “en bruto” (“linelist_raw.xlsx”) y termina con un dataframe de R “limpio” (linelist) que se puede utilizar, guardar, exportar, etc.En un proceso de limpieza, el orden de los pasos es importante. Los pasos de limpieza pueden incluir:Importación de datosImportación de datosLimpieza o cambio de los nombres de las columnasLimpieza o cambio de los nombres de las columnasde-duplicaciónde-duplicaciónCreación y transformación de columnas (por ejemplo, recodificación o normalización de valores)Creación y transformación de columnas (por ejemplo, recodificación o normalización de valores)Filtrado o añadido de filasFiltrado o añadido de filas","code":""},{"path":"cleaning-data-and-core-functions.html","id":"load-packages","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.2 Carga de paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,        # importing data  \n  here,       # relative file pathways  \n  janitor,    # data cleaning and tables\n  lubridate,  # working with dates\n  epikit,     # age_categories() function\n  tidyverse   # data management and visualization\n)"},{"path":"cleaning-data-and-core-functions.html","id":"import-data-1","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.3 Importar datos","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"importar","chapter":"8 Limpieza de datos y funciones básicas","heading":"Importar","text":"Aquí importamos el archivo Excel de la lista de casos “en bruto” utilizando la función import() del paquete rio. El paquete rio maneja con flexibilidad muchos tipos de archivos (por ejemplo, .xlsx, .csv, .tsv, .rds. Consulta la página sobre importación y exportación para obtener más información y consejos sobre situaciones inusuales (por ejemplo, omitir filas, establecer valores que faltan, importar hojas de Google, etc).Para continuar, cliquea para descargar linelist “en crudo” (como archivo .xlsx).Si tu conjunto de datos es grande y tarda mucho en importarse, puede ser útil que el comando de importación esté separado de la cadena de tuberías y que el “crudo” se guarde como un archivo distinto. Esto también permite comparar fácilmente las versiones original y limpia.continuación, importamos el archivo de Excel sin procesar y lo guardamos como el dataframe linelist_raw. Suponemos que el archivo se encuentra en tu directorio de trabajo o en la raíz del proyecto R, por lo que se especifican subcarpetas en la ruta del archivo.Puedes ver las primeras 50 filas del dataframe continuación. Nota: la función base de R head(n) te permite ver sólo las primeras n filas en la consola de R.","code":"\nlinelist_raw <- import(\"linelist_raw.xlsx\")"},{"path":"cleaning-data-and-core-functions.html","id":"revisar","chapter":"8 Limpieza de datos y funciones básicas","heading":"Revisar","text":"Puedes utilizar la función skim() del paquete skimr para obtener una visión general de todo el dataframe (véase la página sobre tablas descriptivas para más información). Las columnas se resumen por clase o tipo, como, por ejemplo, carácter, numérico. Nota: “POSIXct” es un tipo de fecha cruda (ver Trabajar con fechas.\nTable 8.1: Data summary\nVariable type: characterVariable type: numericVariable type: POSIXct","code":"\nskimr::skim(linelist_raw)"},{"path":"cleaning-data-and-core-functions.html","id":"column-names","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.4 Nombres de columnas","text":"En R, los nombres de las columnas son la “cabecera” o el valor “superior” de una columna. Se utilizan para referirse las columnas en el código, y sirven como etiqueta por defecto en las figuras.Otros programas estadísticos, como SAS y STATA, utilizan “etiquetas” que coexisten como versiones impresas más largas de los nombres de columna más cortos. Aunque R ofrece la posibilidad de añadir etiquetas de columna los datos, es una práctica que sea muy utilizada. Para hacer que los nombres de las columnas sean “fáciles de imprimir” para las figuras, normalmente se ajusta su visualización dentro de los comandos de gráficas que crean las salidas (por ejemplo, los títulos de los ejes o de las leyendas de una gráfica, o las cabeceras de las columnas en una tabla impresa - véase la sección de escalas de la página de consejos de ggplot y las páginas de Tablas para la presentación). Si deseas asignar etiquetas de columna en los datos, lee más online aquí y aquí.Como los nombres de las columnas de R se utilizan con mucha frecuencia, deben tener una sintaxis “limpia”. Sugerimos lo siguiente:Nombres cortosSin espacios (sustituir por barras bajas _ )Sin caracteres inusuales (&, #, <, >, …)Nomenclatura de estilo similar (por ejemplo, todas las columnas de fecha nombradas como date_onset, date_report, date_death…)Los nombres de las columnas de linelist_raw se muestran continuación utilizando names() de R base. Podemos ver que inicialmenteAlgunos nombres contienen espacios (por ejemplo, infection date)Algunos nombres contienen espacios (por ejemplo, infection date)Se utilizan diferentes patrones de nomenclatura para las fechas (date onset vs. infection date)Se utilizan diferentes patrones de nomenclatura para las fechas (date onset vs. infection date)Debe haber habido una cabecera fusionada en las dos últimas columnas del .xlsx. Lo sabemos porque el nombre de dos columnas fusionadas (“merged_header”) fue asignado por R la primera columna, y la segunda columna se le asignó un nombre de marcador de posición “…28” (ya que entonces estaba vacía y es la columna 28).Debe haber habido una cabecera fusionada en las dos últimas columnas del .xlsx. Lo sabemos porque el nombre de dos columnas fusionadas (“merged_header”) fue asignado por R la primera columna, y la segunda columna se le asignó un nombre de marcador de posición “…28” (ya que entonces estaba vacía y es la columna 28).NOTA: Para hacer referencia un nombre de columna que incluya espacios, rodea el nombre con tildes, por ejemplo: linelist$` '\\x60infection date\\x60'`. Ten en cuenta que, en tu teclado, la tilde (`) es diferente de la comilla simple (’). ","code":"\nnames(linelist_raw)##  [1] \"case_id\"         \"generation\"      \"infection date\"  \"date onset\"      \"hosp date\"      \n##  [6] \"date_of_outcome\" \"outcome\"         \"gender\"          \"hospital\"        \"lon\"            \n## [11] \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"       \n## [16] \"row_num\"         \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"           \"temp\"           \n## [26] \"time_admission\"  \"merged_header\"   \"...28\""},{"path":"cleaning-data-and-core-functions.html","id":"limpieza-automática","chapter":"8 Limpieza de datos y funciones básicas","heading":"Limpieza automática","text":"La función clean_names() del paquete janitor estandariza los nombres de las columnas y los hace únicos haciendo lo siguiente:Convierte todos los nombres para que estén compuestos sólo por barras bajas, números y letrasConvierte todos los nombres para que estén compuestos sólo por barras bajas, números y letrasLos caracteres acentuados se transliteran ASCII (por ejemplo, la o alemana con diéresis se convierte en “o”, la “ñ” española se convierte en “n”)Los caracteres acentuados se transliteran ASCII (por ejemplo, la o alemana con diéresis se convierte en “o”, la “ñ” española se convierte en “n”)Se puede especificar la preferencia de mayúsculas para los nuevos nombres de columna utilizando case = argumento (“snake” es el valor por defecto, las alternativas incluyen “sentence”, “title”, “small_camel”…)Se puede especificar la preferencia de mayúsculas para los nuevos nombres de columna utilizando case = argumento (“snake” es el valor por defecto, las alternativas incluyen “sentence”, “title”, “small_camel”…)Puedes especificar sustituciones de nombres concretos proporcionando un vector replace = argumento (por ejemplo, replace = c(onset = \"date_of_onset\"))Puedes especificar sustituciones de nombres concretos proporcionando un vector replace = argumento (por ejemplo, replace = c(onset = \"date_of_onset\"))Aquí puedes encontrar una viñeta en línea sobre dicho paquete.Aquí puedes encontrar una viñeta en línea sobre dicho paquete.continuación, el proceso de limpieza comienza utilizando clean_names() sobre linelist_raw.NOTA: El nombre de la última columna “…28” se ha cambiado por “x28”. ","code":"\n# pipe the raw dataset through the function clean_names(), assign result as \"linelist\"  \nlinelist <- linelist_raw %>% \n  janitor::clean_names()\n\n# see the new column names\nnames(linelist)##  [1] \"case_id\"         \"generation\"      \"infection_date\"  \"date_onset\"      \"hosp_date\"      \n##  [6] \"date_of_outcome\" \"outcome\"         \"gender\"          \"hospital\"        \"lon\"            \n## [11] \"lat\"             \"infector\"        \"source\"          \"age\"             \"age_unit\"       \n## [16] \"row_num\"         \"wt_kg\"           \"ht_cm\"           \"ct_blood\"        \"fever\"          \n## [21] \"chills\"          \"cough\"           \"aches\"           \"vomit\"           \"temp\"           \n## [26] \"time_admission\"  \"merged_header\"   \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"limpieza-manual-de-nombres","chapter":"8 Limpieza de datos y funciones básicas","heading":"Limpieza manual de nombres","text":"menudo es necesario renombrar las columnas manualmente, incluso después del paso de estandarización anterior. continuación, el renombramiento se realiza utilizando la función rename() del paquete dplyr, como parte de una cadena de tuberías. rename() utiliza el estilo NUEVO = ANTIGUO - el nombre nuevo de la columna se escribe antes que el antiguo.continuación, se añade un comando de renombramiento la tubería de limpieza. Se han añadido espacios estratégicamente para alinear el código y facilitar la lectura.Ahora puedes ver que los nombres de las columnas han cambiado:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"          \n##  [5] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"              \"gender\"              \n##  [9] \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \n## [17] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"renombrar-por-posición-de-columna","chapter":"8 Limpieza de datos y funciones básicas","heading":"Renombrar por posición de columna","text":"También puedes renombrar por la posición de la columna, en lugar del nombre de la columna, por ejemplo:","code":"\nrename(newNameForFirstColumn  = 1,\n       newNameForSecondColumn = 2)"},{"path":"cleaning-data-and-core-functions.html","id":"renombrar-mediante-select-y-summarise","chapter":"8 Limpieza de datos y funciones básicas","heading":"Renombrar mediante select() y summarise()","text":"Como método abreviado, también puedes cambiar el nombre de las columnas dentro de las funciones de dplyr select() y summarise(). select() se utiliza para mantener sólo ciertas columnas (y se muestra más adelante en esta página). summarise() se muestra en las páginas Agrupar datos y Tablas descriptivas. Estas funciones también utilizan el formato nombre_nuevo = nombre_antiguo. aquí un ejemplo:","code":"\nlinelist_raw %>% \n  select(# NEW name             # OLD name\n         date_infection       = `infection date`,    # rename and KEEP ONLY these columns\n         date_hospitalisation = `hosp date`)"},{"path":"cleaning-data-and-core-functions.html","id":"otros-retos","chapter":"8 Limpieza de datos y funciones básicas","heading":"Otros retos","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nombres-de-columnas-de-excel-vacíos","chapter":"8 Limpieza de datos y funciones básicas","heading":"Nombres de columnas de Excel vacíos","text":"R puede tener columnas de conjuntos de datos que tengan nombres de columnas (cabeceras). Así, si importa unos datos de Excel con datos pero sin cabeceras de columna, R rellenará las cabeceras con nombres como “…1” o “…2”. El nombre asignado representa el número de la columna (por ejemplo, si la cuarta columna de los datos tiene cabecera, R la nombrará “…4”).Puedes limpiar estos nombres manualmente haciendo referencia su número de posición (véase el ejemplo anterior), o su nombre asignado (linelist_raw$...1).","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nombres-de-columnas-y-celdas-fusionadas-de-excel","chapter":"8 Limpieza de datos y funciones básicas","heading":"Nombres de columnas y celdas fusionadas de Excel","text":"Las celdas combinadas en un archivo de Excel son una ocurrencia común cuando se reciben datos. Como se explica en Transición R, las celdas combinadas pueden ser agradables para la lectura humana de los datos, pero son “datos ordenados” y causan muchos problemas para la lectura de los datos por parte de las máquinas. R puede ajustar las celdas combinadas.Recuerda las personas que introducen los datos que los datos legibles para el ser humano son lo mismo que los datos legibles para la máquina. Esfuérzate en formar los usuarios sobre los principios de los datos ordenados. Si es posible, intenta cambiar los procedimientos para que los datos lleguen en un formato ordenado y sin celdas fusionadas.Cada variable debe tener su propia columna.Cada observación debe tener su propia fila.Cada valor debe tener su propia celda.Al utilizar la función import() de rio, el valor de una celda combinada se asignará la primera celda y las siguientes estarán vacías.Una solución para tratar las celdas combinadas es importar los datos con la función readWorkbook() del paquete openxlsx. Establece el argumento fillMergedCells = TRUE. Esto da el valor en una celda fusionada todas las celdas dentro del rango de fusión.PELIGRO: Si los nombres de las columnas se fusionan con readWorkbook(), terminarás con nombres de columnas duplicados, que tendrás que arreglar manualmente - ¡R funciona bien con nombres de columnas duplicados! Puedes renombrarlas haciendo referencia su posición (por ejemplo, la columna 5), como se explica en la sección de limpieza manual de nombres de columnas. ","code":"\nlinelist_raw <- openxlsx::readWorkbook(\"linelist_raw.xlsx\", fillMergedCells = TRUE)"},{"path":"cleaning-data-and-core-functions.html","id":"select-or-re-order-columns","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.5 Seleccionar o reordenar columnas","text":"Utiliza select() de dplyr para seleccionar las columnas que deseas conservar y para especificar su orden en el dataframe.ATENCIÓN: En los ejemplos siguientes, el dataframe linelist se modifica con select() y se muestra, pero se guarda. Esto es efectos de demostración. Los nombres de las columnas modificadas se imprimen pasando el dataframe names().Aquí están TODOS los nombres de las columnas en linelist en este punto de la cadena de limpieza:","code":"\nnames(linelist)##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_onset\"          \n##  [5] \"date_hospitalisation\" \"date_outcome\"         \"outcome\"              \"gender\"              \n##  [9] \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \n## [17] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\""},{"path":"cleaning-data-and-core-functions.html","id":"mantener-las-columnas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Mantener las columnas","text":"Selecciona sólo las columnas que desees conservarEscribe sus nombres en el comando select(), sin comillas. Aparecerán en el dataframe en el orden que indiques. Ten en cuenta que si incluyes una columna que existe, R devolverá un error (véase el uso de any_of() más adelante para evitar un error de este tipo).","code":"\n# linelist dataset is piped through select() command, and names() prints just the column names\nlinelist %>% \n  select(case_id, date_onset, date_hospitalisation, fever) %>% \n  names()  # display the column names## [1] \"case_id\"              \"date_onset\"           \"date_hospitalisation\" \"fever\""},{"path":"cleaning-data-and-core-functions.html","id":"clean_tidyselect","chapter":"8 Limpieza de datos y funciones básicas","heading":"Funciones de ayuda “tidyselect”","text":"Estas funciones de ayuda existen para facilitar la especificación de las columnas conservar, descartar o transformar. Provienen del paquete tidyselect, que se incluye en tidyverse y se basa en la forma en que se seleccionan las columnas en las funciones de dplyr.Por ejemplo, si deseas reordenar las columnas, everything() es una función útil para indicar “todas las demás columnas mencionadas”. El comando siguiente mueve las columnas date_onset y date_hospitalisation al principio (izquierda) de los datos, pero mantiene todas las demás columnas después. Fíjate en que everything() se escribe con paréntesis vacíos:Aquí hay otras funciones de ayuda “tidyselect” que también funcionan dentro de las funciones de dplyr como select(), across() y summarise():everything() - todas las demás columnas mencionadaslast_col() - la última columnawhere() - aplica una función todas las columnas y selecciona las que son TRUEcontains() - columnas que contienen una cadena de caracteres\nejemplo: select(contains(\"time\"))\nejemplo: select(contains(\"time\"))starts_with() - coincide con un prefijo especificado\nejemplo: select(starts_with(\"date_\"))\nejemplo: select(starts_with(\"date_\"))ends_with() - coincide con un sufijo especificado\nejemplo: select(ends_with(\"_post))\nejemplo: select(ends_with(\"_post))matches() - para aplicar una expresión regular (regex)\nejemplo: select(matches(\"[pt]al\"))\nejemplo: select(matches(\"[pt]al\"))num_range() - un rango numérico como x01, x02, x03any_of() - coincide con la columna SI existe pero devuelve ningún error si se encuentra\nejemplo: select(any_of(date_onset, date_death,     cardiac_arrest))\nejemplo: select(any_of(date_onset, date_death,     cardiac_arrest))Además, utiliza operadores normales como c() para listar varias columnas, : para columnas consecutivas, ! para opuestas, & para “Y” y | para “O”.Utiliza () para especificar criterios lógicos para las columnas. Si escribes una función dentro de (), incluyas los paréntesis vacíos de la función. El comando siguiente selecciona las columnas de tipo Numeric.Utiliza contains() para seleccionar sólo las columnas en las que el nombre de la columna contiene una cadena de caracteres especificada. ends_with() y starts_with() proporcionan más matices.La función matches() funciona de forma similar contains(), pero puede escribirse en una expresión regular (mira la página sobre Caracteres y cadenas), como varias cadenas separadas por barras “O” dentro de los paréntesis:ATENCIÓN: Si escrito un nombre de columna y existen datos para ella, puede devolver un error y detener tu código. Considera el uso de any_of() para citar columnas que pueden o existir, especialmente útil en selecciones negativas (eliminar). Sólo existe una de estas columnas, pero se produce ningún error y el código continúa sin detener su cadena de limpieza.","code":"\n# move date_onset and date_hospitalisation to beginning\nlinelist %>% \n  select(date_onset, date_hospitalisation, everything()) %>% \n  names()##  [1] \"date_onset\"           \"date_hospitalisation\" \"case_id\"              \"generation\"          \n##  [5] \"date_infection\"       \"date_outcome\"         \"outcome\"              \"gender\"              \n##  [9] \"hospital\"             \"lon\"                  \"lat\"                  \"infector\"            \n## [13] \"source\"               \"age\"                  \"age_unit\"             \"row_num\"             \n## [17] \"wt_kg\"                \"ht_cm\"                \"ct_blood\"             \"fever\"               \n## [21] \"chills\"               \"cough\"                \"aches\"                \"vomit\"               \n## [25] \"temp\"                 \"time_admission\"       \"merged_header\"        \"x28\"\n# select columns that are class Numeric\nlinelist %>% \n  select(where(is.numeric)) %>% \n  names()## [1] \"generation\" \"lon\"        \"lat\"        \"row_num\"    \"wt_kg\"      \"ht_cm\"      \"ct_blood\"  \n## [8] \"temp\"\n# select columns containing certain characters\nlinelist %>% \n  select(contains(\"date\")) %>% \n  names()## [1] \"date_infection\"       \"date_onset\"           \"date_hospitalisation\" \"date_outcome\"\n# searched for multiple character matches\nlinelist %>% \n  select(matches(\"onset|hosp|fev\")) %>%   # note the OR symbol \"|\"\n  names()## [1] \"date_onset\"           \"date_hospitalisation\" \"hospital\"             \"fever\"\nlinelist %>% \n  select(any_of(c(\"date_onset\", \"village_origin\", \"village_detection\", \"village_residence\", \"village_travel\"))) %>% \n  names()## [1] \"date_onset\""},{"path":"cleaning-data-and-core-functions.html","id":"eliminar-columnas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Eliminar columnas","text":"Indica qué columnas se van eliminar colocando el símbolo “-” delante del nombre de la columna (por ejemplo, select(-outcome)), o un vector de nombres de columnas (como se indica continuación). Todas las demás columnas se mantendrán.También puedes eliminar una columna utilizando la sintaxis de R base, definiéndola como NULL. Por ejemplo:","code":"\nlinelist %>% \n  select(-c(date_onset, fever:vomit)) %>% # remove date_onset and all columns from fever to vomit\n  names()##  [1] \"case_id\"              \"generation\"           \"date_infection\"       \"date_hospitalisation\"\n##  [5] \"date_outcome\"         \"outcome\"              \"gender\"               \"hospital\"            \n##  [9] \"lon\"                  \"lat\"                  \"infector\"             \"source\"              \n## [13] \"age\"                  \"age_unit\"             \"row_num\"              \"wt_kg\"               \n## [17] \"ht_cm\"                \"ct_blood\"             \"temp\"                 \"time_admission\"      \n## [21] \"merged_header\"        \"x28\"\nlinelist$date_onset <- NULL   # deletes column with base R syntax "},{"path":"cleaning-data-and-core-functions.html","id":"independiente","chapter":"8 Limpieza de datos y funciones básicas","heading":"Independiente","text":"select() también puede utilizarse como un comando independiente (en una cadena de tuberías). En este caso, el primer argumento es el dataframe original sobre el que se va operar.","code":"\n# Create a new linelist with id and age-related columns\nlinelist_age <- select(linelist, case_id, contains(\"age\"))\n\n# display the column names\nnames(linelist_age)## [1] \"case_id\"  \"age\"      \"age_unit\""},{"path":"cleaning-data-and-core-functions.html","id":"añadir-a-la-cadena-de-tuberías","chapter":"8 Limpieza de datos y funciones básicas","heading":"Añadir a la cadena de tuberías","text":"En linelist_raw, hay algunas columnas que necesitamos: row_num, merged_header y x28. Las eliminamos con un comando select() en la cadena de tuberías de limpieza:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n\n    # remove column\n    select(-c(row_num, merged_header, x28))"},{"path":"cleaning-data-and-core-functions.html","id":"deduplication","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.6 De-duplicación","text":"Consulta la página sobre de-duplicación para ver la cantidad de opciones sobre cómo eliminar las duplicidades (de-duplicar). Aquí sólo se presenta un ejemplo muy sencillo de de-duplicación de filas.El paquete dplyr ofrece la función distinct(). Esta función examina cada fila y reduce el dataframe con sólo filas únicas. Es decir, elimina las filas que están 100% duplicadas.Al evaluar las filas duplicadas, tiene en cuenta un rango de columnas - por defecto considera todas las columnas. Como se muestra en la página de de-duplicación, puedes ajustar este rango de columnas para que la singularidad de las filas sólo se evalúe con respecto determinadas columnas.En este sencillo ejemplo, simplemente añadimos el comando vacío distinct() la cadena de tuberías. Esto garantiza que haya filas que estén 100% duplicadas de otras filas (evaluadas en todas las columnas).Comenzamos con nrow(linelist) filas en linelist.Después de la de-duplicación hay nrow(linelist) filas. Las filas eliminadas habrían sido 100% duplicados de otras filas.continuación, se añade el comando distinct() la cadena de tuberías de limpieza:","code":"\nlinelist <- linelist %>% \n  distinct()\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    #####################################################\n    \n    # de-duplicate\n    distinct()"},{"path":"cleaning-data-and-core-functions.html","id":"column-creation-and-transformation","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.7 Creación y transformación de columnas","text":"Recomendamos utilizar la función mutate() de dplyr para añadir una nueva columna, o para modificar una existente.continuación se muestra un ejemplo de creación de una nueva columna con mutate(). La sintaxis es: mutate(nombre_nueva_columna = valor o transformación)En Stata, esto es similar al comando generate, pero también se puede utilizar mutate() de R para modificar una columna existente.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"nuevas-columnas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Nuevas columnas","text":"El comando más básico de mutate() para crear una nueva columna podría tener este aspecto. Crea una nueva columna new_col donde el valor en cada fila es 10.También puedes referenciar valores en otras columnas, para realizar cálculos. continuación, se crea una nueva columna bmi para mantener el Índice de Masa Corporal (BMI) de cada caso - calculado mediante la fórmula BMI = kg/m^2, utilizando la columnas ht_cm y wt_kg.Si creas varias columnas nuevas, separa cada una con una coma y una nueva línea. continuación se muestran ejemplos de nuevas columnas, incluidas las que consisten en valores de otras columnas combinadas mediante str_glue() del paquete stringr (véase la página sobre Caracteres y cadenas.Revisa las columnas nuevas. efectos de demostración, sólo se muestran las columnas nuevas y las utilizadas para crearlas:CONSEJO: Una variación de mutate() es la función transmute(). Esta función añade una nueva columna al igual que mutate(), pero también elimina todas las demás columnas que se mencionan dentro de sus paréntesis. ","code":"\nlinelist <- linelist %>% \n  mutate(new_col = 10)\nlinelist <- linelist %>% \n  mutate(bmi = wt_kg / (ht_cm/100)^2)\nnew_col_demo <- linelist %>%                       \n  mutate(\n    new_var_dup    = case_id,             # new column = duplicate/copy another existing column\n    new_var_static = 7,                   # new column = all values the same\n    new_var_static = new_var_static + 5,  # you can overwrite a column, and it can be a calculation using other variables\n    new_var_paste  = stringr::str_glue(\"{hospital} on ({date_hospitalisation})\") # new column = pasting together values from other columns\n    ) %>% \n  select(case_id, hospital, date_hospitalisation, contains(\"new\"))        # show only new columns, for demonstration purposes\n# HIDDEN FROM READER\n# removes new demo columns created above\n# linelist <- linelist %>% \n#   select(-contains(\"new_var\"))"},{"path":"cleaning-data-and-core-functions.html","id":"convertir-el-tipo-de-columna","chapter":"8 Limpieza de datos y funciones básicas","heading":"Convertir el tipo de columna","text":"Las columnas que contienen valores que son fechas, números o valores lógicos (TRUE/FALSE) sólo se comportarán como se espera si están correctamente clasificadas. Hay una diferencia entre “2” de tipo carácter y 2 de tipo numérico!Hay formas de establecer el tipo de la columna durante los comandos de importación, pero esto suele ser engorroso. Consulta la sección sobre los tipos de objeto en Fundamentos de R para saber más sobre la conversión de los tipos de objetos y columnas.En primer lugar, vamos realizar algunas comprobaciones en las columnas importantes para ver si son del tipo correcto. También vimos esto al principio cuando ejecutamos skim().Actualmente, el tipo de la columna age es un carácter. Para realizar análisis cuantitativos, ¡necesitamos que estos números sean reconocidos como numéricos!.El tipo de la columna date_onset ¡también es un carácter! Para realizar los análisis, ¡estas fechas deben ser reconocidas como fechas!Para resolver esto, utiliza la capacidad de mutate() para redefinir una columna mediante una transformación. Definimos la columna como ella misma, pero convertida un tipo diferente. aquí un ejemplo básico, convirtiendo o asegurando que la columna age sea de tipo Numeric:De forma similar, puedes utilizar .character() y .logical(). Para convertir al tipo Factor, puedes utilizar factor() de R base o as_factor() de forcats. Lee más sobre esto en la página de Factores.Hay que tener cuidado al convertir al tipo Fecha. En la página Trabajar con fechas se explican varios métodos. Normalmente, los valores de fecha en el fichero crudo deben estar todos en el mismo formato para que la conversión funcione correctamente (por ejemplo, “MM/DD/AAAA”, o “DD MM AAAA”). Después de convertir al tipo Fecha, comprueba tus datos para confirmar que cada valor se ha convertido correctamente.","code":"\nclass(linelist$age)## [1] \"character\"\nclass(linelist$date_onset)## [1] \"character\"\nlinelist <- linelist %>% \n  mutate(age = as.numeric(age))"},{"path":"cleaning-data-and-core-functions.html","id":"datos-agrupados","chapter":"8 Limpieza de datos y funciones básicas","heading":"Datos agrupados","text":"Si tu dataframe ya está agrupado (véase la página sobre Agrupar datos), mutate() puede comportarse de forma diferente que si el dataframe está agrupado. Cualquier función de resumen, como mean(), median(), max(), etc. calculará con datos agrupados, con filas de registros individualizados.Lee más sobre el uso de mutate() sobre dataframes agrupados en esta documentación mutate de tidyverse.","code":"\n# age normalized to mean of ALL rows\nlinelist %>% \n  mutate(age_norm = age / mean(age, na.rm=T))\n\n# age normalized to mean of hospital group\nlinelist %>% \n  group_by(hospital) %>% \n  mutate(age_norm = age / mean(age, na.rm=T))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_across","chapter":"8 Limpieza de datos y funciones básicas","heading":"Transformar múltiples columnas","text":"menudo, para escribir un código conciso, se desea aplicar la misma transformación varias columnas la vez. Se puede aplicar una transformación varias columnas la vez utilizando la función across() del paquete dplyr (también contenido en el paquete tidyverse). across() se puede utilizar con cualquier función de dplyr, pero se suele utilizar dentro de select(), mutate(), filter() o summarise(). Mira cómo se aplica summarise() en la página sobre Tablas descriptivas.Especificar los argumentos de las columnas .cols = y la(s) función(es) aplicar .fns =. Cualquier argumento adicional la función .fns puede incluirse después de una coma, todavía dentro de across().","code":""},{"path":"cleaning-data-and-core-functions.html","id":"selección-de-columnas-con-across","chapter":"8 Limpieza de datos y funciones básicas","heading":"Selección de columnas con across()","text":"Especificar las columnas de .cols =. Puedes nombrarlas individualmente, o utilizar funciones de ayuda “tidyselect”. Especifica la función en .fns =. Ten en cuenta que, utilizando el modo de función mostrado continuación, la función se escribe sin sus paréntesis ().Aquí la transformación .character() se aplica columnas específicas nombradas dentro de across().Las funciones de ayuda “tidyselect” están disponibles para ayudarle especificar las columnas. Se detallan más arriba en la sección sobre Selección y reordenación de columnas, e incluyen: everything(), last_col(), (), starts_with(), ends_with(), contains(), matches(), num_range() y any_of().Este es un ejemplo de cómo se pueden cambiar todas las columnas al tipo carácter:Convertir en caracteres todas las columnas cuyo nombre contenga la cadena “date” (fíjate en la colocación de comas y paréntesis):continuación, un ejemplo de mutación de las columnas que actualmente son de tipo POSIXct (un tipo datetime cruda que muestra etiquetas) - en otras palabras, donde la función .POSIXct() evalúa TRUE. Entonces queremos convertirlas con la función .Date() en columnas de tipo Date normal.Ten en cuenta que dentro de across() también utilizamos la función () como .POSIXct está evaluando TRUE o FALSE.Ten en cuenta que dentro de across() también utilizamos la función () como .POSIXct está evaluando TRUE o FALSE.Ten en cuenta que .POSIXct() es del paquete lubridate. Otras funciones “” similares como .character(), .numeric(), e .logical() son de R baseTen en cuenta que .POSIXct() es del paquete lubridate. Otras funciones “” similares como .character(), .numeric(), e .logical() son de R base","code":"\nlinelist <- linelist %>% \n  mutate(across(.cols = c(temp, ht_cm, wt_kg), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = everything(), .fns = as.character))\n#to change all columns to character class\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"date\"), .fns = as.character))\nlinelist <- linelist %>% \n  mutate(across(.cols = where(is.POSIXct), .fns = as.Date))"},{"path":"cleaning-data-and-core-functions.html","id":"funciones-across","chapter":"8 Limpieza de datos y funciones básicas","heading":"funciones across()","text":"Puedes leer la documentación de ayuda con detalles sobre cómo proporcionar funciones across() escribiendo ?across: hay varias formas de especificar la(s) función(es) realizar en una columna e incluso puedes definir tus propias funciones:Puedes escribir el nombre de la función sola (por ejemplo, mean o .character)Puedes escribir la función en estilo purrr (por ejemplo, ~ mean(.x, na.rm = TRUE)) (mira esta página)Puedes especificar varias funciones escribiendo una lista (por ejemplo, list(mean = mean, n_miss = ~ sum(.na(.x))). * Si proporcionas varias funciones, se devolverán varias columnas transformadas por cada columna de entrada, con nombres únicos con formato col_fn. Puedes ajustar cómo se nombran las columnas nuevas con el argumento .names = utilizando la sintaxis glue (mira la página sobre Caracteres y cadenas) donde {.col} y {.fn} son la abreviatura de la columna de entrada y la función.Aquí hay algunos recursos en línea sobre el uso de across(): pensamientos/razones del creador Hadley Wickham","code":""},{"path":"cleaning-data-and-core-functions.html","id":"coalesce","chapter":"8 Limpieza de datos y funciones básicas","heading":"coalesce()","text":"Esta función de dplyr encuentra el primer valor missing en cada posición. Rellena los valores que faltan con el primer valor disponible en el orden que especifiques.Aquí hay un ejemplo fuera del contexto de un dataframe: Supongamos que tienes dos vectores, uno que contiene el pueblo de detección del paciente y otro que contiene el pueblo de residencia del paciente. Puedes utilizar coalesce para elegir el primer valor ausente de cada índice:Esto funciona de la misma manera si se proporcionan columnas del dataframe: para cada fila, la función asignará el nuevo valor de la columna con el primer valor que falte en las columnas proporcionadas (en el orden indicado).Este es un ejemplo de operación “por filas”. Para cálculos más complicados por filas, consulta la sección siguiente sobre cálculos por filas.","code":"\nvillage_detection <- c(\"a\", \"b\", NA,  NA)\nvillage_residence <- c(\"a\", \"c\", \"a\", \"d\")\n\nvillage <- coalesce(village_detection, village_residence)\nvillage    # print## [1] \"a\" \"b\" \"a\" \"d\"\nlinelist <- linelist %>% \n  mutate(village = coalesce(village_detection, village_residence))"},{"path":"cleaning-data-and-core-functions.html","id":"matemáticas-acumulativas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Matemáticas acumulativas","text":"Si deseas que una columna refleje acumulados la sum/mean/min/max, etc., tal y como se ha evaluado en las filas de un dataframe hasta ese punto, utiliza las siguientes funciones:cumsum() devuelve la suma acumulada, como se muestra continuación:Esto se puede utilizar en un dataframe al crear una nueva columna. Por ejemplo, para calcular el número acumulado de casos por día en un brote, considere un código como este:continuación se muestran las 10 primeras filas:Consulta la página sobre curvas epidémicas para saber cómo representar la incidencia acumulada con epicurve.Véase también:cumsum(), cummean(), cummin(), cummax(), cumany(), cumall()","code":"\nsum(c(2,4,15,10))     # returns only one number## [1] 31\ncumsum(c(2,4,15,10))  # returns the cumulative sum at each step## [1]  2  6 21 31\ncumulative_case_counts <- linelist %>%  # begin with case linelist\n  count(date_onset) %>%                 # count of rows per day, as column 'n'   \n  mutate(cumulative_cases = cumsum(n))  # new column, of the cumulative sum at each row\nhead(cumulative_case_counts, 10)##    date_onset n cumulative_cases\n## 1  2012-04-15 1                1\n## 2  2012-05-05 1                2\n## 3  2012-05-08 1                3\n## 4  2012-05-31 1                4\n## 5  2012-06-02 1                5\n## 6  2012-06-07 1                6\n## 7  2012-06-14 1                7\n## 8  2012-06-21 1                8\n## 9  2012-06-24 1                9\n## 10 2012-06-25 1               10"},{"path":"cleaning-data-and-core-functions.html","id":"utilizando-r-base","chapter":"8 Limpieza de datos y funciones básicas","heading":"Utilizando R base","text":"Para definir una nueva columna (o redefinir una columna) utilizando R base, escribe el nombre del dataframe, conectado con $, la nueva columna (o la columna modificar). Utiliza el operador de asignación <- para definir el nuevo valor o valores. Recuerda que al usar R base debes especificar siempre el nombre del dataframe antes del nombre de la columna (por ejemplo, dataframe$column). Este es un ejemplo de creación de la columna bmi usando R base:","code":"linelist$bmi = linelist$wt_kg / (linelist$ht_cm / 100) ^ 2)"},{"path":"cleaning-data-and-core-functions.html","id":"añadir-a-la-cadena-de-tuberías-1","chapter":"8 Limpieza de datos y funciones básicas","heading":"Añadir a la cadena de tuberías","text":"continuación, se añade una nueva columna la cadena de tuberías y se convierten algunos tipos.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    # add new column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>% \n  \n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) "},{"path":"cleaning-data-and-core-functions.html","id":"re-code-values","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.8 Recodificar valores","text":"continuación, se presentan algunos escenarios en los que es necesario recodificar (cambiar) los valores:para editar un valor específico (por ejemplo, una fecha con un año o formato incorrecto)para conciliar valores que se escriben igualpara crear una nueva columna de valores categóricospara crear una nueva columna de categorías numéricas (por ejemplo, categorías de edad)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"valores-específicos","chapter":"8 Limpieza de datos y funciones básicas","heading":"Valores específicos","text":"Para cambiar los valores manualmente puedes utilizar la función recode() dentro de la función mutate().Imagínate que hay una fecha sin sentido en los datos (por ejemplo, “2014-14-15”): podrías corregir la fecha manualmente en los datos originales, o bien, podrías escribir el cambio en la serie de comandos de limpieza través de mutate() y recode(). Esto último es más transparente y reproducible para cualquier otra persona que quiera entender o repetir su análisis.La línea mutate() anterior puede leerse como: “mutar la columna date_onset para que sea igual la columna date_onset recodificada de forma que el VALOR ANTIGUO se cambie por el NUEVO VALOR”. Ten en cuenta que este patrón (VIEJO = NUEVO) para recode() es el opuesto la mayoría de los patrones de R (nuevo = viejo). La comunidad de desarrollo de R está trabajando en la revisión de esto.Aquí hay otro ejemplo de recodificación de múltiples valores dentro de una columna.En linelist hay que limpiar los valores de la columna “hospital”. Hay varias grafías diferentes y muchos valores que faltan.El comando recode() de abajo redefine la columna “hospital” como la columna actual “hospital”, pero con los cambios especificados en la recodificación. ¡olvides las comas después de cada uno!Ahora vemos que se han corregido y consolidado las grafías de la columna hospital:CONSEJO: El número de espacios antes y después de un signo de igualdad importa. Haz que tu código sea más fácil de leer alineando el signo = para todas o la mayoría de las filas. Además, considera la posibilidad de añadir una fila de comentarios con hash (#) para aclarar los futuros lectores qué lado es VIEJO y qué lado es NUEVO. CONSEJO: veces existe un valor con caracteres en blanco en unos datos (reconocido como valor Missing - NA de R. Puedes hacer referencia este valor con dos comillas sin espacio intermedio (““). ","code":"\n# fix incorrect values                   # old value       # new value\nlinelist <- linelist %>% \n  mutate(date_onset = recode(date_onset, \"2014-14-15\" = \"2014-04-15\"))\ntable(linelist$hospital, useNA = \"always\")  # print table of all unique values, including missing  ## \n##                      Central Hopital                     Central Hospital \n##                                   11                                  457 \n##                           Hospital A                           Hospital B \n##                                  290                                  289 \n##                     Military Hopital                    Military Hospital \n##                                   32                                  798 \n##                     Mitylira Hopital                    Mitylira Hospital \n##                                    1                                   79 \n##                                Other                         Port Hopital \n##                                  907                                   48 \n##                        Port Hospital St. Mark's Maternity Hospital (SMMH) \n##                                 1756                                  417 \n##   St. Marks Maternity Hopital (SMMH)                                 <NA> \n##                                   11                                 1512\nlinelist <- linelist %>% \n  mutate(hospital = recode(hospital,\n                     # for reference: OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      ))\ntable(linelist$hospital, useNA = \"always\")## \n##                     Central Hospital                           Hospital A \n##                                  468                                  290 \n##                           Hospital B                    Military Hospital \n##                                  289                                  910 \n##                                Other                        Port Hospital \n##                                  907                                 1804 \n## St. Mark's Maternity Hospital (SMMH)                                 <NA> \n##                                  428                                 1512"},{"path":"cleaning-data-and-core-functions.html","id":"por-lógica","chapter":"8 Limpieza de datos y funciones básicas","heading":"Por lógica","text":"continuación, demostramos cómo recodificar los valores de una columna utilizando lógica y condiciones:Uso de replace(), ifelse() e if_else() para una lógica simpleUso de case_when() para una lógica más compleja","code":""},{"path":"cleaning-data-and-core-functions.html","id":"lógica-simple","chapter":"8 Limpieza de datos y funciones básicas","heading":"Lógica simple","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"sustituir-con-replace","chapter":"8 Limpieza de datos y funciones básicas","heading":"sustituir con replace()","text":"Para recodificar con criterios lógicos simples, puedes utilizar replace() dentro de mutate(). replace() es una función de R base. Utiliza una condición lógica para especificar las filas cambiar. La sintaxis general es:mutate(col_to_change = replace(col_a_cambiar, criterio para filas, nuevo valor)).Una situación frecuente es utilizar replace() para cambiar sólo un valor en una fila, utilizando un identificador de fila único. continuación, el género se cambia “Mujer” en la fila donde la columna case_id es “2195”.Abajo se puede ver un ejemplo equivalente utilizando la sintaxis de R base y los paréntesis de indexación [ ]. Se lee como “Cambia el valor de la columna gender del dataframe linelist ‘Female’” (para las filas en las que la columna case_id de linelist tiene el valor ‘2195’).","code":"\n# Example: change gender of one specific observation to \"Female\" \nlinelist <- linelist %>% \n  mutate(gender = replace(gender, case_id == \"2195\", \"Female\"))\nlinelist$gender[linelist$case_id == \"2195\"] <- \"Female\""},{"path":"cleaning-data-and-core-functions.html","id":"ifelse-e-if_else","chapter":"8 Limpieza de datos y funciones básicas","heading":"ifelse() e if_else()","text":"Otra herramienta para la lógica simple es ifelse() y su compañero if_else(). Sin embargo, en la mayoría de los casos para la recodificación es más claro utilizar case_when() (detallado continuación). Estos comandos “else” son versiones simplificadas de una sentencia de programación y else. La sintaxis general es:ifelse(condición, valor devolver si la condición evalúa como TRUE, valor devolver si la condición evalúa como FALSE)continuación, se define la columna source_known. Su valor en una fila determinada se establece como “known” si falta el valor de la fila en la columna source. Si falta el valor en source, el valor de source_known se establece como “unknown”.if_else() es una versión especial de dplyr que maneja fechas. Ten en cuenta que, si el valor “verdadero” es una fecha, el valor “falso” también debe calificar una fecha, de ahí que se utilice el valor especial NA_real_ en lugar de simplemente NA.Evita encadenar muchos comandos ifelse… ¡utilza case_when() en su lugar! case_when() es mucho más fácil de leer y cometerás menos errores.Fuera del contexto de un dataframe, si deseas que un objeto utilizado en su código cambie su valor, considere el uso de switch() de R base.","code":"\nlinelist <- linelist %>% \n  mutate(source_known = ifelse(!is.na(source), \"known\", \"unknown\"))\n# Create a date of death column, which is NA if patient has not died.\nlinelist <- linelist %>% \n  mutate(date_death = if_else(outcome == \"Death\", date_outcome, NA_real_))"},{"path":"cleaning-data-and-core-functions.html","id":"clean_case_when","chapter":"8 Limpieza de datos y funciones básicas","heading":"Lógica compleja","text":"Utiliza case_when() de dplyr si estás recodificando en muchos grupos nuevos, o si necesita utilizar sentencias lógicas complejas para recodificar valores. Esta función evalúa si cada fila del dataframe cumple los criterios especificados y asigna el nuevo valor correcto.Los comandos case_when() consisten en sentencias que tienen un lado derecho (RHS) y un lado izquierdo (LHS) separados por una “tilde” ~ (cola de chancho). Los criterios lógicos están en el lado izquierdo y los valores de conformidad están en el lado derecho de cada sentencia. Las declaraciones están separadas por comas.Por ejemplo, aquí utilizamos las columnas age y age_unit para crear una columna age_years:medida que se evalúa cada fila de los datos, los criterios se aplican/evalúan en el orden en que se escriben las sentencias case_when(), de arriba abajo. Si el criterio superior se evalúa como TRUE para una fila determinada, se asigna el valor RHS, y los criterios restantes ni siquiera se prueban para esa fila. Por lo tanto, es mejor escribir los criterios más específicos primero y los más generales al final. una fila de datos que cumpla ninguno de los criterios del RHS se le asignará NA.En esta línea, en su declaración final, coloca TRUE en el lado izquierdo, lo que capturará cualquier fila que cumpla ninguno de los criterios anteriores. Al lado derecho de esta declaración se le podría asignar un valor como “¡comprobado!” o faltante.continuación se muestra otro ejemplo de case_when() utilizado para crear una nueva columna con la clasificación del paciente, según una definición de caso para los casos confirmados y sospechosos:PELIGRO: Los valores del lado derecho deben ser todos del mismo tipo: numéricos, de caracteres, de fecha, lógicos, etc. Para asignar faltantes (NA), puede ser necesario utilizar variaciones especiales de NA como NA_character_, NA_real_ (para numérico o POSIX), y .Date(NA). Lee más en Trabajar con fechas. ","code":"\nlinelist <- linelist %>% \n  mutate(age_years = case_when(\n            age_unit == \"years\"  ~ age,       # if age is given in years\n            age_unit == \"months\" ~ age/12,    # if age is given in months\n            is.na(age_unit)      ~ age))      # if age unit is missing, assume years\n                                              # any other circumstance, assign NA (missing)\nlinelist <- linelist %>% \n     mutate(case_status = case_when(\n          \n          # if patient had lab test and it is positive,\n          # then they are marked as a confirmed case \n          ct_blood < 20                   ~ \"Confirmed\",\n          \n          # given that a patient does not have a positive lab result,\n          # if patient has a \"source\" (epidemiological link) AND has fever, \n          # then they are marked as a suspect case\n          !is.na(source) & fever == \"yes\" ~ \"Suspect\",\n          \n          # any other patient not addressed above \n          # is marked for follow up\n          TRUE                            ~ \"To investigate\"))"},{"path":"cleaning-data-and-core-functions.html","id":"valores-faltantes","chapter":"8 Limpieza de datos y funciones básicas","heading":"Valores faltantes","text":"continuación, se presentan funciones especiales para el tratamiento de los valores faltantes en el contexto de la limpieza de datos.Consulta la página sobre Valores faltantes para obtener consejos más detallados sobre la identificación y el tratamiento de los valores faltantes. Por ejemplo, la función .na() que comprueba lógicamente la ausencia de datos.replace_na()Para cambiar los valores faltantes (NA) por un valor específico, como “Missing”, utiliza la función de dplyr replace_na() dentro de mutate(). Ten en cuenta que se utiliza de la misma manera que recodificar anteriormente - el nombre de la variable debe repetirse dentro de replace_na().fct_explicit_na()Esta es una función del paquete forcats. El paquete forcats maneja columnas del tipo Factor. Los factores son la forma en que R maneja valores ordenados como c(\"First\", \"Second\", \"Third\") o para establecer el orden en que los valores (por ejemplo, hospitales) aparecen en las tablas y gráficos. Vea la página sobre Factores.Si tus datos son del tipo Factor y tratas de convertir NA en “Missing” utilizando replace_na(), obtendrás este error: invalid factor level, NA generated (nivel de factor válido, NA generado). intentado añadir “Missing” como valor, cuando estaba definido como un posible nivel del factor, y ha sido rechazado.La forma más fácil de resolver esto es utilizar la función fct_explicit_na() de forcats que convierte una columna en factor de tipo, y convierte los valores NA en el carácter “(Missing)”.Una alternativa más lenta sería añadir el nivel del factor utilizando fct_expand() y luego convertir los valores que faltan.na_if()Para convertir un valor específico en NA, utiliza na_if() de dplyr. El comando siguiente realiza la operación opuesta replace_na(). En el siguiente ejemplo, cualquier valor de “Missing” en la columna hospital se convierte en NA.Nota: na_if() puede utilizarse para criterios lógicos (por ejemplo, “todos los valores > 99”) - utiliza replace() o case_when() para ello:","code":"\nlinelist <- linelist %>% \n  mutate(hospital = replace_na(hospital, \"Missing\"))\nlinelist %>% \n  mutate(hospital = fct_explicit_na(hospital))\nlinelist <- linelist %>% \n  mutate(hospital = na_if(hospital, \"Missing\"))\n# Convert temperatures above 40 to NA \nlinelist <- linelist %>% \n  mutate(temp = replace(temp, temp > 40, NA))\n\n# Convert onset dates earlier than 1 Jan 2000 to missing\nlinelist <- linelist %>% \n  mutate(date_onset = replace(date_onset, date_onset > as.Date(\"2000-01-01\"), NA))"},{"path":"cleaning-data-and-core-functions.html","id":"diccionario-de-limpieza","chapter":"8 Limpieza de datos y funciones básicas","heading":"Diccionario de limpieza","text":"Utiliza el paquete R matchmaker y su función match_df() para limpiar un dataframe con un diccionario de limpieza.Crear un diccionario de limpieza con 3 columnas:\nUna columna “desde” (el valor incorrecto)\nUna columna “para” (el valor correcto)\nUna columna que especifica la columna la que se aplicarán los cambios (o “.global” para aplicarlo todas las columnas)\nUna columna “desde” (el valor incorrecto)Una columna “para” (el valor correcto)Una columna que especifica la columna la que se aplicarán los cambios (o “.global” para aplicarlo todas las columnas)Nota: Las entradas del diccionario .global serán anuladas por las entradas del diccionario específico de la columna.Importa el archivo del diccionario R. Este ejemplo puede descargarse través de las instrucciones de la página Descargar manual y datos.Pasa linelist crudas match_df(), especificando en dictionary = el dataframe del diccionario de limpieza. El argumento = debe ser el nombre de la columna del diccionario que contiene los valores “originales”, el argumento = debe ser la columna del diccionario que contiene los correspondientes valores “nuevos”, y la tercera columna enumera la columna en la que se realizará el cambio. Utilice .global en la columna = para aplicar un cambio en todas las columnas. Una cuarta columna del diccionario order se puede utilizar para especificar el orden del factor de los nuevos valores.Ahora desplázate la derecha para ver cómo han cambiado los valores - en particular el gender (de minúsculas mayúsculas), y todas las columnas de síntomas se han transformado de sí/1/0.Ten en cuenta que los nombres de las columnas en el diccionario de limpieza deben corresponder los nombres en este punto de tu script de limpieza. Consulta esta referencia en línea para el paquete linelist para obtener más detalles.","code":"\ncleaning_dict <- import(\"cleaning_dict.csv\")\nlinelist <- linelist %>%     # provide or pipe your dataset\n     matchmaker::match_df(\n          dictionary = cleaning_dict,  # name of your dictionary\n          from = \"from\",               # column with values to be replaced (default is col 1)\n          to = \"to\",                   # column with final values (default is col 2)\n          by = \"col\"                   # column with column names (default is col 3)\n  )"},{"path":"cleaning-data-and-core-functions.html","id":"añadir-a-la-cadena-de-tuberías-2","chapter":"8 Limpieza de datos y funciones básicas","heading":"Añadir a la cadena de tuberías","text":"continuación, se añaden algunas columnas y transformaciones de columna nuevas la cadena de tuberías.","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n  \n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n   # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n   ###################################################\n\n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age))"},{"path":"cleaning-data-and-core-functions.html","id":"num_cats","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.9 Categorías numéricas","text":"Aquí describimos algunos enfoques especiales para crear categorías partir de columnas numéricas. Algunos ejemplos comunes son las categorías de edad, los grupos de valores de laboratorio, etc. Aquí discutiremos:age_categories(), del paquete epikitcut(), de R basecase_when()ruptura de cuantiles con quantile() y ntile()","code":""},{"path":"cleaning-data-and-core-functions.html","id":"revisión-de-la-distribución","chapter":"8 Limpieza de datos y funciones básicas","heading":"Revisión de la distribución","text":"Para este ejemplo crearemos una columna age_cat utilizando la columna age_years.En primer lugar, examina la distribución de tus datos, para hacer los puntos de corte apropiados. Consulta la página sobre Conceptos básicos de ggplot.ATENCIÓN: veces, las variables numéricas se importarán como tipo “carácter”. Esto ocurre si hay caracteres numéricos en algunos de los valores, por ejemplo, una entrada de “2 meses” para la edad, o (dependiendo de la configuración de su configuración local de R) si se utiliza una coma en el lugar de los decimales (por ejemplo, “4,5” para significar cuatro años y medio). ","code":"\n#check the class of the linelist variable age\nclass(linelist$age_years)## [1] \"numeric\"\n# examine the distribution\nhist(linelist$age_years)\nsummary(linelist$age_years, na.rm=T)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.04   23.00   84.00     107"},{"path":"cleaning-data-and-core-functions.html","id":"age_categories","chapter":"8 Limpieza de datos y funciones básicas","heading":"age_categories()","text":"Con el paquete epikit, puedes utilizar la función age_categories() para categorizar y etiquetar fácilmente las columnas numéricas (nota: esta función puede aplicarse también las variables numéricas relacionadas con la edad). Además, la columna de salida es automáticamente un factor ordenado.Aquí están las entradas requeridas:Un vector numérico (columna)El argumento + breakers = ` - proporciona un vector numérico de puntos de ruptura para los nuevos gruposPrimero, el ejemplo más sencillo:Los valores de ruptura que especificas son por defecto los límites inferiores - es decir, están incluidos en el grupo “superior” / los grupos están “abiertos” en la parte inferior/izquierda. Como se muestra continuación, puedes añadir 1 cada valor de ruptura para conseguir grupos que estén abiertos por la parte superior/derecha.Puedes ajustar cómo se muestran las etiquetas con el separator =. El valor predeterminado es “-”Puedes ajustar cómo se manejan los números superiores, con el argumento ceiling =. Para establecer un corte superior establezca ceiling = TRUE. En este uso, el valor de ruptura más alto proporcionado es un “techo” y se crea una categoría “XX+”. Cualquier valor por encima del valor de corte más alto (o hasta el límite upper =, si está definido) se categoriza como NA. continuación, se muestra un ejemplo con ceiling = TRUE, de modo que hay categoría de XX+ y los valores por encima de 70 (el valor de ruptura más alto) se asignan como NA.Alternativamente, en lugar de los breakers =, puedes proporcionar todos los lower =, upper =, =:lower = El número más bajo que se quiere considerar - por defecto es 0upper = El número más alto que quiere que se considereby = El número de años entre los gruposConsulta la página de ayuda de la función para más detalles (escribe ?age_categories en la consola de R).","code":"\n# Simple example\n################\npacman::p_load(epikit)                    # load package\n\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(             # create new column\n      age_years,                            # numeric column to make groups from\n      breakers = c(0, 5, 10, 15, 20,        # break points\n                   30, 40, 50, 60, 70)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-69   70+  <NA> \n##  1227  1223  1048   827  1216   597   251    78    27     7   107\n# Include upper ends for the same categories\n############################################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 6, 11, 16, 21, 31, 41, 51, 61, 71)))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-5  6-10 11-15 16-20 21-30 31-40 41-50 51-60 61-70   71+  <NA> \n##  1469  1195  1040   770  1149   547   231    70    24     6   107\n# With ceiling set to TRUE\n##########################\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      breakers = c(0, 5, 10, 15, 20, 30, 40, 50, 60, 70),\n      ceiling = TRUE)) # 70 is ceiling, all above become NA\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-4   5-9 10-14 15-19 20-29 30-39 40-49 50-59 60-70  <NA> \n##  1227  1223  1048   827  1216   597   251    78    28   113\nlinelist <- linelist %>% \n  mutate(\n    age_cat = age_categories(\n      age_years, \n      lower = 0,\n      upper = 100,\n      by = 10))\n\n# show table\ntable(linelist$age_cat, useNA = \"always\")## \n##   0-9 10-19 20-29 30-39 40-49 50-59 60-69 70-79 80-89 90-99  100+  <NA> \n##  2450  1875  1216   597   251    78    27     6     1     0     0   107"},{"path":"cleaning-data-and-core-functions.html","id":"cut","chapter":"8 Limpieza de datos y funciones básicas","heading":"cut()","text":"cut() es una alternativa age_categories() de R base, pero creo que verás por qué age_categories() se desarrolló para simplificar este proceso. Algunas diferencias notables de age_categories() son:es necesario instalar/cargar otro paquetePuedes especificar si los grupos están abiertos/cerrados la derecha/izquierdaDebes proporcionar etiquetas precisasSi quieres que el 0 se incluya en el grupo más bajo debes especificarloLa sintaxis básica dentro de cut() es proporcionar primero la columna numérica que se va cortar (age_years), y luego el argumento breaks, que es un vector numérico c() de puntos de ruptura. Utilizando cut(), la columna resultante es un factor ordenado.Por defecto, la categorización se produce de manera que el lado derecho/superior es “abierto” e inclusivo (y el lado izquierdo/inferior es “cerrado” o exclusivo). Este es el comportamiento opuesto al de la función age_categories(). Las etiquetas por defecto utilizan la notación “(, B]”, lo que significa que está incluido pero B sí. Invierte este comportamiento proporcionando el argumento right = TRUE.Así, por defecto, ¡los valores “0” se excluyen del grupo más bajo, y se categorizan como NA! Los valores “0” podrían ser codificados para los bebés como edad 0, así que ¡ten cuidado! Para cambiar esto, añade el argumento include.lowest = TRUE para que cualquier valor “0” se incluya en el grupo más bajo. La etiqueta generada automáticamente para la categoría más baja será entonces “[],B]”. Ten en cuenta que si incluye el argumento include.lowest = TRUE y right = TRUE, la inclusión extrema se aplicará ahora al valor del punto de ruptura y la categoría más altos, los más bajos.Puedes proporcionar un vector de etiquetas personalizadas utilizando el argumento labels =. Como se escriben manualmente, ¡ten mucho cuidado de que sean precisas! Comprueba el trabajo utilizando una tabulación cruzada, como se describe continuación.continuación se muestra un ejemplo de cut() aplicado age_years para crear la nueva variable age_cat:¡Comprueba tu trabajo! Verifica que cada valor de edad fue asignado la categoría correcta cruzando las columnas numéricas y de categoría. Examina la asignación de los valores límite (por ejemplo, 15, si las categorías vecinas son 10-15 y 16-20).Re-etiquetado de los valores NAPuedes asignar los valores NA una etiqueta como “Missing”. Como la nueva columna es del tipo Factor (valores restringidos), puedes simplemente mutarla con replace_na(), ya que este valor será rechazado. En su lugar, utilice fct_explicit_na() de forcats como se explica en la página de Factores.Realiza rápidamente pausas y etiquetasPara una forma rápida de hacer rupturas y etiquetar vectores, utiliza algo como lo siguiente. Consulta la página de fundamentos de R para obtener referencias sobre seq() y rep().Lee más sobre cut() en la página de ayuda escribiendo ?cut en la consola de R.","code":"\n# Create new variable, by cutting the numeric age variable\n# lower break is excluded but upper break is included in each category\nlinelist <- linelist %>% \n  mutate(\n    age_cat = cut(\n      age_years,\n      breaks = c(0, 5, 10, 15, 20,\n                 30, 50, 70, 100),\n      include.lowest = TRUE         # include 0 in lowest group\n      ))\n\n# tabulate the number of observations per group\ntable(linelist$age_cat, useNA = \"always\")## \n##    [0,5]   (5,10]  (10,15]  (15,20]  (20,30]  (30,50]  (50,70] (70,100]     <NA> \n##     1469     1195     1040      770     1149      778       94        6      107\n# Cross tabulation of the numeric and category columns. \ntable(\"Numeric Values\" = linelist$age_years,   # names specified in table for clarity.\n      \"Categories\"     = linelist$age_cat,\n      useNA = \"always\")                        # don't forget to examine NA values##                     Categories\n## Numeric Values       [0,5] (5,10] (10,15] (15,20] (20,30] (30,50] (50,70] (70,100] <NA>\n##   0                    136      0       0       0       0       0       0        0    0\n##   0.0833333333333333     1      0       0       0       0       0       0        0    0\n##   0.25                   2      0       0       0       0       0       0        0    0\n##   0.333333333333333      6      0       0       0       0       0       0        0    0\n##   0.416666666666667      1      0       0       0       0       0       0        0    0\n##   0.5                    6      0       0       0       0       0       0        0    0\n##   0.583333333333333      3      0       0       0       0       0       0        0    0\n##   0.666666666666667      3      0       0       0       0       0       0        0    0\n##   0.75                   3      0       0       0       0       0       0        0    0\n##   0.833333333333333      1      0       0       0       0       0       0        0    0\n##   0.916666666666667      1      0       0       0       0       0       0        0    0\n##   1                    275      0       0       0       0       0       0        0    0\n##   1.5                    2      0       0       0       0       0       0        0    0\n##   2                    308      0       0       0       0       0       0        0    0\n##   3                    246      0       0       0       0       0       0        0    0\n##   4                    233      0       0       0       0       0       0        0    0\n##   5                    242      0       0       0       0       0       0        0    0\n##   6                      0    241       0       0       0       0       0        0    0\n##   7                      0    256       0       0       0       0       0        0    0\n##   8                      0    239       0       0       0       0       0        0    0\n##   9                      0    245       0       0       0       0       0        0    0\n##   10                     0    214       0       0       0       0       0        0    0\n##   11                     0      0     220       0       0       0       0        0    0\n##   12                     0      0     224       0       0       0       0        0    0\n##   13                     0      0     191       0       0       0       0        0    0\n##   14                     0      0     199       0       0       0       0        0    0\n##   15                     0      0     206       0       0       0       0        0    0\n##   16                     0      0       0     186       0       0       0        0    0\n##   17                     0      0       0     164       0       0       0        0    0\n##   18                     0      0       0     141       0       0       0        0    0\n##   19                     0      0       0     130       0       0       0        0    0\n##   20                     0      0       0     149       0       0       0        0    0\n##   21                     0      0       0       0     158       0       0        0    0\n##   22                     0      0       0       0     149       0       0        0    0\n##   23                     0      0       0       0     125       0       0        0    0\n##   24                     0      0       0       0     144       0       0        0    0\n##   25                     0      0       0       0     107       0       0        0    0\n##   26                     0      0       0       0     100       0       0        0    0\n##   27                     0      0       0       0     117       0       0        0    0\n##   28                     0      0       0       0      85       0       0        0    0\n##   29                     0      0       0       0      82       0       0        0    0\n##   30                     0      0       0       0      82       0       0        0    0\n##   31                     0      0       0       0       0      68       0        0    0\n##   32                     0      0       0       0       0      84       0        0    0\n##   33                     0      0       0       0       0      78       0        0    0\n##   34                     0      0       0       0       0      58       0        0    0\n##   35                     0      0       0       0       0      58       0        0    0\n##   36                     0      0       0       0       0      33       0        0    0\n##   37                     0      0       0       0       0      46       0        0    0\n##   38                     0      0       0       0       0      45       0        0    0\n##   39                     0      0       0       0       0      45       0        0    0\n##   40                     0      0       0       0       0      32       0        0    0\n##   41                     0      0       0       0       0      34       0        0    0\n##   42                     0      0       0       0       0      26       0        0    0\n##   43                     0      0       0       0       0      31       0        0    0\n##   44                     0      0       0       0       0      24       0        0    0\n##   45                     0      0       0       0       0      27       0        0    0\n##   46                     0      0       0       0       0      25       0        0    0\n##   47                     0      0       0       0       0      16       0        0    0\n##   48                     0      0       0       0       0      21       0        0    0\n##   49                     0      0       0       0       0      15       0        0    0\n##   50                     0      0       0       0       0      12       0        0    0\n##   51                     0      0       0       0       0       0      13        0    0\n##   52                     0      0       0       0       0       0       7        0    0\n##   53                     0      0       0       0       0       0       4        0    0\n##   54                     0      0       0       0       0       0       6        0    0\n##   55                     0      0       0       0       0       0       9        0    0\n##   56                     0      0       0       0       0       0       7        0    0\n##   57                     0      0       0       0       0       0       9        0    0\n##   58                     0      0       0       0       0       0       6        0    0\n##   59                     0      0       0       0       0       0       5        0    0\n##   60                     0      0       0       0       0       0       4        0    0\n##   61                     0      0       0       0       0       0       2        0    0\n##   62                     0      0       0       0       0       0       1        0    0\n##   63                     0      0       0       0       0       0       5        0    0\n##   64                     0      0       0       0       0       0       1        0    0\n##   65                     0      0       0       0       0       0       5        0    0\n##   66                     0      0       0       0       0       0       3        0    0\n##   67                     0      0       0       0       0       0       2        0    0\n##   68                     0      0       0       0       0       0       1        0    0\n##   69                     0      0       0       0       0       0       3        0    0\n##   70                     0      0       0       0       0       0       1        0    0\n##   72                     0      0       0       0       0       0       0        1    0\n##   73                     0      0       0       0       0       0       0        3    0\n##   76                     0      0       0       0       0       0       0        1    0\n##   84                     0      0       0       0       0       0       0        1    0\n##   <NA>                   0      0       0       0       0       0       0        0  107\nlinelist <- linelist %>% \n  \n  # cut() creates age_cat, automatically of class Factor      \n  mutate(age_cat = cut(\n    age_years,\n    breaks = c(0, 5, 10, 15, 20, 30, 50, 70, 100),          \n    right = FALSE,\n    include.lowest = TRUE,        \n    labels = c(\"0-4\", \"5-9\", \"10-14\", \"15-19\", \"20-29\", \"30-49\", \"50-69\", \"70-100\")),\n         \n    # make missing values explicit\n    age_cat = fct_explicit_na(\n      age_cat,\n      na_level = \"Missing age\")  # you can specify the label\n  )    \n\n# table to view counts\ntable(linelist$age_cat, useNA = \"always\")## \n##         0-4         5-9       10-14       15-19       20-29       30-49       50-69      70-100 \n##        1227        1223        1048         827        1216         848         105           7 \n## Missing age        <NA> \n##         107           0\n# Make break points from 0 to 90 by 5\nage_seq = seq(from = 0, to = 90, by = 5)\nage_seq\n\n# Make labels for the above categories, assuming default cut() settings\nage_labels = paste0(age_seq + 1, \"-\", age_seq + 5)\nage_labels\n\n# check that both vectors are the same length\nlength(age_seq) == length(age_labels)"},{"path":"cleaning-data-and-core-functions.html","id":"roturas-cuartílicas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Roturas cuartílicas","text":"En el entendimiento común, los “cuartiles” o “percentiles” suelen referirse un valor por debajo del cual cae una proporción de valores. Por ejemplo, el percentil 95 de las edades en linelist sería la edad por debajo de la cual cae el 95% de las edades.Sin embargo, en el lenguaje común, “cuartiles” y “deciles” también pueden referirse los grupos de datos divididos por igual en 4 o 10 grupos (Ten en cuenta que habrá un punto de ruptura más que un grupo).Para obtener los puntos de ruptura de los cuartiles, se puede utilizar quantile() del paquete stats de R base. Se proporciona un vector numérico (por ejemplo, una columna en unos datos) y un vector de valores de probabilidad numérica que van de 0 1,0. Los puntos de ruptura se devuelven como un vector numérico. Explore los detalles de las metodologías estadísticas escribiendo ?quantile.Si su vector numérico de entrada tiene valores faltantes, es mejor establecer na.rm = TRUEEstablecer names = FALSE para obtener un vector numérico sin nombrePuedes utilizar los resultados de quantile() como puntos de ruptura en age_categories() o cut(). continuación creamos una nueva columna deciles utilizando cut() donde los puntos de ruptura se definen utilizando quantiles() en age_years. continuación, mostramos los resultados utilizando tabyl() de janitor para que puedas ver los porcentajes (véase la página de tablas descriptivas). Observa cómo son exactamente el 10% en cada grupo.","code":"\nquantile(linelist$age_years,               # specify numeric vector to work on\n  probs = c(0, .25, .50, .75, .90, .95),   # specify the percentiles you want\n  na.rm = TRUE)                            # ignore missing values ##  0% 25% 50% 75% 90% 95% \n##   0   6  13  23  33  41\nlinelist %>%                                # begin with linelist\n  mutate(deciles = cut(age_years,           # create new column decile as cut() on column age_years\n    breaks = quantile(                      # define cut breaks using quantile()\n      age_years,                               # operate on age_years\n      probs = seq(0, 1, by = 0.1),             # 0.0 to 1.0 by 0.1\n      na.rm = TRUE),                           # ignore missing values\n    include.lowest = TRUE)) %>%             # for cut() include age 0\n  janitor::tabyl(deciles)                   # pipe to table to display##  deciles   n    percent valid_percent\n##    [0,2] 748 0.11319613    0.11505922\n##    (2,5] 721 0.10911017    0.11090601\n##    (5,7] 497 0.07521186    0.07644978\n##   (7,10] 698 0.10562954    0.10736810\n##  (10,13] 635 0.09609564    0.09767728\n##  (13,17] 755 0.11425545    0.11613598\n##  (17,21] 578 0.08746973    0.08890940\n##  (21,26] 625 0.09458232    0.09613906\n##  (26,33] 596 0.09019370    0.09167820\n##  (33,84] 648 0.09806295    0.09967697\n##     <NA> 107 0.01619249            NA"},{"path":"cleaning-data-and-core-functions.html","id":"grupos-de-tamaño-uniforme","chapter":"8 Limpieza de datos y funciones básicas","heading":"Grupos de tamaño uniforme","text":"Otra herramienta para hacer grupos numéricos es la función ntile() de dplyr, que intenta dividir los datos en n grupos de tamaño uniforme - pero ten en cuenta que, diferencia de quantile(), el mismo valor podría aparecer en más de un grupo. Proporcione el vector numérico y luego el número de grupos. Los valores de la nueva columna creada son sólo “números” de grupo (por ejemplo, del 1 al 10), el rango de valores en sí mismo como cuando se utiliza cut().","code":"\n# make groups with ntile()\nntile_data <- linelist %>% \n  mutate(even_groups = ntile(age_years, 10))\n\n# make table of counts and proportions by group\nntile_table <- ntile_data %>% \n  janitor::tabyl(even_groups)\n  \n# attach min/max values to demonstrate ranges\nntile_ranges <- ntile_data %>% \n  group_by(even_groups) %>% \n  summarise(\n    min = min(age_years, na.rm=T),\n    max = max(age_years, na.rm=T)\n  )## Warning in min(age_years, na.rm = T): no non-missing arguments to min; returning Inf## Warning in max(age_years, na.rm = T): no non-missing arguments to max; returning -Inf\n# combine and print - note that values are present in multiple groups\nleft_join(ntile_table, ntile_ranges, by = \"even_groups\")##  even_groups   n    percent valid_percent min  max\n##            1 651 0.09851695    0.10013844   0    2\n##            2 650 0.09836562    0.09998462   2    5\n##            3 650 0.09836562    0.09998462   5    7\n##            4 650 0.09836562    0.09998462   7   10\n##            5 650 0.09836562    0.09998462  10   13\n##            6 650 0.09836562    0.09998462  13   17\n##            7 650 0.09836562    0.09998462  17   21\n##            8 650 0.09836562    0.09998462  21   26\n##            9 650 0.09836562    0.09998462  26   33\n##           10 650 0.09836562    0.09998462  33   84\n##           NA 107 0.01619249            NA Inf -Inf"},{"path":"cleaning-data-and-core-functions.html","id":"case_when","chapter":"8 Limpieza de datos y funciones básicas","heading":"case_when()","text":"Es posible utilizar la función case_when() de dplyr para crear categorías partir de una columna numérica, pero es más fácil utilizar age_categories() de epikit o cut() porque éstas crearán un factor ordenado automáticamente.Si utilizas case_when(), por favor, revise el uso adecuado como se ha descrito anteriormente en la sección Re-codificar valores de esta página. También Ten en cuenta que todos los valores del lado derecho deben ser del mismo tipo. Por lo tanto, si quiere NA en el lado derecho debes escribir “Missing” o utilizar el valor especial NA_character_.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"añadir-a-la-cadena-de-tuberías-3","chapter":"8 Limpieza de datos y funciones básicas","heading":"Añadir a la cadena de tuberías","text":"continuación, se añade el código para crear dos columnas categóricas de edad la cadena de tuberías de limpieza:","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################   \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5)))"},{"path":"cleaning-data-and-core-functions.html","id":"add-rows","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.10 Añadir filas","text":"","code":""},{"path":"cleaning-data-and-core-functions.html","id":"uno-a-uno","chapter":"8 Limpieza de datos y funciones básicas","heading":"Uno a uno","text":"Añadir filas una una manualmente es tedioso pero puede hacerse con add_row() de dplyr. Recuerda que cada columna debe contener valores de un solo tipo (ya sea carácter, numérico, lógico, etc.). Así que añadir una fila requiere matizar para mantener esto.Utiliza .y .. para especificar la ubicación de la fila que deseas añadir. .= 3 pondrá la nueva fila antes de la tercera fila actual. El comportamiento por defecto es añadir la fila al final. Las columnas especificadas se dejarán vacías (NA).El nuevo número de fila puede parecer extraño (“…23”) pero los números de fila de las filas preexistentes han cambiado. Por lo tanto, si utiliza el comando dos veces, examine/pruebe la inserción cuidadosamente.Si uno de los tipos que proporcionas está desactivado, verás un error como este:(al insertar una fila con un valor de fecha, recuerde envolver la fecha en la función .Date() como .Date(\"2020-10-10\")).","code":"\nlinelist <- linelist %>% \n  add_row(row_num = 666,\n          case_id = \"abc\",\n          generation = 4,\n          `infection date` = as.Date(\"2020-10-10\"),\n          .before = 2)Error: Can't combine ..1$infection date <date> and ..2$infection date <character>."},{"path":"cleaning-data-and-core-functions.html","id":"unir-filas","chapter":"8 Limpieza de datos y funciones básicas","heading":"Unir filas","text":"Para combinar conjuntos de datos uniendo las filas de un dataframe al final de otro dataframe, puedes utilizar bind_rows() de dplyr. Esto se explica con más detalle en la página Unir datos.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"filter-rows","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.11 Filtrar filas","text":"Un paso típico de limpieza después de haber limpiado las columnas y recodificado los valores es filtrar el dataframe para filas específicas usando el verbo dplyr filter().Dentro de filter(), especifique la lógica que debe ser TRUE para que se mantenga una fila en los datos. continuación, mostramos cómo filtrar filas basándose en condiciones lógicas simples y complejas.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"filtro-simple","chapter":"8 Limpieza de datos y funciones básicas","heading":"Filtro simple","text":"Este sencillo ejemplo redefine el dataframe linelist en sí mismo, habiendo filtrado las filas para que cumplan una condición lógica. Sólo se conservan las filas en las que la declaración lógica dentro de los paréntesis se evalúa como TRUE.En este ejemplo, la sentencia lógica es gender == \"f\", que pregunta si el valor de la columna gender es igual “f” (distingue entre mayúsculas y minúsculas).Antes de aplicar el filtro, el número de filas de linelist es nrow(linelist).Después de aplicar el filtro, el número de filas de linelist linelist %>% filter(gender == \"f\") %>% nrow().","code":"\nlinelist <- linelist %>% \n  filter(gender == \"f\")   # keep only rows where gender is equal to \"f\""},{"path":"cleaning-data-and-core-functions.html","id":"filtrar-los-valores-faltantes","chapter":"8 Limpieza de datos y funciones básicas","heading":"Filtrar los valores faltantes","text":"Es bastante común querer filtrar las filas que tienen valores faltantes. Resiste la tentación de escribir filter(!.na(column) & !.na(column)) y utiliza en su lugar la función de tidyr que está hecha medida para este propósito: drop_na(). Si se ejecuta con paréntesis vacíos, elimina las filas con cualquier valor que falte. Como alternativa, puedes proporcionar los nombres de las columnas específicas que deben evaluarse para comprobar si faltan, o utilizar las funciones de ayuda “tidyselect” descritas anteriormente.Consulta la página sobre Valores faltantes para conocer muchas técnicas para analizar y gestionar los datos ausentes.","code":"\nlinelist %>% \n  drop_na(case_id, age_years)  # drop rows with missing values for case_id or age_years"},{"path":"cleaning-data-and-core-functions.html","id":"filtrar-por-número-de-fila","chapter":"8 Limpieza de datos y funciones básicas","heading":"Filtrar por número de fila","text":"En un dataframe o tibble, cada fila suele tener un “número de fila” que (cuando se ve en R Viewer) aparece la izquierda de la primera columna. es en sí misma una columna real en los datos, pero puede utilizarse en una sentencia filter().Para filtrar en base al “número de fila”, puedes utilizar la función row_number() de dplyr con paréntesis abiertos como parte de una sentencia lógica de filtrado. menudo se utiliza el operador %% y un rango de números como parte de esa sentencia lógica, como se muestra continuación. Para ver las primeras N filas, también puedes utilizar la función especial head() de dplyr.También puedes convertir los números de fila en una verdadera columna pasando su dataframe la función rownames_to_column() de tibble (escribas nada en los paréntesis).","code":"\n# View first 100 rows\nlinelist %>% head(100)     # or use tail() to see the n last rows\n\n# Show row 5 only\nlinelist %>% filter(row_number() == 5)\n\n# View rows 2 through 20, and three specific columns\nlinelist %>% filter(row_number() %in% 2:20) %>% select(date_onset, outcome, age)"},{"path":"cleaning-data-and-core-functions.html","id":"filtro-complejo","chapter":"8 Limpieza de datos y funciones básicas","heading":"Filtro complejo","text":"Se pueden construir sentencias lógicas más complejas utilizando paréntesis ( ), |, negación ! , %%, y operadores &. Un ejemplo es el siguiente:Nota: Puedes utilizar el operador ! delante de un criterio lógico para negarlo. Por ejemplo, !.na(column) se evalúa como verdadero si el valor de la columna falta. Del mismo modo, !column %% c(\"\", \"b\", \"c\") es verdadero si el valor de la columna está en el vector.","code":""},{"path":"cleaning-data-and-core-functions.html","id":"examinar-los-datos","chapter":"8 Limpieza de datos y funciones básicas","heading":"Examinar los datos","text":"continuación, se muestra un sencillo comando de una línea para crear un histograma de las fechas de inicio. Vea que un segundo brote más pequeño de 2012-2013 también está incluido en este conjunto de datos sin procesar. Para nuestros análisis, queremos eliminar las entradas de este brote anterior.","code":"\nhist(linelist$date_onset, breaks = 50)"},{"path":"cleaning-data-and-core-functions.html","id":"cómo-manejan-los-filtros-los-valores-numéricos-y-de-fecha-que-faltan","chapter":"8 Limpieza de datos y funciones básicas","heading":"¿Cómo manejan los filtros los valores numéricos y de fecha que faltan?","text":"¿Podemos simplemente filtrar por date_onset las filas posteriores junio de 2013? Precaución. La aplicación del código filter(date_onset > .Date(\"2013-06-01\")) eliminaría todas las filas de la epidemia posterior con una fecha de inicio ausente!PELIGRO: Filtrar mayor que (>) o menor que (<) una fecha o número puede eliminar cualquier fila con valores faltantes (NA). Esto se debe que NA es tratado como infinitamente grande y pequeño. (Consulta la página sobre el trabajando con fechas para obtener más información sobre el trabajo con fechas y el paquete lubridate)","code":""},{"path":"cleaning-data-and-core-functions.html","id":"diseñar-el-filtro","chapter":"8 Limpieza de datos y funciones básicas","heading":"Diseñar el filtro","text":"Examina una tabulación cruzada para asegurarte de que excluimos sólo las filas correctas:¿Qué otros criterios podemos filtrar para eliminar el primer brote (en 2012 y 2013) de los datos? Vemos que:La primera epidemia en 2012 y 2013 ocurrió en el Hospital , el Hospital B, y que también hubo 10 casos en el Hospital del Puerto.Los hospitales y B tuvieron casos en la segunda epidemia, pero Port Hospital sí.Queremos excluir:Las filas con inicio en 2012 y 2013 en cualquiera de los hospitales , B o Port nrow(linelist %>% filter(hospital %% c(\"Hospital \", \"Hospital B\") | date_onset < .Date(\"2013-06-01\"))) :\nExcluir nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) filas con inicio en 2012 y 2013 * Excluir nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) filas de los hospitales y B con fechas de inicio ausentes\nexcluir nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) otras filas con fechas de inicio ausentes.\nExcluir nrow(linelist %>% filter(date_onset < .Date(\"2013-06-01\"))) filas con inicio en 2012 y 2013 * Excluir nrow(linelist %>% filter(hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) filas de los hospitales y B con fechas de inicio ausentesNo excluir nrow(linelist %>% filter(!hospital %% c('Hospital ', 'Hospital B') & .na(date_onset))) otras filas con fechas de inicio ausentes.Comenzamos con un listado de nrow(linelist). Aquí está nuestro filtro:Cuando volvemos hacer la tabulación cruzada, vemos que los hospitales y B se eliminan por completo, y los 10 casos del Port Hospital de 2012 y 2013 se eliminan, y todos los demás valores son los mismos, tal y como queríamos.Se pueden incluir varias sentencias dentro de un comando de filtrado (separadas por comas), o siempre se puede canalizar un comando filter() separado para mayor claridad.Nota: algunos lectores pueden notar que sería más fácil filtrar sólo por date_hospitalisation porque es 100% completo sin valores faltantes. Esto es cierto. Pero date_onset se utiliza para demostrar un filtro complejo.","code":"\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2012 2013 2014 2015 <NA>\n##   Central Hospital                        0    0  351   99   18\n##   Hospital A                            229   46    0    0   15\n##   Hospital B                            227   47    0    0   15\n##   Military Hospital                       0    0  676  200   34\n##   Missing                                 0    0 1117  318   77\n##   Other                                   0    0  684  177   46\n##   Port Hospital                           9    1 1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)    0    0  322   93   13\n##   <NA>                                    0    0    0    0    0\nlinelist <- linelist %>% \n  # keep rows where onset is after 1 June 2013 OR where onset is missing and it was a hospital OTHER than Hospital A or B\n  filter(date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))\n\nnrow(linelist)## [1] 6019\ntable(Hospital  = linelist$hospital,                     # hospital name\n      YearOnset = lubridate::year(linelist$date_onset),  # year of date_onset\n      useNA     = \"always\")                              # show missing values##                                       YearOnset\n## Hospital                               2014 2015 <NA>\n##   Central Hospital                      351   99   18\n##   Military Hospital                     676  200   34\n##   Missing                              1117  318   77\n##   Other                                 684  177   46\n##   Port Hospital                        1372  347   75\n##   St. Mark's Maternity Hospital (SMMH)  322   93   13\n##   <NA>                                    0    0    0"},{"path":"cleaning-data-and-core-functions.html","id":"independiente-1","chapter":"8 Limpieza de datos y funciones básicas","heading":"Independiente","text":"El filtrado también puede realizarse como un comando independiente (como parte de una cadena de tuberías). Como otros verbos de dplyr, en este caso el primer argumento debe ser el propio conjunto de datos.También puedes utilizar R base para hacer un subconjunto utilizando corchetes que reflejen las [filas, columnas] que deseas conservar.","code":"\n# dataframe <- filter(dataframe, condition(s) for rows to keep)\n\nlinelist <- filter(linelist, !is.na(case_id))\n# dataframe <- dataframe[row conditions, column conditions] (blank means keep all)\n\nlinelist <- linelist[!is.na(case_id), ]"},{"path":"cleaning-data-and-core-functions.html","id":"revisar-rápidamente-los-registros","chapter":"8 Limpieza de datos y funciones básicas","heading":"Revisar rápidamente los registros","text":"menudo se quiere revisar rápidamente unos pocos registros, para sólo unas pocas columnas. La función View() de R base imprimirá un dataframe para su visualización en su RStudio.Mira el listado en RStudio:Aquí hay dos ejemplos de visualización de celdas específicas (filas específicas y columnas específicas):Con las funciones filter() y select() de dplyr :Dentro de View(), canaliza los datos filter() para mantener ciertas filas, y luego select() para mantener ciertas columnas. Por ejemplo, para revisar las fechas de inicio y hospitalización de 3 casos específicos:Puedes lograr lo mismo con la sintaxis de R base, utilizando los corchetes [ ] para el subconjunto que deseas ver.","code":"\nView(linelist)\nView(linelist %>%\n       filter(case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\")) %>%\n       select(date_onset, date_hospitalisation))\nView(linelist[linelist$case_id %in% c(\"11f8ea\", \"76b97a\", \"47a5f5\"), c(\"date_onset\", \"date_hospitalisation\")])"},{"path":"cleaning-data-and-core-functions.html","id":"añadir-a-la-cadena-de-pipes","chapter":"8 Limpieza de datos y funciones básicas","heading":"Añadir a la cadena de pipes","text":"","code":"\n# CLEANING 'PIPE' CHAIN (starts with raw data and pipes it through cleaning steps)\n##################################################################################\n\n# begin cleaning pipe chain\n###########################\nlinelist <- linelist_raw %>%\n    \n    # standardize column name syntax\n    janitor::clean_names() %>% \n    \n    # manually re-name columns\n           # NEW name             # OLD name\n    rename(date_infection       = infection_date,\n           date_hospitalisation = hosp_date,\n           date_outcome         = date_of_outcome) %>% \n    \n    # remove column\n    select(-c(row_num, merged_header, x28)) %>% \n  \n    # de-duplicate\n    distinct() %>% \n\n    # add column\n    mutate(bmi = wt_kg / (ht_cm/100)^2) %>%     \n\n    # convert class of columns\n    mutate(across(contains(\"date\"), as.Date), \n           generation = as.numeric(generation),\n           age        = as.numeric(age)) %>% \n    \n    # add column: delay to hospitalisation\n    mutate(days_onset_hosp = as.numeric(date_hospitalisation - date_onset)) %>% \n    \n    # clean values of hospital column\n    mutate(hospital = recode(hospital,\n                      # OLD = NEW\n                      \"Mitylira Hopital\"  = \"Military Hospital\",\n                      \"Mitylira Hospital\" = \"Military Hospital\",\n                      \"Military Hopital\"  = \"Military Hospital\",\n                      \"Port Hopital\"      = \"Port Hospital\",\n                      \"Central Hopital\"   = \"Central Hospital\",\n                      \"other\"             = \"Other\",\n                      \"St. Marks Maternity Hopital (SMMH)\" = \"St. Mark's Maternity Hospital (SMMH)\"\n                      )) %>% \n    \n    mutate(hospital = replace_na(hospital, \"Missing\")) %>% \n\n    # create age_years column (from age and age_unit)\n    mutate(age_years = case_when(\n          age_unit == \"years\" ~ age,\n          age_unit == \"months\" ~ age/12,\n          is.na(age_unit) ~ age)) %>% \n  \n    mutate(\n          # age categories: custom\n          age_cat = epikit::age_categories(age_years, breakers = c(0, 5, 10, 15, 20, 30, 50, 70)),\n        \n          # age categories: 0 to 85 by 5s\n          age_cat5 = epikit::age_categories(age_years, breakers = seq(0, 85, 5))) %>% \n    \n    # ABOVE ARE UPSTREAM CLEANING STEPS ALREADY DISCUSSED\n    ###################################################\n    filter(\n          # keep only rows where case_id is not missing\n          !is.na(case_id),  \n          \n          # also filter to keep only the second outbreak\n          date_onset > as.Date(\"2013-06-01\") | (is.na(date_onset) & !hospital %in% c(\"Hospital A\", \"Hospital B\")))"},{"path":"cleaning-data-and-core-functions.html","id":"row-wise-calculations","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.12 Cálculos por filas","text":"Si deseas realizar un cálculo dentro de una fila, puedes utilizar rowwise() de dplyr. Consulta esta viñeta en línea sobre los cálculos por filas. Por ejemplo, este código aplica rowwise() y luego crea una nueva columna que suma el número de las columnas de síntomas especificadas que tienen valor “yes”, para cada fila Las columnas se especifican dentro de sum() por su nombre dentro de un vector c(). rowwise() es esencialmente un tipo especial de group_by(), por lo que es mejor utilizar ungroup() cuando hayas terminado (página sobre Agrupar datos).Al especificar la columna evaluar, puedes utilizar las funciones de ayuda “tidyselect” descritas en la sección select() de esta página. Sólo tiene que hacer un ajuste (porque las está utilizando dentro de una función de dplyr como select() o summarise()).Especifica los criterios de la columna dentro de la función c_across() de dplyr. Esto se debe que c_across (documentación) está diseñada para trabajar con rowwise() específicamente. Por ejemplo, el siguiente código:Utiliza rowwise() para que la siguiente operación (sum()) se aplique dentro de cada fila (sumando columnas enteras)Crea una nueva columna num_NA_dates, definida para cada fila como el número de columnas (con nombre que contiene “date”) para las que .na() se evaluó como TRUE (son valores faltantes).ungroup() para eliminar los efectos de rowwise() en los pasos siguientesTambién podrías proporcionar otras funciones, como max() para obtener la fecha más reciente o más reciente de cada fila:","code":"\nlinelist %>%\n  rowwise() %>%\n  mutate(num_symptoms = sum(c(fever, chills, cough, aches, vomit) == \"yes\")) %>% \n  ungroup() %>% \n  select(fever, chills, cough, aches, vomit, num_symptoms) # for display## # A tibble: 5,888 × 6\n##    fever chills cough aches vomit num_symptoms\n##    <chr> <chr>  <chr> <chr> <chr>        <int>\n##  1 no    no     yes   no    yes              2\n##  2 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  3 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  4 no    no     no    no    no               0\n##  5 no    no     yes   no    yes              2\n##  6 no    no     yes   no    yes              2\n##  7 <NA>  <NA>   <NA>  <NA>  <NA>            NA\n##  8 no    no     yes   no    yes              2\n##  9 no    no     yes   no    yes              2\n## 10 no    no     yes   no    no               1\n## # … with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(num_NA_dates = sum(is.na(c_across(contains(\"date\"))))) %>% \n  ungroup() %>% \n  select(num_NA_dates, contains(\"date\")) # for display## # A tibble: 5,888 × 5\n##    num_NA_dates date_infection date_onset date_hospitalisation date_outcome\n##           <int> <date>         <date>     <date>               <date>      \n##  1            1 2014-05-08     2014-05-13 2014-05-15           NA          \n##  2            1 NA             2014-05-13 2014-05-14           2014-05-18  \n##  3            1 NA             2014-05-16 2014-05-18           2014-05-30  \n##  4            1 2014-05-04     2014-05-18 2014-05-20           NA          \n##  5            0 2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6            0 2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7            0 2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8            0 2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9            1 NA             2014-06-05 2014-06-06           2014-06-18  \n## 10            1 NA             2014-06-05 2014-06-07           2014-06-09  \n## # … with 5,878 more rows\nlinelist %>%\n  rowwise() %>%\n  mutate(latest_date = max(c_across(contains(\"date\")), na.rm=T)) %>% \n  ungroup() %>% \n  select(latest_date, contains(\"date\"))  # for display## # A tibble: 5,888 × 5\n##    latest_date date_infection date_onset date_hospitalisation date_outcome\n##    <date>      <date>         <date>     <date>               <date>      \n##  1 2014-05-15  2014-05-08     2014-05-13 2014-05-15           NA          \n##  2 2014-05-18  NA             2014-05-13 2014-05-14           2014-05-18  \n##  3 2014-05-30  NA             2014-05-16 2014-05-18           2014-05-30  \n##  4 2014-05-20  2014-05-04     2014-05-18 2014-05-20           NA          \n##  5 2014-05-29  2014-05-18     2014-05-21 2014-05-22           2014-05-29  \n##  6 2014-05-24  2014-05-03     2014-05-22 2014-05-23           2014-05-24  \n##  7 2014-06-01  2014-05-22     2014-05-27 2014-05-29           2014-06-01  \n##  8 2014-06-07  2014-05-28     2014-06-02 2014-06-03           2014-06-07  \n##  9 2014-06-18  NA             2014-06-05 2014-06-06           2014-06-18  \n## 10 2014-06-09  NA             2014-06-05 2014-06-07           2014-06-09  \n## # … with 5,878 more rows"},{"path":"cleaning-data-and-core-functions.html","id":"arrange-and-sort","chapter":"8 Limpieza de datos y funciones básicas","heading":"8.13 Ordenar y clasificar","text":"Utiliza la función arrange() de dplyr para ordenar las filas por los valores de las columnas.Lista las columnas en el orden en que deben ser ordenadas. Especifica .by_group = TRUE si deseas que la ordenación se realice primero por cualquier agrupación aplicada los datos (véase la página sobre Agrupar datos).Por defecto, la columna se ordenará en orden “ascendente” (que se aplica las columnas numéricas y también las de caracteres). Puedes ordenar una variable en orden “descendente” envolviéndola con desc().La ordenación de los datos con arrange() es particularmente útil cuando se hacen Tablas para presentaciones, utilizando slice() para tomar las filas “superiores” por grupo, o estableciendo el orden de los niveles de los factores por orden de aparición.Por ejemplo, para ordenar las filas de nuestro linelist por hospital y luego por date_onset (fecha de inicio) en orden descendente, utilizaríamos:","code":"\nlinelist %>% \n   arrange(hospital, desc(date_onset))"},{"path":"working-with-dates.html","id":"working-with-dates","chapter":"9 Trabajando con Fechas","heading":"9 Trabajando con Fechas","text":"Trabajar con fechas en R requiere más atención que trabajar con otros tipos de objetos. continuación, ofrecemos algunas herramientas y ejemplos para hacer este proceso menos doloroso. Por suerte, las fechas pueden manejarse fácilmente con la práctica y con un conjunto de paquetes útiles como lubridate.Al importar los datos en bruto, R suele interpretar las fechas como objetos de carácter, lo que significa que pueden utilizarse para operaciones generales con fechas, como la creación de series temporales y el cálculo de intervalos de tiempo. Para hacer las cosas más difíciles, hay muchas maneras de formatear una fecha y debes ayudar R saber qué parte de una fecha representa qué (mes, día, hora, etc.).Las fechas en R son su propio tipo de objeto - el tipo Date. Hay que tener en cuenta que también hay un tipo que almacena objetos con fecha y hora. Los objetos fecha-hora se denominan formalmente tipos POSIXt, POSIXct, o POSIXlt (la diferencia es importante). Estos objetos se denominan informalmente tipos datetime.Es importante hacer que R reconozca cuando una columna contiene fechas.Las fechas son un tipo de objeto y pueden ser difíciles de trabajar.Aquí presentamos varias formas de convertir columnas de fecha al tipo Date.","code":""},{"path":"working-with-dates.html","id":"preparation","chapter":"9 Trabajando con Fechas","heading":"9.1 Preparación","text":"","code":""},{"path":"working-with-dates.html","id":"cargar-paquetes","chapter":"9 Trabajando con Fechas","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de paquetes necesaria para esta página. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre los Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\n# Ccomprueba si el paquete está instalado, lo instala si es necesario y lo carga para la sesión actual.\n\n\npacman::p_load(\n  lubridate,  # general package for handling and converting dates  \n  linelist,   # has function to \"guess\" messy dates\n  aweek,      # another option for converting dates to weeks, and weeks to dates\n  zoo,        # additional date/time functions\n  tidyverse,  # data management and visualization  \n  rio)        # data import/export"},{"path":"working-with-dates.html","id":"importar-datos","chapter":"9 Trabajando con Fechas","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso paso, consulta las instrucciones en la página de descarga de manuales y datos. Asumimos que el archivo está en el directorio de trabajo, por lo que se especifican subcarpetas en esta ruta de archivo.","code":"\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"working-with-dates.html","id":"current-date","chapter":"9 Trabajando con Fechas","heading":"9.2 Fecha actual","text":"Puedes obtener la fecha actual del “sistema” o la fecha-hora del sistema de tu ordenador haciendo lo siguiente con R base.Con el paquete lubridate también se pueden devolver con today() y now(), respectivamente. date() devuelve la fecha y la hora actuales con los nombres del día de la semana y del mes.","code":"\n# get the system date - this is a DATE class\nSys.Date()## [1] \"2022-11-22\"\n# get the system time - this is a DATETIME class\nSys.time()## [1] \"2022-11-22 14:52:20 CET\""},{"path":"working-with-dates.html","id":"convert-to-date","chapter":"9 Trabajando con Fechas","heading":"9.3 Convertir en fecha","text":"Después de importar unos datos R, los valores de las columnas de fecha pueden tener el aspecto de “1989/12/30”, “05/06/2014” o “13 Ene 2020”. En estos casos, es probable que R siga tratando estos valores como valores de carácter. Hay que decirle R que estos valores son fechas… y cuál es el formato de la fecha (qué parte es Día, cuál es Mes, cuál es Año, etc).Una vez dicho esto, R convierte estos valores al tipo Date. En segundo plano, R almacenará las fechas como números (el número de días desde su fecha “origen” 1 Ene 1970). interactuarás con el número de la fecha menudo, pero esto permite R tratar las fechas como variables continuas y permitir operaciones especiales como el cálculo de la distancia entre las fechas.Por defecto, los valores del tipo Date en R se muestran como AAAA-MM-DD. Más adelante en esta sección discutiremos cómo cambiar la visualización de los valores de fecha.continuación presentamos dos enfoques para convertir una columna de valores de carácter al tipo Date.CONSEJO:: Puedes comprobar el tipo actual de una columna con la función class()de R base, como class(linelist$date_onset).","code":""},{"path":"working-with-dates.html","id":"r-base","chapter":"9 Trabajando con Fechas","heading":"R base","text":".Date() es la función estándar de R base para convertir un objeto o una columna en el tipo Date (nótese la “D” en mayúscula).El uso de .Date() requiere que:Se especifique el formato existente de la fecha de carácter en bruto o la fecha de origen si se suministran las fechas como números (véase la sección sobre las fechas de Excel)Si se utiliza en una columna de caracteres, todos los valores de fecha deben tener el mismo formato exacto (si es el caso, pruebe con parse_date() del paquete parsedate)En primer lugar, comprueba el tipo de la columna con class() de R base . Si estás seguro o estás confundido sobre el tipo de datos (por ejemplo, ve “POSIXct”, etc.) puede ser más fácil convertir primero la columna al tipo Character con .character(), y luego convertirla al tipo Date.En segundo lugar, dentro de la función .Date(), utiliza el argumento format = para indicar R el formato actual de los componentes de la fecha con caracteres - qué caracteres se refieren al mes, al día y al año, y cómo están separados. Si sus valores ya están en uno de los formatos de fecha estándar de R (“AAAA-MM-DD” o “AAAA/MM/DD”) el argumento format = es necesario.Para usar format =, escribe una cadena de caracteres (entre comillas) que represente el formato actual de la fecha utilizando las abreviaturas especiales “strptime” que aparecen continuación. Por ejemplo, si las fechas de caracteres están actualmente en el formato “DD/MM/AAAA”, como “24/04/1968”, entonces usarías format = \"%d/%m/%Y\" para convertir los valores en fechas. Es necesario poner el formato entre comillas. ¡Y olvides las barras o guiones!.La mayoría de las abreviaturas de strptime se enumeran continuación. Puedes ver la lista completa ejecutando ?strptime.%d = Número del día del mes (5, 17, 28, etc.)\n%j = Número del día del año (día juliano 001-366)\n%= Día de la semana abreviado (lunes, martes, miércoles, etc.)\n%= Día de la semana completo (lunes, martes, etc.) %w = Número del día de la semana (0-6, el domingo es 0)\n%u = Número del día de la semana (1-7, el lunes es 1)\n%W = Número de la semana (00-53, el lunes es el comienzo de la semana)\n%U = Número de la semana (01-53, el domingo es el comienzo de la semana)\n%m = Número del mes (p. ej. 01, 02, 03, 04)\n%b = Mes abreviado (enero, febrero, etc.)\n%B = Mes completo (enero, febrero, etc.)\n%y = Año de 2 dígitos (p. ej. 89)\n%Y = Año de 4 dígitos (p. ej. 1989)\n%h = Horas (reloj de 24 horas)\n%m = Minutos\n%s = Segundos\n%z = Desplazamiento respecto GMT\n%Z = Huso horario (carácter)CONSEJO: El argumento format = de .Date() le dice R el formato que quiere que tengan las fechas, sino cómo identificar las partes de la fecha tal y como son antes de ejecutar el comando.CONSEJO: Asegúrate que en el argumento format = se utiliza el mismo separador de partes de fechas (por ejemplo, /, -, o espacio) que está en tus fechas.Una vez que los valores están en el tipo Fecha, R los mostrará por defecto en el formato estándar, que es AAAA-MM-DD.","code":"\n# Convert to class date\nlinelist <- linelist %>% \n  mutate(date_onset = as.Date(date_of_onset, format = \"%d/%m/%Y\"))"},{"path":"working-with-dates.html","id":"lubridate","chapter":"9 Trabajando con Fechas","heading":"lubridate","text":"La conversión de objetos de carácter fechas puede facilitarse utilizando el paquete lubridate. Se trata de un paquete tidyverse diseñado para hacer que el trabajo con fechas y horas sea más sencillo y consistente que en R base. Por estas razones, el paquete lubridate se considera menudo el estándar de oro para las fechas y la hora, y se recomienda siempre que se trabaje con ellas.El paquete lubridate proporciona varias funciones de ayuda diferentes diseñadas para convertir objetos de caracteres en fechas de una manera intuitiva y más indulgente que especificando el formato en .Date(). Estas funciones son específicas para el formato de fecha aproximado, pero permiten una variedad de separadores, y sinónimos para las fechas (por ejemplo, 01 vs Jan vs Enero) - se denominan según las abreviaturas de los formatos de fecha.La flexibilidad de la función ymd() convierte de forma flexible los valores de fecha suministrados como año, luego mes y luego día.La función mdy() convierte de forma flexible los valores de fecha suministrados como mes, luego día y luego año.La función dmy() convierte de forma flexible los valores de fecha suministrados como día, luego mes y luego año.Si se utilizan pipes, la conversión de una columna de caracteres fechas con lubridate podría tener este aspecto:Una vez completado, puedes ejecutar class() para verificar el tipo de la columnaUna vez que los valores están en el tipo Fecha, R los mostrará por defecto en el formato estándar, que es AAAA-MM-DD.Ten en cuenta que las funciones anteriores funcionan mejor con años de 4 dígitos. Los años de 2 dígitos pueden producir resultados inesperados, ya que lubridate intenta adivinar el siglo.Para convertir un año de 2 dígitos en un año de 4 dígitos (todos en el mismo siglo) puedes convertirlo tipo carácter y luego combinar los dígitos existentes con un prefijo usando str_glue() del paquete stringr. Ver Caracteres y cadenas. continuación, convierte fecha.","code":"\n# install/load lubridate \npacman::p_load(lubridate)\n# read date in year-month-day format\nymd(\"2020-10-11\")## [1] \"2020-10-11\"\nymd(\"20201011\")## [1] \"2020-10-11\"\n# read date in month-day-year format\nmdy(\"10/11/2020\")## [1] \"2020-10-11\"\nmdy(\"Oct 11 20\")## [1] \"2020-10-11\"\n# read date in day-month-year format\ndmy(\"11 10 2020\")## [1] \"2020-10-11\"\ndmy(\"11 October 2020\")## [1] \"2020-10-11\"\nlinelist <- linelist %>%\n  mutate(date_onset = lubridate::dmy(date_onset))\n# Check the class of the column\nclass(linelist$date_onset)  \ntwo_digit_years <- c(\"15\", \"15\", \"16\", \"17\")\nstr_glue(\"20{two_digit_years}\")## 2015\n## 2015\n## 2016\n## 2017"},{"path":"working-with-dates.html","id":"combinar-columnas","chapter":"9 Trabajando con Fechas","heading":"Combinar columnas","text":"Puedes utilizar las funciones de lubridate make_date() y make_datetime() para combinar varias columnas numéricas en una columna de fecha. Por ejemplo, si tiene columnas numéricas onset_day, onset_month y onset_year en el dataframe linelist:","code":"\nlinelist <- linelist %>% \n  mutate(onset_date = make_date(year = onset_year, month = onset_month, day = onset_day))"},{"path":"working-with-dates.html","id":"excel-dates","chapter":"9 Trabajando con Fechas","heading":"9.4 Fechas en Excel","text":"En el fondo, la mayoría de los programas informáticos almacenan las fechas como números. R almacena las fechas desde un origen del 1 de enero de 1970. Así, si ejecutas .numeric(.Date(\"1970-01-01\")) obtendrás 0.Microsoft Excel almacena las fechas con un origen dependiendo del sistema operativo, del 30 de diciembre de 1899 (Windows) o del 1 de enero de 1904 (Mac). Consulta esta guía de Microsoft para obtener más información.Las fechas de Excel suelen importarse R como estos valores numéricos en lugar de como caracteres. Si los datos que importado de Excel muestran las fechas como números o caracteres como “41369”… utiliza .Date() (o la función as_date() de lubridate) para convertirlas, pero en lugar de suministrar un “formato” como el anterior, suministra la fecha de origen de Excel al argumento origin = .Esto funcionará si la fecha de Excel se almacena en R como de tipo carácter, ¡así que asegúrate de que el número es de tipo numérico!.NOTA: Debes proporcionar la fecha de origen en el formato de fecha por defecto de R (“AAAA-MM-DD”).","code":"\n# An example of providing the Excel 'origin date' when converting Excel number dates\ndata_cleaned <- data %>% \n  mutate(date_onset = as.numeric(date_onset)) %>%   # ensure class is numeric\n  mutate(date_onset = as.Date(date_onset, origin = \"1899-12-30\")) # convert to date using Excel origin"},{"path":"working-with-dates.html","id":"messy-dates","chapter":"9 Trabajando con Fechas","heading":"9.5 Fechas desordenadas","text":"La función parse_date() del paquete parsedate intenta leer una columna de fecha “desordenada” que contiene fechas en muchos formatos diferentes y convertir las fechas un formato estándar. Puedes leer más en línea sobre guess_dates().Por ejemplo parse_date() vería un vector de las siguientes fechas de caracteres “03 Ene 2018”, “07/03/1982”, y “08/20/85” y las convertiría al tipo Date como 2018-01-03, 1982-03-07, y 1985-08-20.","code":"\nparsedate::parse_date(c(\"03 Jany 2018\",\n                        \"07/03/1982\",\n                        \"08/20/85\"))## [1] \"2018-01-03 UTC\" \"1982-07-03 UTC\" \"1985-08-20 UTC\"\n# An example using guess_dates on the column dater_onset\nlinelist <- linelist %>%                 # the dataset is called linelist\n  mutate(\n    date_onset = parsedate::parse_date(date_onset))  # the parse_date() from package \"parsedate\""},{"path":"working-with-dates.html","id":"working-with-date-time-class","chapter":"9 Trabajando con Fechas","heading":"9.6 Trabajar con el tipo fecha-hora","text":"Como se mencionó anteriormente, R también soporta un tipo datetime - una columna que contiene información de fecha y hora. Al igual que con el tipo Date, menudo es necesario convertirlas de objetos character objetos datetime.","code":""},{"path":"working-with-dates.html","id":"convertir-fechas-con-horas","chapter":"9 Trabajando con Fechas","heading":"Convertir fechas con horas","text":"Un objeto datetime estándar se formatea con la fecha en primer lugar, seguida de un componente de tiempo - por ejemplo, 01 Ene 2020, 16:30. Al igual que con las fechas, hay muchas maneras de formatearlas, y hay numerosos niveles de precisión (horas, minutos, segundos) que se pueden suministrar.Por suerte, también existen funciones de ayuda de lubridate para ayudar convertir estas cadenas en objetos datetime. Estas funciones son extensiones de las funciones de ayuda la fecha, con _h (sólo se suministran las horas), _hm (se suministran las horas y los minutos), o _hms (se suministran las horas, los minutos y los segundos) añadidas al final (por ejemplo, dmy_hms()). Se pueden utilizar como se indica:Convertir datetime con sólo horas objeto datetimeConvertir datetime con horas y minutos objeto datetimeConvertir datetime con horas, minutos y segundos objeto datetimePuedes indicar la zona horaria, pero se ignora. Consulta la sección más adelante en esta página sobre las zonas horarias.Cuando se trabaja con un dataframe, las columnas de fecha y hora pueden combinarse para crear una columna de fecha y hora utilizando str_glue()del paquete stringr y una función apropiada de lubridate. Consulta la página sobre Caracteres y cadenas para obtener detalles sobre stringr.En este ejemplo, el dataframe linelist tiene una columna con formato “horas:minutos”. Para convertirla en una fecha, hay que seguir algunos pasos:Crea una columna de tiempo de admisión “limpia” con los valores faltantes rellenados con la mediana de la columna. Hacemos esto porque lubridate opera con valores faltantes. Combínala con la columna date_hospitalisation y utiliza la función ymd_hm() para convertirla.","code":"\nymd_h(\"2020-01-01 16hrs\")## [1] \"2020-01-01 16:00:00 UTC\"\nymd_h(\"2020-01-01 4PM\")## [1] \"2020-01-01 16:00:00 UTC\"\ndmy_hm(\"01 January 2020 16:20\")## [1] \"2020-01-01 16:20:00 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40\")## [1] \"2020-01-20 16:20:40 UTC\"\nmdy_hms(\"01 January 2020, 16:20:40 PST\")## [1] \"2020-01-20 16:20:40 UTC\"# packages\npacman::p_load(tidyverse, lubridate, stringr)\n\n# time_admission is a column in hours:minutes\nlinelist <- linelist %>%\n  \n  # when time of admission is not given, assign the median admission time\n  mutate(\n    time_admission_clean = ifelse(\n      is.na(time_admission),         # if time is missing\n      median(time_admission),        # assign the median\n      time_admission                 # if not missing keep as is\n  ) %>%\n  \n    # use str_glue() to combine date and time columns to create one character column\n    # and then use ymd_hm() to convert it to datetime\n  mutate(\n    date_time_of_admission = str_glue(\"{date_hospitalisation} {time_admission_clean}\") %>% \n      ymd_hm()\n  )"},{"path":"working-with-dates.html","id":"convertir-sólo-horas","chapter":"9 Trabajando con Fechas","heading":"Convertir sólo horas","text":"Si tus datos contienen sólo un carácter de tiempo (horas y minutos), puedes convertirlos y manipularlos como tiempos utilizando strptime() desde R base. Por ejemplo, para obtener la diferencia entre dos de estos horas:Sin embargo, ten en cuenta que si se proporciona un valor de fecha, se asume que la fecha es hoy. Para combinar una cadena de fecha y una cadena de hora, observa cómo se usa stringr en la sección anterior. Puedes leer más sobre strptime() aquí.Para convertir números de un solo dígito dos dígitos (por ejemplo, para “rellenar” las horas o los minutos con ceros la izquierda para conseguir 2 dígitos), consulta la sección “Longitud de relleno” de la página Caracteres y cadenas.","code":"\n# raw character times\ntime1 <- \"13:45\" \ntime2 <- \"15:20\"\n\n# Times converted to a datetime class\ntime1_clean <- strptime(time1, format = \"%H:%M\")\ntime2_clean <- strptime(time2, format = \"%H:%M\")\n\n# Difference is of class \"difftime\" by default, here converted to numeric hours \nas.numeric(time2_clean - time1_clean)   # difference in hours## [1] 1.583333"},{"path":"working-with-dates.html","id":"extraer-fracciones-de-hora","chapter":"9 Trabajando con Fechas","heading":"Extraer fracciones de hora","text":"Puedes extraer elementos de una hora con hour(), minute(), o second() de lubridate.aquí un ejemplo de extracción de la hora y posterior clasificación como parte del día. Comenzamos con la columna time_admission, que es de tipo Carácter en formato “HH:MM”. En primer lugar, se utiliza strptime() como se ha descrito anteriormente para convertir los caracteres en tipo datetime. continuación, se extrae la hora con hour(), devolviendo un número del 0 al 24. Por último, se crea una columna time_period utilizando la lógica con case_when() para clasificar las filas en Mañana/Tarde/Anochecer/Noche en función de su hora de entrada.Para saber más sobre case_when(), consulta la página sobre Limpieza de datos y funciones básicas.","code":"\nlinelist <- linelist %>%\n  mutate(hour_admit = hour(strptime(time_admission, format = \"%H:%M\"))) %>%\n  mutate(time_period = case_when(\n    hour_admit > 06 & hour_admit < 12 ~ \"Morning\",\n    hour_admit >= 12 & hour_admit < 17 ~ \"Afternoon\",\n    hour_admit >= 17 & hour_admit < 21 ~ \"Evening\",\n    hour_admit >=21 | hour_admit <= 6 ~ \"Night\"))"},{"path":"working-with-dates.html","id":"working-with-dates-1","chapter":"9 Trabajando con Fechas","heading":"9.7 Trabajar con fechas","text":"lubridate también puede utilizarse para otras funciones, como la extracción de aspectos de una fecha/hora, realización de cálculos aritméticos de fechas o cálculo de intervalos de fechasAquí definimos una fecha que se utilizará para los ejemplos:","code":"\n# create object of class Date\nexample_date <- ymd(\"2020-03-01\")"},{"path":"working-with-dates.html","id":"extraer-los-componentes-de-la-fecha","chapter":"9 Trabajando con Fechas","heading":"Extraer los componentes de la fecha","text":"Puedes extraer aspectos comunes como el mes, el día, el día de la semana:También puede extraer componentes de tiempo de un objeto o columna datetime. Esto puede ser útil si quieres ver la distribución de los tiempos de admisión.Hay varias opciones para recuperar las semanas. Consulta la sección sobre semanas epidemiológicas más abajo.Ten en cuenta que si deseas mostrar una fecha de una forma determinada (por ejemplo, “enero de 2020” o “jueves 20 de marzo” o “semana 20 de 1977”) puedes hacerlo de forma más flexible, tal y como se describe en la sección sobre Visualización de fechas.","code":"\nmonth(example_date)  # month number## [1] 3\nday(example_date)    # day (number) of the month## [1] 1\nwday(example_date)   # day number of the week (1-7)## [1] 1\nexample_datetime <- ymd_hm(\"2020-03-01 14:45\")\n\nhour(example_datetime)     # extract hour\nminute(example_datetime)   # extract minute\nsecond(example_datetime)   # extract second"},{"path":"working-with-dates.html","id":"fecha-matemática","chapter":"9 Trabajando con Fechas","heading":"Fecha matemática","text":"Puedes añadir ciertos números de días o semanas utilizando su respectiva función de lubridate.","code":"\n# add 3 days to this date\nexample_date + days(3)## [1] \"2020-03-04\"\n# add 7 weeks and subtract two days from this date\nexample_date + weeks(7) - days(2)## [1] \"2020-04-17\""},{"path":"working-with-dates.html","id":"intervalos-de-fechas","chapter":"9 Trabajando con Fechas","heading":"Intervalos de fechas","text":"La diferencia entre las fechas se puede calcular mediante:Asegúrate que ambas fechas son del mismo tipoUtiliza la resta para devolver la diferencia “difftime” entre las dos fechasSi es necesario, convierte el resultado en tipo numéricoa para realizar los cálculos matemáticos posterioresA continuación se calcula y muestra el intervalo entre dos fechas. Se pueden encontrar intervalos utilizando el símbolo de resta “menos” en los valores que son de tipo Fecha. Ten en cuenta, sin embargo, que el tipo del valor devuelto es “difftime”, como se muestra continuación, y debe ser convertido numérico.Para realizar operaciones posteriores sobre un “difftime”, conviértelo en numérico con .numeric().Todo esto puede unirse para trabajar con datos, por ejemplo:En un contexto de dataframe, si falta alguna de las fechas anteriores, la operación fallará para esa fila. El resultado será un NA en lugar de un valor numérico. Cuando utilices esta columna para los cálculos, asegúrate de establecer el argumento na.rm = en TRUE. Por ejemplo:","code":"\n# find the interval between this date and Feb 20 2020 \noutput <- example_date - ymd(\"2020-02-20\")\noutput    # print## Time difference of 10 days\nclass(output)## [1] \"difftime\"\npacman::p_load(lubridate, tidyverse)   # load packages\n\nlinelist <- linelist %>%\n  \n  # convert date of onset from character to date objects by specifying dmy format\n  mutate(date_onset = dmy(date_onset),\n         date_hospitalisation = dmy(date_hospitalisation)) %>%\n  \n  # filter out all cases without onset in march\n  filter(month(date_onset) == 3) %>%\n    \n  # find the difference in days between onset and hospitalisation\n  mutate(days_onset_to_hosp = date_hospitalisation - date_of_onset)\n# calculate the median number of days to hospitalisation for all cases where data are available\nmedian(linelist_delay$days_onset_to_hosp, na.rm = T)"},{"path":"working-with-dates.html","id":"date-display","chapter":"9 Trabajando con Fechas","heading":"9.8 Visualización de fechas","text":"Una vez que las fechas son del tipo correcto, menudo se desea mostrarlas de forma diferente, por ejemplo para que se muestren como “lunes 05 de enero” en lugar de “2018-01-05”. También puedes querer ajustar la visualización para agrupar las filas por los elementos de fecha mostrados, por ejemplo, para agrupar por mes-año.","code":""},{"path":"working-with-dates.html","id":"format","chapter":"9 Trabajando con Fechas","heading":"format()","text":"Ajusta la visualización de la fecha con la función format() de R base. Esta función acepta una cadena de caracteres (entre comillas) que especifica el formato de salida deseado en las abreviaturas strptime “%” (la misma sintaxis que se utiliza en .Date()). continuación se muestran las abreviaturas más comunes.Nota: el uso de format() convertirá los valores al tipo Character, por lo que generalmente se utiliza hacia el final de un análisis o sólo para fines de visualización. Puedes ver la lista completa ejecutando ?strptime.%d = Número del día del mes (5, 17, 28, etc.)\n%j = Número del día del año (día juliano 001-366)\n%= Día de la semana abreviado (lunes, martes, miércoles, etc.)\n%= Día de la semana completo (lunes, martes, etc.)\n%w = Número del día de la semana (0-6, el domingo es 0)\n%u = Número del día de la semana (1-7, el lunes es 1)\n%W = Número de la semana (00-53, el lunes es el comienzo de la semana)\n%U = Número de la semana (01-53, el domingo es el comienzo de la semana)\n%m = Número del mes (p. ej. 01, 02, 03, 04)\n%b = Mes abreviado (enero, febrero, etc.)\n%B = Mes completo (enero, febrero, etc.)\n%y = Año de 2 dígitos (p. ej. 89)\n%Y = Año de 4 dígitos (p. ej. 1989)\n%h = Horas (reloj de 24 horas)\n%m = Minutos\n%s = Segundos\n%z = Desplazamiento respecto GMT\n%Z = Huso horario (carácter)Un ejemplo de formato de la fecha de hoy:Ten en cuenta que si utilizas str_glue(), dentro de las comillas dobles ” sólo debes utilizar comillas simples (como arriba).","code":"\n# today's date, with formatting\nformat(Sys.Date(), format = \"%d %B %Y\")## [1] \"22 November 2022\"\n# easy way to get full date and time (default formatting)\ndate()## [1] \"Tue Nov 22 14:52:21 2022\"\n# formatted combined date, time, and time zone using str_glue() function\nstr_glue(\"{format(Sys.Date(), format = '%A, %B %d %Y, %z  %Z, ')}{format(Sys.time(), format = '%H:%M:%S')}\")## Tuesday, November 22 2022, +0000  UTC, 14:52:21\n# Using format to display weeks\nformat(Sys.Date(), \"%Y Week %W\")## [1] \"2022 Week 47\""},{"path":"working-with-dates.html","id":"mes-año","chapter":"9 Trabajando con Fechas","heading":"Mes-Año","text":"Para convertir una columna de fecha al formato mes-año, te sugerimos que utilice la función .yearmon() del paquete zoo. Esto convierte la fecha al tipo “yearmon” y mantiene el orden correcto. Por el contrario, usar format(columna, \"%Y %B\") convertirá al tipo Carácter y ordenará los valores alfabéticamente (incorrectamente).continuación, se crea una nueva columna yearmonth partir de la columna date_onset, utilizando la función .yearmon()`. La ordenación por defecto (correcta) de los valores resultantes se muestra en la tabla.Por el contrario, se puede ver cómo sólo utilizando format() se consigue el formato de visualización deseado, pero el orden correcto.Nota: si estás trabajando con ggplot() y quieres ajustar sólo cómo se muestran las fechas, puede ser suficiente proporcionar un formato strptime al argumento date_labels = en scale_x_date() - puedes utilizar \"%b %Y\" o \"%Y %b\". Consulta la página de consejos de ggplot.zoo también ofrece la función .yearqtr(), y puedes usar scale_x_yearmon() cuando uses ggplot().","code":"\n# create new column \ntest_zoo <- linelist %>% \n     mutate(yearmonth = zoo::as.yearmon(date_onset))\n\n# print table\ntable(test_zoo$yearmon)## \n## Apr 2014 May 2014 Jun 2014 Jul 2014 Aug 2014 Sep 2014 Oct 2014 Nov 2014 Dec 2014 Jan 2015 Feb 2015 \n##        7       64      100      226      528     1070     1112      763      562      431      306 \n## Mar 2015 Apr 2015 \n##      277      186\n# create new column\ntest_format <- linelist %>% \n     mutate(yearmonth = format(date_onset, \"%b %Y\"))\n\n# print table\ntable(test_format$yearmon)## \n## Apr 2014 Apr 2015 Aug 2014 Dec 2014 Feb 2015 Jan 2015 Jul 2014 Jun 2014 Mar 2015 May 2014 Nov 2014 \n##        7      186      528      562      306      431      226      100      277       64      763 \n## Oct 2014 Sep 2014 \n##     1112     1070"},{"path":"working-with-dates.html","id":"dates_epi_wks","chapter":"9 Trabajando con Fechas","heading":"9.9 Semanas epidemiológicas","text":"","code":""},{"path":"working-with-dates.html","id":"lubridate-1","chapter":"9 Trabajando con Fechas","heading":"lubridate","text":"Consulta la página sobre Agrupar datos para ver ejemplos más extensos de agrupación de datos por fecha. continuación describimos brevemente la agrupación de datos por semanas.Generalmente recomendamos utilizar la función floor_date() de lubridate, con el argumento unit = \"week\". Esto redondea la fecha hacia abajo al “inicio” de la semana, como se define por el argumento week_start =. El inicio de la semana por defecto es el 1 (para los lunes), pero se puede especificar cualquier día de la semana como inicio (por ejemplo, el 7 para los domingos). floor_date() es versátil y se puede utilizar para redondear hacia abajo otras unidades de tiempo estableciendo unit = “second”, “minute”, “hour”, “day”, “month”, o “year”.El valor devuelto es la fecha de inicio de la semana, en tipo Date. El tipo Date es útil la hora de representar los datos, ya que serán fácilmente reconocidos y ordenados correctamente por ggplot().Si sólo tienes interés en ajustar las fechas para que se muestren por semanas en un gráfico, consulta la sección de esta página sobre Visualización de fechas. Por ejemplo, al representar una epicurva puedes formatear la visualización de la fecha proporcionando la nomenclatura strptime “%” deseada. Por ejemplo, utiliza “%Y-%W” o “%Y-%U” para devolver el año y el número de semana (dado el comienzo de la semana del lunes o del domingo, respectivamente).","code":""},{"path":"working-with-dates.html","id":"recuentos-semanales","chapter":"9 Trabajando con Fechas","heading":"Recuentos semanales","text":"Consulta la página sobre Agrupar datos para obtener una explicación detallada de la agrupación de datos con count(), group_by(), summarise(). continuación se muestra un breve ejemplo.Crear una nueva columna “semana” con mutate(), utilizando floor_date() con unit = \"week\"Crear una nueva columna “semana” con mutate(), utilizando floor_date() con unit = \"week\"Obtener el recuento de filas (casos) por semana con count(); filtra los casos los que les falte la fechaObtener el recuento de filas (casos) por semana con count(); filtra los casos los que les falte la fechaTermina con complete() de tidyr para asegurarte que todas las semanas aparecen en los datos - incluso las que tienen filas/casos. Por defecto, los valores de recuento para cualquier fila “nueva” son NA, pero puedes hacerlos 0 con el argumento fill =, que espera una lista con nombre (abajo, n es el nombre de la columna de recuentos).Termina con complete() de tidyr para asegurarte que todas las semanas aparecen en los datos - incluso las que tienen filas/casos. Por defecto, los valores de recuento para cualquier fila “nueva” son NA, pero puedes hacerlos 0 con el argumento fill =, que espera una lista con nombre (abajo, n es el nombre de la columna de recuentos).Aquí están las primeras filas del dataframe resultante:","code":"\n# Make aggregated dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%             # remove cases missing onset date\n  mutate(weekly_cases = floor_date(   # make new column, week of onset\n    date_onset,\n    unit = \"week\")) %>%            \n  count(weekly_cases) %>%           # group data by week and count rows per group (creates column 'n')\n  tidyr::complete(                  # ensure all weeks are present, even those with no cases reported\n    weekly_cases = seq.Date(          # re-define the \"weekly_cases\" column as a complete sequence,\n      from = min(weekly_cases),       # from the minimum date\n      to = max(weekly_cases),         # to the maxiumum date\n      by = \"week\"),                   # by weeks\n    fill = list(n = 0))             # fill-in NAs in the n counts column with 0"},{"path":"working-with-dates.html","id":"alternativas-a-epiweek","chapter":"9 Trabajando con Fechas","heading":"Alternativas a Epiweek","text":"Ten en cuenta que lubridate también tiene las funciones week(), epiweek(), e isoweek(), cada una de las cuales tiene fechas de inicio ligeramente diferentes y otros matices. Sin embargo, en términos generales, floor_date() debería ser todo lo que necesitas. Puedes leer más detalles de estas funciones introduciendo ?week en la consola o leyendo la documentación aquí.Puedes usar del paquete aweek para establecer semanas epidemiológicas. Puedes leer más sobre él en el sitio web de RECON. Tiene las funciones date2week() y week2date() en las que se puede establecer el día de inicio de la semana con week_start = \"Monday\". Este paquete es el más fácil si se desea obtener resultados del tipo “week” (por ejemplo, “2020-W12”). Otra ventaja de aweek es que cuando date2week() se aplica una columna de fecha, la columna devuelta (formato de semana) es automáticamente del tipo Factor e incluye niveles para todas las semanas en el lapso de tiempo (esto evita el paso extra de complete() descrito anteriormente). Sin embargo, aweek tiene la funcionalidad de redondear fechas otras unidades de tiempo como meses, años, etc.Otra alternativa para las series temporales que también funciona bien para mostrar un formato de “semana” (“2020 W12”) es yearweek() del paquete tsibble, como se demuestra en la página sobre series temporales y detección de brotes.","code":""},{"path":"working-with-dates.html","id":"converting-datestime-zones","chapter":"9 Trabajando con Fechas","heading":"9.10 Conversión de fechas/zonas horarias","text":"Cuando los datos están presentes en diferentes husos horarios, menudo puede ser importante normalizar estos datos en un huso horario unificado. Esto puede suponer un reto adicional, ya que el componente de zona horaria de los datos debe codificarse manualmente en la mayoría de los casos.En R, cada objeto datetime tiene un componente de zona horaria. Por defecto, todos los objetos datetime llevarán la zona horaria local para el ordenador que se está utilizando - esto es generalmente específico para una ubicación en lugar de una zona horaria, ya que las zonas horarias menudo cambian en los lugares debido al horario de verano. es posible compensar con precisión las zonas horarias sin un componente de tiempo de una fecha, ya que el evento que representa una columna de fecha puede ser atribuido un tiempo específico, y por lo tanto los cambios de tiempo medidos en horas pueden ser razonablemente contabilizados.Para tratar las zonas horarias, hay una serie de funciones de ayuda en lubridate que pueden utilizarse para cambiar la zona horaria de un objeto datetime de la zona horaria local una zona horaria diferente. Las zonas horarias se establecen atribuyendo una zona horaria válida de la base de datos tz al objeto datetime. Aquí se puede encontrar una lista de éstas - si la ubicación que se está utilizando en los datos está en esta lista, las grandes ciudades cercanas en la zona horaria están disponibles y sirven para el mismo propósito.Esto puede parecer muy abstracto, y menudo es necesario si el usuario está trabajando través de zonas horarias.","code":"\n# assign the current time to a column\ntime_now <- Sys.time()\ntime_now## [1] \"2022-11-22 14:52:22 CET\"\n# use with_tz() to assign a new timezone to the column, while CHANGING the clock time\ntime_london_real <- with_tz(time_now, \"Europe/London\")\n\n# use force_tz() to assign a new timezone to the column, while KEEPING the clock time\ntime_london_local <- force_tz(time_now, \"Europe/London\")\n\n\n# note that as long as the computer that was used to run this code is NOT set to London time,\n# there will be a difference in the times \n# (the number of hours difference from the computers time zone to london)\ntime_london_real - time_london_local## Time difference of -1 hours"},{"path":"working-with-dates.html","id":"lagging-and-leading-calculations","chapter":"9 Trabajando con Fechas","heading":"9.11 Cálculos de retardo y de avance","text":"lead() y lag() son funciones del paquete dplyr que ayudan encontrar los valores anteriores (retardados) o posteriores (principales) en un vector, normalmente un vector numérico o de fechas. Esto es útil cuando se hacen cálculos de cambio/diferencia entre unidades de tiempo.`Supongamos que se quiere calcular la diferencia de casos entre una semana actual y la anterior. Los datos se proporcionan inicialmente en recuentos semanales, como se muestra continuación.Al utilizar lag() o lead(), el orden de las filas en el dataframe es muy importante. - presta atención si tus fechas/números son ascendentes o descendentesEn primer lugar, crea una nueva columna que contenga el valor de la semana anterior (retardada).Controla el número de unidades hacia atrás/adelante con n = (debe ser un entero negativo)Controla el número de unidades hacia atrás/adelante con n = (debe ser un entero negativo)Utiliza default = para definir el valor colocado en las filas existentes (por ejemplo, la primera fila para la que hay un valor retardado). Por defecto es NA.Utiliza default = para definir el valor colocado en las filas existentes (por ejemplo, la primera fila para la que hay un valor retardado). Por defecto es NA.Utiliza order_by = TRUE si tus filas están ordenadas por su columna de referenciaUtiliza order_by = TRUE si tus filas están ordenadas por su columna de referenciaA continuación, crea una nueva columna que sea la diferencia entre las dos columnas de los casos:Puedes leer más sobre lead() y lag() en esta documentación aquí o introduciendo ?lag en tu consola.","code":"\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1))\ncounts <- counts %>% \n  mutate(cases_prev_wk = lag(cases_wk, n = 1),\n         case_diff = cases_wk - cases_prev_wk)"},{"path":"working-with-dates.html","id":"resources-2","chapter":"9 Trabajando con Fechas","heading":"9.12 Recursos","text":"Página de lubridate** tidyversePágina de lubridate RStudio cheatsheetR Data Science en español sobre [fechas y horas]https://es.r4ds.hadley.nz/fechas-y-horas.htmlTutorial en líneaFormatos de fecha]","code":""},{"path":"characters-and-strings.html","id":"characters-and-strings","chapter":"10 Caracteres y cadenas","heading":"10 Caracteres y cadenas","text":"Esta página muestra el uso del paquete stringr para evaluar y manejar valores de caracteres, también denominados “cadenas” (“strings”).Combinar, ordenar, dividir, organizar - str_c(), str_glue(), str_order(), str_split()Combinar, ordenar, dividir, organizar - str_c(), str_glue(), str_order(), str_split()Limpiar y normalizar\nAjustar la longitud - str_pad(), str_trunc(), str_wrap()\nCambiar mayúsculas y minúsculas - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()\nLimpiar y normalizarAjustar la longitud - str_pad(), str_trunc(), str_wrap()Cambiar mayúsculas y minúsculas - str_to_upper(), str_to_title(), str_to_lower(), str_to_sentence()Evaluar y extraer por posición - str_length(), str_sub(), word()Evaluar y extraer por posición - str_length(), str_sub(), word()Patrones\nDetectar y localizar - str_detect(), str_subset(), str_match(), str_extract()\nModificar y reemplazar - str_sub(), str_replace_all()\nPatronesDetectar y localizar - str_detect(), str_subset(), str_match(), str_extract()Modificar y reemplazar - str_sub(), str_replace_all()Expresiones regulares (“regex”)Expresiones regulares (“regex”)Para facilitar la visualización, la mayoría de los ejemplos se muestran actuando sobre un vector de caracteres definido brevemente, aunque pueden adaptarse fácilmente una columna dentro de un dataframe.Esta viñeta de stringr proporcionó gran parte de la inspiración para esta página.","code":""},{"path":"characters-and-strings.html","id":"preparation-1","chapter":"10 Caracteres y cadenas","heading":"10.1 Preparación","text":"","code":""},{"path":"characters-and-strings.html","id":"cargar-paquetes-1","chapter":"10 Caracteres y cadenas","heading":"Cargar paquetes","text":"Instala o carga el paquete stringr y otros paquetes de tidyverse.","code":"\n# install/load packages\npacman::p_load(\n  stringr,    # many functions for handling strings\n  tidyverse,  # for optional data manipulation\n  tools)      # alternative for converting to title case"},{"path":"characters-and-strings.html","id":"importar-datos-1","chapter":"10 Caracteres y cadenas","heading":"Importar datos","text":"Importar datosEn esta página haremos referencia de vez en cuando la lista limpia de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"characters-and-strings.html","id":"unite-split-and-arrange","chapter":"10 Caracteres y cadenas","heading":"10.2 Unir, dividir y ordenar","text":"Esta sección abarca:Uso de str_c(), str_glue(), y unite() para combinar cadenasUso de str_c(), str_glue(), y unite() para combinar cadenasUso de str_order() para ordenar las cadenasUso de str_order() para ordenar las cadenasUso de str_split() y separate() para dividir cadenasUso de str_split() y separate() para dividir cadenas","code":""},{"path":"characters-and-strings.html","id":"combinar-cadenas","chapter":"10 Caracteres y cadenas","heading":"Combinar cadenas","text":"Para combinar o concatenar varias cadenas en una sola, sugerimos utilizar str_c de stringr. Si tienes valores de caracteres distintos para combinar, simplemente proporciónalos como argumentos únicos, separados por comas.El argumento sep = inserta un valor de carácter entre cada uno de los argumentos proporcionados (por ejemplo, insertando una coma, un espacio o una nueva línea \"\\n\")El argumento collapse = es relevante si estás introduciendo múltiples vectores como argumentos str_c(). Se utiliza para separar los elementos de lo que sería un vector de salida, de forma que el vector de salida sólo tenga un elemento de carácter largo.El ejemplo siguiente muestra la combinación de dos vectores en uno (nombres y apellidos). Otro ejemplo similar podría ser el de las jurisdicciones y su número de casos. En este ejemplo:El valor sep = aparece entre cada nombre y apellidoEl valor sep = aparece entre cada nombre y apellidoEl valor de collapse = aparece entre cada personaEl valor de collapse = aparece entre cada personaNota: Dependiendo del contexto de visualización deseado, al imprimir una cadena combinada de este tipo con nuevas líneas, puede ser necesario envolver toda la frase en cat() para que las nuevas líneas se impriman correctamente:","code":"\nstr_c(\"String1\", \"String2\", \"String3\")## [1] \"String1String2String3\"\nstr_c(\"String1\", \"String2\", \"String3\", sep = \", \")## [1] \"String1, String2, String3\"\nfirst_names <- c(\"abdul\", \"fahruk\", \"janice\") \nlast_names  <- c(\"hussein\", \"akinleye\", \"okeke\")\n\n# sep displays between the respective input strings, while collapse displays between the elements produced\nstr_c(first_names, last_names, sep = \" \", collapse = \";  \")## [1] \"abdul hussein;  fahruk akinleye;  janice okeke\"\n# For newlines to print correctly, the phrase may need to be wrapped in cat()\ncat(str_c(first_names, last_names, sep = \" \", collapse = \";\\n\"))## abdul hussein;\n## fahruk akinleye;\n## janice okeke"},{"path":"characters-and-strings.html","id":"cadenas-dinámicas","chapter":"10 Caracteres y cadenas","heading":"Cadenas dinámicas","text":"Utiliza str_glue() para insertar código R dinámico en una cadena. Se trata de una función muy útil para crear títulos o pies de gráfico dinámicos, como se muestra continuación.Todo el contenido va entre comillas dobles str_glue(\"\")Todo el contenido va entre comillas dobles str_glue(\"\")Cualquier código dinámico o referencias valores predefinidos se colocan entre llaves {} dentro de las comillas dobles. Puede haber muchas llaves en el mismo comando str_glue().Cualquier código dinámico o referencias valores predefinidos se colocan entre llaves {} dentro de las comillas dobles. Puede haber muchas llaves en el mismo comando str_glue().Para usar las comillas de caracteres ’’ dentro de la función, utiliza comillas simples dentro de las comillas dobles que las rodean (por ejemplo, al proporcionar el formato de la fecha - véase el ejemplo siguiente)Para usar las comillas de caracteres ’’ dentro de la función, utiliza comillas simples dentro de las comillas dobles que las rodean (por ejemplo, al proporcionar el formato de la fecha - véase el ejemplo siguiente)Consejo: Puedes utilizar \\n para forzar una nueva líneaConsejo: Puedes utilizar \\n para forzar una nueva líneaConsejo: Utiliza format() para ajustar la visualización de la fecha, y utiliza Sys.Date() para mostrar la fecha actualConsejo: Utiliza format() para ajustar la visualización de la fecha, y utiliza Sys.Date() para mostrar la fecha actualUn ejemplo sencillo, de un título de gráfico dinámico:Un formato alternativo es utilizar marcadores de posición dentro de los paréntesis y definir el código en argumentos separados al final de la función str_glue(), como se indica continuación. Esto puede mejorar la legibilidad del código si el texto es largo.Extraer de un dataframeA veces, es útil extraer datos de un dataframe y pegarlos secuencialmente. continuación se muestra un ejemplo de dataframe. Lo utilizaremos para hacer una declaración resumida sobre las jurisdicciones y los recuentos de casos nuevos y totales.Utiliza str_glue_data(), que está hecho especialmente para obtener datos de las filas del dataframe:Combinar cadenas través de las filasSi estás intentando “enrollar” valores en una columna del dataframe, por ejemplo, combinar valores de varias filas en una sola fila pegándolos con un separador, consulta la sección “combinación de valores” de la página de De-duplicación.Dataframe una líneaPuedes hacer que la declaración aparezca en una línea utilizando str_c() (especificando el dataframe y los nombres de las columnas), y proporcionando los argumentos sep = y collapse =.Podría añadir el texto “Nuevos casos:” fijado al principio de la frase envolviéndolo con un str_c() separado (si “Nuevos casos:” estuviera dentro del str_c() original aparecería varias veces).","code":"\nstr_glue(\"Data include {nrow(linelist)} cases and are current to {format(Sys.Date(), '%d %b %Y')}.\")## Data include 5888 cases and are current to 22 Nov 2022.\nstr_glue(\"Linelist as of {current_date}.\\nLast case hospitalized on {last_hospital}.\\n{n_missing_onset} cases are missing date of onset and not shown\",\n         current_date = format(Sys.Date(), '%d %b %Y'),\n         last_hospital = format(as.Date(max(linelist$date_hospitalisation, na.rm=T)), '%d %b %Y'),\n         n_missing_onset = nrow(linelist %>% filter(is.na(date_onset)))\n         )## Linelist as of 22 Nov 2022.\n## Last case hospitalized on 30 Apr 2015.\n## 256 cases are missing date of onset and not shown\n# make case data frame\ncase_table <- data.frame(\n  zone        = c(\"Zone 1\", \"Zone 2\", \"Zone 3\", \"Zone 4\", \"Zone 5\"),\n  new_cases   = c(3, 0, 7, 0, 15),\n  total_cases = c(40, 4, 25, 10, 103)\n  )\ncase_table %>% \n  str_glue_data(\"{zone}: {new_cases} ({total_cases} total cases)\")## Zone 1: 3 (40 total cases)\n## Zone 2: 0 (4 total cases)\n## Zone 3: 7 (25 total cases)\n## Zone 4: 0 (10 total cases)\n## Zone 5: 15 (103 total cases)\nstr_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \")## [1] \"Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\"\nstr_c(\"New Cases: \", str_c(case_table$zone, case_table$new_cases, sep = \" = \", collapse = \";  \"))## [1] \"New Cases: Zone 1 = 3;  Zone 2 = 0;  Zone 3 = 7;  Zone 4 = 0;  Zone 5 = 15\""},{"path":"characters-and-strings.html","id":"str_unite","chapter":"10 Caracteres y cadenas","heading":"Unir columnas","text":"Dentro de un dataframe, la unión de valores de caracteres de varias columnas puede lograrse con unite() de tidyr. Esto es lo contrario de separate().Indica el nombre de la nueva columna (que contendrá los valores unidos) y, continuación, indica los nombres de las columnas que deseas unir.Por defecto, el separador utilizado en la columna unida es el guión bajo _, pero puede cambiarse con el argumento sep =.Por defecto, el separador utilizado en la columna unida es el guión bajo _, pero puede cambiarse con el argumento sep =.remove = elimina las columnas del dataframe que queremos unir (TRUE por defecto)remove = elimina las columnas del dataframe que queremos unir (TRUE por defecto)na.rm = elimina los valores perdidos (NA) al realizar la unión (FALSE por defecto)na.rm = elimina los valores perdidos (NA) al realizar la unión (FALSE por defecto)continuación, definimos un mini-dataframe con el que hacer una demostración:Este es el dataframe de ejemplo:continuación, unimos las tres columnas de síntomas:","code":"\ndf <- data.frame(\n  case_ID = c(1:6),\n  symptoms  = c(\"jaundice, fever, chills\",     # patient 1\n                \"chills, aches, pains\",        # patient 2 \n                \"fever\",                       # patient 3\n                \"vomiting, diarrhoea\",         # patient 4\n                \"bleeding from gums, fever\",   # patient 5\n                \"rapid pulse, headache\"),      # patient 6\n  outcome = c(\"Recover\", \"Death\", \"Death\", \"Recover\", \"Recover\", \"Recover\"))\ndf_split <- separate(df, symptoms, into = c(\"sym_1\", \"sym_2\", \"sym_3\"), extra = \"merge\")## Warning: Expected 3 pieces. Missing pieces filled with `NA` in 2 rows [3, 4].\ndf_split %>% \n  unite(\n    col = \"all_symptoms\",         # name of the new united column\n    c(\"sym_1\", \"sym_2\", \"sym_3\"), # columns to unite\n    sep = \", \",                   # separator to use in united column\n    remove = TRUE,                # if TRUE, removes input cols from the data frame\n    na.rm = TRUE                  # if TRUE, missing values are removed before uniting\n  )##   case_ID                all_symptoms outcome\n## 1       1     jaundice, fever, chills Recover\n## 2       2        chills, aches, pains   Death\n## 3       3                       fever   Death\n## 4       4         vomiting, diarrhoea Recover\n## 5       5 bleeding, from, gums, fever Recover\n## 6       6      rapid, pulse, headache Recover"},{"path":"characters-and-strings.html","id":"dividir","chapter":"10 Caracteres y cadenas","heading":"Dividir","text":"Para dividir una cadena basada en un patrón, utiliza str_split(). Esta función evalúa las cadenas y devuelve una lista de vectores de caracteres formada por los valores recién divididos.El ejemplo que sigue evalúa una cadena y la divide en tres. Por defecto, devuelve un objeto de tipo list con un elemento (un vector de caracteres) por cada cadena proporcionada inicialmente. Si simplify = TRUE devuelve una matriz de caracteres.En este ejemplo, se proporciona una cadena y la función devuelve una lista con un elemento: un vector de caracteres con tres valores.Si se guarda la salida, puedes acceder al enésimo valor dividido con la sintaxis de corchetes. Para acceder un valor específico puedes utilizar una sintaxis como esta: the_returned_object[[1]][2], que accedería al segundo valor de la primera cadena evaluada (“fever”). Consulta la página de fundamentos de R para obtener más detalles sobre el acceso los elementos.Si se proporcionan varias cadenas mediante str_split(), habrá más de un elemento en la lista devuelta.Para devolver una “matriz de caracteres” en su lugar, que puede ser útil si se crean columnas de dataframes, establece el argumento simplify = TRUE como se muestra continuación:También puedes ajustar el número de divisiones crear con el argumento n =. Por ejemplo, esto restringe el número de divisiones 2. De este modo, cualquier otra coma permanece dentro del segundo valor.Nota - los mismos resultados se pueden conseguir con str_split_fixed(), en la que se da el argumento simplify, sino que se debe designar el número de columnas (n).","code":"\nstr_split(string = \"jaundice, fever, chills\",\n          pattern = \",\")## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\"\npt1_symptoms <- str_split(\"jaundice, fever, chills\", \",\")\n\npt1_symptoms[[1]][2]  # extracts 2nd value from 1st (and only) element of the list## [1] \" fever\"\nsymptoms <- c(\"jaundice, fever, chills\",     # patient 1\n              \"chills, aches, pains\",        # patient 2 \n              \"fever\",                       # patient 3\n              \"vomiting, diarrhoea\",         # patient 4\n              \"bleeding from gums, fever\",   # patient 5\n              \"rapid pulse, headache\")       # patient 6\n\nstr_split(symptoms, \",\")                     # split each patient's symptoms## [[1]]\n## [1] \"jaundice\" \" fever\"   \" chills\" \n## \n## [[2]]\n## [1] \"chills\" \" aches\" \" pains\"\n## \n## [[3]]\n## [1] \"fever\"\n## \n## [[4]]\n## [1] \"vomiting\"   \" diarrhoea\"\n## \n## [[5]]\n## [1] \"bleeding from gums\" \" fever\"            \n## \n## [[6]]\n## [1] \"rapid pulse\" \" headache\"\nstr_split(symptoms, \",\", simplify = TRUE)##      [,1]                 [,2]         [,3]     \n## [1,] \"jaundice\"           \" fever\"     \" chills\"\n## [2,] \"chills\"             \" aches\"     \" pains\" \n## [3,] \"fever\"              \"\"           \"\"       \n## [4,] \"vomiting\"           \" diarrhoea\" \"\"       \n## [5,] \"bleeding from gums\" \" fever\"     \"\"       \n## [6,] \"rapid pulse\"        \" headache\"  \"\"\nstr_split(symptoms, \",\", simplify = TRUE, n = 2)##      [,1]                 [,2]            \n## [1,] \"jaundice\"           \" fever, chills\"\n## [2,] \"chills\"             \" aches, pains\" \n## [3,] \"fever\"              \"\"              \n## [4,] \"vomiting\"           \" diarrhoea\"    \n## [5,] \"bleeding from gums\" \" fever\"        \n## [6,] \"rapid pulse\"        \" headache\"\nstr_split_fixed(symptoms, \",\", n = 2)"},{"path":"characters-and-strings.html","id":"dividir-columnas","chapter":"10 Caracteres y cadenas","heading":"Dividir columnas","text":"Si estás intentando dividir una columna de un dataframe, es mejor utilizar la función separate() de dplyr. Se utiliza para dividir una columna de caracteres en otras columnas.Digamos que tenemos un dataframe simple df (definido y unido en la sección de unir columnas) que contiene una columna case_ID, una columna de caracteres con muchos síntomas y una columna de resultados. Nuestro objetivo es separar la columna de symptoms en varias columnas, cada una de las cuales contiene un síntoma.Asumiendo que los datos son enlazados con pipe en separate(), primero proporciona la columna separar. continuación, proporcione en = como un vector c() que contiene los nombres de las nuevas columnas, como se muestra continuación.sep = el separador, puede ser un carácter, o un número (interpretado como la posición del carácter dividir)sep = el separador, puede ser un carácter, o un número (interpretado como la posición del carácter dividir)remove = FALSE por defecto, elimina la columna de entradaremove = FALSE por defecto, elimina la columna de entradaconvert = FALSE por defecto, hará que las cadenas “NA”s se conviertan en NAconvert = FALSE por defecto, hará que las cadenas “NA”s se conviertan en NAextra = controla lo que sucede si hay más valores creados por la separación que nuevas columnas nombradas.extra = controla lo que sucede si hay más valores creados por la separación que nuevas columnas nombradas.extra = \"warn\" significa que verá una advertencia, pero quitará los valores en exceso (el valor por defecto)extra = \"warn\" significa que verá una advertencia, pero quitará los valores en exceso (el valor por defecto)extra = \"drop\" significa que los valores sobrantes se eliminarán sin previo avisoextra = \"drop\" significa que los valores sobrantes se eliminarán sin previo avisoextra = \"merge\" sólo dividirá hasta el número de nuevas columnas listadas en - esta configuración preservará todos tus datosextra = \"merge\" sólo dividirá hasta el número de nuevas columnas listadas en - esta configuración preservará todos tus datosA continuación se muestra un ejemplo con extra = \"merge\" - se pierde ningún dato. Se definen dos nuevas columnas pero cualquier tercer síntoma se deja en la segunda columna nueva:Cuando se utiliza el extra = \"drop\" por defecto continuación, se da una advertencia pero se pierden los terceros síntomas:PRECAUCIÓN: Si proporcionas suficientes valores en las nuevas columnas, tus datos pueden quedar truncados. ","code":"\n# third symptoms combined into second new column\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\", extra = \"merge\")## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1          sym_2 outcome\n## 1       1           jaundice  fever, chills Recover\n## 2       2             chills   aches, pains   Death\n## 3       3              fever           <NA>   Death\n## 4       4           vomiting      diarrhoea Recover\n## 5       5 bleeding from gums          fever Recover\n## 6       6        rapid pulse       headache Recover\n# third symptoms are lost\ndf %>% \n  separate(symptoms, into = c(\"sym_1\", \"sym_2\"), sep=\",\")## Warning: Expected 2 pieces. Additional pieces discarded in 2 rows [1, 2].## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [3].##   case_ID              sym_1      sym_2 outcome\n## 1       1           jaundice      fever Recover\n## 2       2             chills      aches   Death\n## 3       3              fever       <NA>   Death\n## 4       4           vomiting  diarrhoea Recover\n## 5       5 bleeding from gums      fever Recover\n## 6       6        rapid pulse   headache Recover"},{"path":"characters-and-strings.html","id":"ordenar-alfabéticamente","chapter":"10 Caracteres y cadenas","heading":"Ordenar alfabéticamente","text":"Se pueden ordenar varias cadenas por orden alfabético. str_order() devuelve el orden, mientras que str_sort() devuelve las cadenas en ese orden.Para utilizar un alfabeto diferente, añade el argumento locale =. Mira lista completa de locales introduciendo stringi::stri_locale_list() en la consola de R.","code":"\n# strings\nhealth_zones <- c(\"Alba\", \"Takota\", \"Delta\")\n\n# return the alphabetical order\nstr_order(health_zones)## [1] 1 3 2\n# return the strings in alphabetical order\nstr_sort(health_zones)## [1] \"Alba\"   \"Delta\"  \"Takota\""},{"path":"characters-and-strings.html","id":"funciones-r-base","chapter":"10 Caracteres y cadenas","heading":"funciones R base","text":"Es común ver las funciones de R base paste() y paste0(), que concatenan vectores después de convertir todas las partes en caracteres. Actúan de forma similar str_c() pero la sintaxis es posiblemente más complicada - en los paréntesis cada parte está separada por una coma. Las partes son o bien texto de carácter (entre comillas) o bien objetos de código predefinidos (sin comillas). Por ejemplo:Se pueden especificar los argumentos sep = y collapse =. paste() es simplemente paste0() con un sep = ” ” por defecto (un espacio).","code":"\nn_beds <- 10\nn_masks <- 20\n\npaste0(\"Regional hospital needs \", n_beds, \" beds and \", n_masks, \" masks.\")## [1] \"Regional hospital needs 10 beds and 20 masks.\""},{"path":"characters-and-strings.html","id":"clean-and-standardise","chapter":"10 Caracteres y cadenas","heading":"10.3 Limpiar y normalizar","text":"","code":""},{"path":"characters-and-strings.html","id":"cambiar-mayúsculas","chapter":"10 Caracteres y cadenas","heading":"Cambiar mayúsculas","text":"menudo hay que alterar las mayúsculas y minúsculas de un valor de cadena, por ejemplo los nombres de las jurisdicciones. Utiliza str_to_upper(), str_to_lower(), y str_to_title(), de stringr, como se muestra continuación:Usando R base, lo anterior también se puede lograr con toupper(), tolower().Capitalización del títuloSe puede transformar la cadena para que cada palabra esté en mayúsculas con str_to_title():Utiliza toTitleCase() del paquete de tools para lograr una capitalización más matizada (palabras como “”, “el” y “de” se escriben en mayúsculas).También puedes utilizar str_to_sentence(), que sólo pone en mayúsculas la primera letra de la cadena.","code":"\nstr_to_upper(\"California\")## [1] \"CALIFORNIA\"\nstr_to_lower(\"California\")## [1] \"california\"\nstr_to_title(\"go to the US state of california \")## [1] \"Go To The Us State Of California \"\ntools::toTitleCase(\"This is the US state of california\")## [1] \"This is the US State of California\"\nstr_to_sentence(\"the patient must be transported\")## [1] \"The patient must be transported\""},{"path":"characters-and-strings.html","id":"str_pad","chapter":"10 Caracteres y cadenas","heading":"Longitud de la cadena","text":"Utiliza str_pad() para añadir caracteres una cadena, con una longitud mínima. Por defecto se añaden espacios, pero también puedes rellenar con otros caracteres utilizando el argumento pad =.Por ejemplo, para rellenar números con ceros la izquierda (como en el caso de las horas o los minutos), puedes rellenar el número hasta una longitud mínima de 2 con pad = “0”.","code":"\n# ICD codes of differing length\nICD_codes <- c(\"R10.13\",\n               \"R10.819\",\n               \"R17\")\n\n# ICD codes padded to 7 characters on the right side\nstr_pad(ICD_codes, 7, \"right\")## [1] \"R10.13 \" \"R10.819\" \"R17    \"\n# Pad with periods instead of spaces\nstr_pad(ICD_codes, 7, \"right\", pad = \".\")## [1] \"R10.13.\" \"R10.819\" \"R17....\"\n# Add leading zeros to two digits (e.g. for times minutes/hours)\nstr_pad(\"4\", 2, pad = \"0\") ## [1] \"04\"\n# example using a numeric column named \"hours\"\n# hours <- str_pad(hours, 2, pad = \"0\")"},{"path":"characters-and-strings.html","id":"truncar","chapter":"10 Caracteres y cadenas","heading":"Truncar","text":"str_trunc() establece una longitud máxima para cada cadena. Si una cadena supera esta longitud, se trunca (acorta) y se incluye una elipsis (…) para indicar que la cadena era antes más larga. Ten en cuenta que la elipsis se cuenta en la longitud. Los caracteres de la elipsis pueden cambiarse con el argumento ellipsis =. El argumento opcional side =especifica dónde aparecerá la elipsis dentro de la cadena truncada (“left”, “right”, o “center”).","code":"\noriginal <- \"Symptom onset on 4/3/2020 with vomiting\"\nstr_trunc(original, 10, \"center\")## [1] \"Symp...ing\""},{"path":"characters-and-strings.html","id":"normalizar-la-longitud","chapter":"10 Caracteres y cadenas","heading":"Normalizar la longitud","text":"Utiliza str_trunc() para establecer una longitud máxima y, continuación, utiliza str_pad() para ampliar las cadenas muy cortas hasta esa longitud truncada. En el ejemplo siguiente, se establece 6 como longitud máxima (se trunca un valor), y luego se rellena un valor muy corto para alcanzar la longitud de 6.","code":"\n# ICD codes of differing length\nICD_codes   <- c(\"R10.13\",\n                 \"R10.819\",\n                 \"R17\")\n\n# truncate to maximum length of 6\nICD_codes_2 <- str_trunc(ICD_codes, 6)\nICD_codes_2## [1] \"R10.13\" \"R10...\" \"R17\"\n# expand to minimum length of 6\nICD_codes_3 <- str_pad(ICD_codes_2, 6, \"right\")\nICD_codes_3## [1] \"R10.13\" \"R10...\" \"R17   \""},{"path":"characters-and-strings.html","id":"eliminar-los-espacios-en-blanco-iniciales-y-finales","chapter":"10 Caracteres y cadenas","heading":"Eliminar los espacios en blanco iniciales y finales","text":"Utiliza str_trim() para eliminar los espacios, las nuevas líneas (\\n) o los tabuladores (\\t) de los lados de una cadena de entrada. Añade \"right\" \"left\", o \"\" al comando para especificar qué lado recortar (por ejemplo, str_trim(x, \"right\").","code":"\n# ID numbers with excess spaces on right\nIDs <- c(\"provA_1852  \", # two excess spaces\n         \"provA_2345\",   # zero excess spaces\n         \"provA_9460 \")  # one excess space\n\n# IDs trimmed to remove excess spaces on right side only\nstr_trim(IDs)## [1] \"provA_1852\" \"provA_2345\" \"provA_9460\""},{"path":"characters-and-strings.html","id":"eliminar-los-espacios-en-blanco-repetidos-en-una-cadena","chapter":"10 Caracteres y cadenas","heading":"Eliminar los espacios en blanco repetidos en una cadena","text":"Utiliza str_squish() para eliminar los espacios repetidos que aparecen dentro de una cadena. Por ejemplo, para convertir espacios dobles en espacios simples. También elimina espacios, nuevas líneas o tabulaciones en el exterior de la cadena como str_trim().Escribe ?str_trim, ?str_pad en tu consola de R para ver más detalles.","code":"\n# original contains excess spaces within string\nstr_squish(\"  Pt requires   IV saline\\n\") ## [1] \"Pt requires IV saline\""},{"path":"characters-and-strings.html","id":"convertir-en-párrafos","chapter":"10 Caracteres y cadenas","heading":"convertir en párrafos","text":"Utiliza str_wrap() para convertir un texto largo estructurado en un párrafo estructurado con una longitud de línea fija. Proporciona la longitud de caracteres ideal para cada línea, y aplica un algoritmo para insertar nuevas líneas () dentro del párrafo, como se ve en el ejemplo siguiente.La función base cat() puede envolver el comando anterior para imprimir la salida, mostrando las nuevas líneas añadidas.","code":"\npt_course <- \"Inicio de los síntomas 1/4/2020 vómitos escalofríos fiebre. La paciente consultó a un curandero tradicional en su pueblo natal el 2/4/2020. El 5/4/2020 los síntomas empeoraron y fue ingresada en la clínica Lumta. Se tomó una muestra y fue trasladada al hospital regional el 6/4/2020. La paciente murió en el hospital regional el 7/4/2020\"\n\nstr_wrap(pt_course, 40)## [1] \"Inicio de los síntomas 1/4/2020 vómitos\\nescalofríos fiebre. La paciente consultó\\na un curandero tradicional en su pueblo\\nnatal el 2/4/2020. El 5/4/2020 los\\nsíntomas empeoraron y fue ingresada en\\nla clínica Lumta. Se tomó una muestra\\ny fue trasladada al hospital regional\\nel 6/4/2020. La paciente murió en el\\nhospital regional el 7/4/2020\"\ncat(str_wrap(pt_course, 40))## Inicio de los síntomas 1/4/2020 vómitos\n## escalofríos fiebre. La paciente consultó\n## a un curandero tradicional en su pueblo\n## natal el 2/4/2020. El 5/4/2020 los\n## síntomas empeoraron y fue ingresada en\n## la clínica Lumta. Se tomó una muestra\n## y fue trasladada al hospital regional\n## el 6/4/2020. La paciente murió en el\n## hospital regional el 7/4/2020"},{"path":"characters-and-strings.html","id":"handle-by-position","chapter":"10 Caracteres y cadenas","heading":"10.4 Manipular por posición","text":"","code":""},{"path":"characters-and-strings.html","id":"extraer-por-posición-de-carácter","chapter":"10 Caracteres y cadenas","heading":"Extraer por posición de carácter","text":"Utiliza str_sub() para devolver sólo una parte de una cadena. La función toma tres argumentos principales:el(los) vector(es) de caracteresel(los) vector(es) de caracteresposición de inicioposición de inicioposición finalposición finalAlgunas notas sobre los números de posición:Si un número de posición es positivo, la posición se cuenta partir del extremo izquierdo de la cadena.Si un número de posición es positivo, la posición se cuenta partir del extremo izquierdo de la cadena.Si un número de posición es negativo, se cuenta partir del extremo derecho de la cadena.Si un número de posición es negativo, se cuenta partir del extremo derecho de la cadena.Los números de posición son inclusivos.Los números de posición son inclusivos.Las posiciones que se extienden más allá de la cadena serán truncadas (eliminadas).Las posiciones que se extienden más allá de la cadena serán truncadas (eliminadas).continuación se muestran algunos ejemplos aplicados la cadena “pneumonia”:","code":"\n# start and end third from left (3rd letter from left)\nstr_sub(\"pneumonia\", 3, 3)## [1] \"e\"\n# 0 is not present\nstr_sub(\"pneumonia\", 0, 0)## [1] \"\"\n# 6th from left, to the 1st from right\nstr_sub(\"pneumonia\", 6, -1)## [1] \"onia\"\n# 5th from right, to the 2nd from right\nstr_sub(\"pneumonia\", -5, -2)## [1] \"moni\"\n# 4th from left to a position outside the string\nstr_sub(\"pneumonia\", 4, 15)## [1] \"umonia\""},{"path":"characters-and-strings.html","id":"extraer-por-posición-de-palabra","chapter":"10 Caracteres y cadenas","heading":"Extraer por posición de palabra","text":"Para extraer la enésima ‘palabra’, utiliza word(), también de stringr. Proporciona la(s) cadena(s), luego la primera y la última posición de la palabra extraer.Por defecto, se asume que el separador entre ‘palabras’ es un espacio, menos que se indica lo contrario con sep = (por ejemplo, sep = \"_\" cuando las palabras están separadas por barra baja.","code":"\n# strings to evaluate\nchief_complaints <- c(\"I just got out of the hospital 2 days ago, but still can barely breathe.\",\n                      \"My stomach hurts\",\n                      \"Severe ear pain\")\n\n# extract 1st to 3rd words of each string\nword(chief_complaints, start = 1, end = 3, sep = \" \")## [1] \"I just got\"       \"My stomach hurts\" \"Severe ear pain\""},{"path":"characters-and-strings.html","id":"sustituir-por-posición-de-carácter","chapter":"10 Caracteres y cadenas","heading":"Sustituir por posición de carácter","text":"str_sub() emparejado con el operador de asignación (<-) puede utilizarse para modificar una parte de una cadena:Un ejemplo aplicado varias cadenas (por ejemplo, una columna). Obsérvese la ampliación de la longitud de “HIV”.","code":"\nword <- \"pneumonia\"\n\n# convert the third and fourth characters to X \nstr_sub(word, 3, 4) <- \"XX\"\n\n# print\nword## [1] \"pnXXmonia\"\nwords <- c(\"pneumonia\", \"tubercolosis\", \"HIV\")\n\n# convert the third and fourth characters to X \nstr_sub(words, 3, 4) <- \"XX\"\n\nwords## [1] \"pnXXmonia\"    \"tuXXrcolosis\" \"HIXX\""},{"path":"characters-and-strings.html","id":"evaluar-la-longitud","chapter":"10 Caracteres y cadenas","heading":"Evaluar la longitud","text":"Como alternativa, utiliza nchar() de R base","code":"\nstr_length(\"abc\")## [1] 3"},{"path":"characters-and-strings.html","id":"patterns","chapter":"10 Caracteres y cadenas","heading":"10.5 Patrones","text":"Muchas funciones de stringr trabajan para detectar, localizar, extraer, hacer coincidir, reemplazar y dividir basándose en un patrón especificado.","code":""},{"path":"characters-and-strings.html","id":"detectar-un-patrón","chapter":"10 Caracteres y cadenas","heading":"Detectar un patrón","text":"Utiliza str_detect() como se indica continuación para detectar la presencia/ausencia de un patrón dentro de una cadena. Primero proporciona la cadena o vector en la que buscar (string =), y luego el patrón buscar (pattern =). Ten en cuenta que, por defecto, la búsqueda distingue entre mayúsculas y minúsculas.Se puede incluir el argumento negate = y ponerlo TRUE si se quiere saber si el patrón está presente.Para ignorar las mayúsculas y minúsculas, envuelve el patrón dentro de regex(), y dentro de regex() añade el argumento ignore_case = TRUE (o T como abreviatura).Cuando str_detect() se aplica un vector de caracteres o una columna de un dataframe, devolverá TRUE o FALSE para cada uno de los valores.Si necesitas contar los TRUE, simplemente sum() la salida. Esto cuenta el número de TRUE.Para buscar con varios términos, inclúyelos separados por barras (|) dentro del argumento pattern =, como se muestra continuación:Si necesitas construir una larga lista de términos de búsqueda, puedes combinarlos usando str_c() y sep = |, luego definir que esto es un objeto de caracteres, y luego referenciar el vector más adelante de manera más sucinta. El ejemplo siguiente incluye posibles términos de búsqueda de ocupación para proveedores médicos de primera línea.Este comando devuelve el número de ocupaciones que contienen alguno de los términos de búsqueda para proveedores médicos de primera línea (occupation_med_frontline):Funciones de búsqueda de cadenas en R basegrepl() de R base funciona de forma similar str_detect(), en el sentido de que busca coincidencias con un patrón y devuelve un vector lógico. La sintaxis básica es grepl(patrón,  cadenas_de_búsqueda, ignore.case = FALSE, ...). Una ventaja es que el argumento ignore.case es más fácil de escribir (hay necesidad de involucrar la función regex()).Asimismo, las funciones sub() y gsub()de R base actúan de forma similar str_replace(). Su sintaxis básica es: gsub(patrón, reemplazo, cadenas_de_búsqueda, ignore.case = FALSE). sub() reemplazará la primera instancia del patrón, mientras que gsub() reemplazará todas las instancias del patrón.","code":"\nstr_detect(string = \"primary school teacher\", pattern = \"teach\")## [1] TRUE\nstr_detect(string = \"primary school teacher\", pattern = \"teach\", negate = TRUE)## [1] FALSE\nstr_detect(string = \"Teacher\", pattern = regex(\"teach\", ignore_case = T))## [1] TRUE\n# a vector/column of occupations \noccupations <- c(\"field laborer\",\n                 \"university professor\",\n                 \"primary school teacher & tutor\",\n                 \"tutor\",\n                 \"nurse at regional hospital\",\n                 \"lineworker at Amberdeen Fish Factory\",\n                 \"physican\",\n                 \"cardiologist\",\n                 \"office worker\",\n                 \"food service\")\n\n# Detect presence of pattern \"teach\" in each string - output is vector of TRUE/FALSE\nstr_detect(occupations, \"teach\")##  [1] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\nsum(str_detect(occupations, \"teach\"))## [1] 1\nsum(str_detect(string = occupations, pattern = \"teach|professor|tutor\"))## [1] 3\n# search terms\noccupation_med_frontline <- str_c(\"medical\", \"medicine\", \"hcw\", \"healthcare\", \"home care\", \"home health\",\n                                \"surgeon\", \"doctor\", \"doc\", \"physician\", \"surgery\", \"peds\", \"pediatrician\",\n                               \"intensivist\", \"cardiologist\", \"coroner\", \"nurse\", \"nursing\", \"rn\", \"lpn\",\n                               \"cna\", \"pa\", \"physician assistant\", \"mental health\",\n                               \"emergency department technician\", \"resp therapist\", \"respiratory\",\n                                \"phlebotomist\", \"pharmacy\", \"pharmacist\", \"hospital\", \"snf\", \"rehabilitation\",\n                               \"rehab\", \"activity\", \"elderly\", \"subacute\", \"sub acute\",\n                                \"clinic\", \"post acute\", \"therapist\", \"extended care\",\n                                \"dental\", \"dential\", \"dentist\", sep = \"|\")\n\noccupation_med_frontline## [1] \"medical|medicine|hcw|healthcare|home care|home health|surgeon|doctor|doc|physician|surgery|peds|pediatrician|intensivist|cardiologist|coroner|nurse|nursing|rn|lpn|cna|pa|physician assistant|mental health|emergency department technician|resp therapist|respiratory|phlebotomist|pharmacy|pharmacist|hospital|snf|rehabilitation|rehab|activity|elderly|subacute|sub acute|clinic|post acute|therapist|extended care|dental|dential|dentist\"\nsum(str_detect(string = occupations, pattern = occupation_med_frontline))## [1] 2"},{"path":"characters-and-strings.html","id":"convertir-comas-en-puntos","chapter":"10 Caracteres y cadenas","heading":"Convertir comas en puntos","text":"aquí un ejemplo de uso de gsub() para convertir comas en puntos en un vector de números. Esto podría ser útil si tus datos proceden de otras partes del mundo que sean Estados Unidos o Gran Bretaña.gsub() internamente actúa primero sobre lengths convirtiendo cualquier punto en sin espacio ““. El carácter de punto”.” tiene que ser “escapado” con dos barras inclinadas para significar realmente un punto, porque “.” en regex significa “cualquier carácter”. continuación, el resultado (con sólo comas) se pasa la función externa gsub() en la que las comas se sustituyen por puntos.","code":"\nlengths <- c(\"2.454,56\", \"1,2\", \"6.096,5\")\n\nas.numeric(gsub(pattern = \",\",                # find commas     \n                replacement = \".\",            # replace with periods\n                x = gsub(\"\\\\.\", \"\", lengths)  # vector with other periods removed (periods escaped)\n                )\n           )                                  # convert outcome to numeric"},{"path":"characters-and-strings.html","id":"sustituir-todo","chapter":"10 Caracteres y cadenas","heading":"Sustituir todo","text":"Utiliza str_replace_all() como herramienta de “búsqueda y sustitución”. Primero, proporcione las cadenas evaluar string =, luego el patrón reemplazar pattern =, y luego el valor de reemplazo replacement =. El ejemplo siguiente reemplaza todas las instancias de “dead” con “deceased”. Ten en cuenta que esto distingue entre mayúsculas y minúsculas.Notas:Para sustituir un patrón por NA, utiliza str_replace_na().Para sustituir un patrón por NA, utiliza str_replace_na().La función str_replace() reemplaza sólo la primera instancia del patrón dentro de cada cadena evaluada.La función str_replace() reemplaza sólo la primera instancia del patrón dentro de cada cadena evaluada.","code":"\noutcome <- c(\"Karl: dead\",\n            \"Samantha: dead\",\n            \"Marco: not dead\")\n\nstr_replace_all(string = outcome, pattern = \"dead\", replacement = \"deceased\")## [1] \"Karl: deceased\"      \"Samantha: deceased\"  \"Marco: not deceased\""},{"path":"characters-and-strings.html","id":"detectar-con-lógica","chapter":"10 Caracteres y cadenas","heading":"Detectar con lógica","text":"Dentro de case_when()str_detect() se utiliza menudo dentro de case_when() (de dplyr). Digamos que ocupaciones es una columna en linelist. La función mutate() de abajo crea una nueva columna llamada is_educator utilizando la lógica condicional través de case_when(). Mira la página sobre limpieza de datos para aprender más sobre case_when().Como recordatorio, puede ser importante añadir criterios de exclusión la lógica condicional (negate = F):","code":"\ndf <- df %>% \n  mutate(is_educator = case_when(\n    # term search within occupation, not case sensitive\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\",\n                     ignore_case = TRUE))              ~ \"Educator\",\n    # all others\n    TRUE                                               ~ \"Not an educator\"))df <- df %>% \n  # value in new column is_educator is based on conditional logic\n  mutate(is_educator = case_when(\n    \n    # occupation column must meet 2 criteria to be assigned \"Educator\":\n    # it must have a search term AND NOT any exclusion term\n    \n    # Must have a search term\n    str_detect(occupations,\n               regex(\"teach|prof|tutor|university\", ignore_case = T)) &              \n    \n    # AND must NOT have an exclusion term\n    str_detect(occupations,\n               regex(\"admin\", ignore_case = T),\n               negate = TRUE                        ~ \"Educator\"\n    \n    # All rows not meeting above criteria\n    TRUE                                            ~ \"Not an educator\"))"},{"path":"characters-and-strings.html","id":"localizar-la-posición-de-un-patrón","chapter":"10 Caracteres y cadenas","heading":"Localizar la posición de un patrón","text":"Para localizar la primera posición de un patrón, utiliza str_locate(). Esta función da como resultado una posición inicial y una final.Al igual que otras funciones str, existe una versión “_all” (str_locate_all()) que devolverá las posiciones de todas las instancias del patrón dentro de cada cadena. La salida es una lista.","code":"\nstr_locate(\"I wish\", \"sh\")##      start end\n## [1,]     5   6\nphrases <- c(\"I wish\", \"I hope\", \"he hopes\", \"He hopes\")\n\nstr_locate(phrases, \"h\" )     # position of *first* instance of the pattern##      start end\n## [1,]     6   6\n## [2,]     3   3\n## [3,]     1   1\n## [4,]     4   4\nstr_locate_all(phrases, \"h\" ) # position of *every* instance of the pattern## [[1]]\n##      start end\n## [1,]     6   6\n## \n## [[2]]\n##      start end\n## [1,]     3   3\n## \n## [[3]]\n##      start end\n## [1,]     1   1\n## [2,]     4   4\n## \n## [[4]]\n##      start end\n## [1,]     4   4"},{"path":"characters-and-strings.html","id":"extraer-una-coincidencia","chapter":"10 Caracteres y cadenas","heading":"Extraer una coincidencia","text":"str_extract_all() devuelve los patrones coincidentes en sí mismos, lo que resulta muy útil cuando se han ofrecido varios patrones mediante condiciones “”. Por ejemplo, buscando en el vector de cadenas de ocupaciones (véase la pestaña anterior) cualquiera “enseñ”, “profesor” o “tutor”.str_extract_all() devuelve una lista que contiene todas las coincidencias de cada cadena evaluada. Mira continuación cómo la ocupación 3 tiene dos coincidencias de patrón dentro de ella.str_extract() extrae sólo la primera coincidencia en cada cadena evaluada, produciendo un vector de caracteres con un elemento por cada cadena evaluada. Devuelve NA cuando hay coincidencias. Los NAs pueden ser eliminados envolviendo el vector devuelto con na.exclude(). Observa cómo la segunda de las coincidencias de la ocupación 3 se muestra.","code":"\nstr_extract_all(occupations, \"teach|prof|tutor\")## [[1]]\n## character(0)\n## \n## [[2]]\n## [1] \"prof\"\n## \n## [[3]]\n## [1] \"teach\" \"tutor\"\n## \n## [[4]]\n## [1] \"tutor\"\n## \n## [[5]]\n## character(0)\n## \n## [[6]]\n## character(0)\n## \n## [[7]]\n## character(0)\n## \n## [[8]]\n## character(0)\n## \n## [[9]]\n## character(0)\n## \n## [[10]]\n## character(0)\nstr_extract(occupations, \"teach|prof|tutor\")##  [1] NA      \"prof\"  \"teach\" \"tutor\" NA      NA      NA      NA      NA      NA"},{"path":"characters-and-strings.html","id":"subconjunto-y-recuento","chapter":"10 Caracteres y cadenas","heading":"Subconjunto y recuento","text":"Las funciones alineadas incluyen str_subset() y str_count().str_subset() devuelve los valores reales que contienen el patrón:str_count() devuelve un vector de números: el número de veces que aparece un término de búsqueda en cada valor evaluado.","code":"\nstr_subset(occupations, \"teach|prof|tutor\")## [1] \"university professor\"           \"primary school teacher & tutor\" \"tutor\"\nstr_count(occupations, regex(\"teach|prof|tutor\", ignore_case = TRUE))##  [1] 0 1 2 1 0 0 0 0 0 0"},{"path":"characters-and-strings.html","id":"grupos-regex","chapter":"10 Caracteres y cadenas","heading":"Grupos Regex","text":"EN CONSTRUCCIÓN","code":""},{"path":"characters-and-strings.html","id":"special-characters","chapter":"10 Caracteres y cadenas","heading":"10.6 Caracteres especiales","text":"Barra invertida \\ como código de escapeLa barra invertida \\ se utiliza para “escapar” del significado del siguiente carácter. De este modo, se puede utilizar una barra invertida para que una comilla aparezca dentro de otras comillas (\\\") - la comilla del medio “romperá” las comillas circundantes.Nota - por lo tanto, si quieres mostrar una barra invertida, debes escapar su significado con otra barra invertida. Así que debes escribir dos barras invertidas \\\\ para mostrar una.Caracteres especialesEjecuta ?\"'\" en la consola de R para mostrar una lista completa de estos caracteres especiales (aparecerá en el panel de ayuda de RStudio).","code":""},{"path":"characters-and-strings.html","id":"regular-expressions-regex","chapter":"10 Caracteres y cadenas","heading":"10.7 Expresiones regulares (regex)","text":"","code":""},{"path":"characters-and-strings.html","id":"regex-and-special-characters","chapter":"10 Caracteres y cadenas","heading":"10.8 Regex y caracteres especiales","text":"Las expresiones regulares, o “regex”, son un lenguaje conciso para describir patrones en las cadenas. Si está familiarizado con él, una expresión regular puede parecer un lenguaje extraño. Aquí tratamos de desmitificar un poco este lenguaje.Gran parte de esta sección está adaptada de este tutorial y de esta hoja de trucos. Aquí adaptamos selectivamente sabiendo que este manual podría ser visto por personas sin acceso internet para ver los otros tutoriales.Una expresión regular se aplica menudo para extraer patrones específicos de texto “estructurado”, por ejemplo, notas médicas, quejas principales, historial del paciente u otras columnas de texto libre en un dataframe.Hay cuatro herramientas básicas que se pueden utilizar para crear una expresión regular básica:Juegos de caracteresJuegos de caracteresMetacaracteresMetacaracteresCuantificadoresCuantificadoresGruposGruposJuegos de caracteresLos conjuntos de caracteres, son una forma de expresar las opciones de la lista para una coincidencia de caracteres, entre paréntesis. Así, cualquier coincidencia se activará si cualquiera de los caracteres dentro de los paréntesis se encuentra en la cadena. Por ejemplo, para buscar vocales se podría utilizar este conjunto de caracteres “[aeiou]”. Otros conjuntos de caracteres comunes son:Los conjuntos de caracteres pueden combinarse dentro de un paréntesis (¡sin espacios!), como \"[-Za-z]\" (cualquier letra mayúscula o minúscula), u otro ejemplo \"[t-z0-5]\" (de la t la z en minúscula o del número 0 al 5).Meta caracteresLos metacaracteres son la abreviatura de los juegos de caracteres. continuación se enumeran algunos de los más importantes:CuantificadoresNormalmente se desea buscar una coincidencia en un solo carácter. Los cuantificadores le permiten designar la longitud de las letras/números para permitir la coincidencia.Los cuantificadores son números escritos entre corchetes { } después del carácter que cuantifican, por ejemplo,\"{2}\" devolverá instancias de dos letras mayúsculas.\"{2}\" devolverá instancias de dos letras mayúsculas.\"{2,4}\" devolverá instancias de entre dos y cuatro letras mayúsculas (¡ponga espacios!).\"{2,4}\" devolverá instancias de entre dos y cuatro letras mayúsculas (¡ponga espacios!).\"{2,}\" devolverá instancias de dos o más letras mayúsculas.\"{2,}\" devolverá instancias de dos o más letras mayúsculas.\"+\" devolverá instancias de una o más letras mayúsculas (grupo extendido hasta que se encuentre un carácter diferente).\"+\" devolverá instancias de una o más letras mayúsculas (grupo extendido hasta que se encuentre un carácter diferente).Preceder con un asterisco * para devolver cero o más coincidencias (útil si está seguro de que el patrón está presente)Preceder con un asterisco * para devolver cero o más coincidencias (útil si está seguro de que el patrón está presente)Utilizando el símbolo + como cuantificador, la coincidencia se producirá hasta que se encuentre un carácter diferente. Por ejemplo, esta expresión devolverá todas las palabras (caracteres alfa: \"[-Za-z]+\"Cuando se utiliza un cuantificador de {2}, sólo se devuelven los pares de consecutivos. Se identifican dos pares dentro de AAAA.Cuando se utiliza un cuantificador de {2,4}, se devuelven grupos de consecutivos de dos cuatro.Con el cuantificador +, se devuelven grupos de uno o más:Posición relativaExpresan los requisitos de lo que precede o sigue un patrón. Por ejemplo, para extraer frases, “dos números que van seguidos de un punto” (\"\"). (?<=\\.)\\s(?=[-Z])GruposLa captura de grupos en su expresión regular es una forma de tener una salida más organizada al momento de la extracción.Ejemplos de RegexA continuación se presenta un texto libre para los ejemplos. Intentaremos extraer información útil del mismo utilizando un término de búsqueda de expresión regular.Esta expresión coincide con todas las palabras (cualquier carácter hasta llegar un carácter como un espacio):La expresión \"[0-9]{1,2}\" coincide con números consecutivos de 1 o 2 dígitos. También podría escribirse \"\\\\d{1,2}\", o \"[:digit:]{1,2}\".Puedes ver una lista útil de expresiones regex y consejos en la página 2 de esta hoja de trucosMira también este tutorial.","code":"\n# test string for quantifiers\ntest <- \"A-AA-AAA-AAAA\"\nstr_extract_all(test, \"A{2}\")## [[1]]\n## [1] \"AA\" \"AA\" \"AA\" \"AA\"\nstr_extract_all(test, \"A{2,4}\")## [[1]]\n## [1] \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"A+\")## [[1]]\n## [1] \"A\"    \"AA\"   \"AAA\"  \"AAAA\"\nstr_extract_all(test, \"\")## [[1]]\n##  [1] \"A\" \"-\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"-\" \"A\" \"A\" \"A\" \"A\"\npt_note <- \"El paciente llegó a la sala de urgencias del Broward Hospital a las 18:00 horas del 6/12/2005. Se presentó con dolor abdominal irradiado desde el cuadrante LR. La piel estaba pálida, fría y húmeda. Su temperatura era de 99,8 grados Farinheit. El pulso era de 100 lpm y filiforme. La frecuencia respiratoria era de 29 por minuto\"\nstr_extract_all(pt_note, \"[A-Za-z]+\")## [[1]]\n##  [1] \"El\"           \"paciente\"     \"lleg\"         \"a\"            \"la\"           \"sala\"        \n##  [7] \"de\"           \"urgencias\"    \"del\"          \"Broward\"      \"Hospital\"     \"a\"           \n## [13] \"las\"          \"horas\"        \"del\"          \"Se\"           \"present\"      \"con\"         \n## [19] \"dolor\"        \"abdominal\"    \"irradiado\"    \"desde\"        \"el\"           \"cuadrante\"   \n## [25] \"LR\"           \"La\"           \"piel\"         \"estaba\"       \"p\"            \"lida\"        \n## [31] \"fr\"           \"a\"            \"y\"            \"h\"            \"meda\"         \"Su\"          \n## [37] \"temperatura\"  \"era\"          \"de\"           \"grados\"       \"Farinheit\"    \"El\"          \n## [43] \"pulso\"        \"era\"          \"de\"           \"lpm\"          \"y\"            \"filiforme\"   \n## [49] \"La\"           \"frecuencia\"   \"respiratoria\" \"era\"          \"de\"           \"por\"         \n## [55] \"minuto\"\nstr_extract_all(pt_note, \"[0-9]{1,2}\")## [[1]]\n##  [1] \"18\" \"00\" \"6\"  \"12\" \"20\" \"05\" \"99\" \"8\"  \"10\" \"0\"  \"29\""},{"path":"characters-and-strings.html","id":"resources-3","chapter":"10 Caracteres y cadenas","heading":"10.9 Recursos","text":"Puedes encontrar una hoja de referencia para las funciones de stringr aquíPuedes encontrar una viñeta sobre stringr aquí","code":""},{"path":"factors.html","id":"factors","chapter":"11 Factores","heading":"11 Factores","text":"En R, los factores son un tipo de datos que permiten categorías ordenadas con un conjunto fijo de valores.Normalmente, se convierte una columna de tipo numérico o de caracteres en un factor si se desea establecer un orden intrínseco los valores (“niveles”) para que puedan mostrarse de forma alfabética en gráficos y tablas. Otro uso común de los factores es normalizar las leyendas de los gráficos para que fluctúen si ciertos valores están temporalmente faltantes de datos.En esta página se muestra el uso de las funciones del paquete forcats (nombre abreviado de “categorical variables”) y algunas funciones de R base. También se aborda el uso de lubridate y aweek para casos de factores especiales relacionados con semanas epidemiológicas.Puedes encontrar una lista completa de las funciones de forcats en línea aquí. continuación mostramos algunas de las más comunes.","code":""},{"path":"factors.html","id":"preparation-2","chapter":"11 Factores","heading":"11.1 Preparación","text":"","code":""},{"path":"factors.html","id":"cargar-paquetes-2","chapter":"11 Factores","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,           # import/export\n  here,          # filepaths\n  lubridate,     # working with dates\n  forcats,       # factors\n  aweek,         # create epiweeks with automatic factor levels\n  janitor,       # tables\n  tidyverse      # data mgmt and viz\n  )"},{"path":"factors.html","id":"importar-datos-2","chapter":"11 Factores","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa sus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"factors.html","id":"fct_newcat","chapter":"11 Factores","heading":"Nueva variable categórica","text":"Para mostrarlo en esta página utilizaremos un escenario común - la creación de una nueva variable categórica.Ten en cuenta que si conviertes una columna numérica en una de tipo factor, podrás calcular estadísticas numéricas sobre ella.","code":""},{"path":"factors.html","id":"crear-columna","chapter":"11 Factores","heading":"Crear columna","text":"Utilizamos la columna existente days_onset_hosp (días desde el inicio de los síntomas hasta el ingreso en el hospital) y creamos una nueva columna delay_cat clasificando cada fila en una de varias categorías. Lo hacemos con la función dplyr case_when(), que aplica secuencialmente criterios lógicos (lado derecho) cada fila y devuelve el valor correspondiente del lado izquierdo para la nueva columna delay_cat. Puedes leer más sobre case_when() en Limpieza de datos y funciones básicas.","code":"\nlinelist <- linelist %>% \n  mutate(delay_cat = case_when(\n    # criteria                                   # new value if TRUE\n    days_onset_hosp < 2                        ~ \"<2 days\",\n    days_onset_hosp >= 2 & days_onset_hosp < 5 ~ \"2-5 days\",\n    days_onset_hosp >= 5                       ~ \">5 days\",\n    is.na(days_onset_hosp)                     ~ NA_character_,\n    TRUE                                       ~ \"Check me\"))  "},{"path":"factors.html","id":"orden-de-valores-por-defecto","chapter":"11 Factores","heading":"Orden de valores por defecto","text":"Tal y como se creó con case_when(), la nueva columna delay_cat es una columna categórica de tipo Character - aún es un factor. Así, en una tabla de frecuencias, vemos que los valores únicos aparecen en un orden alfanumérico por defecto - un orden que tiene mucho sentido intuitivo:Del mismo modo, si hacemos un gráfico de barras, los valores también aparecen en este orden en el eje x (ver la página de conceptos básicos de ggplot para más información sobre ggplot2 - el paquete de visualización más común en R).","code":"\ntable(linelist$delay_cat, useNA = \"always\")## \n##  <2 days  >5 days 2-5 days     <NA> \n##     2990      602     2040      256\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"convert-to-factor","chapter":"11 Factores","heading":"11.2 Convertir en factor","text":"Para convertir una columna numérica o de caracteres en una de tipo factor, puedes utilizar cualquier función del paquete forcats (muchas se detallan continuación). Las convertirán en otra de tipo factor y luego también realizarán o permitirán cierto ordenamiento de los niveles - por ejemplo usando fct_relevel() permite especificar manualmente el orden de los niveles. La función as_factor() simplemente convierte el tipo sin ninguna otra capacidad.La función factor() de R base convierte una columna en factor y permite especificar manualmente el orden de los niveles, como un vector de caracteres su argumento levels =.continuación utilizamos mutate() y fct_relevel() para convertir la columna delay_cat de tipo carácter tipo factor. La columna delay_cat se crea en la sección de preparación anterior.Los “valores” únicos de esta columna se consideran ahora “niveles” del factor. Los niveles tienen un orden, que puede imprimirse con la función de levels(), o alternativamente verse en una tabla de recuento mediante table() de R base o tabyl() de janitor. Por defecto, el orden de los niveles será alfanumérico, como antes. Ten en cuenta que NA es un nivel de factor.La función fct_relevel() tiene la utilidad adicional de permitir especificar manualmente el orden de los niveles. Simplemente escribe los valores de nivel en orden, entre comillas, separados por comas, como se muestra continuación. Ten en cuenta que la ortografía debe coincidir exactamente con los valores. Si deseas crear niveles que existen en los datos, utiliza fct_expand() en su lugar).Ahora podemos ver que los niveles están ordenados, como se especificó en el comando anterior, en un orden sensato.Ahora el orden de la gráfica también tiene un sentido más intuitivo.","code":"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \">5 days\"  \"2-5 days\"\nlinelist <- linelist %>%\n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", \"2-5 days\", \">5 days\"))\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = delay_cat))"},{"path":"factors.html","id":"add-or-drop-levels","chapter":"11 Factores","heading":"11.3 Añadir o quitar niveles","text":"","code":""},{"path":"factors.html","id":"fct_add","chapter":"11 Factores","heading":"Añadir","text":"Si necesitas añadir niveles un factor, puedes hacerlo con fct_expand(). Basta con escribir el nombre de la columna seguido de los nuevos niveles (separados por comas). Al tabular los valores, podemos ver los nuevos niveles y los recuentos de cero. Puedes utilizar table() de R base, o tabyl() de janitor:Nota: existe una función especial de forcats para añadir fácilmente valores faltantes (NA) como nivel. Véase la sección sobre valores faltantes más adelante.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_expand(delay_cat, \"Not admitted to hospital\", \"Transfer to other jurisdiction\")) %>% \n  tabyl(delay_cat)   # print table##                       delay_cat    n    percent valid_percent\n##                         <2 days 2990 0.50781250     0.5308949\n##                        2-5 days 2040 0.34646739     0.3622159\n##                         >5 days  602 0.10224185     0.1068892\n##        Not admitted to hospital    0 0.00000000     0.0000000\n##  Transfer to other jurisdiction    0 0.00000000     0.0000000\n##                            <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"quitar","chapter":"11 Factores","heading":"Quitar","text":"Si utilizas fct_drop(), los niveles “utilizados” con recuento cero se eliminarán del conjunto de niveles. Los niveles que hemos añadido anteriormente (“admitido en un hospital”) existen como nivel, pero ninguna fila tiene realmente esos valores. Por tanto, se eliminarán aplicando fct_drop() nuestra columna de factores:","code":"\nlinelist %>% \n  mutate(delay_cat = fct_drop(delay_cat)) %>% \n  tabyl(delay_cat)##  delay_cat    n    percent valid_percent\n##    <2 days 2990 0.50781250     0.5308949\n##   2-5 days 2040 0.34646739     0.3622159\n##    >5 days  602 0.10224185     0.1068892\n##       <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"fct_adjust","chapter":"11 Factores","heading":"11.4 Ajustar el orden de los niveles","text":"El paquete forcats ofrece funciones útiles para ajustar fácilmente el orden de los niveles de un factor (después de haber definido una columna como de tipo factor):Estas funciones pueden aplicarse una columna de factores en dos contextos:la columna del dataframe, como es habitual, para que la transformación esté disponible para cualquier uso posterior de los datosDentro de un gráfico, para que el cambio se aplique sólo dentro del gráfico","code":""},{"path":"factors.html","id":"manualmente","chapter":"11 Factores","heading":"Manualmente","text":"Esta función se utiliza para ordenar manualmente los niveles de los factores. Si se utiliza en una columna factorial, la columna se convertirá primero en de tipo factor.Dentro del paréntesis, indica primero el nombre de la columna del factor y, continuación, escribeTodos los niveles en el orden deseado (como un vector de caracteres c()), oUn nivel y se corrige la colocación utilizando el argumento =aquí un ejemplo de redefinición de la columna delay_cat (que ya es de tipo Factor) y especificando todo el orden de niveles deseado.Si sólo quieres mover un nivel, puedes especificarlo sólo en fct_relevel() y dar un número al argumento =para indicar en qué lugar del orden debe estar. Por ejemplo, el comando siguiente desplaza “<2 días” la segunda posición:","code":"\n# re-define level order\nlinelist <- linelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\")))\n# re-define level order\nlinelist %>% \n  mutate(delay_cat = fct_relevel(delay_cat, \"<2 days\", after = 1)) %>% \n  tabyl(delay_cat)"},{"path":"factors.html","id":"dentro-de-un-gráfico","chapter":"11 Factores","heading":"Dentro de un gráfico","text":"Los comandos forcats pueden utilizarse para establecer el orden de los niveles en el dataframe, o sólo dentro de un gráfico. Al utilizar el comando para “envolver” el nombre de la columna dentro del comando ggplot(), puedes invertir/nivelar/etc. la transformación sólo se aplicará dentro de ese gráfico.continuación, se crean dos gráficos con ggplot() (véase la página de conceptos básicos de ggplot). En el primero, la columna delay_cat se asigna al eje x del gráfico, con su orden de nivel por defecto como en linelist de datos. En el segundo ejemplo se envuelve dentro de fct_relevel() y se cambia el orden en el gráfico.Ten en cuenta que el título del eje x por defecto es ahora bastante complicado - puedes sobrescribir este título con el argumento de ggplot2 labs().","code":"\n# Alpha-numeric default order - no adjustment within ggplot\nggplot(data = linelist)+\n    geom_bar(mapping = aes(x = delay_cat))\n\n# Factor level order adjusted within ggplot\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = fct_relevel(delay_cat, c(\"<2 days\", \"2-5 days\", \">5 days\"))))"},{"path":"factors.html","id":"invertir","chapter":"11 Factores","heading":"Invertir","text":"Es bastante común que se quiera invertir el orden de los niveles. Basta con envolver el factor con fct_rev().Ten en cuenta que si deseas revertir sólo una leyenda del gráfico pero los niveles reales del factor, puedes hacerlo con guides() (ver consejos de ggplot).","code":""},{"path":"factors.html","id":"por-frecuencia","chapter":"11 Factores","heading":"Por frecuencia","text":"Para ordenar por la frecuencia con que el valor aparece en los datos, utiliza fct_infreq(). Cualquier valor que falte (NA) se incluirá automáticamente al final, menos que se convierta en un nivel explícito (véase esta sección). Puedes invertir el orden envolviendo más con fct_rev().Esta función puede utilizarse dentro de ggplot(), como se muestra continuación.","code":"\n# ordered by frequency\nggplot(data = linelist, aes(x = fct_infreq(delay_cat)))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by frequency\")\n\n# reversed frequency\nggplot(data = linelist, aes(x = fct_rev(fct_infreq(delay_cat))))+\n  geom_bar()+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Reverse of order by frequency\")"},{"path":"factors.html","id":"por-apariencia","chapter":"11 Factores","heading":"Por apariencia","text":"Utiliza fct_inorder() para establecer el orden de los niveles para que coincida con el orden de aparición en los datos, empezando por la primera fila. Esto puede ser útil si primero organizas cuidadosamente arrange() los datos en el dataframe, y luego utiliza esto para establecer el orden de los factores.","code":""},{"path":"factors.html","id":"por-estadística-resumida-de-otra-columna","chapter":"11 Factores","heading":"Por estadística resumida de otra columna","text":"Puedes utilizar fct_reorder() para ordenar los niveles de una columna por una estadística de resumen de otra columna. Visualmente, esto puede dar lugar gráficos agradables en los que las barras/puntos ascienden o descienden de forma constante través del gráfico.En los ejemplos siguientes, el eje x es delay_cat, y el eje y es la columna numérica ct_blood (valor de umbral de ciclo). Los gráficos de caja muestran la distribución del valor CT por grupo delay_cat. Queremos ordenar los gráficos de caja en orden ascendente por mediana del grupo CT.En el primer ejemplo de abajo, se utiliza el orden por defecto de los niveles alfa-numéricos. Se puede ver que las alturas de los gráficos de caja están mezcladas y en ningún orden particular. En el segundo ejemplo, la columna delay_cat (asignada al eje x) se ha envuelto en fct_reorder(), la columna ct_blood se da como segundo argumento, y la “mediana” se da como tercer argumento (también podría usar “max”, “mean”, “min”, etc). Por lo tanto, el orden de los niveles de delay_cat reflejará ahora los valores ascendentes de la mediana del CT de cada grupo de delay_cat. Esto se refleja en el segundo gráfico: los gráficos de caja se han reordenado de forma ascendente. Observa cómo NA (missing) aparecerá al final, menos que se convierta en un nivel explícito.Observa que en este ejemplo se requieren pasos previos la llamada ggplot() - la agrupación y los cálculos se realizan internamente en el comando ggplot.","code":"\n# boxplots ordered by original factor levels\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = delay_cat,\n        y = ct_blood, \n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by original alpha-numeric levels\")+\n  theme_classic()+\n  theme(legend.position = \"none\")\n\n\n# boxplots ordered by median CT value\nggplot(data = linelist)+\n  geom_boxplot(\n    aes(x = fct_reorder(delay_cat, ct_blood, \"median\"),\n        y = ct_blood,\n        fill = delay_cat))+\n  labs(x = \"Delay onset to admission (days)\",\n       title = \"Ordered by median CT value in group\")+\n  theme_classic()+\n  theme(legend.position = \"none\")"},{"path":"factors.html","id":"por-valor-final","chapter":"11 Factores","heading":"Por valor “final”","text":"Utiliza fct_reorder2() para los gráficos de líneas agrupadas. Ordena los niveles (y, por tanto, la leyenda) para que se alineen con la ordenación vertical de las líneas en el “final” del gráfico. Técnicamente hablando, “ordena por los valores-y asociados los valores-x más grandes”.Por ejemplo, si tienes líneas que muestran los recuentos de casos por hospital lo largo del tiempo, puedes aplicar fct_reorder2() al argumento color =dentro de aes(), de forma que el orden vertical de los hospitales que aparecen en la leyenda se alinee con el orden de las líneas en el extremo terminal del gráfico. Lee más en la documentación en línea.","code":"\nepidemic_data <- linelist %>%         # begin with the linelist   \n    filter(date_onset < as.Date(\"2014-09-21\")) %>%    # cut-off date, for visual clarity\n    count(                                            # get case counts per week and by hospital\n      epiweek = lubridate::floor_date(date_onset, \"week\"),  \n      hospital                                            \n    ) \n  \nggplot(data = epidemic_data)+                       # start plot\n  geom_line(                                        # make lines\n    aes(\n      x = epiweek,                                  # x-axis epiweek\n      y = n,                                        # height is number of cases per week\n      color = fct_reorder2(hospital, epiweek, n)))+ # data grouped and colored by hospital, with factor order by height at end of plot\n  labs(title = \"Factor levels (and legend display) by line height at end of plot\",\n       color = \"Hospital\")                          # change legend title"},{"path":"factors.html","id":"fct_missing","chapter":"11 Factores","heading":"11.5 Valores faltantes","text":"Si hay valores NA en lu columna de factores, puede convertirlos fácilmente un nivel con nombre como “Missing” con fct_explicit_na(). Los valores NA se convierten por defecto en “(Missing)” al final del orden de los niveles. Puedes ajustar el nombre del nivel con el argumento na_level =.continuación, esta operación se realiza en la columna delay_cat y se imprime una tabla con tabyl() con NA convertido en “Missing delay”.","code":"\nlinelist %>% \n  mutate(delay_cat = fct_explicit_na(delay_cat, na_level = \"Missing delay\")) %>% \n  tabyl(delay_cat)##      delay_cat    n    percent\n##       2-5 days 2040 0.34646739\n##        <2 days 2990 0.50781250\n##        >5 days  602 0.10224185\n##  Missing delay  256 0.04347826"},{"path":"factors.html","id":"combine-levels","chapter":"11 Factores","heading":"11.6 Combinar niveles","text":"","code":""},{"path":"factors.html","id":"manualmente-1","chapter":"11 Factores","heading":"Manualmente","text":"Puedes ajustar las visualizaciones de los niveles manualmente con fct_recode(). Es como la función recode() de dplyr (véase Limpieza de datos y funciones básicas), pero permite la creación de nuevos niveles de factores. Si utilizas la función simple recode() en un factor, los nuevos valores recodificados serán rechazados menos que ya hayan sido establecidos como niveles permitidos.Esta herramienta también puede utilizarse para “combinar” niveles, asignando varios niveles el mismo valor recodificado. Sólo hay que tener cuidado de perder información. Considere la posibilidad de realizar estos pasos de combinación en una nueva columna (sin sobreescribir la columna existente).fct_recode() tiene una sintaxis diferente la de recode(). recode() utiliza OLD = NEW, mientras que fct_recode() utiliza NEW = OLD.Los niveles actuales de delay_cat son:Los nuevos niveles se crean utilizando la sintaxis fct_recode(column, \"new\" = \"old\", \"new\" = \"old\", \"new\" = \"old\") y se imprimen:Aquí se combinan manualmente con fct_recode(). Obsérvese que se produce ningún error en la creación de un nuevo nivel “Menos de 5 días”.","code":"\nlevels(linelist$delay_cat)## [1] \"<2 days\"  \"2-5 days\" \">5 days\"\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 2 days\" = \"<2 days\",\n    \"2 to 5 days\"      = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 2 days 2990 0.50781250     0.5308949\n##       2 to 5 days 2040 0.34646739     0.3622159\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA\nlinelist %>% \n  mutate(delay_cat = fct_recode(\n    delay_cat,\n    \"Less than 5 days\" = \"<2 days\",\n    \"Less than 5 days\" = \"2-5 days\",\n    \"More than 5 days\" = \">5 days\")) %>% \n  tabyl(delay_cat)##         delay_cat    n    percent valid_percent\n##  Less than 5 days 5030 0.85427989     0.8931108\n##  More than 5 days  602 0.10224185     0.1068892\n##              <NA>  256 0.04347826            NA"},{"path":"factors.html","id":"reducir-a-otros","chapter":"11 Factores","heading":"Reducir a “Otros”","text":"Puedes utilizar fct_other() para asignar manualmente niveles de factor un nivel “Otro”. continuación, todos los niveles de la columna hospital, aparte de “Port Hospital” y “Central Hospital”, se combinan en “Otros”. Puedes proporcionar el vector keep =, o drop = para mantener o eliminarlo. Puedes cambiar la visualización del nivel “Otro” con other_level =.","code":"\nlinelist %>%    \n  mutate(hospital = fct_other(                      # adjust levels\n    hospital,\n    keep = c(\"Port Hospital\", \"Central Hospital\"),  # keep these separate\n    other_level = \"Other Hospital\")) %>%            # All others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##          hospital    n    percent\n##  Central Hospital  454 0.07710598\n##     Port Hospital 1762 0.29925272\n##    Other Hospital 3672 0.62364130"},{"path":"factors.html","id":"reducir-por-frecuencia","chapter":"11 Factores","heading":"Reducir por frecuencia","text":"Puedes combinar los niveles del factor menos frecuente automáticamente utilizando fct_lump().Para “agrupar” muchos niveles de baja frecuencia en un grupo “Otros”, puedes hacer una de las siguientes cosas:Establecer con n = el número de grupos que deseas conservar. Los n niveles más frecuentes se mantendrán, y todos los demás se combinarán en “Otros”.Establecer con n = el número de grupos que deseas conservar. Los n niveles más frecuentes se mantendrán, y todos los demás se combinarán en “Otros”.Fijar con prop = la proporción de frecuencia del umbral para los niveles por encima de los cuales deseas mantener. Todos los demás valores se combinarán en “Otros”.Fijar con prop = la proporción de frecuencia del umbral para los niveles por encima de los cuales deseas mantener. Todos los demás valores se combinarán en “Otros”.Puedes cambiar la visualización del nivel “Otros” con other_level =. continuación, todos los hospitales excepto los dos más frecuentes se combinan en “hospitals”.","code":"\nlinelist %>%    \n  mutate(hospital = fct_lump(                      # adjust levels\n    hospital,\n    n = 2,                                          # keep top 2 levels\n    other_level = \"Other Hospital\")) %>%            # all others as \"Other Hospital\"\n  tabyl(hospital)                                   # print table##        hospital    n   percent\n##         Missing 1469 0.2494905\n##   Port Hospital 1762 0.2992527\n##  Other Hospital 2657 0.4512568"},{"path":"factors.html","id":"show-all-levels","chapter":"11 Factores","heading":"11.7 Mostrar todos los niveles","text":"Una de las ventajas del uso de factores es la estandarización del aspecto de las leyendas de los gráficos y de las tablas, independientemente de los valores que estén realmente presentes en unos datos.Si estás preparando muchas figuras (por ejemplo, para varias jurisdicciones), querrás que las leyendas y las tablas aparezcan de forma idéntica incluso con distintos niveles de cumplimentación o de composición de los datos.","code":""},{"path":"factors.html","id":"en-los-gráficos","chapter":"11 Factores","heading":"En los gráficos","text":"En una figura ggplot(), basta con añadir el argumento drop = FALSE en la función scale_xxxx() correspondiente. Se mostrarán todos los niveles de los factores, independientemente de si están presentes en los datos. Si sus niveles de columna de factores se muestran con fill =, entonces en scale_fill_discrete() incluye drop = FALSE, como se muestra continuación. Si sus niveles se muestran con x = (al eje-x) color = o size =, deberás establecer esto con scale_color_discrete() o scale_size_discrete() según corresponda.Este ejemplo es un gráfico de barras apiladas de la categoría de edad, por hospital. Añadiendo scale_fill_discrete(drop = FALSE) se garantiza que todos los grupos de edad aparezcan en la leyenda, aunque estén presentes en los datos.","code":"\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = hospital, fill = age_cat)) +\n  scale_fill_discrete(drop = FALSE)+                        # show all age groups in the legend, even those not present\n  labs(\n    title = \"All age groups will appear in legend, even if not present in data\")"},{"path":"factors.html","id":"en-tablas","chapter":"11 Factores","heading":"En tablas","text":"Tanto table() de R base como tabyl() de janitor mostrarán todos los niveles de los factores (incluso los utilizados).Si utilizas count() o summarise() de dplyr para hacer una tabla, añade el argumento .drop = FALSE para incluir los recuentos de todos los niveles del factor, incluso los utilizados.Puedes leer más en la página de tablas descriptivas, o en la documentación de scale_discrete, o en la documentación de count(). Puedes ver otro ejemplo en la página de rastreo de contactos.","code":""},{"path":"factors.html","id":"epiweeks","chapter":"11 Factores","heading":"11.8 Epiweeks","text":"Por favor, consulta la extensa discusión sobre cómo crear semanas epidemiológicas en la página de Agrupar datos. Consulta también la página Trabajar con fechas para obtener consejos sobre cómo crear y dar formato las semanas epidemiológicas.","code":""},{"path":"factors.html","id":"epiweeks-en-un-gráfico","chapter":"11 Factores","heading":"Epiweeks en un gráfico","text":"Si tu objetivo es crear epiweeks para mostrarlos en un gráfico, puedes hacerlo simplemente con floor_date() de lubridate, como se explica en la página de Agrupar datos. Los valores devueltos serán del tipo Date con el formato YYYY-MM-DD. Si utilizas esta columna en un gráfico, las fechas se ordenarán correctamente de forma natural, y tendrá que preocuparse de los niveles o de la conversión al tipo Factor. Mira el histograma ggplot() de las fechas de inicio más abajo.En este enfoque, se puede ajustar la visualización de las fechas en un eje con scale_x_date(). Consulta la página sobre curvas epidémicas para obtener más información. Puedes especificar un formato de visualización “strptime” al argumento date_labels = de scale_x_date(). Estos formatos utilizan marcadores de posición “%” y se tratan en la página Trabajar con fechas. Utiliza “%Y” para representar un año de 4 dígitos, y “%W” o “%U” para representar el número de la semana (semana del lunes o del domingo respectivamente).","code":"\nlinelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\")) %>%  # create week column\n  ggplot()+                                                  # begin ggplot\n  geom_histogram(mapping = aes(x = epiweek_date))+           # histogram of date of onset\n  scale_x_date(date_labels = \"%Y-W%W\")                       # adjust disply of dates to be YYYY-WWw"},{"path":"factors.html","id":"epiweeks-en-los-datos","chapter":"11 Factores","heading":"Epiweeks en los datos","text":"Sin embargo, si tu propósito al factorizar es hacer gráficos, puedes enfocar esto de dos maneras:Para un control preciso de la visualización, convierte la columna de la semana-epi lubrificada (AAAA-MM-DD) al formato de visualización deseado (AAAA-WWw) dentro del propio dataframe, y luego conviértala en tipo Factor.En primer lugar, utiliza format() para convertir la visualización de la fecha de YYYY-MM-DD YYYY-Www (consulta la página Trabajar con fechas). En este proceso el tipo será convertida carácter. continuación, convierta de carácter tipo Factor con factor().PELIGRO: Si colocas las semanas por delante de los años (“Www-YYY”) (“%W-%Y”), la ordenación por defecto del nivel alfanumérico será incorrecta (por ejemplo, 01-2015 estará antes que 35-2014). Podría ser necesario ajustar manualmente el orden, lo que sería un proceso largo y doloroso. Para una visualización rápida por defecto, utiliza el paquete aweek y su función date2week(). Puedes establecer el día de comienzo con week_start =, y si estableces factor = TRUE entonces la columna de salida es un factor ordenado. Como ventaja, el factor incluye niveles para todas las semanas posibles en el lapso - incluso si hay casos esa semana.Consulta la página Trabajar con fechas para obtener más información sobre aweek. También ofrece la función inversa week2date().","code":"\nlinelist <- linelist %>% \n  mutate(epiweek_date = floor_date(date_onset, \"week\"),       # create epiweeks (YYYY-MM-DD)\n         epiweek_formatted = format(epiweek_date, \"%Y-W%W\"),  # Convert to display (YYYY-WWw)\n         epiweek_formatted = factor(epiweek_formatted))       # Convert to factor\n\n# Display levels\nlevels(linelist$epiweek_formatted)##  [1] \"2014-W13\" \"2014-W14\" \"2014-W15\" \"2014-W16\" \"2014-W17\" \"2014-W18\" \"2014-W19\" \"2014-W20\" \"2014-W21\"\n## [10] \"2014-W22\" \"2014-W23\" \"2014-W24\" \"2014-W25\" \"2014-W26\" \"2014-W27\" \"2014-W28\" \"2014-W29\" \"2014-W30\"\n## [19] \"2014-W31\" \"2014-W32\" \"2014-W33\" \"2014-W34\" \"2014-W35\" \"2014-W36\" \"2014-W37\" \"2014-W38\" \"2014-W39\"\n## [28] \"2014-W40\" \"2014-W41\" \"2014-W42\" \"2014-W43\" \"2014-W44\" \"2014-W45\" \"2014-W46\" \"2014-W47\" \"2014-W48\"\n## [37] \"2014-W49\" \"2014-W50\" \"2014-W51\" \"2015-W00\" \"2015-W01\" \"2015-W02\" \"2015-W03\" \"2015-W04\" \"2015-W05\"\n## [46] \"2015-W06\" \"2015-W07\" \"2015-W08\" \"2015-W09\" \"2015-W10\" \"2015-W11\" \"2015-W12\" \"2015-W13\" \"2015-W14\"\n## [55] \"2015-W15\" \"2015-W16\"\ndf <- linelist %>% \n  mutate(epiweek = date2week(date_onset, week_start = \"Monday\", factor = TRUE))\n\nlevels(df$epiweek)"},{"path":"factors.html","id":"resources-4","chapter":"11 Factores","heading":"11.9 Recursos","text":"Página de R Data Science en español sobre factores\nviñeta del paquete aweek","code":""},{"path":"pivoting-data.html","id":"pivoting-data","chapter":"12 Pivotar datos","heading":"12 Pivotar datos","text":"En la gestión de datos, se puede entender que el pivoteo se refiere uno de los dos procesos:La creación de tablas dinámicas, que son tablas de estadísticas que resumen los datos de una tabla más extensaLa creación de tablas dinámicas, que son tablas de estadísticas que resumen los datos de una tabla más extensaLa conversión de una tabla de formato largo formato ancho, o viceversa.La conversión de una tabla de formato largo formato ancho, o viceversa.En esta página, nos centraremos en la última definición. La primera es un paso crucial en el análisis de datos, y se trata en las páginas Agrupar datos y Tablas descriptivas.En esta página se tratan los formatos de los datos. Es útil conocer la idea de “datos ordenados”, en la que cada variable tiene su propia columna, cada observación tiene su propia fila y cada valor tiene su propia celda. Se puede encontrar más información sobre este tema en este capítulo en línea de R Data Science.","code":""},{"path":"pivoting-data.html","id":"preparation-3","chapter":"12 Pivotar datos","heading":"12.1 Preparación","text":"","code":""},{"path":"pivoting-data.html","id":"cargar-paquetes-3","chapter":"12 Pivotar datos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse)    # data management + ggplot2 graphics"},{"path":"pivoting-data.html","id":"importar-datos-3","chapter":"12 Pivotar datos","heading":"Importar datos","text":"","code":""},{"path":"pivoting-data.html","id":"recuento-de-casos-de-malaria","chapter":"12 Pivotar datos","heading":"Recuento de casos de malaria","text":"En esta página, utilizaremos unos datos ficticios de casos diarios de malaria, por centro y grupo de edad. Si quieres seguirlo, clica aquí para descargarlo (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas.","code":"\n# Import data\ncount_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"pivoting-data.html","id":"listado-de-casos-de-linelist","chapter":"12 Pivotar datos","heading":"Listado de casos de Linelist","text":"En la parte posterior de esta página, también utilizaremos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aqui para descargar linelist “limpio” (como archivo .rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - mira la página de importación y exportación para más detalles).","code":"\n# import your dataset\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"pivoting-data.html","id":"wide-to-long","chapter":"12 Pivotar datos","heading":"12.2 De ancho a largo","text":"","code":""},{"path":"pivoting-data.html","id":"formato-ancho","chapter":"12 Pivotar datos","heading":"“Formato ancho”","text":"Los datos suelen introducirse y almacenarse en un formato “amplio”, en el que las características o respuestas de un sujeto se almacenan en una sola fila. Aunque esto puede ser útil para la presentación, es ideal para algunos tipos de análisis.Tomemos como ejemplo el set de datos count_data importado en la sección “Preparación”. Puedes ver que cada fila representa un “centro-día”. Los recuentos de casos reales (las columnas más la derecha) se almacenan en un formato “ancho”, de modo que la información de cada grupo de edad en un día determinado del centro se almacena en una sola fila.Cada observación de este conjunto de datos se refiere los recuentos de paludismo en una de las 65 instalaciones en una fecha determinada, que va desde count_data$data_date %\\>% min() hasta count_data$data_date %\\>% max(). Estas instalaciones están situadas en una Province (Norte) y cuatro District (Spring, Bolo, Dingo y Barnard). Los datos proporcionan los recuentos globales de malaria, así como los recuentos específicos por edad en cada uno de los tres grupos de edad: <4 años, 5-14 años y 15 años o más.Los datos “anchos” como éste se ajustan las normas de “datos ordenados”, porque los encabezados de las columnas representan realmente “variables”, sino que representan valores de una hipotética variable “grupo de edad”.Este formato puede ser útil para presentar la información en una tabla, o para introducir datos (por ejemplo, en Excel) partir de formularios de informes de casos. Sin embargo, en la etapa de análisis, estos datos normalmente deben ser transformados un formato “largo” más alineado con los estándares de “datos ordenados”. El paquete ggplot2, en particular, funciona mejor cuando los datos están en un formato “largo”.La visualización de los recuentos totales de malaria lo largo del tiempo plantea ninguna dificultad con los datos en su formato actual:Sin embargo, ¿qué pasaría si quisiéramos mostrar las contribuciones relativas de cada grupo de edad este recuento total? En este caso, necesitamos asegurarnos de que la variable de interés (grupo de edad), aparezca en el conjunto de datos en una sola columna que pueda pasarse {ggplot2} el argumento aes() de “mapping aesthetics”.","code":"\nggplot(count_data) +\n  geom_col(aes(x = data_date, y = malaria_tot), width = 1)"},{"path":"pivoting-data.html","id":"pivot_longer","chapter":"12 Pivotar datos","heading":"pivot_longer()","text":"La función pivot_longer() de tidyr hace que los datos sean “largos”. tidyr forma parte de los paquetes tidyverse .Acepta un rango de columnas para transformar (especificado cols =). Por lo tanto, puede operar sólo en una parte de unos datos. Esto es útil para los datos de la malaria, ya que sólo queremos pivotar las columnas de recuento de casos.En este proceso, terminará con dos “nuevas” columnas - una con las categorías (los antiguos nombres de las columnas), y otra con los valores correspondientes (por ejemplo, recuento de casos). Puedes aceptar los nombres por defecto para estas nuevas columnas, o puede especificar otros con names_to = y values_to = respectivamente.Veamos pivot_longer() en acción…","code":""},{"path":"pivoting-data.html","id":"pivoteo-estándar","chapter":"12 Pivotar datos","heading":"Pivoteo estándar","text":"Queremos utilizar la función pivot_longer() de tidyr para convertir los datos “anchos” en un formato “largo”. Concretamente, para convertir las cuatro columnas numéricas con datos sobre los recuentos de malaria en dos nuevas columnas: una que contenga los grupos de edad y otra que contenga los valores correspondientes.Observa que el dataframe recién creado (df_long) tiene más filas (12.152 frente 3.038); se ha hecho más largo. De hecho, es precisamente cuatro veces más largo, porque cada fila de los datos originales representa ahora cuatro filas en df_long, una para cada una de las observaciones de recuento de malaria (<4 años, 5-14 años, 15 años+ y total).Además de ser más largo, el nuevo conjunto de datos tiene menos columnas (8 frente 10), ya que los datos que antes se almacenaban en cuatro columnas (las que empiezan por el prefijo malaria_) se almacenan ahora en dos.Dado que los nombres de estas cuatro columnas comienzan con el prefijo malaria_, podríamos haber hecho uso de la práctica función “tidyselect” starts_with() para conseguir el mismo resultado (véase la página Limpieza de datos y funciones básicas para conocer más sobre estas funciones de ayuda).o por posición:o por rango de nombres:Estas dos nuevas columnas reciben los nombres por defecto de name y value, pero podemos cambiar estos valores por defecto para proporcionar nombres más significativos, que pueden ayudar recordar lo que se almacena dentro, utilizando los argumentos names_to y values_to. Utilicemos los nombres age_group y counts:Ahora podemos pasar este nuevo conjunto de datos ggplot2, y asignar la nueva columna count al eje-y y la nueva columna age_group al argumento fill = (el color interno de la columna). Esto mostrará los recuentos de malaria en un gráfico de barras apilado, por grupo de edad:Examina esta nueva gráfica y compárala con la que hemos creado antes: ¿qué ha fallado?Nos hemos encontrado con un problema común al manejar los datos de vigilancia: hemos incluido también los recuentos totales de la columna malaria_tot, por lo que la magnitud de cada barra en el gráfico es el doble de lo que debería ser.Podemos manejar esto de varias maneras. Podríamos simplemente filtrar estos totales en los datos antes de pasarlo ggplot():Como alternativa, podríamos haber excluido esta variable al ejecutar pivot_longer(), manteniéndola así en set de datos como una variable independiente. Observa cómo se “expanden” sus valores para llenar las nuevas filas.","code":"\ndf_long <- count_data %>% \n  pivot_longer(\n    cols = c(`malaria_rdt_0-4`, `malaria_rdt_5-14`, `malaria_rdt_15`, `malaria_tot`)\n  )\n\ndf_long\n# provide column with a tidyselect helper function\ncount_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\")\n  )## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid name             value\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>            <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4     11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14    12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15      23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot         46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4     11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14    10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15       5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot         26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4      8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14     5\n## # … with 12,142 more rows\n# provide columns by position\ncount_data %>% \n  pivot_longer(\n    cols = 6:9\n  )\n# provide range of consecutive columns\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_tot\n  )\ndf_long <- \n  count_data %>% \n  pivot_longer(\n    cols = starts_with(\"malaria_\"),\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )\n\ndf_long## # A tibble: 12,152 × 8\n##    location_name data_date  submitted_date Province District newid age_group        counts\n##    <chr>         <date>     <date>         <chr>    <chr>    <int> <chr>             <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_0-4      11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_5-14     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_rdt_15       23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring       1 malaria_tot          46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_0-4      11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_5-14     10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_rdt_15        5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo         2 malaria_tot          26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_0-4       8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo        3 malaria_rdt_5-14      5\n## # … with 12,142 more rows\nggplot(data = df_long) +\n  geom_col(\n    mapping = aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ndf_long %>% \n  filter(age_group != \"malaria_tot\") %>% \n  ggplot() +\n  geom_col(\n    aes(x = data_date, y = counts, fill = age_group),\n    width = 1\n  )\ncount_data %>% \n  pivot_longer(\n    cols = `malaria_rdt_0-4`:malaria_rdt_15,   # does not include the totals column\n    names_to = \"age_group\",\n    values_to = \"counts\"\n  )## # A tibble: 9,114 × 9\n##    location_name data_date  submitted_date Province District malaria_tot newid age_group        counts\n##    <chr>         <date>     <date>         <chr>    <chr>          <int> <int> <chr>             <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_0-4      11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_5-14     12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring            46     1 malaria_rdt_15       23\n##  4 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_0-4      11\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_5-14     10\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo              26     2 malaria_rdt_15        5\n##  7 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_0-4       8\n##  8 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_5-14      5\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo             18     3 malaria_rdt_15        5\n## 10 Facility 4    2020-08-11 2020-08-12     North    Bolo              49     4 malaria_rdt_0-4      16\n## # … with 9,104 more rows"},{"path":"pivoting-data.html","id":"pivotear-datos-de-múltiples-tipos","chapter":"12 Pivotar datos","heading":"Pivotear datos de múltiples tipos","text":"El ejemplo anterior funciona bien en situaciones en las que todas las columnas que se quieren “pivotar más” son del mismo tipo (carácter, numérico, lógico…).Sin embargo, habrá muchos casos en los que, en el trabajo de campo, se trabaje con datos preparados por personas especializadas y que sigan su propia lógica estándar - como señaló Hadley Wickham (haciendo referencia Tolstoi) en su artículo seminal sobre los principios de Tidy Data: “Como las familias, los conjuntos de datos ordenados son todos iguales, pero cada conjunto de datos desordenado es desordenado su manera”.Un problema particularmente común que encontrarás será la necesidad de pivotar columnas que contienen diferentes tipos de datos. Este pivote resultará en el almacenamiento de estos diferentes tipos de datos en una sola columna, lo cual es una buena situación. Se pueden seguir varios enfoques para separar el desorden que esto crea, pero hay un paso importante que puedes seguir usando pivot_longer() para evitar crear tal situación tu mismo.Tomemos una situación en la que ha habido una serie de observaciones en diferentes pasos de tiempo para cada uno de los tres elementos , B y C. Ejemplos de estos elementos podrían ser individuos (por ejemplo, contactos de un caso de ébola que se rastrean cada día durante 21 días) o puestos de salud de aldeas remotas que se supervisan una vez al año para garantizar que siguen funcionando. Utilicemos el ejemplo del rastreo de contactos. Imaginemos que los datos se almacenan de la siguiente manera:Como puede verse, los datos son un poco complicados. Cada fila almacena información sobre un elemento, pero con la serie temporal cada vez más alejada hacia la derecha medida que avanza el tiempo. Además, los tipos de columnas alternan entre valores de fecha y caracteres.Un ejemplo particularmente malo que encontró este autor fue el de los datos de vigilancia del cólera, en el que se añadieron 8 nuevas columnas de observaciones cada día en el transcurso de 4 años. El simple hecho de abrir el archivo de Excel en el que se almacenaban estos datos llevó más de 10 minutos en mi ordenador portátil.Para trabajar con estos datos, necesitamos transformar el dataframe formato largo, pero manteniendo la separación entre una columna date y una columna de character (estado), para cada observación de cada elemento. Si lo hacemos, podríamos terminar con una mezcla de tipos de variables en una sola columna (un gran “-” cuando se trata de gestión de datos y de datos ordenados):Arriba, nuestro pivote ha fusionado fechas y caracteres en una sola columna de value. R reaccionará convirtiendo toda la columna en tipo carácter, y se pierde la utilidad de las fechas.Para evitar esta situación, podemos aprovechar la estructura sintáctica de los nombres de las columnas originales. Hay una estructura de nombres común, con el número de observación, un guión bajo, y luego “estado” o “fecha”. Podemos aprovechar esta sintaxis para mantener estos dos tipos de datos en columnas separadas después del pivote.Para ello:Proporcionar un vector de caracteres al argumento names_to =, siendo el segundo elemento (\".value\"). Este término especial indica que las columnas pivotadas se dividirán basándose en un carácter de su nombre…También se debe proporcionar el carácter de “división” al argumento names_sep =. En este caso, es el guión bajo “_“.Así, la denominación y división de las nuevas columnas se basa en el guión bajo de los nombres de las variables existentes.Toques finales:Ten en cuenta que la columna de fecha es actualmente de tipo carácter - podemos convertirla fácilmente en tipo fecha utilizando las funciones mutate() y as_date() descritas en la página Trabajar con fechas.También podemos convertir la columna de observation un formato numeric eliminando el prefijo “obs” y convirtiendo numérico. Podemos hacer esto con str_remove_all() del paquete stringr (véase la página Caracteres y cadenas).Y ahora, podemos empezar trabajar con los datos en este formato, por ejemplo, trazando un mosaico de calor descriptivo:","code":"\ndf %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\")\n  )## # A tibble: 18 × 3\n##    id    observation value     \n##    <chr> <chr>       <chr>     \n##  1 A     obs1_date   2021-04-23\n##  2 A     obs1_status Healthy   \n##  3 A     obs2_date   2021-04-24\n##  4 A     obs2_status Healthy   \n##  5 A     obs3_date   2021-04-25\n##  6 A     obs3_status Unwell    \n##  7 B     obs1_date   2021-04-23\n##  8 B     obs1_status Healthy   \n##  9 B     obs2_date   2021-04-24\n## 10 B     obs2_status Healthy   \n## 11 B     obs3_date   2021-04-25\n## 12 B     obs3_status Healthy   \n## 13 C     obs1_date   2021-04-23\n## 14 C     obs1_status Missing   \n## 15 C     obs2_date   2021-04-24\n## 16 C     obs2_status Healthy   \n## 17 C     obs3_date   2021-04-25\n## 18 C     obs3_status Healthy\ndf_long <- \n  df %>% \n  pivot_longer(\n    cols = -id,\n    names_to = c(\"observation\", \".value\"),\n    names_sep = \"_\"\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr> <chr>       <chr>      <chr>  \n## 1 A     obs1        2021-04-23 Healthy\n## 2 A     obs2        2021-04-24 Healthy\n## 3 A     obs3        2021-04-25 Unwell \n## 4 B     obs1        2021-04-23 Healthy\n## 5 B     obs2        2021-04-24 Healthy\n## 6 B     obs3        2021-04-25 Healthy\n## 7 C     obs1        2021-04-23 Missing\n## 8 C     obs2        2021-04-24 Healthy\n## 9 C     obs3        2021-04-25 Healthy\ndf_long <- \n  df_long %>% \n  mutate(\n    date = date %>% lubridate::as_date(),\n    observation = \n      observation %>% \n      str_remove_all(\"obs\") %>% \n      as.numeric()\n  )\n\ndf_long## # A tibble: 9 × 4\n##   id    observation date       status \n##   <chr>       <dbl> <date>     <chr>  \n## 1 A               1 2021-04-23 Healthy\n## 2 A               2 2021-04-24 Healthy\n## 3 A               3 2021-04-25 Unwell \n## 4 B               1 2021-04-23 Healthy\n## 5 B               2 2021-04-24 Healthy\n## 6 B               3 2021-04-25 Healthy\n## 7 C               1 2021-04-23 Missing\n## 8 C               2 2021-04-24 Healthy\n## 9 C               3 2021-04-25 Healthy\nggplot(data = df_long, mapping = aes(x = date, y = id, fill = status)) +\n  geom_tile(colour = \"black\") +\n  scale_fill_manual(\n    values = \n      c(\"Healthy\" = \"lightgreen\", \n        \"Unwell\" = \"red\", \n        \"Missing\" = \"orange\")\n  )"},{"path":"pivoting-data.html","id":"long-to-wide","chapter":"12 Pivotar datos","heading":"12.3 De largo a ancho","text":"En algunos casos, es posible que queramos convertir unos datos un formato ancho. Para ello, podemos utilizar la función pivot_wider().Un caso de uso típico es cuando queremos transformar los resultados de un análisis en un formato que sea más digerible para el lector (como una tabla para su presentación). Por lo general, se trata de transformar unos datos en el que la información de un sujeto está repartida en varias filas en un formato en el que esa información se almacena en una sola fila.","code":""},{"path":"pivoting-data.html","id":"datos","chapter":"12 Pivotar datos","heading":"Datos","text":"Para esta sección de la página, utilizaremos la lista de casos (véase la sección Preparación), que contiene una fila por caso.Aquí están las primeras 50 filas:Supongamos que queremos conocer los recuentos de individuos en los diferentes grupos de edad, por género:Esto nos da un largo conjunto de datos que es genial para producir visualizaciones en ggplot2, pero es ideal para la presentación en una tabla:","code":"\ndf_wide <- \n  linelist %>% \n  count(age_cat, gender)\n\ndf_wide##    age_cat gender   n\n## 1      0-4      f 640\n## 2      0-4      m 416\n## 3      0-4   <NA>  39\n## 4      5-9      f 641\n## 5      5-9      m 412\n## 6      5-9   <NA>  42\n## 7    10-14      f 518\n## 8    10-14      m 383\n## 9    10-14   <NA>  40\n## 10   15-19      f 359\n## 11   15-19      m 364\n## 12   15-19   <NA>  20\n## 13   20-29      f 468\n## 14   20-29      m 575\n## 15   20-29   <NA>  30\n## 16   30-49      f 179\n## 17   30-49      m 557\n## 18   30-49   <NA>  18\n## 19   50-69      f   2\n## 20   50-69      m  91\n## 21   50-69   <NA>   2\n## 22     70+      m   5\n## 23     70+   <NA>   1\n## 24    <NA>   <NA>  86\nggplot(df_wide) +\n  geom_col(aes(x = age_cat, y = n, fill = gender))"},{"path":"pivoting-data.html","id":"pivote-ancho","chapter":"12 Pivotar datos","heading":"Pivote ancho","text":"Por lo tanto, podemos utilizar pivot_wider() para transformar los datos en un formato mejor para incluirlos como tablas en nuestros informes.El argumento names_from especifica la columna que genera la columna nueva names, mientras que el argumento values_from especifica la columna de la que tomar los values para rellenar las celdas. El argumento id_cols = es opcional, pero se puede proporcionar un vector de nombres de columnas que deben ser pivotadas, y que por tanto identificarán cada fila.Esta tabla es mucho más fácil de leer y, por tanto, mejor para incluirla en nuestros informes. Se puede convertir en una tabla bonita con varios paquetes, como flextable y knitr. Este proceso se elabora en la página Tablas para presentaciones.","code":"\ntable_wide <- \n  df_wide %>% \n  pivot_wider(\n    id_cols = age_cat,\n    names_from = gender,\n    values_from = n\n  )\n\ntable_wide## # A tibble: 9 × 4\n##   age_cat     f     m  `NA`\n##   <fct>   <int> <int> <int>\n## 1 0-4       640   416    39\n## 2 5-9       641   412    42\n## 3 10-14     518   383    40\n## 4 15-19     359   364    20\n## 5 20-29     468   575    30\n## 6 30-49     179   557    18\n## 7 50-69       2    91     2\n## 8 70+        NA     5     1\n## 9 <NA>       NA    NA    86\ntable_wide %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% # adds row and column totals\n  knitr::kable() %>% \n  kableExtra::row_spec(row = 10, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) "},{"path":"pivoting-data.html","id":"fill","chapter":"12 Pivotar datos","heading":"12.4 Rellenar","text":"En algunas situaciones después de pivotar, y más comúnmente después de unir con bind, nos quedan huecos en algunas celdas que nos gustaría rellenar.","code":""},{"path":"pivoting-data.html","id":"datos-1","chapter":"12 Pivotar datos","heading":"Datos","text":"Por ejemplo, toma dos conjuntos de datos, cada uno con observaciones para el número de medición, el nombre del centro y el recuento de casos en ese momento. Sin embargo, el segundo conjunto de datos también tiene la variable Year.Cuando realizamos un bind_rows() para unir los dos conjuntos de datos, la variable Year se rellena con NA para aquellas filas en las que había información previa (es decir, el primer conjunto de datos):","code":"\ndf1 <- \n  tibble::tribble(\n       ~Measurement, ~Facility, ~Cases,\n                  1,  \"Hosp 1\",     66,\n                  2,  \"Hosp 1\",     26,\n                  3,  \"Hosp 1\",      8,\n                  1,  \"Hosp 2\",     71,\n                  2,  \"Hosp 2\",     62,\n                  3,  \"Hosp 2\",     70,\n                  1,  \"Hosp 3\",     47,\n                  2,  \"Hosp 3\",     70,\n                  3,  \"Hosp 3\",     38,\n       )\n\ndf1 ## # A tibble: 9 × 3\n##   Measurement Facility Cases\n##         <dbl> <chr>    <dbl>\n## 1           1 Hosp 1      66\n## 2           2 Hosp 1      26\n## 3           3 Hosp 1       8\n## 4           1 Hosp 2      71\n## 5           2 Hosp 2      62\n## 6           3 Hosp 2      70\n## 7           1 Hosp 3      47\n## 8           2 Hosp 3      70\n## 9           3 Hosp 3      38\ndf2 <- \n  tibble::tribble(\n    ~Year, ~Measurement, ~Facility, ~Cases,\n     2000,            1,  \"Hosp 4\",     82,\n     2001,            2,  \"Hosp 4\",     87,\n     2002,            3,  \"Hosp 4\",     46\n  )\n\ndf2## # A tibble: 3 × 4\n##    Year Measurement Facility Cases\n##   <dbl>       <dbl> <chr>    <dbl>\n## 1  2000           1 Hosp 4      82\n## 2  2001           2 Hosp 4      87\n## 3  2002           3 Hosp 4      46\ndf_combined <- \n  bind_rows(df1, df2) %>% \n  arrange(Measurement, Facility)\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66    NA\n##  2           1 Hosp 2      71    NA\n##  3           1 Hosp 3      47    NA\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26    NA\n##  6           2 Hosp 2      62    NA\n##  7           2 Hosp 3      70    NA\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8    NA\n## 10           3 Hosp 2      70    NA\n## 11           3 Hosp 3      38    NA\n## 12           3 Hosp 4      46  2002"},{"path":"pivoting-data.html","id":"fill-1","chapter":"12 Pivotar datos","heading":"fill()","text":"En este caso, Year es una variable útil para incluir, especialmente si queremos explorar las tendencias lo largo del tiempo. Por lo tanto, utilizamos fill() para rellenar esas celdas vacías, especificando la columna rellenar y la dirección (en este caso hacia arriba):Alternativamente, podemos reordenar los datos para que tengamos que rellenar en sentido descendente:Ahora tenemos unos datos útiles para representarlos gráficamente:Pero es menos útil para presentarlo en una tabla, así que practiquemos la conversión de este largo y desordenado dataframe en un dataframe ancho y ordenado:N.B. En este caso, tuvimos que especificar que sólo se incluyeran las tres variables Facility, Year, y Cases, ya que la variable adicional Measurement interferiría en la creación de la tabla:","code":"\ndf_combined %>% \n  fill(Year, .direction = \"up\")## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 1      66  2000\n##  2           1 Hosp 2      71  2000\n##  3           1 Hosp 3      47  2000\n##  4           1 Hosp 4      82  2000\n##  5           2 Hosp 1      26  2001\n##  6           2 Hosp 2      62  2001\n##  7           2 Hosp 3      70  2001\n##  8           2 Hosp 4      87  2001\n##  9           3 Hosp 1       8  2002\n## 10           3 Hosp 2      70  2002\n## 11           3 Hosp 3      38  2002\n## 12           3 Hosp 4      46  2002\ndf_combined <- \n  df_combined %>% \n  arrange(Measurement, desc(Facility))\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47    NA\n##  3           1 Hosp 2      71    NA\n##  4           1 Hosp 1      66    NA\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70    NA\n##  7           2 Hosp 2      62    NA\n##  8           2 Hosp 1      26    NA\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38    NA\n## 11           3 Hosp 2      70    NA\n## 12           3 Hosp 1       8    NA\ndf_combined <- \n  df_combined %>% \n  fill(Year, .direction = \"down\")\n\ndf_combined## # A tibble: 12 × 4\n##    Measurement Facility Cases  Year\n##          <dbl> <chr>    <dbl> <dbl>\n##  1           1 Hosp 4      82  2000\n##  2           1 Hosp 3      47  2000\n##  3           1 Hosp 2      71  2000\n##  4           1 Hosp 1      66  2000\n##  5           2 Hosp 4      87  2001\n##  6           2 Hosp 3      70  2001\n##  7           2 Hosp 2      62  2001\n##  8           2 Hosp 1      26  2001\n##  9           3 Hosp 4      46  2002\n## 10           3 Hosp 3      38  2002\n## 11           3 Hosp 2      70  2002\n## 12           3 Hosp 1       8  2002\nggplot(df_combined) +\n  aes(Year, Cases, fill = Facility) +\n  geom_col()\ndf_combined %>% \n  pivot_wider(\n    id_cols = c(Measurement, Facility),\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  arrange(Facility) %>% \n  janitor::adorn_totals(c(\"row\", \"col\")) %>% \n  knitr::kable() %>% \n  kableExtra::row_spec(row = 5, bold = TRUE) %>% \n  kableExtra::column_spec(column = 5, bold = TRUE) \ndf_combined %>% \n  pivot_wider(\n    names_from = \"Year\",\n    values_from = \"Cases\"\n  ) %>% \n  knitr::kable()"},{"path":"pivoting-data.html","id":"resources-5","chapter":"12 Pivotar datos","heading":"12.5 Recursos","text":"Aquí hay un tutorial útil","code":""},{"path":"grouping-data.html","id":"grouping-data","chapter":"13 Agrupar datos","heading":"13 Agrupar datos","text":"Esta página cubre cómo agrupar y agregar datos para el análisis descriptivo. Hace uso de la familia de paquetes tidyverse para funciones comunes y fáciles de usar.La agrupación de datos es un componente esencial de la gestión y el análisis de datos. Los datos agrupados se resumen estadísticamente y pueden representarse gráficamente por grupos. Las funciones del paquete dplyr (parte del tidyverse) facilitan la agrupación y las operaciones posteriores.En esta página se tratarán los siguientes temas:Agrupar datos con la función group_by()Des-agrupar datossummarise() datos agrupados con estadísticasLa diferencia entre count() y tally()arrange() aplicada datos agrupadosfilter() aplicada datos agrupadosmutate() aplicada datos agrupadosselect() aplicada datos agrupadosEl comando aggregate() de R base como alternativa","code":""},{"path":"grouping-data.html","id":"preparation-4","chapter":"13 Agrupar datos","heading":"13.1 Preparación","text":"","code":""},{"path":"grouping-data.html","id":"cargar-paquetes-4","chapter":"13 Agrupar datos","heading":"Cargar paquetes","text":"Este trozo de código (chunk) muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,       # para importar datos\n  here,      # para identificar las carpetas donde se encuentran\n  tidyverse, # para limpiar, manipular y dibujar los datos (incluye dplyr)\n  janitor)   # para añadir totales en las filas y columnas"},{"path":"grouping-data.html","id":"importar-datos-4","chapter":"13 Agrupar datos","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguirlo, clica para descargar linelist “limpio” (como archivo .rds). Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.#{r, eval=F} #linelist <- import(\"linelist_cleaned.rds\") #Las primeras 50 filas de linelist:","code":""},{"path":"grouping-data.html","id":"grouping","chapter":"13 Agrupar datos","heading":"13.2 Agrupar","text":"La función group_by() de dplyr agrupa las filas por los valores únicos de la columna que se le especifica. Si se especifican varias columnas, las filas se agrupan por las combinaciones únicas de valores entre las columnas. Cada valor único (o combinación de valores) constituye un grupo. Los cambios posteriores en los datos o los cálculos pueden realizarse en el contexto de cada grupo.Por ejemplo, el siguiente comando toma linelist y agrupa las filas por valores únicos en la columna outcome, guardando la salida como un nuevo dataframe ll_by_outcome. La(s) columna(s) de agrupación se colocan dentro de los paréntesis de la función group_by().Ten en cuenta que hay ningún cambio perceptible en los datos después de ejecutar group_by(), hasta que se aplique otro verbo de dplyr como mutate(), summarise(), o arrange() en el dataframe “agrupado”.Sin embargo, puedes “ver” las agrupaciones imprimiendo el dataframe. Al imprimir un dataframe agrupado, verás que se ha transformado en un objeto de clase tibble que, al imprimirse, muestra qué agrupaciones se han aplicado y cuántos grupos están -escritos justo encima de la fila de cabecera.","code":"\nll_by_outcome <- linelist %>% \n  group_by(outcome)\n# print para ver los grupos que están activos\nll_by_outcome## # A tibble: 5,888 × 30\n## # Groups:   outcome [3]\n##    case_id generation date_infec…¹ date_onset date_hos…² date_out…³ outcome gender   age age_u…⁴ age_y…⁵\n##    <chr>        <dbl> <date>       <date>     <date>     <date>     <chr>   <chr>  <dbl> <chr>     <dbl>\n##  1 5fe599           4 2014-05-08   2014-05-13 2014-05-15 NA         <NA>    m          2 years         2\n##  2 8689b7           4 NA           2014-05-13 2014-05-14 2014-05-18 Recover f          3 years         3\n##  3 11f8ea           2 NA           2014-05-16 2014-05-18 2014-05-30 Recover m         56 years        56\n##  4 b8812a           3 2014-05-04   2014-05-18 2014-05-20 NA         <NA>    f         18 years        18\n##  5 893f25           3 2014-05-18   2014-05-21 2014-05-22 2014-05-29 Recover m          3 years         3\n##  6 be99c8           3 2014-05-03   2014-05-22 2014-05-23 2014-05-24 Recover f         16 years        16\n##  7 07e3e8           4 2014-05-22   2014-05-27 2014-05-29 2014-06-01 Recover f         16 years        16\n##  8 369449           4 2014-05-28   2014-06-02 2014-06-03 2014-06-07 Death   f          0 years         0\n##  9 f393b4           4 NA           2014-06-05 2014-06-06 2014-06-18 Recover m         61 years        61\n## 10 1389ca           4 NA           2014-06-05 2014-06-07 2014-06-09 Death   f         27 years        27\n## # … with 5,878 more rows, 19 more variables: age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>,\n## #   days_onset_hosp <dbl>, and abbreviated variable names ¹​date_infection, ²​date_hospitalisation,\n## #   ³​date_outcome, ⁴​age_unit, ⁵​age_years"},{"path":"grouping-data.html","id":"grupos-únicos","chapter":"13 Agrupar datos","heading":"Grupos únicos","text":"Los grupos creados reflejan cada combinación única de valores en las columnas de agrupación.Para ver los grupos y el número de filas en cada grupo, pasa los datos agrupados tally(). Para ver sólo los grupos únicos sin recuento puedes pasárselos group_keys().Mira continuación que hay tres valores únicos en el resultado de la columna outcome: “Death”, “Recover”, y NA. Fíjate que hubo nrow(linelist %\\>% filter(outcome == \"Death\")) muertes, nrow(linelist %\\>% filter(outcome == \"Recover\")) recuperaciones, y nrow(linelist %\\>% filter(.na(outcome)) sin resultado registrado.Se puede agrupar por más de una columna. continuación, el dataframe se agrupa por outcome y gender, y luego se cuenta. Observa cómo cada combinación única de outcome y gender se registra como su propio grupo, incluyendo los valores faltantes para cualquier columna.","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  tally()## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally()## # A tibble: 9 × 3\n## # Groups:   outcome [3]\n##   outcome gender     n\n##   <chr>   <chr>  <int>\n## 1 Death   f       1227\n## 2 Death   m       1228\n## 3 Death   <NA>     127\n## 4 Recover f        953\n## 5 Recover m        950\n## 6 Recover <NA>      80\n## 7 <NA>    f        627\n## 8 <NA>    m        625\n## 9 <NA>    <NA>      71"},{"path":"grouping-data.html","id":"columnas-nuevas","chapter":"13 Agrupar datos","heading":"Columnas nuevas","text":"También puedes crear una nueva columna de agrupación dentro de la sentencia group_by(). Esto equivale llamar mutate() antes de group_by(). Para una tabulación rápida este estilo puede ser útil, pero para una mayor claridad en el código mejor crear esta columna en su propio paso mutate() y luego canalizarla group_by().","code":"\n# group dat based on a binary column created *within* the group_by() command\nlinelist %>% \n  group_by(\n    age_class = ifelse(age >= 18, \"adult\", \"child\")) %>% \n  tally(sort = T)## # A tibble: 3 × 2\n##   age_class     n\n##   <chr>     <int>\n## 1 child      3618\n## 2 adult      2184\n## 3 <NA>         86"},{"path":"grouping-data.html","id":"añadirdescartar-columnas-de-agrupación","chapter":"13 Agrupar datos","heading":"Añadir/descartar columnas de agrupación","text":"Por defecto, si ejecutas group_by() sobre datos que ya están agrupados, se eliminarán los grupos antiguos y se aplicarán los nuevos. Si deseas añadir nuevos grupos los existentes, incluye el argumento .add = TRUE.** Mantener todos los grupos**Si se agrupa en una columna de tipo factor, puede haber niveles del factor que estén presentes en los datos. Si agrupas en esta columna, por defecto esos niveles presentes se descartan y se incluyen como grupos. Para cambiar esto de manera que todos los niveles aparezcan como grupos (incluso si están presentes en los datos), escribe .drop = FALSE en su comando group_by().","code":"\n# Grouped by outcome\nby_outcome <- linelist %>% \n  group_by(outcome)\n\n# Add grouping by gender in addition\nby_outcome_gender <- by_outcome %>% \n  group_by(gender, .add = TRUE)"},{"path":"grouping-data.html","id":"un-group","chapter":"13 Agrupar datos","heading":"13.3 Des-agrupar","text":"Los datos que han sido agrupados permanecerán agrupados hasta que sean específicamente desagrupados mediante ungroup(). Si se olvida desagrupar, puede dar lugar cálculos incorrectos. continuación se muestra un ejemplo de eliminación de todas las agrupaciones:También puedes eliminar la agrupación sólo para columnas específicas, colocando el nombre de la columna dentro de ungroup().NOTA: El verbo count() desagrupa automáticamente los datos después del recuento. ","code":"\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup()\nlinelist %>% \n  group_by(outcome, gender) %>% \n  tally() %>% \n  ungroup(gender) # remove the grouping by gender, leave grouping by outcome"},{"path":"grouping-data.html","id":"group_summarise","chapter":"13 Agrupar datos","heading":"13.4 Resumir","text":"Véase la sección dplyr de la página Tablas descriptivas para una descripción detallada de cómo producir tablas de resumen con summarise(). Aquí abordamos brevemente cómo cambia su comportamiento cuando se aplica datos agrupados.La función dplyr summarise() (o summarize()) toma un dataframe y lo convierte en un nuevo dataframe de resumen, con columnas que contienen los estadísticos de resumen que definas. En un dataframe sin agrupar, las estadísticas de resumen se calcularán partir de todas las filas. La aplicación de summarise() los datos agrupados produce esas estadísticas de resumen para cada grupo.La sintaxis de summarise() es tal que se proporciona el nombre de la(s) nueva(s) columna(s) de resumen, un signo de igualdad y, continuación, una función estadística para aplicar los datos, como se muestra continuación. Por ejemplo, min(), max(), median(), o sd(). Dentro de la función estadística, indica la columna con la que se va operar y cualquier argumento relevante (por ejemplo, na.rm = TRUE). Puedes utilizar sum() para contar el número de filas que cumplen un criterio lógico (con doble igual ==).continuación se muestra un ejemplo de summarise() aplicado sin datos agrupados. Las estadísticas devueltas se producen partir del set de datos completo.Por el contrario, continuación se muestra la misma sentencia summarise() aplicada los datos agrupados. Las estadísticas se calculan para cada grupo de outcome. Observa cómo se trasladan las columnas de agrupación al nuevo dataframe.SUGERENCIA: La función summarise funciona tanto con la ortografía del Reino Unido como con la de EE.UU. - summarise() y summarize() llaman la misma función. ","code":"\n# summary statistics on ungrouped linelist\nlinelist %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males  = sum(gender == \"m\", na.rm=T))##   n_cases mean_age max_age min_age n_males\n## 1    5888 16.01831      84       0    2803\n# summary statistics on grouped linelist\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(\n    n_cases  = n(),\n    mean_age = mean(age_years, na.rm=T),\n    max_age  = max(age_years, na.rm=T),\n    min_age  = min(age_years, na.rm=T),\n    n_males    = sum(gender == \"m\", na.rm=T))## # A tibble: 3 × 6\n##   outcome n_cases mean_age max_age min_age n_males\n##   <chr>     <int>    <dbl>   <dbl>   <dbl>   <int>\n## 1 Death      2582     15.9      76       0    1228\n## 2 Recover    1983     16.1      84       0     950\n## 3 <NA>       1323     16.2      69       0     625"},{"path":"grouping-data.html","id":"counts-and-tallies","chapter":"13 Agrupar datos","heading":"13.5 Counts y tallies","text":"count() y tally() proporcionan una funcionalidad similar pero son diferentes. Lee más sobre la distinción entre tally() y count() aquí","code":""},{"path":"grouping-data.html","id":"tally","chapter":"13 Agrupar datos","heading":"tally()","text":"tally() es la abreviatura de summarise(n = n()), y agrupa los datos. Por lo tanto, para lograr recuentos agrupados debe seguir un comando group_by(). Puedes añadir sort = TRUE para ver primero los grupos más grandes.","code":"\nlinelist %>% \n  tally()##      n\n## 1 5888\nlinelist %>% \n  group_by(outcome) %>% \n  tally(sort = TRUE)## # A tibble: 3 × 2\n##   outcome     n\n##   <chr>   <int>\n## 1 Death    2582\n## 2 Recover  1983\n## 3 <NA>     1323"},{"path":"grouping-data.html","id":"count","chapter":"13 Agrupar datos","heading":"count()","text":"En cambio, count() hace lo siguiente:aplica group_by() la(s) columna(s) especificada(s)aplica summarise() y devuelve la columna n con el número de filas por grupoaplica ungroup()Al igual que con group_by() puedes crear una nueva columna dentro del comando count():Puedes llamar varias veces count(), con la funcionalidad “combinada”. Por ejemplo, para resumir el número de hospitales presentes para cada género, ejecuta lo siguiente. Ten en cuenta que el nombre de la columna final se ha cambiado de “n” por defecto para mayor claridad (con name  =).","code":"\nlinelist %>% \n  count(outcome)##   outcome    n\n## 1   Death 2582\n## 2 Recover 1983\n## 3    <NA> 1323\nlinelist %>% \n  count(age_class = ifelse(age >= 18, \"adult\", \"child\"), sort = T)##   age_class    n\n## 1     child 3618\n## 2     adult 2184\n## 3      <NA>   86\nlinelist %>% \n  # produce counts by unique outcome-gender groups\n  count(gender, hospital) %>% \n  # gather rows by gender (3) and count number of hospitals per gender (6)\n  count(gender, name = \"hospitals per gender\" ) ##   gender hospitals per gender\n## 1      f                    6\n## 2      m                    6\n## 3   <NA>                    6"},{"path":"grouping-data.html","id":"añadir-recuentos","chapter":"13 Agrupar datos","heading":"Añadir recuentos","text":"diferencia de count() y summarise(), puedes utilizar add_count() para añadir una nueva columna n con los recuentos de filas por grupo conservando todas las demás columnas del dataframe.Esto significa que el número de recuentos de un grupo, en la nueva columna n, se imprimirá en cada fila del grupo. Para fines de demostración, añadimos esta columna y luego reordenamos las columnas para facilitar la visualización. Consulta la sección siguiente sobre filtrar por tamaño del grupo para ver otro ejemplo.","code":"\nlinelist %>% \n  as_tibble() %>%                   # convert to tibble for nicer printing \n  add_count(hospital) %>%           # add column n with counts by hospital\n  select(hospital, n, everything()) # re-arrange for demo purposes## # A tibble: 5,888 × 31\n##    hospital           n case_id gener…¹ date_inf…² date_onset date_hos…³ date_out…⁴ outcome gender   age\n##    <chr>          <int> <chr>     <dbl> <date>     <date>     <date>     <date>     <chr>   <chr>  <dbl>\n##  1 Other            885 5fe599        4 2014-05-08 2014-05-13 2014-05-15 NA         <NA>    m          2\n##  2 Missing         1469 8689b7        4 NA         2014-05-13 2014-05-14 2014-05-18 Recover f          3\n##  3 St. Mark's Ma…   422 11f8ea        2 NA         2014-05-16 2014-05-18 2014-05-30 Recover m         56\n##  4 Port Hospital   1762 b8812a        3 2014-05-04 2014-05-18 2014-05-20 NA         <NA>    f         18\n##  5 Military Hosp…   896 893f25        3 2014-05-18 2014-05-21 2014-05-22 2014-05-29 Recover m          3\n##  6 Port Hospital   1762 be99c8        3 2014-05-03 2014-05-22 2014-05-23 2014-05-24 Recover f         16\n##  7 Missing         1469 07e3e8        4 2014-05-22 2014-05-27 2014-05-29 2014-06-01 Recover f         16\n##  8 Missing         1469 369449        4 2014-05-28 2014-06-02 2014-06-03 2014-06-07 Death   f          0\n##  9 Missing         1469 f393b4        4 NA         2014-06-05 2014-06-06 2014-06-18 Recover m         61\n## 10 Missing         1469 1389ca        4 NA         2014-06-05 2014-06-07 2014-06-09 Death   f         27\n## # … with 5,878 more rows, 20 more variables: age_unit <chr>, age_years <dbl>, age_cat <fct>,\n## #   age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>,\n## #   ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>, and abbreviated variable names ¹​generation,\n## #   ²​date_infection, ³​date_hospitalisation, ⁴​date_outcome"},{"path":"grouping-data.html","id":"añadir-totales","chapter":"13 Agrupar datos","heading":"Añadir totales","text":"Para añadir fácilmente filas o columnas del total de la suma después de utilizar tally() o count(), consulta la sección de janitor de la página Tablas descriptivas. Este paquete ofrece funciones como adorn_totals() y adorn_percentages() para añadir totales y convertirlos para mostrar porcentajes. continuación se muestra un breve ejemplo:Para añadir filas de totales más complejas que incluyan estadísticas de resumen distintas de las sumas, consulta esta sección de la página Tablas descriptivas.","code":"\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts of two columns\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions with column denominator\n  adorn_pct_formatting() %>%                  # convert proportions to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \n##  Age Category             f             m          NA_\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"grouping-data.html","id":"grouping-by-date","chapter":"13 Agrupar datos","heading":"13.6 Agrupar por fechas","text":"Al agrupar datos por fecha, debes tener (o crear) una columna para la unidad de fecha de interés - por ejemplo “día”, “epiweek”, “mes”, etc. Puedes crear esta columna utilizando floor_date() de lubridate, como se explica en la sección Semanas epidemiológicas de la página Trabajar con fechas. Una vez que tengas esta columna, puedes utilizar count() de dplyr para agrupar las filas por esos valores de fecha únicos y lograr recuentos agregados.Un paso adicional común para las situaciones de fechas, es “rellenar” cualquier fecha en la que haya datos. Utiliza complete() de tidyr para que la serie de fechas agregadas esté completa, incluyendo todas las unidades de fecha posibles dentro del rango. Sin este paso, una semana sin casos reportados podría aparecer en tus datos.Dentro de complete() redefine la columna de fecha como una secuencia de fechas seq.Date() desde el mínimo hasta el máximo - así las fechas se expanden. Por defecto, los valores del recuento de casos en cualquier nueva fila “expandida” serán NA. Puedes establecerlos 0 utilizando el argumento fill = de complete(), que espera una lista con nombre (si la columna de recuentos se llama n, escribe fill = list(n = 0). Consulta ?complete para obtener más detalles y la página Trabajar con fechas para ver un ejemplo.","code":""},{"path":"grouping-data.html","id":"casos-por-día","chapter":"13 Agrupar datos","heading":"Casos por día","text":"Aquí hay un ejemplo de agrupación de casos en días sin usar complete(). Obsérvese que las primeras filas omiten las fechas sin casos.continuación añadimos el comando complete() para asegurarnos de que todos los días del rango están representados.","code":"\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%        # remove that were missing date_onset\n  count(date_onset)              # count number of rows per unique date\ndaily_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove case missing date_onset\n  count(date_onset) %>%                   # count number of rows per unique date\n  complete(                               # ensure all days appear even if no cases\n    date_onset = seq.Date(                # re-define date colume as daily sequence of dates\n      from = min(date_onset, na.rm=T), \n      to = max(date_onset, na.rm=T),\n      by = \"day\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping-data.html","id":"casos-por-semana","chapter":"13 Agrupar datos","heading":"Casos por semana","text":"Se puede aplicar el mismo principio para las semanas. Primero crea una nueva columna que sea la semana del caso utilizando floor_date() con unit = \"week\". continuación, utiliza count() como en el caso anterior para obtener los recuentos de casos semanales. Termina con complete() para asegurarte de que todas las semanas están representadas, incluso si contienen casos.Aquí están las primeras 50 filas del dataframe resultante:","code":"\n# Make dataset of weekly case counts\nweekly_counts <- linelist %>% \n  drop_na(date_onset) %>%                 # remove cases missing date_onset\n  mutate(week = lubridate::floor_date(date_onset, unit = \"week\")) %>%  # new column of week of onset\n  count(week) %>%                         # group data by week and count rows per group\n  complete(                               # ensure all days appear even if no cases\n    week = seq.Date(                      # re-define date colume as daily sequence of dates\n      from = min(week, na.rm=T), \n      to = max(week, na.rm=T),\n      by = \"week\"),\n    fill = list(n = 0))                   # set new filled-in rows to display 0 in column n (not NA as default) "},{"path":"grouping-data.html","id":"casos-por-mes","chapter":"13 Agrupar datos","heading":"Casos por mes","text":"Para agregar casos en meses, vuelve utilizar floor_date() del paquete lubridate, pero con el argumento unit = \"months\". Esto redondea cada fecha hacia abajo al día 1 de su mes. La salida será el tipo Date. Ten en cuenta que en el paso complete() también utilizamos = \"months\".","code":"\n# Make dataset of monthly case counts\nmonthly_counts <- linelist %>% \n  drop_na(date_onset) %>% \n  mutate(month = lubridate::floor_date(date_onset, unit = \"months\")) %>%  # new column, 1st of month of onset\n  count(month) %>%                          # count cases by month\n  complete(\n    month = seq.Date(\n      min(month, na.rm=T),     # include all months with no cases reported\n      max(month, na.rm=T),\n      by=\"month\"),\n    fill = list(n = 0))"},{"path":"grouping-data.html","id":"recuentos-diarios-en-semanas","chapter":"13 Agrupar datos","heading":"Recuentos diarios en semanas","text":"Para agregar los recuentos diarios en recuentos semanales, utiliza floor_date() igual queo arriba. Sin embargo, utiliza group_by() y summarize() en lugar de count() porque necesita sum() los recuentos de casos diarios en lugar de limitarse contar el número de filas por semana.","code":""},{"path":"grouping-data.html","id":"daily-counts-into-months","chapter":"13 Agrupar datos","heading":"Daily counts into months","text":"Para agregar los recuentos diarios en recuentos por meses, utiliza floor_date() con unit = \"month\" como en el caso anterior. Sin embargo, utiliza group_by() y summarize() en lugar de count() porque necesitasum()los recuentos de casos diarios en lugar de limitarse contar el número de filas por mes.","code":""},{"path":"grouping-data.html","id":"arranging-grouped-data","chapter":"13 Agrupar datos","heading":"13.7 Ordenar los datos agrupados","text":"El verbo arrange() de dplyr para ordenar las filas de un dataframe se comporta igual cuando los datos están agrupados, menos que se establezca el argumento .by_group =TRUE. En este caso, las filas se ordenan primero por las columnas de agrupación y luego por cualquier otra columna que se especifique en arrange().","code":""},{"path":"grouping-data.html","id":"filter-on-grouped-data","chapter":"13 Agrupar datos","heading":"13.8 Filtrar sobre datos agrupados","text":"","code":""},{"path":"grouping-data.html","id":"filter","chapter":"13 Agrupar datos","heading":"filter()","text":"Cuando se aplica junto con funciones que evalúan el dataframe (como max(), min(), mean()), estas funciones se aplicarán ahora los grupos. Por ejemplo, si deseas filtrar y mantener las filas en las que los pacientes están por encima de la edad media, esto se aplicará ahora por grupo, filtrando para mantener las filas por encima de la edad media del grupo.","code":""},{"path":"grouping-data.html","id":"clasificar-filas-por-grupo","chapter":"13 Agrupar datos","heading":"Clasificar filas por grupo","text":"La función slice() de dplyr, que filtra las filas según su posición en los datos, también puede aplicarse por grupo. Recuerda que debes tener en cuenta la ordenación de los datos dentro de cada grupo para obtener la “rebanada” deseada.Por ejemplo, para recuperar sólo los últimos 5 ingresos de cada hospital:Agrupar linelist por columna hospitalOrdenar los registros por date_hospitalisation de más reciente la más antigua dentro de cada grupo de hospitalesClasificar para recuperar las 5 primeras filas de cada hospitalslice_head() - selecciona n filas de la parte superior\nslice_tail() - selecciona n filas del final\nslice_sample() - selecciona aleatoriamente n filas\nslice_min() - selecciona n filas con los valores más altos en order_by =columna, usa with_ties = TRUE para mantener los empates slice_max() - selecciona n filas con los valores más bajos en order_by =columna, utiliza with_ties = TRUE para mantener los empatesConsulta la página de De-duplicación para ver más ejemplos y detalles sobre slice().","code":"\nlinelist %>%\n  group_by(hospital) %>%\n  arrange(hospital, date_hospitalisation) %>%\n  slice_head(n = 5) %>% \n  arrange(hospital) %>%                            # for display\n  select(case_id, hospital, date_hospitalisation)  # for display## # A tibble: 30 × 3\n## # Groups:   hospital [6]\n##    case_id hospital          date_hospitalisation\n##    <chr>   <chr>             <date>              \n##  1 20b688  Central Hospital  2014-05-06          \n##  2 d58402  Central Hospital  2014-05-10          \n##  3 b8f2fd  Central Hospital  2014-05-13          \n##  4 acf422  Central Hospital  2014-05-28          \n##  5 275cc7  Central Hospital  2014-05-28          \n##  6 d1fafd  Military Hospital 2014-04-17          \n##  7 974bc1  Military Hospital 2014-05-13          \n##  8 6a9004  Military Hospital 2014-05-13          \n##  9 09e386  Military Hospital 2014-05-14          \n## 10 865581  Military Hospital 2014-05-15          \n## # … with 20 more rows"},{"path":"grouping-data.html","id":"group_filter_grp_size","chapter":"13 Agrupar datos","heading":"Filtro por tamaño de grupo","text":"La función add_count() añade una columna n los datos originales dando el número de filas en el grupo de esa fila.continuación, add_count() se aplica la columna hospital, por lo que los valores de la nueva columna n reflejan el número de filas del grupo de hospitales de esa fila. Observe cómo se repiten los valores de la columna n. En el ejemplo siguiente, el nombre de la columna n podría cambiarse utilizando name = dentro de add_count(). Para fines de demostración reordenamos las columnas con select().De este modo, resulta fácil filtrar los casos que fueron hospitalizados en un hospital “pequeño”, por ejemplo, un hospital que admitió menos de 500 pacientes:","code":"\nlinelist %>% \n  as_tibble() %>% \n  add_count(hospital) %>%          # add \"number of rows admitted to same hospital as this row\" \n  select(hospital, n, everything())## # A tibble: 5,888 × 31\n##    hospital           n case_id gener…¹ date_inf…² date_onset date_hos…³ date_out…⁴ outcome gender   age\n##    <chr>          <int> <chr>     <dbl> <date>     <date>     <date>     <date>     <chr>   <chr>  <dbl>\n##  1 Other            885 5fe599        4 2014-05-08 2014-05-13 2014-05-15 NA         <NA>    m          2\n##  2 Missing         1469 8689b7        4 NA         2014-05-13 2014-05-14 2014-05-18 Recover f          3\n##  3 St. Mark's Ma…   422 11f8ea        2 NA         2014-05-16 2014-05-18 2014-05-30 Recover m         56\n##  4 Port Hospital   1762 b8812a        3 2014-05-04 2014-05-18 2014-05-20 NA         <NA>    f         18\n##  5 Military Hosp…   896 893f25        3 2014-05-18 2014-05-21 2014-05-22 2014-05-29 Recover m          3\n##  6 Port Hospital   1762 be99c8        3 2014-05-03 2014-05-22 2014-05-23 2014-05-24 Recover f         16\n##  7 Missing         1469 07e3e8        4 2014-05-22 2014-05-27 2014-05-29 2014-06-01 Recover f         16\n##  8 Missing         1469 369449        4 2014-05-28 2014-06-02 2014-06-03 2014-06-07 Death   f          0\n##  9 Missing         1469 f393b4        4 NA         2014-06-05 2014-06-06 2014-06-18 Recover m         61\n## 10 Missing         1469 1389ca        4 NA         2014-06-05 2014-06-07 2014-06-09 Death   f         27\n## # … with 5,878 more rows, 20 more variables: age_unit <chr>, age_years <dbl>, age_cat <fct>,\n## #   age_cat5 <fct>, lon <dbl>, lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>,\n## #   ct_blood <dbl>, fever <chr>, chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>,\n## #   time_admission <chr>, bmi <dbl>, days_onset_hosp <dbl>, and abbreviated variable names ¹​generation,\n## #   ²​date_infection, ³​date_hospitalisation, ⁴​date_outcome\nlinelist %>% \n  add_count(hospital) %>% \n  filter(n < 500)"},{"path":"grouping-data.html","id":"mutate-on-grouped-data","chapter":"13 Agrupar datos","heading":"13.9 Mutate con datos agrupados","text":"Para conservar todas las columnas y filas (resumir) y añadir una nueva columna que contenga estadísticas de grupo, utiliza mutate() después de group_by() en lugar de summarise().Esto es útil si se desea obtener estadísticas de grupo en los datos originales con todas las demás columnas presentes, por ejemplo, para los cálculos que comparan una fila con su grupo.Por ejemplo, este código calcula la diferencia entre la demora en el ingreso de una fila y la demora media de su hospital. Los pasos son:Agrupar los datos por hospitalUtiliza la columna days_onset_hosp (retraso hasta la hospitalización) para crear una nueva columna que contenga el retraso medio en el hospital de esa filaCalcular la diferencia entre las dos columnasSeleccionamos (select()) sólo ciertas columnas para mostrarlas, con fines de demostración.","code":"\nlinelist %>% \n  # group data by hospital (no change to linelist yet)\n  group_by(hospital) %>% \n  \n  # new columns\n  mutate(\n    # mean days to admission per hospital (rounded to 1 decimal)\n    group_delay_admit = round(mean(days_onset_hosp, na.rm=T), 1),\n    \n    # difference between row's delay and mean delay at their hospital (rounded to 1 decimal)\n    diff_to_group     = round(days_onset_hosp - group_delay_admit, 1)) %>%\n  \n  # select certain rows only - for demonstration/viewing purposes\n  select(case_id, hospital, days_onset_hosp, group_delay_admit, diff_to_group)## # A tibble: 5,888 × 5\n## # Groups:   hospital [6]\n##    case_id hospital                             days_onset_hosp group_delay_admit diff_to_group\n##    <chr>   <chr>                                          <dbl>             <dbl>         <dbl>\n##  1 5fe599  Other                                              2               2             0  \n##  2 8689b7  Missing                                            1               2.1          -1.1\n##  3 11f8ea  St. Mark's Maternity Hospital (SMMH)               2               2.1          -0.1\n##  4 b8812a  Port Hospital                                      2               2.1          -0.1\n##  5 893f25  Military Hospital                                  1               2.1          -1.1\n##  6 be99c8  Port Hospital                                      1               2.1          -1.1\n##  7 07e3e8  Missing                                            2               2.1          -0.1\n##  8 369449  Missing                                            1               2.1          -1.1\n##  9 f393b4  Missing                                            1               2.1          -1.1\n## 10 1389ca  Missing                                            2               2.1          -0.1\n## # … with 5,878 more rows"},{"path":"grouping-data.html","id":"select-on-grouped-data","chapter":"13 Agrupar datos","heading":"13.10 Seleccionar sobre datos agrupados","text":"El verbo select() funciona con datos agrupados, pero las columnas de agrupación siempre se incluyen (aunque se mencionen en select()). Si deseas estas columnas de agrupación, utiliza primero ungroup().","code":""},{"path":"grouping-data.html","id":"resources-5","chapter":"13 Agrupar datos","heading":"13.11 Recursos","text":"continuación, algunos recursos útiles para obtener más información:Puedes realizar cualquier función de resumen sobre datos agrupados; consulta la hoja de trucos de transformación de datos de RStudioLa página de Data Carpentry sobre dplyrLas páginas de referencia de tidyverse sobre group_by() y agrupaciónEsta página sobre Manipulación de datosResumir con condiciones en dplyr","code":""},{"path":"joining-data.html","id":"joining-data","chapter":"14 Unir datos","heading":"14 Unir datos","text":"Arriba: un ejemplo animado de una unión por la izquierda (fuente de la imagen)Esta página describe diferentes formas de unir datos (“join”, “match”, “link”, “bind”) y combinar dataframes.","code":""},{"path":"joining-data.html","id":"preparation-5","chapter":"14 Unir datos","heading":"14.1 Preparación","text":"","code":""},{"path":"joining-data.html","id":"cargar-paquetes-5","chapter":"14 Unir datos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,            # import and export\n  here,           # locate files \n  tidyverse,      # data management and visualisation\n  RecordLinkage,  # probabilistic matches\n  fastLink        # probabilistic matches\n)"},{"path":"joining-data.html","id":"importar-datos-5","chapter":"14 Unir datos","heading":"Importar datos","text":"Para empezar, importamos la lista de casos limpiada de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar el listado “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"joining-data.html","id":"datos-de-los-ejemplos","chapter":"14 Unir datos","heading":"Datos de los ejemplos","text":"En la sección de unión que sigue, utilizaremos los siguientes datos:Una versión “en miniatura” de casos de linelist, que contiene sólo las columnas case_id, date_onset, y hospital, y sólo las 10 primeras filasUn dataframe separado llamado hosp_info, que contiene más detalles sobre cada hospitalEn la sección sobre el emparejamiento probabilístico, utilizaremos dos pequeños conjuntos de datos diferentes. El código para crear esos conjuntos de datos se da en esa sección.","code":""},{"path":"joining-data.html","id":"joins_llmini","chapter":"14 Unir datos","heading":"“Miniatura” de casos de linelist","text":"continuación se muestra la lista de casos en miniatura, que contiene sólo 10 filas y sólo las columnas case_id, date_onset, y hospital.","code":"\nlinelist_mini <- linelist %>%                 # start with original linelist\n  select(case_id, date_onset, hospital) %>%   # select columns\n  head(10)                                    # only take the first 10 rows"},{"path":"joining-data.html","id":"joins_hosp_info","chapter":"14 Unir datos","heading":"dataframe de información hospitalaria","text":"continuación se muestra el código para crear un dataframe separado con información adicional sobre siete hospitales (la población de captación y el nivel de atención disponible). Obsérvese que el nombre “Hospital Militar” pertenece dos hospitales diferentes: uno de nivel primario que atiende 10000 residentes y otro de nivel secundario que atiende 50280 residentes.Aquí está este dataframe:","code":"\n# Make the hospital information data frame\nhosp_info = data.frame(\n  hosp_name     = c(\"central hospital\", \"military\", \"military\", \"port\", \"St. Mark's\", \"ignace\", \"sisters\"),\n  catchment_pop = c(1950280, 40500, 10000, 50280, 12000, 5000, 4200),\n  level         = c(\"Tertiary\", \"Secondary\", \"Primary\", \"Secondary\", \"Secondary\", \"Primary\", \"Primary\")\n)"},{"path":"joining-data.html","id":"pre-limpieza","chapter":"14 Unir datos","heading":"Pre-limpieza","text":"Las uniones tradicionales (probabilísticas) distinguen entre mayúsculas y minúsculas y requieren coincidencias de caracteres exactas entre los valores de los dos dataframes. Para mostrar algunos de los pasos de limpieza que puedes necesitar antes de iniciar una unión, ahora limpiaremos y alinearemos los datos linelist_mini y hosp_info.Identificar las diferenciasNecesitamos que los valores de la columna hosp_name en el dataframe hosp_info coincidan con los valores de la columna hospital en el dataframe linelist_mini.Aquí están los valores del dataframe linelist_mini, impresos con la función de R base unique():y aquí están los valores del dataframe hosp_info:Puedes ver que, aunque algunos de los hospitales existen en ambos dataframes, hay muchas diferencias en la ortografía.Alinear los valoresComenzamos limpiando los valores del dataframe hosp_info. Como se explica en la página Limpieza de datos y funciones básicas, podemos recodificar los valores con criterios lógicos utilizando la función case_when() de dplyr. Para los cuatro hospitales que existen en ambos dataframes, cambiamos los valores para alinearlos con los valores de linelist_mini. Para los demás hospitales dejamos los valores como están (TRUE ~ hosp_name).PRECAUCIÓN: Normalmente, al limpiar se debe crear una nueva columna (por ejemplo, hosp_name_clean), pero para facilitar la demostración mostramos la modificación de la antigua columna Los nombres de los hospitales que aparecen en ambos dataframes están alineados. Hay dos hospitales en hosp_info que están presentes en linelist_mini - nos ocuparemos de ellos más adelante, en la unión.Antes de una unión, menudo es más fácil convertir en una columna todas minúsculas o todas mayúsculas. Si necesitas convertir todos los valores de una columna MAYÚSCULAS o minúsculas, utiliza mutate() y envuelva la columna con una de estas funciones de stringr, como se muestra en la página sobre Caracteres y cadenas.str_to_upper()str_to_upper()str_to_title()","code":"\nunique(linelist_mini$hospital)## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"\nunique(hosp_info$hosp_name)## [1] \"central hospital\" \"military\"         \"port\"             \"St. Mark's\"       \"ignace\"          \n## [6] \"sisters\"\nhosp_info <- hosp_info %>% \n  mutate(\n    hosp_name = case_when(\n      # criteria                         # new value\n      hosp_name == \"military\"          ~ \"Military Hospital\",\n      hosp_name == \"port\"              ~ \"Port Hospital\",\n      hosp_name == \"St. Mark's\"        ~ \"St. Mark's Maternity Hospital (SMMH)\",\n      hosp_name == \"central hospital\"  ~ \"Central Hospital\",\n      TRUE                             ~ hosp_name\n      )\n    )\nunique(hosp_info$hosp_name)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\n## [5] \"ignace\"                               \"sisters\""},{"path":"joining-data.html","id":"dplyr-joins","chapter":"14 Unir datos","heading":"14.2 Uniones en dplyr","text":"El paquete dplyr ofrece varias funciones de unión. dplyr está incluido en el paquete tidyverse. Estas funciones de unión se describen continuación, con casos de uso sencillos.Muchas gracias https://github.com/gadenbuie por los gifs informativos.","code":""},{"path":"joining-data.html","id":"sintaxis-general","chapter":"14 Unir datos","heading":"Sintaxis general","text":"Los comandos de unión pueden ejecutarse como comandos independientes para unir dos dataframes en un nuevo objeto, o pueden utilizarse dentro de una cadena de pipes (%>%) para fusionar un dataframe en otro mientras se limpia o se modifica de alguna manera.En el siguiente ejemplo, la función left_join() se utiliza como un comando independiente para crear un nuevo dataframe joined_data. Las entradas son los dataframes 1 y 2 (df1 y df2). El primer dataframe es el dataframe de referencia, y el segundo se une él.El tercer argumento = es donde se especifican las columnas de cada dataframe que se utilizarán para alinear las filas de los dos dataframes. Si los nombres de estas columnas son diferentes, proporciónelos dentro de un vector c() como se muestra continuación, donde las filas se emparejan sobre la base de valores comunes entre la columna ID en df1 y la columna identifier en df2.Si las columnas de ambos dataframes tienen exactamente el mismo nombre, puedes proporcionar sólo este nombre, entre comillas.Si estás uniendo los dataframes basándote en valores comunes en varios campos, enumera estos campos dentro del vector c(). Este ejemplo une filas si los valores de tres columnas de cada conjunto de datos se alinean exactamente.Los comandos de unión también pueden ejecutarse dentro de una cadena de pipes. Esto modificará el dataframe que se está canalizando.En el ejemplo siguiente, df1 se pasa por los pipes, df2 se une él y, por tanto, dfse modifica y se redefine.ATENCIÓN: ¡Las uniones son específicas para cada caso! Por lo tanto, es útil convertir todos los valores minúsculas o mayúsculas antes de la unión. Consulta la página sobre caracteres/cadenas. ","code":"\n# Join based on common values between column \"ID\" (first data frame) and column \"identifier\" (second data frame)\njoined_data <- left_join(df1, df2, by = c(\"ID\" = \"identifier\"))\n# Joint based on common values in column \"ID\" in both data frames\njoined_data <- left_join(df1, df2, by = \"ID\")\n# join based on same first name, last name, and age\njoined_data <- left_join(df1, df2, by = c(\"name\" = \"firstname\", \"surname\" = \"lastname\", \"Age\" = \"age\"))\ndf1 <- df1 %>%\n  filter(date_onset < as.Date(\"2020-03-05\")) %>% # miscellaneous cleaning \n  left_join(df2, by = c(\"ID\" = \"identifier\"))    # join df2 to df1"},{"path":"joining-data.html","id":"uniones-izquierda-y-derecha","chapter":"14 Unir datos","heading":"Uniones izquierda y derecha","text":"Una unión la izquierda o la derecha se utiliza habitualmente para añadir información un dataframe: la nueva información se añade sólo las filas que ya existían en el dataframe de referencia. Estas uniones son comunes en el trabajo epidemiológico, ya que se utilizan para añadir información de unos datos otro.Al utilizar estas uniones, el orden de escritura de los dataframes en el comando es importante*.En una unión la izquierda, el primer dataframe escrito es el de baseEn una unión la derecha, el segundo dataframe escrito es el de baseSe conservan todas las filas del dataframe de referencia. La información del otro dataframe (secundario) se une al dataframe de referencia sólo si hay una coincidencia través de la(s) columna(s) del identificador. Además:Las filas del dataframe secundario que coinciden se eliminan.Si hay muchas filas de la línea de base que coinciden con una fila del dataframe secundarios (muchos uno), la información secundaria se añade cada fila de la línea de base que coincide.Si una fila del de base coincide con varias filas del dataframe secundario (uno varios), se dan todas las combinaciones, lo que significa que se pueden añadir nuevas filas al dataframe devuelto.Ejemplos animados de uniones la izquierda y la derecha (fuente de la imagen)EjemploA continuación se muestra el resultado de un left_join() de hosp_info (dataframe secundario, ver aquí) en linelist_mini (dataframe de referencia, ver aquí). linelist_mini original tiene filas nrow(linelist_mini). Se muestra linelist_mini modificada. Observa lo siguiente:Se han añadido dos nuevas columnas, catchment_pop y level en la parte izquierda de linelist_miniSe mantienen todas las filas originales del dataframe de referencia linelist_miniCualquier fila original de linelist_mini para “Hospital Militar” está duplicada porque coincide con dos filas en el dataframe secundario, por lo que se devuelven ambas combinacionesLa columna del identificador de la unión del set de datos secundario (hosp_name) ha desaparecido porque es redundante con la columna del identificador primario (hospital)Cuando una fila de referencia coincide con ninguna fila secundaria (por ejemplo, cuando el hospital “” “Missing”), NA (en blanco) rellena las columnas del dataframe secundarioSe eliminaron las filas del dataframe secundario que coincidían con el dataframe de referencia (hospitales “sisters” e “ignace”)","code":"\nlinelist_mini %>% \n  left_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"debo-usar-una-unión-a-la-derecha-o-a-la-izquierda","chapter":"14 Unir datos","heading":"“¿Debo usar una unión a la derecha o a la izquierda?”","text":"Para responder la pregunta anterior, hay que tener claro “¿qué dataframe debe conservar todas sus filas?” - Utiliza éste como base. Una unión la izquierda conserva todas las filas del primer dataframe escrito en el comando, mientras que una unión la derecha conserva todas las filas del segundo dataframe.Los dos comandos de abajo consiguen el mismo resultado - 10 filas de hosp_info unidas en base linelist_mini, pero utilizan diferentes uniones. El resultado es que el orden de las columnas variará en función de si hosp_info llega por la derecha (en la unión izquierda) o llega por la izquierda (en la unión derecha). El orden de las filas también puede cambiar en consecuencia. Pero ambas consecuencias pueden ser tratadas posteriormente, utilizando select() para reordenar las columnas o arrange() para ordenar las filas.Este es el resultado de hosp_info en linelist_mini través de una unión la izquierda (nuevas columnas entrando por la derecha)Este es el resultado de hosp_info en linelist_mini través de una unión la derecha (nuevas columnas entrando desde la izquierda)Considera también si tu caso de uso está dentro de una cadena de pipes (%>%). Si los datos del pipe son la base, es probable que utilices una unión izquierda para añadir datos ella.","code":"\n# The two commands below achieve the same data, but with differently ordered rows and columns\nleft_join(linelist_mini, hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nright_join(hosp_info, linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"unión-completa","chapter":"14 Unir datos","heading":"Unión completa","text":"Una unión completa (Full join) es la más inclusiva de las uniones: devuelve todas las filas de ambos dataframes.Si hay filas presentes en una y en la otra (donde se encontró ninguna coincidencia), el dataframe las incluirá y se hará más largo. Los valores faltantes NA se utilizan para rellenar los huecos creados. medida que se une, observa el número de columnas y filas con cuidado para solucionar el problema de las coincidencias de mayúsculas y minúsculas y de los caracteres exactos.El dataframe de “base” es el que se escribe primero en el comando. El ajuste de esto afectará los registros devueltos por la unión, pero puede afectar al orden de las columnas resultantes, al orden de las filas y las columnas de los identificadores que se conservan.Ejemplo animado de una unión completa (fuente de la imagen)EjemploA continuación se muestra la salida de un full_join() de hosp_info (originalmente nrow(hosp_info), view ) linelist_mini (originalmente nrow(linelist_mini), view ). Nota lo siguiente:Se mantienen todas las filas de la base (linelist_mini)Se conservan las filas de los datos secundarios que coinciden con la de base (“ignace” y “sisters”), con los valores de las columnas correspondientes de la de base case_id y onset rellenados con los valores que faltanDel mismo modo, se conservan las filas de los datos de referencia que coinciden con el secundario (“Otros” y “Falta”), y las columnas secundarias catchment_pop y level se rellenan con los valores que faltanEn el caso de coincidencias de uno muchos o de muchos uno (por ejemplo, filas para “Hospital Militar”), se devuelven todas las combinaciones posibles (alargando el conjunto de datos final)Sólo se mantiene la columna del identificador de la línea de base (hospital)","code":"\nlinelist_mini %>% \n  full_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"unión-interna","chapter":"14 Unir datos","heading":"Unión interna","text":"Una unión interna es la más restrictiva de las uniones: sólo devuelve las filas que coinciden en ambos dataframes.\nEsto significa que el número de filas en el dataframe de referencia puede reducirse. El ajuste de qué dataframe es el de “base” (escrito en primer lugar en la función) afectará las filas que se devuelven, pero sí al orden de las columnas, al orden de las filas y las columnas de los identificadores que se conservan.Ejemplo animado de una unión interna (fuente de la imagen)EjemploA continuación se muestra la salida de un inner_join() de linelist_mini (base) con hosp_info (secundario). Observa lo siguiente:Se eliminan las filas del de base que coinciden con los datos secundarios (filas en las que el hospital es “Missing” u “”) * Asimismo, se eliminan las filas del dataframe secundario que tenían ninguna coincidencia en la de base (filas en las que hosp_name es “sisters” o “ignace”)Sólo se conserva la columna del identificador del de base (hospital)","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"semi-unión","chapter":"14 Unir datos","heading":"Semi-unión","text":"Una semi-unión join es una “unión filtrada” que utiliza otro conjunto de datos para añadir filas o columnas, sino para realizar un filtrado.Un semi-join mantiene todas las observaciones en el dataframe de referencia que tienen una coincidencia con el dataframe secundario (pero añade nuevas columnas ni duplica ninguna fila para las coincidencias múltiples). Lee más sobre estas uniones de “filtrado” aquí.Ejemplo animado de una semiunión (fuente de la imagen)Como ejemplo, el siguiente código devuelve las filas del dataframe hosp_info que tienen coincidencias en linelist_mini basadas en el nombre del hospital.","code":"\nhosp_info %>% \n  semi_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))##                              hosp_name catchment_pop     level\n## 1                    Military Hospital         40500 Secondary\n## 2                    Military Hospital         10000   Primary\n## 3                        Port Hospital         50280 Secondary\n## 4 St. Mark's Maternity Hospital (SMMH)         12000 Secondary"},{"path":"joining-data.html","id":"anti-unión","chapter":"14 Unir datos","heading":"Anti unión","text":"La anti unión es otra “unión filtrada” que devuelve las filas del dataframe de referencia que tienen una coincidencia en el dataframe secundario.Lee más sobre el filtrado de las uniones aquí.Los anti-join son útiles para la identificación de registros que están presentes en otro dataframe, la solución de problemas de ortografía en un join (revisión de registros que deberían haber coincidido) y el examen de registros que fueron excluidos después de otro join.Al igual que con right_join() y left_join(), el dataframe de base (que aparece primero) es importante. Las filas devueltas son sólo las del dataframe de referencia. Observa en el siguiente gif que la fila del dataframe secundario (fila púrpura 4) se devuelve pesar de que coincide con la línea de base.Ejemplo animado de una anti-unión (fuente de la imagen)","code":""},{"path":"joining-data.html","id":"ejemplo-de-anti_join-sencillo","chapter":"14 Unir datos","heading":"Ejemplo de anti_join() sencillo","text":"Para un ejemplo sencillo, encontremos los hospitales de hosp_info que tienen ningún caso en linelist_mini. Enumeramos primero hosp_info, como dataframe de referencia. Se devuelven los hospitales que están presentes en linelist_mini.","code":"\nhosp_info %>% \n  anti_join(linelist_mini, by = c(\"hosp_name\" = \"hospital\"))"},{"path":"joining-data.html","id":"ejemplo-de-anti_join-complejo","chapter":"14 Unir datos","heading":"Ejemplo de anti_join() complejo","text":"Para otro ejemplo, digamos que ejecutamos un inner_join() entre linelist_mini y hosp_info. Esto devuelve sólo un subconjunto de los registros originales de linelist_mini, ya que algunos están presentes en hosp_info.Para revisar los registros de linelist_mini que fueron excluidos durante el inner join, podemos ejecutar un anti-join con la misma configuración (linelist_mini como base).Para ver los registros de hosp_info que se excluyeron en la unión interna, también podríamos ejecutar una anti unión con hosp_info como dataframe de referencia.","code":"\nlinelist_mini %>% \n  inner_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))\nlinelist_mini %>% \n  anti_join(hosp_info, by = c(\"hospital\" = \"hosp_name\"))"},{"path":"joining-data.html","id":"probabalistic-matching","chapter":"14 Unir datos","heading":"14.3 Emparejamiento probabilístico","text":"Si dispones de un identificador único común todos los conjuntos de datos para unirlos, considera la posibilidad de utilizar un algoritmo de coincidencia probabilística. Este algoritmo buscaría coincidencias entre los registros basándose en la similitud (por ejemplo, la distancia de cadena de Jaro-Winkler o la distancia numérica). continuación se muestra un ejemplo sencillo utilizando el paquete fastLink .Cargar paquetesA continuación se presentan dos pequeños conjuntos de datos de ejemplo que utilizaremos para demostrar la correspondencia probabilística (cases y test_results):Aquí está el código utilizado para hacer estos conjuntos de datos:El dataset cases tiene 9 registros de pacientes que están la espera de los resultados de las pruebas.El set de datos test_results tiene 14 registros y contiene la columna resultado, que queremos añadir los registros en cases basado en la coincidencia probabilística de registros.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualization\n  fastLink        # record matching\n  )\n# make datasets\n\ncases <- tribble(\n  ~gender, ~first,      ~middle,     ~last,        ~yr,   ~mon, ~day, ~district,\n  \"M\",     \"Amir\",      NA,          \"Khan\",       1989,  11,   22,   \"River\",\n  \"M\",     \"Anthony\",   \"B.\",        \"Smith\",      1970, 09, 19,      \"River\", \n  \"F\",     \"Marialisa\", \"Contreras\", \"Rodrigues\",  1972, 04, 15,      \"River\",\n  \"F\",     \"Elizabeth\", \"Casteel\",   \"Chase\",      1954, 03, 03,      \"City\",\n  \"M\",     \"Jose\",      \"Sanchez\",   \"Lopez\",      1996, 01, 06,      \"City\",\n  \"F\",     \"Cassidy\",   \"Jones\",      \"Davis\",     1980, 07, 20,      \"City\",\n  \"M\",     \"Michael\",   \"Murphy\",     \"O'Calaghan\",1969, 04, 12,      \"Rural\", \n  \"M\",     \"Oliver\",    \"Laurent\",    \"De Bordow\" , 1971, 02, 04,     \"River\",\n  \"F\",      \"Blessing\",  NA,          \"Adebayo\",   1955,  02, 14,     \"Rural\"\n)\n\nresults <- tribble(\n  ~gender,  ~first,     ~middle,     ~last,          ~yr, ~mon, ~day, ~district, ~result,\n  \"M\",      \"Amir\",     NA,          \"Khan\",         1989, 11,   22,  \"River\", \"positive\",\n  \"M\",      \"Tony\",   \"B\",         \"Smith\",          1970, 09,   19,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Contreras\", \"Rodriguez\",    1972, 04,   15,  \"Cty\",   \"negative\",\n  \"F\",      \"Betty\",    \"Castel\",   \"Chase\",        1954,  03,   30,  \"City\",  \"positive\",\n  \"F\",      \"Andrea\",   NA,          \"Kumaraswamy\",  2001, 01,   05,  \"Rural\", \"positive\",      \n  \"F\",      \"Caroline\", NA,          \"Wang\",         1988, 12,   11,  \"Rural\", \"negative\",\n  \"F\",      \"Trang\",    NA,          \"Nguyen\",       1981, 06,   10,  \"Rural\", \"positive\",\n  \"M\",      \"Olivier\" , \"Laurent\",   \"De Bordeaux\",  NA,   NA,   NA,  \"River\", \"positive\",\n  \"M\",      \"Mike\",     \"Murphy\",    \"O'Callaghan\",  1969, 04,   12,  \"Rural\", \"negative\",\n  \"F\",      \"Cassidy\",  \"Jones\",     \"Davis\",        1980, 07,   02,  \"City\",  \"positive\",\n  \"M\",      \"Mohammad\", NA,          \"Ali\",          1942, 01,   17,  \"City\",  \"negative\",\n  NA,       \"Jose\",     \"Sanchez\",   \"Lopez\",        1995, 01,   06,  \"City\",  \"negative\",\n  \"M\",      \"Abubakar\", NA,          \"Abullahi\",     1960, 01,   01,  \"River\", \"positive\",\n  \"F\",      \"Maria\",    \"Salinas\",   \"Contreras\",    1955, 03,   03,  \"River\", \"positive\"\n  )"},{"path":"joining-data.html","id":"correspondencia-probabilística","chapter":"14 Unir datos","heading":"Correspondencia probabilística","text":"La función fastLink() del paquete fastLink puede utilizarse para aplicar un algoritmo de coincidencia. Esta es la información básica. Puedes leer más detalles escribiendo ?fastLink en tu consola.Define los dos dataframes para la comparación con los argumentos dfA =y dfB =En varnames = indica todos los nombres de columnas que se utilizarán para la comparación. Todos ellos deben existir tanto en dfA como en dfB.En stringdist.match = escribe columnas de las que están en varnames para ser evaluadas en la cadena “distance”.En numeric.match = dar columnas de las que están en varnames para ser evaluadas en la distancia numérica.Los valores faltantes se ignoranPor defecto, cada fila de cualquiera de los dos dataframes coincide como máximo con una fila del otro dataframe. Si deseas ver todas las coincidencias evaluadas, establece dedupe.matches = FALSE. La deduplicación se realiza mediante la solución de asignación lineal de Winkler.Sugerencia: divide una columna de fecha en tres columnas numéricas separadas utilizando day(), month(), year() del paquete lubridateEl umbral por defecto para las coincidencias es de 0,94 (threshold.match =), pero puedes ajustarlo más alto o más bajo. Si defines el umbral, ten en cuenta que los umbrales más altos podrían producir más falsos negativos (filas que coinciden y que en realidad deberían coincidir) y, del mismo modo, un umbral más bajo podría producir más falsos positivos.continuación, los datos se emparejan según la distancia de las cadenas en las columnas de nombre y distrito, y según la distancia numérica para el año, el mes y el día de nacimiento. Se establece un umbral de coincidencia del 95% de probabilidad.Revisar los coincidentesDefinimos el objeto devuelto por fastLink() como fl_output. Es de tipo list, y en realidad contiene varios dataframes dentro de él, detallando los resultados de la coincidencia. Uno de estos dataframes es matches, que contiene las coincidencias más probables entre cases y results. Puedes acceder este dataframe “coincidencias” con fl_output$matches. continuación, se guarda como my_matches para facilitar el acceso posterior.Cuando se imprime my_matches, se ven dos vectores de columnas: los pares de números de fila/índices (también llamados “rownames”) en cases (“inds.”) y en results (“inds.b”) que representan las mejores coincidencias. Si falta un número de fila de un dataframe, entonces se ha encontrado ninguna coincidencia en el otro dataframe con el umbral de coincidencia especificado.Cosas tener en cuenta:Las coincidencias se produjeron pesar de las ligeras diferencias en la ortografía del nombre y las fechas de nacimiento:\n“Tony B. Smith” coincide con “Anthony B Smith”\n“María Rodríguez” coincide con “Marialisa Rodrigues”\n“Betty Chase” coincide con “Elizabeth Chase”\n“Olivier Laurent De Bordeaux” coincide con “Oliver Laurent De Bordow” (se ignora la fecha de nacimiento que falta)\n“Tony B. Smith” coincide con “Anthony B Smith”“María Rodríguez” coincide con “Marialisa Rodrigues”“Betty Chase” coincide con “Elizabeth Chase”“Olivier Laurent De Bordeaux” coincide con “Oliver Laurent De Bordow” (se ignora la fecha de nacimiento que falta)Una fila de cases (para “Blessing Adebayo”, fila 9) tuvo una buena coincidencia en results, por lo que está presente en my_matches.Unión en base las coincidencias probabilísticasPara utilizar estas coincidencias para unir los resultados los casos, una estrategia es:Utilizar left_join() para unir my_matches cases (haciendo coincidir rownames en cases con “inds.” en my_matches)continuación, utiliza otro left_join() para unir results cases (haciendo coincidir los “inds.b” recién adquiridos en cases con los rownames en results)Antes de las uniones, debemos limpiar los tres dataframes:Tanto dfA como dfB deben tener sus números de fila (“rowname”) convertidos en una columna propia.Las dos columnas de my_matches se convierten en tipo carácter, por lo que pueden unirse las filasComo se realiza utilizando el código anterior, el dataframe resultante complete contendrá todas las columnas tanto de cases como de results. muchas de ellas se les añadirán los sufijos “.x” e “.y”, ya que de lo contrario los nombres de las columnas estarían duplicados.Alternativamente, para conseguir sólo los 9 registros “originales” en los casos con la(s) nueva(s) columna(s) de results, usa select() en results antes de las uniones, de forma que sólo contenga los nombres y las columnas que deseas añadir cases (por ej. la columna result).Si deseas subconjuntar cualquiera de los dos conjuntos de datos sólo con las filas que coincidan, puedes utilizar los siguientes códigos:O, para ver sólo las filas que coinciden:","code":"\nfl_output <- fastLink::fastLink(\n  dfA = cases,\n  dfB = results,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\"),\n  stringdist.match = c(\"first\", \"middle\", \"last\", \"district\"),\n  numeric.match = c(\"yr\", \"mon\", \"day\"),\n  threshold.match = 0.95)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Deduping the estimated matches.\n## Getting the match patterns for each estimated match.\n# print matches\nmy_matches <- fl_output$matches\nmy_matches##   inds.a inds.b\n## 1      1      1\n## 2      2      2\n## 3      3      3\n## 4      4      4\n## 5      8      8\n## 6      7      9\n## 7      6     10\n## 8      5     12\n# Clean data prior to joining\n#############################\n\n# convert cases rownames to a column \ncases_clean <- cases %>% rownames_to_column()\n\n# convert test_results rownames to a column\nresults_clean <- results %>% rownames_to_column()  \n\n# convert all columns in matches dataset to character, so they can be joined to the rownames\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n\n\n# Join matches to dfA, then add dfB\n###################################\n# column \"inds.b\" is added to dfA\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\n\n# column(s) from dfB are added \ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_clean <- cases %>% rownames_to_column()\n\nresults_clean <- results %>%\n  rownames_to_column() %>% \n  select(rowname, result)    # select only certain columns \n\nmatches_clean <- my_matches %>%\n  mutate(across(everything(), as.character))\n\n# joins\ncomplete <- left_join(cases_clean, matches_clean, by = c(\"rowname\" = \"inds.a\"))\ncomplete <- left_join(complete, results_clean, by = c(\"inds.b\" = \"rowname\"))\ncases_matched <- cases[my_matches$inds.a,]  # Rows in cases that matched to a row in results\nresults_matched <- results[my_matches$inds.b,]  # Rows in results that matched to a row in cases\ncases_not_matched <- cases[!rownames(cases) %in% my_matches$inds.a,]  # Rows in cases that did NOT match to a row in results\nresults_not_matched <- results[!rownames(results) %in% my_matches$inds.b,]  # Rows in results that did NOT match to a row in cases"},{"path":"joining-data.html","id":"de-duplicación-probabilística","chapter":"14 Unir datos","heading":"De-duplicación probabilística","text":"La coincidencia probabilística también puede utilizarse para de-duplicar unos datos. Consulta la página sobre de-duplicación para conocer otros métodos de de-duplicación.Aquí comenzamos con el conjunto de datos cases, pero ahora lo llamamos cases_dup, ya que tiene 2 filas adicionales que podrían ser duplicados de filas anteriores: Ver “Tony” con “Anthony”, y “Marialisa Rodrigues” con “Maria Rodriguez”.Ejecuta fastLink() como antes, pero compara el dataframe cases_dup consigo mismo. Cuando los dos dataframes proporcionados son idénticos, la función asume que se quiere de-duplicar. Observa que especificamos stringdist.match = o numeric.match = como hicimos anteriormente.Ahora, puedes revisar los duplicados potenciales con getMatches(). Proporciona el dataframe como dfA = y dfB =, y proporciona la salida de la función fastLink() como fl.=. fl.debe ser del tipo fastLink.dedupe, o en otras palabras, el resultado de fastLink().Véase la columna de la derecha, que indica los IDs duplicados: las dos últimas filas se identifican como probables duplicados de las filas 2 y 3.Para devolver los números de fila de las filas que probablemente sean duplicadas, puede contar el número de filas por valor único en la columna dedupe.ids, y luego filtrar para mantener sólo aquellas con más de una fila. En este caso, esto deja las filas 2 y 3.Para inspeccionar las filas completas de los probables duplicados, pon el número de fila en este comando:","code":"\n## Run fastLink on the same dataset\ndedupe_output <- fastLink(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  varnames = c(\"gender\", \"first\", \"middle\", \"last\", \"yr\", \"mon\", \"day\", \"district\")\n)## \n## ==================== \n## fastLink(): Fast Probabilistic Record Linkage\n## ==================== \n## \n## If you set return.all to FALSE, you will not be able to calculate a confusion table as a summary statistic.\n## dfA and dfB are identical, assuming deduplication of a single data set.\n## Setting return.all to FALSE.\n## \n## Calculating matches for each variable.\n## Getting counts for parameter estimation.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Running the EM algorithm.\n## Getting the indices of estimated matches.\n##     Parallelizing calculation using OpenMP. 1 threads out of 12 are used.\n## Calculating the posterior for each pair of matched observations.\n## Getting the match patterns for each estimated match.\n## Run getMatches()\ncases_dedupe <- getMatches(\n  dfA = cases_dup,\n  dfB = cases_dup,\n  fl.out = dedupe_output)\ncases_dedupe %>% \n  count(dedupe.ids) %>% \n  filter(n > 1)##   dedupe.ids n\n## 1          2 2\n## 2          3 2\n# displays row 2 and all likely duplicates of it\ncases_dedupe[cases_dedupe$dedupe.ids == 2,]   ##    gender   first middle  last   yr mon day district dedupe.ids\n## 2       M Anthony     B. Smith 1970   9  19    River          2\n## 10      M    Tony     B. Smith 1970   9  19    River          2"},{"path":"joining-data.html","id":"binding-and-aligning","chapter":"14 Unir datos","heading":"14.4 Enlazamiento y alineación","text":"Otro método para combinar dos dataframes es “unirlos”. También se puede pensar en esto como “anexar” o “añadir” filas o columnas.En esta sección también se discutirá cómo “alinear” el orden de las filas de un dataframe con el orden de otro dataframe. Este tema se discute más adelante en la sección sobre Vinculación de columnas.","code":""},{"path":"joining-data.html","id":"enlazar-filas","chapter":"14 Unir datos","heading":"Enlazar filas","text":"Para unir las filas de un dataframe con el fondo de otro dataframe, utiliza bind_rows() de dplyr. Es muy inclusivo, por lo que cualquier columna presente en cualquiera de los dataframes se incluirá en la salida. Algunas notas:diferencia de la versión de R base de R row.bind(), bind_rows() de dplyr requiere que el orden de las columnas sea el mismo en ambos dataframes. Siempre que los nombres de las columnas se escriban de forma idéntica, las alineará correctamente.Puedes especificar opcionalmente el argumento .id =. Proporcionar un nombre de columna de caracteres. Esto producirá una nueva columna que sirve para identificar de qué dataframe procede originalmente cada fila.Puedes utilizar bind_rows() en una lista de dataframes de estructura similar para combinarlos en un dataframe. Mira un ejemplo en la página Iteración, bucles y listas que implica la importación de múltiples listas de líneas con purrr.Un ejemplo común de vinculación de filas es vincular una fila “total” una tabla descriptiva hecha con la función summarise() de dplyr. continuación, creamos una tabla de recuentos de casos y valores medianos de TC por hospital con una fila de totales.La función summarise() se utiliza en los datos agrupados por hospital para devolver un dataframe resumido por hospital. Pero la función summarise() produce automáticamente una fila de “totales”, así que la creamos resumiendo los datos de nuevo, pero con los datos agrupados por hospital. Esto produce un segundo dataframe de una sola fila. continuación, podemos unir estos dataframes para obtener la tabla final.Mira otros ejemplos trabajados como éste en las páginas de Tablas descriptivas y Tablas para presentaciones.Este es el dataframe de hosp_summary:Crea un dataframe con las estadísticas “totales” (agrupadas por hospital). Esto devolverá una sola fila.Y continuación está el dataframe totals. Observa que sólo hay dos columnas. Estas columnas también están en hosp_summary, pero hay una columna en hosp_summary que está en totals (hospital).Ahora podemos unir las filas con bind_rows().Ahora podemos ver el resultado. Observa cómo en la última fila se rellena un valor NA vacío para la columna hospital que estaba en hosp_summary. Como se explica en la página de Tablas para presentaciones, podrías “rellenar” esta celda con “Total” utilizando replace_na().","code":"\n# Create core table\n###################\nhosp_summary <- linelist %>% \n  group_by(hospital) %>%                        # Group data by hospital\n  summarise(                                    # Create new summary columns of indicators of interest\n    cases = n(),                                  # Number of rows per hospital-outcome group     \n    ct_value_med = median(ct_blood, na.rm=T))     # median CT value per group\n# create totals\n###############\ntotals <- linelist %>% \n  summarise(\n    cases = n(),                               # Number of rows for whole dataset     \n    ct_value_med = median(ct_blood, na.rm=T))  # Median CT for whole dataset\n# Bind data frames together\ncombined <- bind_rows(hosp_summary, totals)"},{"path":"joining-data.html","id":"enlazar-columnas","chapter":"14 Unir datos","heading":"Enlazar columnas","text":"Existe una función similar de dplyr bind_cols() que se puede utilizar para combinar dos dataframes de forma lateral. Ten en cuenta que las filas se emparejan entre sí por posición (como una unión anterior) - por ejemplo, la fila 12 en cada dataframe se alineará.Como ejemplo, unimos varias tablas de resumen. Para ello, también mostramos cómo reordenar el orden de las filas de un dataframe para que coincida con el orden de otro dataframe, con match().Aquí definimos case_info como un dataframe resumido de los casos del listado, por hospital, con el número de casos y el número de muertes.Y digamos que aquí hay un dataframe diferente contact_fu que contiene información sobre el porcentaje de contactos expuestos investigados y “seguidos”, de nuevo por hospital.Observa que los hospitales son los mismos, pero están en diferente orden en cada dataframe. La solución más sencilla sería utilizar un left_join() en la columna hospitals, pero también podría utilizar bind_cols() con un paso adicional.","code":"\n# Case information\ncase_info <- linelist %>% \n  group_by(hospital) %>% \n  summarise(\n    cases = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T)\n  )\ncontact_fu <- data.frame(\n  hospital = c(\"St. Mark's Maternity Hospital (SMMH)\", \"Military Hospital\", \"Missing\", \"Central Hospital\", \"Port Hospital\", \"Other\"),\n  investigated = c(\"80%\", \"82%\", NA, \"78%\", \"64%\", \"55%\"),\n  per_fu = c(\"60%\", \"25%\", NA, \"20%\", \"75%\", \"80%\")\n)"},{"path":"joining-data.html","id":"utiliza-match-para-alinear-la-ordenación","chapter":"14 Unir datos","heading":"Utiliza match() para alinear la ordenación","text":"Debido que los órdenes de las filas son diferentes, un simple comando bind_cols() daría lugar un desajuste de los datos. Para solucionarlo podemos utilizar match() de R base para alinear las filas de un dataframe en el mismo orden que en otro. Asumimos para este enfoque que hay valores duplicados en ninguno de los dos dataframes.Cuando utilizamos match(), la sintaxis es match(TARGET ORDER VECTOR, DATA FRAME COLUMN CHANGE), donde el primer argumento es el orden deseado (ya sea un vector independiente, o en este caso una columna en un dataframe), y el segundo argumento es la columna del dataframe que se reordenará. La salida de match() es un vector de números que representa el ordenamiento correcto de las posiciones. Puedes obtener más información con ?match.Puedes utilizar este vector numérico para reordenar el dataframe - colócalo dentro de los subcorchetes [ ] antes de la coma. Lee más sobre la sintaxis del subconjunto de corchetes en la página de Fundamentos de R. El comando de abajo crea un nuevo dataframe, definido como el anterior en el que las filas están ordenadas en el vector numérico de arriba.Ahora podemos unir las columnas del dataframe, con el orden correcto de las filas. Ten en cuenta que algunas columnas están duplicadas y será necesario limpiarlas con rename(). Lee más sobre bind_rows() aquí.Una alternativa en R base bind_cols es cbind(), que realiza la misma operación.","code":"\nmatch(case_info$hospital, contact_fu$hospital)## [1] 4 2 3 6 5 1\ncontact_fu_aligned <- contact_fu[match(case_info$hospital, contact_fu$hospital),]\nbind_cols(case_info, contact_fu)## New names:\n## • `hospital` -> `hospital...1`\n## • `hospital` -> `hospital...4`## # A tibble: 6 × 6\n##   hospital...1                         cases deaths hospital...4                         invest…¹ per_fu\n##   <chr>                                <int>  <int> <chr>                                <chr>    <chr> \n## 1 Central Hospital                       454    193 St. Mark's Maternity Hospital (SMMH) 80%      60%   \n## 2 Military Hospital                      896    399 Military Hospital                    82%      25%   \n## 3 Missing                               1469    611 Missing                              <NA>     <NA>  \n## 4 Other                                  885    395 Central Hospital                     78%      20%   \n## 5 Port Hospital                         1762    785 Port Hospital                        64%      75%   \n## 6 St. Mark's Maternity Hospital (SMMH)   422    199 Other                                55%      80%   \n## # … with abbreviated variable name ¹​investigated"},{"path":"joining-data.html","id":"resources-7","chapter":"14 Unir datos","heading":"14.5 Recursos","text":"Las páginas de tidyverse sobre joinLa página de R Data Science sobre datos relacionalesLa página de tidyverse en dplyr en la encuadernaciónUna viñeta sobre fastLink en la página de Github del paquetePublicación que describe la metodología de fastLinkPublicación que describe el paquete RecordLinkage","code":""},{"path":"de-duplication.html","id":"de-duplication","chapter":"15 De-duplicación","heading":"15 De-duplicación","text":"Esta página cubre las siguientes técnicas de De-duplicación:Identificación y eliminación de filas duplicadas“Recortar” filas para mantener sólo determinadas filas (por ejemplo, mínimas o máximas) de cada grupo de filas“Reunir” o combinar valores de varias filas en una sola fila","code":""},{"path":"de-duplication.html","id":"preparation-6","chapter":"15 De-duplicación","heading":"15.1 Preparación","text":"","code":""},{"path":"de-duplication.html","id":"cargar-paquetes-6","chapter":"15 De-duplicación","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para el análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  tidyverse,   # deduplication, grouping, and slicing functions\n  janitor,     # function for reviewing duplicates\n  stringr)      # for string searches, can be used in \"rolling-up\" values"},{"path":"de-duplication.html","id":"importar-datos-6","chapter":"15 De-duplicación","heading":"Importar datos","text":"Para la demostración, utilizaremos unos datos de ejemplo que se crea con el código R que aparece continuación.Los datos son registros de encuentros telefónicos COVID-19, incluyendo encuentros con contactos y con casos. Las columnas incluyen recordID (generado por ordenador), personID, name, date del encuentro, time del encuentro, purpose del encuentro (para entrevistar como caso o como contacto), y symptoms_ever (si la persona en ese encuentro declaró haber tenido síntomas alguna vez).Este es el código para crear el set de datos obs:","code":"\nobs <- data.frame(\n  recordID  = c(1,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18),\n  personID  = c(1,1,2,2,3,2,4,5,6,7,2,1,3,3,4,5,5,7,8),\n  name      = c(\"adam\", \"adam\", \"amrish\", \"amrish\", \"mariah\", \"amrish\", \"nikhil\", \"brian\", \"smita\", \"raquel\", \"amrish\",\n                \"adam\", \"mariah\", \"mariah\", \"nikhil\", \"brian\", \"brian\", \"raquel\", \"natalie\"),\n  date      = c(\"1/1/2020\", \"1/1/2020\", \"2/1/2020\", \"2/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\", \"5/1/2020\",\"5/1/2020\", \"2/1/2020\",\n                \"5/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"6/1/2020\", \"7/1/2020\", \"7/1/2020\", \"7/1/2020\"),\n  time      = c(\"09:00\", \"09:00\", \"14:20\", \"14:20\", \"12:00\", \"16:10\", \"13:01\", \"15:20\", \"14:20\", \"12:30\", \"10:24\",\n                \"09:40\", \"07:25\", \"08:32\", \"15:36\", \"15:31\", \"07:59\", \"11:13\", \"17:12\"),\n  encounter = c(1,1,1,1,1,3,1,1,1,1,2,\n                2,2,3,2,2,3,2,1),\n  purpose   = c(\"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"contact\",\n                \"case\", \"contact\", \"contact\", \"contact\", \"contact\", \"case\", \"contact\", \"case\"),\n  symptoms_ever = c(NA, NA, \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", NA, \"Yes\",\n                    \"No\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\",\"No\", \"No\")) %>% \n  mutate(date = as.Date(date, format = \"%d/%m/%Y\"))"},{"path":"de-duplication.html","id":"dedup_data","chapter":"15 De-duplicación","heading":"Este es el dataframe","text":"Utiliza los cuadros de filtro de la parte superior para revisar los encuentros de cada persona.Hay que tener en cuenta algunas cosas al revisar los datos:Los dos primeros registros están 100% duplicados, incluido el recordID de registro duplicado (¡debe ser un fallo informático!)Las dos segundas filas están duplicadas, en todas las columnas excepto en recordIDVarias personas tuvieron múltiples encuentros telefónicos, en diversas fechas y horas, y como contactos y/o casosEn cada encuentro se preguntaba la persona si había tenido alguna vez síntomas, y parte de esta información falta.Y aquí hay un resumen rápido de las personas y los propósitos de sus encuentros, usando tabyl() de janitor:","code":"\nobs %>% \n  tabyl(name, purpose)##     name case contact\n##     adam    1       2\n##   amrish    1       3\n##    brian    1       2\n##   mariah    1       2\n##  natalie    1       0\n##   nikhil    0       2\n##   raquel    0       2\n##    smita    0       1"},{"path":"de-duplication.html","id":"deduplication-1","chapter":"15 De-duplicación","heading":"15.2 De-duplicación","text":"Esta sección describe cómo revisar y eliminar filas duplicadas en un dataframe. También muestra cómo manejar los elementos duplicados en un vector.","code":""},{"path":"de-duplication.html","id":"examinar-las-filas-duplicadas","chapter":"15 De-duplicación","heading":"Examinar las filas duplicadas","text":"Para revisar rápidamente las filas que tienen duplicados, puedes utilizar get_dupes() del paquete janitor. Por defecto, se revisan todas las columnas cuando se evalúan los duplicados - las filas devueltas por la función están 100% duplicadas considerando los valores de todas las columnas.En el dataframe obs, las dos primeras filas están 100% duplicadas - tienen el mismo valor en cada columna (incluyendo la columna recordID, que se supone que es única - debe ser algún fallo informático). El dataframe devuelto incluye automáticamente una nueva columna dupe_count en el lado derecho, que muestra el número de filas con esa combinación de valores duplicados.Ver los datos originalesSin embargo, si decidimos ignorar recordID, las filas 3 y 4 también están duplicadas entre sí. Es decir, tienen los mismos valores en todas las columnas excepto en recordID. Puedes especificar las columnas que se van ignorar en la función mediante el símbolo - menos.También puedes especificar positivamente las columnas considerar. continuación, sólo se devuelven las filas que tienen los mismos valores en las columnas name y purpose. Observa cómo “amrish” tiene ahora dupe_count igual 3 para reflejar sus tres encuentros de “contacto”.*Desplázate la izquierda para ver más filas**Ver los datos originales.Para más detalles, consulta ?get_dupes o esta referencia en línea","code":"\n# 100% duplicates across all columns\nobs %>% \n  janitor::get_dupes()\n# Duplicates when column recordID is not considered\nobs %>% \n  janitor::get_dupes(-recordID)         # if multiple columns, wrap them in c()\n# duplicates based on name and purpose columns ONLY\nobs %>% \n  janitor::get_dupes(name, purpose)"},{"path":"de-duplication.html","id":"mantener-sólo-filas-únicas","chapter":"15 De-duplicación","heading":"Mantener sólo filas únicas","text":"Para mantener sólo las filas únicas de un dataframe, utiliza distinct() de dplyr (como se muestra en la página Limpieza de datos y funciones básicas). Las filas duplicadas se eliminan de forma que sólo se conserva la primera de dichas filas. Por defecto, “primero” significa el rownumber más alto (orden de filas de arriba abajo). Sólo se mantienen las filas únicas.En el ejemplo siguiente, ejecutamos distinct() de forma que la columna recordID se excluye de la consideración - así se eliminan dos filas duplicadas. La primera fila (para “adam”) estaba 100% duplicada y ha sido eliminada. También la fila 3 (para “amrish”) estaba duplicada en todas las columnas excepto en recordID (que se tiene en cuenta), por lo que también se ha eliminado. El set de datos obs tiene ahora nrow(obs)-2 filas, nrow(obs)).Desplázate la izquierda para ver el dataframe completoPRECAUCIÓN: Si se utiliza distinct() en datos agrupados, la función se aplicará cada grupo.De-duplicar en base columnas específicasTambién puedes especificar las columnas que serán la base de la De-duplicación. De esta manera, la De-duplicación sólo se aplica las filas que están duplicadas dentro de las columnas especificadas. menos que establece .keep_all = TRUE, todas las columnas mencionadas se eliminarán.En el ejemplo siguiente, la De-duplicación sólo se aplica las filas que tienen valores idénticos para las columnas name y purpose. Por lo tanto, “brian” sólo tiene 2 filas en lugar de 3: su primer encuentro como “contacto” y su único encuentro como “caso”. Para ajustar que se mantenga el último encuentro de brian de cada propósito, Mira el apartado Cortar dentro de los grupos.Desplázate la izquierda para ver el dataframe completoVer los datos originales.","code":"\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(across(-recordID), # reduces data frame to only unique rows (keeps first one of any duplicates)\n           .keep_all = TRUE) \n\n# if outside pipes, include the data as first argument \n# distinct(obs)\n# added to a chain of pipes (e.g. data cleaning)\nobs %>% \n  distinct(name, purpose, .keep_all = TRUE) %>%  # keep rows unique by name and purpose, retain all columns\n  arrange(name)                                  # arrange for easier viewing"},{"path":"de-duplication.html","id":"de-duplicar-elementos-en-un-vector","chapter":"15 De-duplicación","heading":"De-duplicar elementos en un vector","text":"La función duplicated() de R base evaluará un vector (columna) y devolverá un vector lógico de la misma longitud (TRUE/FALSE). La primera vez que aparezca un valor, devolverá FALSE (es un duplicado), y las siguientes veces que aparezca ese valor devolverá TRUE. Nótese que NA se trata igual que cualquier otro valor.Para devolver sólo los elementos duplicados, se pueden utilizar paréntesis para subconjuntar el vector original:Para devolver sólo los elementos únicos, utiliza unique() de R base. Para eliminar los NA de la salida, anida na.omit() dentro de unique().","code":"\nx <- c(1, 1, 2, NA, NA, 4, 5, 4, 4, 1, 2)\nduplicated(x)##  [1] FALSE  TRUE FALSE FALSE  TRUE FALSE FALSE  TRUE  TRUE  TRUE  TRUE\nx[duplicated(x)]## [1]  1 NA  4  4  1  2\nunique(x)           # alternatively, use x[!duplicated(x)]## [1]  1  2 NA  4  5\nunique(na.omit(x))  # remove NAs ## [1] 1 2 4 5"},{"path":"de-duplication.html","id":"utilizando-r-base-1","chapter":"15 De-duplicación","heading":"Utilizando R base","text":"Para devolver las filas duplicadasEn R base, también se puede ver qué filas están 100% duplicadas en un dataframe df con el comando duplicated(df) (devuelve un vector lógico de las filas).Así, también puedes utilizar el subconjunto base [ ] en el dataframe para ver las filas duplicadas con df[duplicated(df),] (¡olvides la coma, que significa que quieres ver todas las columnas!)Para devolver filas únicasVer las notas anteriores. Para ver las filas únicas se añade el negador lógico ! delante de la función duplicated():\ndf[!duplicated(df),]Para devolver las filas que son duplicados de sólo ciertas columnasSubconjunta el df que está dentro de los paréntesis de duplicated(), para que esta función opere sólo en ciertas columnas del df.\nPara especificar las columnas, proporciona los números o nombres de las columnas después de una coma (recuerda que todo esto está dentro de la función duplicated()).¡Asegúrate también de mantener la coma , fuera, después de la función duplicated()!Por ejemplo, para evaluar sólo las columnas 2 5 en busca de duplicados: df[!duplicated(df[, 2:5]),]\nPara evaluar sólo las columnas name y purpose en busca de duplicados: df[!duplicated(df[, c(\"name\", \"purpose)]),]","code":""},{"path":"de-duplication.html","id":"slicing","chapter":"15 De-duplicación","heading":"15.3 Recortar","text":"Para “recortar” un dataframe con un filtro de filas por su número de fila/posición. Esto resulta especialmente útil si tiene varias filas por grupo funcional (por ejemplo, por “persona”) y sólo quieres conservar una o algunas de ellas.La función básica slice() acepta números y devuelve filas en esas posiciones. Si los números proporcionados son positivos, sólo se devuelven éstos. Si son negativos, se devuelven esas filas. Los números deben ser todos positivos o todos negativos.Ver los datos originales.Existen diversas variantes: Se les debe proporcionar una columna y un número de filas devolver (n =).slice_min() y slice_max() mantienen sólo la(s) fila(s) con el valor(es) mínimo o máximo de la columna especificada. Esto también funciona para devolver el “min” y el “max” de los factores ordenados.slice_head() y slice_tail() - mantienen sólo la primera o la última fila.slice_sample() - mantener sólo una muestra aleatoria de las filas.Utiliza los argumentos n = o prop = para especificar el número o la proporción de filas que deben conservarse. Si se utiliza la función en una cadena de tuberías, proporciona primero el argumento datos (por ejemplo, slice(datos, n = 2)). Para más información, consulta con ?slice.Otros argumentos:.order_by = utilizado en slice_min() y slice_max() esta es una columna para ordenar por antes de recortarlas.\nwith_ties = TRUE por defecto, lo que significa que se mantienen los empates.\n.preserve = FALSE por defecto. Si es TRUE, la estructura de agrupación se recalcula después del recorte.\nweight_by = Opcional, columna numérica para ponderar por (un número mayor tiene más probabilidades de ser muestreado). También replace = para saber si el muestreo se realiza con/sin reemplazo.CONSEJO: Al utilizar slice_max() y slice_min(), asegúrate de especificar/escribir el n = (por ejemplo, n = 2, simplemente 2). De lo contrario, puedes obtener un error Error: …empty.. NOTA: Es posible que encuentres la función top_n(), que ha sido sustituida por las funciones slice. ","code":"\nobs %>% slice(4)  # return the 4th row##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        3        2 amrish 2020-01-02 14:20         1 contact            No\nobs %>% slice(c(2,4))  # return rows 2 and 4##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        1        1   adam 2020-01-01 09:00         1 contact          <NA>\n## 2        3        2 amrish 2020-01-02 14:20         1 contact            No\n#obs %>% slice(c(2:4))  # return rows 2 through 4\nobs %>% slice_max(encounter, n = 1)  # return rows with the largest encounter number##   recordID personID   name       date  time encounter purpose symptoms_ever\n## 1        5        2 amrish 2020-01-05 16:10         3    case           Yes\n## 2       13        3 mariah 2020-01-06 08:32         3 contact            No\n## 3       16        5  brian 2020-01-07 07:59         3    case            No"},{"path":"de-duplication.html","id":"recortar-con-grupos","chapter":"15 De-duplicación","heading":"Recortar con grupos","text":"Las funciones slice_*() pueden ser muy útiles si se aplican un dataframe agrupado porque la operación de recorte se realiza en cada grupo por separado. Utiliza la función group_by() junto con slice() para agrupar los datos y tomar un corte de cada grupo.Esto es útil para la De-duplicación si tienes varias filas por persona pero sólo quieres mantener una de ellas. Primero se utiliza group_by() con columnas clave que son las mismas por persona, y luego se utiliza una función slice en una columna que será diferente entre las filas agrupadas.En el ejemplo siguiente, para mantener sólo el último encuentro por persona, agrupamos las filas por nombre y luego utilizamos slice_max() con n = 1 en la columna de date. Ten en cuenta que Para aplicar una función como `slice_max() en las fechas, la columna de fecha debe ser de tipo Date.Por defecto, los “empates” (por ejemplo, la misma fecha en este escenario) se mantienen, y todavía obtendríamos múltiples filas para algunas personas (por ejemplo, adam). Para evitar esto, establecemos with_ties = FALSE. Sólo obtendremos una fila por persona.PRECACUCIÓN: Si utilizas arrange(), especifica .by_group = TRUE para que los datos se ordenen dentro de cada grupo.PELIGRO: Si with_ties = FALSE, se mantiene la primera fila de un empate. Esto puede ser engañoso. Mira cómo para Mariah, ella tiene dos encuentros en su última fecha (6 de enero) y el primero (el más temprano) se mantuvo. Es probable que queramos mantener tu último encuentro en ese día. Mira cómo “romper” estos vínculos en el siguiente ejemplo. Arriba, por ejemplo, podemos ver que sólo se conservó la fila de Amrish del 5 de enero, y sólo se conservó la fila de Brian del 7 de enero. Ver los datos originales.Romper los “empates”Se pueden ejecutar múltiples sentencias de recorte para “romper empates”. En este caso, si una persona tiene varios encuentros en tu última fecha, se mantiene el encuentro con la última hora (se utiliza lubridate::hm() para convertir los caracteres de tiempo en tipo tiempo, ordenable).\nObserva ahora cómo, la única fila que se mantiene para “Mariah” el 6 de enero es el encuentro 3 de las 08:32, el encuentro 2 de las 07:25.En el ejemplo anterior, también habría sido posible realizar un recorte por número de encuentro, pero mostramos el corte por fecha y hora modo de ejemplo.CONSEJO: Para utilizar slice_max() o slice_min() en una columna “carácter”, ¡mútala un tipo de factor ordenado!Ver los datos originales.","code":"\nobs %>% \n  group_by(name) %>%       # group the rows by 'name'\n  slice_max(date,          # keep row per group with maximum date value \n            n = 1,         # keep only the single highest row \n            with_ties = F) # if there's a tie (of date), take the first row\n# Example of multiple slice statements to \"break ties\"\nobs %>%\n  group_by(name) %>%\n  \n  # FIRST - slice by latest date\n  slice_max(date, n = 1, with_ties = TRUE) %>% \n  \n  # SECOND - if there is a tie, select row with latest time; ties prohibited\n  slice_max(lubridate::hm(time), n = 1, with_ties = FALSE)"},{"path":"de-duplication.html","id":"mantener-todos-pero-marcados","chapter":"15 De-duplicación","heading":"Mantener todos pero marcados","text":"Si deseas conservar todos los registros pero marcar sólo algunos para tu análisis, considera un enfoque de dos pasos utilizando un número de registro/encuentro único:Reduce/recorta el dataframe original sólo las filas para el análisis. Guarda/conserva este dataframe reducido.En el dataframe original, marca las filas según corresponda con case_when(), basándose en si tu identificador único de registro (recordID en este ejemplo) está presente en el dataframe reducido.Ver los datos originales.","code":"\n# 1. Define data frame of rows to keep for analysis\nobs_keep <- obs %>%\n  group_by(name) %>%\n  slice_max(encounter, n = 1, with_ties = FALSE) # keep only latest encounter per person\n\n\n# 2. Mark original data frame\nobs_marked <- obs %>%\n\n  # make new dup_record column\n  mutate(dup_record = case_when(\n    \n    # if record is in obs_keep data frame\n    recordID %in% obs_keep$recordID ~ \"For analysis\", \n    \n    # all else marked as \"Ignore\" for analysis purposes\n    TRUE                            ~ \"Ignore\"))\n\n# print\nobs_marked##    recordID personID    name       date  time encounter purpose symptoms_ever   dup_record\n## 1         1        1    adam 2020-01-01 09:00         1 contact          <NA>       Ignore\n## 2         1        1    adam 2020-01-01 09:00         1 contact          <NA>       Ignore\n## 3         2        2  amrish 2020-01-02 14:20         1 contact            No       Ignore\n## 4         3        2  amrish 2020-01-02 14:20         1 contact            No       Ignore\n## 5         4        3  mariah 2020-01-05 12:00         1    case            No       Ignore\n## 6         5        2  amrish 2020-01-05 16:10         3    case           Yes For analysis\n## 7         6        4  nikhil 2020-01-05 13:01         1 contact           Yes       Ignore\n## 8         7        5   brian 2020-01-05 15:20         1 contact            No       Ignore\n## 9         8        6   smita 2020-01-05 14:20         1 contact           Yes For analysis\n## 10        9        7  raquel 2020-01-05 12:30         1 contact          <NA>       Ignore\n## 11       10        2  amrish 2020-01-02 10:24         2 contact           Yes       Ignore\n## 12       11        1    adam 2020-01-05 09:40         2    case            No For analysis\n## 13       12        3  mariah 2020-01-06 07:25         2 contact            No       Ignore\n## 14       13        3  mariah 2020-01-06 08:32         3 contact            No For analysis\n## 15       14        4  nikhil 2020-01-06 15:36         2 contact           Yes For analysis\n## 16       15        5   brian 2020-01-06 15:31         2 contact           Yes       Ignore\n## 17       16        5   brian 2020-01-07 07:59         3    case            No For analysis\n## 18       17        7  raquel 2020-01-07 11:13         2 contact            No For analysis\n## 19       18        8 natalie 2020-01-07 17:12         1    case            No For analysis"},{"path":"de-duplication.html","id":"calcular-la-exhaustividad-de-las-filas","chapter":"15 De-duplicación","heading":"Calcular la exhaustividad de las filas","text":"Crea una columna que contenga una métrica para la exhaustividad/completitud de la fila (que tenga valores faltantes). Esto podría ser útil la hora de decidir qué filas se priorizan sobre otras al de-duplicar/repartir.En este ejemplo, las columnas “clave” sobre las que se quiere medir la integridad se guardan en un vector de nombres de columnas.continuación se crea la nueva columna key_completeness con mutate(). El nuevo valor de cada fila se define como una fracción calculada: el número de valores ausentes en esa fila entre las columnas clave, dividido por el número de columnas clave.Esto implica la función rowSums() de R base. También se utiliza . , que dentro del piping se refiere al dataframe en ese punto (en este caso, se está subconjuntando con corchetes []).*Desplázate la derecha para ver más filas**.Ver los datos originales.","code":"\n# create a \"key variable completeness\" column\n# this is a *proportion* of the columns designated as \"key_cols\" that have non-missing values\n\nkey_cols = c(\"personID\", \"name\", \"symptoms_ever\")\n\nobs %>% \n  mutate(key_completeness = rowSums(!is.na(.[,key_cols]))/length(key_cols)) "},{"path":"de-duplication.html","id":"str_rollup","chapter":"15 De-duplicación","heading":"15.4 Combinación de valores","text":"Esta sección describe:Cómo “combinar” valores de varias filas en una sola fila, con algunas variacionesUna vez que se hayan “combinado” los valores, cómo sobrescribir/priorizar los valores en cada celdaEsta sección utiliza los datos de ejemplo de la sección Preparación.","code":""},{"path":"de-duplication.html","id":"combinar-los-valores-en-una-fila","chapter":"15 De-duplicación","heading":"Combinar los valores en una fila","text":"El código de ejemplo que se muestra continuación utiliza group_by() y summarise() para agrupar las filas por persona, y luego pega todos los valores únicos dentro de las filas agrupadas. Así, se obtiene una fila de resumen por persona. Algunas notas:Se añade un sufijo todas las nuevas columnas (“_roll” en este ejemplo)Si quieres mostrar sólo los valores únicos por celda, entonces envuelve el na.omit() con unique()na.omit() elimina los valores NA, pero si se desea se puede eliminar con paste0(.x)…El resultado es una fila por grupo (ID), con entradas ordenadas por fecha y pegadas. Desplázate la izquierda para ver más filasVer los datos originales.Esta variación sólo muestra valores únicos:Esta variación añade un sufijo cada columna.\nEn este caso, “_roll” para indicar que se ha combinado (roll):","code":"\n# \"Roll-up\" values into one row per group (per \"personID\") \ncases_rolled <- obs %>% \n  \n  # create groups by name\n  group_by(personID) %>% \n  \n  # order the rows within each group (e.g. by date)\n  arrange(date, .by_group = TRUE) %>% \n  \n  # For each column, paste together all values within the grouped rows, separated by \";\"\n  summarise(\n    across(everything(),                           # apply to all columns\n           ~paste0(na.omit(.x), collapse = \"; \"))) # function is defined which combines non-NA values\n# Variation - show unique values only \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                                   # apply to all columns\n           ~paste0(unique(na.omit(.x)), collapse = \"; \"))) # function is defined which combines unique non-NA values\n# Variation - suffix added to column names \ncases_rolled <- obs %>% \n  group_by(personID) %>% \n  arrange(date, .by_group = TRUE) %>% \n  summarise(\n    across(everything(),                \n           list(roll = ~paste0(na.omit(.x), collapse = \"; \")))) # _roll is appended to column names"},{"path":"de-duplication.html","id":"sobrescribir-valoresjerarquía","chapter":"15 De-duplicación","heading":"Sobrescribir valores/jerarquía","text":"Si luego quieres evaluar todos los valores combinados, y mantener sólo un valor específico (por ejemplo, el “mejor” o el “máximo” valor), puedes utilizar mutate() través de las columnas deseadas, para implementar case_when(), que utiliza str_detect() del paquete stringr para buscar secuencialmente patrones de cadena y sobrescribir el contenido de la celda.Ahora puedes ver en la columna symptoms_ever que si la persona ALGUNA vez dijo “Sí” los síntomas, entonces sólo se muestra “Sí”.Ver los datos originales.","code":"\n# CLEAN CASES\n#############\ncases_clean <- cases_rolled %>% \n    \n    # clean Yes-No-Unknown vars: replace text with \"highest\" value present in the string\n    mutate(across(c(contains(\"symptoms_ever\")),                     # operates on specified columns (Y/N/U)\n             list(mod = ~case_when(                                 # adds suffix \"_mod\" to new cols; implements case_when()\n               \n               str_detect(.x, \"Yes\")       ~ \"Yes\",                 # if \"Yes\" is detected, then cell value converts to yes\n               str_detect(.x, \"No\")        ~ \"No\",                  # then, if \"No\" is detected, then cell value converts to no\n               str_detect(.x, \"Unknown\")   ~ \"Unknown\",             # then, if \"Unknown\" is detected, then cell value converts to Unknown\n               TRUE                        ~ as.character(.x)))),   # then, if anything else if it kept as is\n      .keep = \"unused\")                                             # old columns removed, leaving only _mod columns"},{"path":"de-duplication.html","id":"probabilistic-de-duplication","chapter":"15 De-duplicación","heading":"15.5 De-duplicación probabilística","text":"veces, puedes querer identificar duplicados “probables” basándote en la similitud (por ejemplo, la “distancia” de la cadena) en varias columnas como el nombre, la edad, el sexo, la fecha de nacimiento, etc. Puedes aplicar un algoritmo de coincidencia probabilística para identificar duplicados probables.Consulta la página sobre la unión de datos para obtener una explicación sobre este método. La sección sobre Coincidencia probabilística contiene un ejemplo de aplicación de estos algoritmos para comparar un dataframe consigo mismo, realizando así una De-duplicación probabilística.","code":""},{"path":"de-duplication.html","id":"resources-8","chapter":"15 De-duplicación","heading":"15.6 Recursos","text":"Gran parte de la información de esta página está adaptada de estos recursos y viñetas en línea:datanoviaReferencia de dplyr tidyverseViñeta janitor de CRAN","code":""},{"path":"iteration-loops-and-lists.html","id":"iteration-loops-and-lists","chapter":"16 Iteración, bucles y listas","heading":"16 Iteración, bucles y listas","text":"Con frecuencia nos enfrentamos la repetición de análisis por subgrupos, como países, distritos o grupos de edad. Estas son sólo algunas de las situaciones frecuentes que implican la iteración. La codificación de sus operaciones iterativas utilizando los enfoques que se indican continuación te ayudarán realizar estas tareas repetitivas más rápidamente, reducir la posibilidad de error y reducir la longitud del código.Esta página presentará dos enfoques de las operaciones iterativas: el uso de bucles y el uso del paquete purrr.Los bucles iteran el código través de una serie de entradas, pero son menos comunes en R que en otros lenguajes de programación. obstante, los presentamos aquí como herramienta de aprendizaje y referenciaEl paquete purrr es el enfoque tidyverse de las operaciones iterativas - funciona “mapeando” una función través de muchas entradas (valores, columnas, conjuntos de datos, etc.)En el camino, mostraremos ejemplos como:Importación y exportación de múltiples archivosCreación de epicurvas para múltiples jurisdiccionesEjecución de pruebas T para varias columnas en un dataframeEn la sección de purrr también proporcionaremos varios ejemplos de creación y manejo de listas.","code":""},{"path":"iteration-loops-and-lists.html","id":"preparation-6","chapter":"16 Iteración, bucles y listas","heading":"16.1 Preparación","text":"","code":""},{"path":"iteration-loops-and-lists.html","id":"cargar-paquetes-7","chapter":"16 Iteración, bucles y listas","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n     rio,         # import/export\n     here,        # file locator\n     purrr,       # iteration\n     tidyverse    # data management and visualization\n)"},{"path":"iteration-loops-and-lists.html","id":"importar-datos-7","chapter":"16 Iteración, bucles y listas","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"iteration-loops-and-lists.html","id":"for-loops","chapter":"16 Iteración, bucles y listas","heading":"16.2 bucles for","text":"","code":""},{"path":"iteration-loops-and-lists.html","id":"iter_loops","chapter":"16 Iteración, bucles y listas","heading":"bucles for en R","text":"Los bucles se resaltan mucho en R, pero son comunes en otros lenguajes de programación. Como principiante, pueden ser útiles para aprender y practicar, ya que son más fáciles de “explorar”, “depurar”, y de otra manera comprender exactamente lo que está sucediendo para cada iteración, especialmente cuando todavía te sientes cómodo escribiendo tus propias funciones.Puedes pasar rápidamente de los bucles la iteración con funciones mapeadas con purrr (véase la sección siguiente).","code":""},{"path":"iteration-loops-and-lists.html","id":"componentes-básicos","chapter":"16 Iteración, bucles y listas","heading":"Componentes básicos","text":"Un bucle tiene tres partes fundamentales:La secuencia de elementos iterarLas operaciones realizar por cada elemento de la secuenciaEl contenedor de los resultados (opcional)La sintaxis básica es: (para cada elemento de la secuencia) {hacer operaciones con el elemento}. Fíjate en los paréntesis y las llaves. Los resultados pueden ser impresos en la consola, o almacenados en un objeto R contenedor.continuación se muestra un sencillo ejemplo de bucle .","code":"\nfor (num in c(1,2,3,4,5)) {  # La SECUENCIA está definida (números de 1 a 5) y el bucle se abre con \"{\"\n  print(num + 2)             # Las OPERACIONES (añadir dos a cada elemento de la secuencia e imprimirlos en la consola)\n}                            # El bucle se cierra con \"}\"                            ## [1] 3\n## [1] 4\n## [1] 5\n## [1] 6\n## [1] 7\n                             # No hay CONTENEDOR\" en este ejemplo"},{"path":"iteration-loops-and-lists.html","id":"secuencia","chapter":"16 Iteración, bucles y listas","heading":"Secuencia","text":"Esta es la parte “” de un bucle - las operaciones se ejecutarán “para” () cada elemento de la secuencia. La secuencia puede ser una serie de valores (por ejemplo, nombres de jurisdicciones, enfermedades, nombres de columnas, elementos de listas, etc.), o puede ser una serie de números consecutivos (por ejemplo, 1,2,3,4,5). Cada enfoque tiene sus propias utilidades, que se describen continuación.La estructura básica de una declaración de secuencia es el elemento en el vector.Puedes escribir cualquier carácter o palabra en lugar de “item” (por ejemplo, “”, “num”, “hosp”, “district”, etc.). El valor de este “elemento” cambia con cada iteración del bucle, pasando por cada valor del vector.El vector puede ser de valores de caracteres, nombres de columnas, o quizás una secuencia de números - estos son los valores que cambiarán con cada iteración. Puedes utilizarlos dentro de las operaciones del bucle utilizando el término “item”.Ejemplo: secuencia de valores de caracteresEn este ejemplo, se realiza un bucle para cada valor de un vector de caracteres predefinido de nombres de hospitales.Hemos elegido el término hosp para representar los valores del vector nombres_de_hospital. Para la primera iteración del bucle, el valor de hosp será hospital_names[1]]. Para la segunda iteración del bucle será hospital_names[2]]. Y así sucesivamente…Ejemplo: secuencia de nombres de columnasSe trata de una variación de la secuencia de caracteres anterior, en la que se extraen los nombres de un objeto R existente y se convierten en el vector. Por ejemplo, los nombres de las columnas de un dataframe. Convenientemente, en el código de operaciones del bucle , los nombres de las columnas se pueden utilizar para indexar (subconjuntar) tu dataframe originalA continuación, la secuencia son los names() (nombres de columnas) del dataframe linelist. El nombre de nuestro “elemento” es col, que representará el nombre de cada columna medida que avanzan los bucles.modo de ejemplo, incluimos código de operaciones dentro del bucle , que se ejecuta para cada valor de la secuencia. En este código, los valores de la secuencia (nombres de las columnas) se utilizan para indexar (subconjuntar) linelist, una por una. Como se enseñó en la página de fundamentos de R, se utilizan dobles ramificaciones [[ ]] para el subconjunto. La columna resultante se pasa .na(), y luego sum() para producir el número de valores de la columna que faltan. El resultado se imprime en la consola: un número por cada columna.Una nota sobre la indexación con los nombres de las columnas - ¡cuando se refiera la propia columna ¡escribas simplemente “col”! ya que representa sólo el nombre de la columna de caracteres! Para referirse la columna completa debe utilizar el nombre de la columna como un índice en linelist través de linelist[[col]].Secuencia de númerosEn este enfoque, la secuencia es una serie de números consecutivos. Por lo tanto, el valor del “ítem” es un valor de carácter (por ejemplo, “Hospital Central” o “fecha_de_inicio”), sino que es un número. Esto es útil para hacer un bucle través de los dataframes, ya que puedeS utilizar el número del “ítem” dentro del bucle para indexar el dataframe por número de fila.Por ejemplo, digamos que quiereS recorrer cada fila de tu dataframe y extraer cierta información. Sus “elementos” serían números de fila numéricos. menudo, los “elementos” en este caso se escriben como .El proceso del bucle podría explicarse en palabras como “para cada elemento de una secuencia de números desde 1 hasta el número total de filas de mi dataframe, haz X”. Para la primera iteración del bucle, el valor del “elemento” sería 1. Para la segunda iteración, sería 2, etc.Aquí está el aspecto de la secuencia en código: (1:nrow(linelist)) {CODIGO DE OPERACIONES} donde representa el “elemento” y 1:nrow(linelist) produce una secuencia de números consecutivos desde 1 hasta el número de filas en linelist.Si quieres que la secuencia sea numérica, pero partes de un vector (de un dataframe), utiliza el atajo seq_along() para devolver una secuencia de números para cada elemento del vector. Por ejemplo, (en seq_along(nombres_de_hospital) {Código_de_operaciones}.El código siguiente devuelve en realidad números, que se convertirían en el valor deien tu respectivo bucle.Una ventaja de usar números en la secuencia es que es fácil usar también el númeroipara indexar un contenedor que almacene las salidas del bucle. Hay un ejemplo de esto en la sección de Operaciones más abajo.","code":"\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\nhospital_names # print## [1] \"Other\"                                \"Missing\"                             \n## [3] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [5] \"Military Hospital\"                    \"Central Hospital\"\n# a 'for loop' with character sequence\n\nfor (hosp in hospital_names){       # sequence\n  \n       # OPERATIONS HERE\n  }\nfor (col in names(linelist)){        # loop runs for each column in linelist; column name represented by \"col\" \n  \n  # Example operations code - print number of missing values in column\n  print(sum(is.na(linelist[[col]])))  # linelist is indexed by current value of \"col\"\n     \n}## [1] 0\n## [1] 0\n## [1] 2087\n## [1] 256\n## [1] 0\n## [1] 936\n## [1] 1323\n## [1] 278\n## [1] 86\n## [1] 0\n## [1] 86\n## [1] 86\n## [1] 86\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 2088\n## [1] 2088\n## [1] 0\n## [1] 0\n## [1] 0\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 249\n## [1] 149\n## [1] 765\n## [1] 0\n## [1] 256\nfor (i in 1:nrow(linelist)) {  # use on a data frame\n  # OPERATIONS HERE\n}  \nseq_along(hospital_names)  # use on a named vector## [1] 1 2 3 4 5 6"},{"path":"iteration-loops-and-lists.html","id":"operaciones","chapter":"16 Iteración, bucles y listas","heading":"Operaciones","text":"Este es el código dentro de las llaves { } del bucle . Quieres que este código se ejecute para cada “elemento” de la secuencia. Por lo tanto, ¡ten cuidado de que cada parte de tu código que cambia por el “ítem” esté correctamente codificado de manera que realmente cambie! Por ejemplo, recuerda usar [[ ]] para la indexación.En el ejemplo siguiente, iteramos por cada fila de linelist. Los valores de género y edad de cada fila se pegan juntos y se almacenan en el vector de caracteres contenedor cases_demographics. Observa cómo también utilizamos la indexación [[]] para guardar la salida del bucle en la posición correcta en el vector “contenedor”.","code":"\n# create container to store results - a character vector\ncases_demographics <- vector(mode = \"character\", length = nrow(linelist))\n\n# the for loop\nfor (i in 1:nrow(linelist)){\n  \n  # OPERATIONS\n  # extract values from linelist for row i, using brackets for indexing\n  row_gender  <- linelist$gender[[i]]\n  row_age     <- linelist$age_years[[i]]    # don't forget to index!\n     \n  # combine gender-age and store in container vector at indexed location\n  cases_demographics[[i]] <- str_c(row_gender, row_age, sep = \",\") \n\n}  # end for loop\n\n\n# display first 10 rows of container\nhead(cases_demographics, 10)##  [1] \"m,2\"  \"f,3\"  \"m,56\" \"f,18\" \"m,3\"  \"f,16\" \"f,16\" \"f,0\"  \"m,61\" \"f,27\""},{"path":"iteration-loops-and-lists.html","id":"contenedor","chapter":"16 Iteración, bucles y listas","heading":"Contenedor","text":"veces los resultados de tu bucle se imprimirán en la consola o en el panel de gráficos de RStudio. Otras veces, querrás almacenar los resultados en un “contenedor” para su uso posterior. Dicho contenedor puede ser un vector, un dataframe o incluso una lista.Lo más eficiente es crear el contenedor de los resultados antes de comenzar el bucle . En la práctica, esto significa crear un vector vacío, un dataframe o una lista. Estos pueden ser creados con las funciones vector() para vectores o listas, o con matrix() y data.frame() para un dataframe.Vector vacíoUtiliza vector() y especifica el mode = en función del tipo esperado de objetos que vas insertar - ya sea “double” (para contener números), “carácter” o “lógico”. También debes establecer la length = (longitud) por adelantado. Esta debe ser la longitud de tu secuencia de bucle .Digamos que quieres almacenar la mediana de la demora hasta el ingreso para cada hospital. Utilizarís “double” y establecerías que la longitud fuera el número de salidas esperadas (el número de hospitales únicos en el set de datos).Dataframe vacíoPuedes hacer un dataframe vacío especificando el número de filas y columnas de esta manera:Lista vacíaEs posible que desees almacenar algunos gráficos creados por un bucle en una lista. Una lista es como un vector, pero contiene otros objetos R dentro de ella que pueden ser de diferente tipo. Los elementos de una lista pueden ser un solo número, un dataframe, un vector e incluso otra lista.En realidad, se inicializa una lista vacía utilizando el mismo comando vector() que el anterior, pero con mode = \"list\". Especifica la longitud como quieras.","code":"\ndelays <- vector(\n  mode = \"double\",                            # we expect to store numbers\n  length = length(unique(linelist$hospital))) # the number of unique hospitals in the dataset\ndelays <- data.frame(matrix(ncol = 2, nrow = 3))\nplots <- vector(mode = \"list\", length = 16)"},{"path":"iteration-loops-and-lists.html","id":"impresión","chapter":"16 Iteración, bucles y listas","heading":"Impresión","text":"Ten en cuenta que para imprimir desde dentro de un bucle probablemente tendrás que envolver explícitamente con la función print().\nEn este ejemplo, la secuencia es un vector de caracteres explícito, que se utiliza para subsumir linelist en un hospital. Los resultados se almacenan en un contenedor, sino que se imprimen en la consola con la función print().###Probar tu bucle {.unnumbered}Para probar tu bucle, puedes ejecutar un comando para hacer una asignación temporal del “elemento”, como <- 10 o hosp <- \"Central Hospital \". Haz esto fuera del bucle y luego ejecuta tu código de operaciones solamente (el código dentro de las llaves) para ver si se producen los resultados esperados.","code":"\nfor (hosp in hospital_names){ \n     hospital_cases <- linelist %>% filter(hospital == hosp)\n     print(nrow(hospital_cases))\n}## [1] 885\n## [1] 1469\n## [1] 422\n## [1] 1762\n## [1] 896\n## [1] 454"},{"path":"iteration-loops-and-lists.html","id":"bucles-con-gráficos","chapter":"16 Iteración, bucles y listas","heading":"Bucles con gráficos","text":"Para reunir los tres componentes (contenedor, secuencia y operaciones) vamos intentar trazar una epicurva para cada hospital (véase la página sobre curvas epidémicas).Podemos hacer una bonita epicurva de todos los casos por género utilizando el paquete incidence2 como se indica continuación:Para producir un gráfico separado para cada caso del hospital, podemos poner este código de epicurva dentro de un bucle .En primer lugar, guardamos un vector con los nombres únicos de los hospitales, hospital_names. El bucle se ejecutará una vez para cada uno de estos nombres: (hosp hospital_names). En cada iteración del bucle , el nombre actual del hospital del vector se representará como hosp para tu uso dentro del bucle.Dentro de las operaciones del bucle, puedes escribir el código R de forma normal, pero utilizando el “elemento” (hosp en este caso) sabiendo que tu valor será cambiante. Dentro de este bucle:Se aplica un filter() linelist, de forma que la columna hospital debe ser igual al valor actual de hospEl objeto de incidencia se crea en linelist filtradasSe crea una gráfica del hospital actual, con un título autoajustable que utiliza hospEl gráfico del hospital actual se guarda temporalmente y luego se imprimeEl bucle sigue adelante para repetirse con el siguiente hospital de hospital_names","code":"\n# create 'incidence' object\noutbreak <- incidence2::incidence(   \n     x = linelist,                   # dataframe - complete linelist\n     date_index = date_onset,        # date column\n     interval = \"week\",              # aggregate counts weekly\n     groups = gender,                # group values by gender\n     na_as_group = TRUE)             # missing gender is own group\n\n# plot epi curve\nplot(outbreak,                       # name of incidence object\n     fill = \"gender\",                # color bars by gender\n     color = \"black\",                # outline color of bars\n     title = \"Outbreak of ALL cases\" # title\n     )\n# make vector of the hospital names\nhospital_names <- unique(linelist$hospital)\n\n# for each name (\"hosp\") in hospital_names, create and print the epi curve\nfor (hosp in hospital_names) {\n     \n     # create incidence object specific to the current hospital\n     outbreak_hosp <- incidence2::incidence(\n          x = linelist %>% filter(hospital == hosp),   # linelist is filtered to the current hospital\n          date_index = date_onset,\n          interval = \"week\", \n          groups = gender,\n          na_as_group = TRUE\n     )\n     \n     # Create and save the plot. Title automatically adjusts to the current hospital\n     plot_hosp <- plot(\n       outbreak_hosp,\n       fill = \"gender\",\n       color = \"black\",\n       title = stringr::str_glue(\"Epidemic of cases admitted to {hosp}\")\n     )\n     \n     # print the plot for the current hospital\n     print(plot_hosp)\n     \n} # end the for loop when it has been run for every hospital in hospital_names "},{"path":"iteration-loops-and-lists.html","id":"seguimiento-del-progreso-de-un-bucle","chapter":"16 Iteración, bucles y listas","heading":"Seguimiento del progreso de un bucle","text":"Un bucle con muchas iteraciones puede funcionar durante muchos minutos o incluso horas. Por lo tanto, puede ser útil imprimir el progreso en la consola de R. La sentencia de abajo puede colocarse dentro de las operaciones del bucle para imprimir cada 100 números. Sólo tiene que ajustarla para que sea el “elemento” de tu bucle.","code":"# loop with code to print progress every 100 iterations\nfor (i in seq_len(nrow(linelist))){\n\n  # print progress\n  if(i %% 100==0){    # The %% operator is the remainder\n    print(i)\n\n}"},{"path":"iteration-loops-and-lists.html","id":"iter_purrr","chapter":"16 Iteración, bucles y listas","heading":"16.3 purrr y listas","text":"Otro enfoque de las operaciones iterativas es el paquete purrr - es el enfoque tidyverse de la iteración.Si tienes que realizar la misma tarea varias veces, probablemente merezca la pena crear una solución generalizada que puedas utilizar en muchas entradas. Por ejemplo, producir gráficos para múltiples jurisdicciones, o importar y combinar muchos archivos.También hay algunas otras ventajas de purrr - puedes usarlo con pipes %>%, que maneja los errores mejor que los bucles normales, ¡y la sintaxis es bastante limpia y simple! Si estás utilizando un bucle , probablemente puedas hacerlo de forma más clara y sucinta con purrr!Ten en cuenta que purrr es una herramienta de programación funcional. Es decir, las operaciones que se van aplicar de forma iterativa están envueltas en funciones. Consulta la página Escribir funciones para aprender escribir tus propias funciones.purrr también se basa casi por completo en listas y vectores, así que piensa en ello como si aplicaras una función cada elemento de esa lista/vector.","code":""},{"path":"iteration-loops-and-lists.html","id":"cargar-paquetes-8","chapter":"16 Iteración, bucles y listas","heading":"Cargar paquetes","text":"purrr forma parte de tidyverse, por lo que es necesario instalar/cargar un paquete aparte.","code":"\npacman::p_load(\n     rio,            # import/export\n     here,           # relative filepaths\n     tidyverse,      # data mgmt and viz\n     writexl,        # write Excel file with multiple sheets\n     readxl          # import Excel with multiple sheets\n)"},{"path":"iteration-loops-and-lists.html","id":"map","chapter":"16 Iteración, bucles y listas","heading":"map()","text":"Una de las funciones principales de purrr es map(), que “mapea” (aplica) una función cada elemento de entrada de una lista/vector que proporcionado.La sintaxis básica es map(.x = SECUENCIA, .f = FUNCIÓN, OTROS ARGUMENTOS). Con un poco más de detalle:.x = son las entradas sobre las que se aplicará iterativamente la función .f - por ejemplo, un vector de nombres de jurisdicciones, columnas de un dataframe o una lista de dataframes.f = es la función aplicar cada elemento de la entrada .x - puede ser una función como print() que ya existe, o una función personalizada que tu definas. La función se suele escribir después de una tilde ~ (detalles más abajo).Algunas notas más sobre la sintaxis:Si la función necesita especificar más argumentos, puede escribirse sin paréntesis y sin tilde (por ejemplo, .f = mean). Para proporcionar argumentos que tendrán el mismo valor en cada iteración, escríbelos dentro de map() pero fuera del argumento .f =, como por ejemplo na.rm = T en map(.x = mi_lista, .f = mean, na.rm=T).Puedes utilizar .x (o simplemente . ) dentro de la función .f = como marcador de posición para el valor .x de esa iteraciónUtiliza la sintaxis con tilde (~) para tener un mayor control sobre la función - escribe la función de forma normal con paréntesis, como por ejemplo: map(.x = mi_lista, .f = \\~mean(., na.rm = T)). Utiliza esta sintaxis sobre todo si el valor de un argumento va cambiar en cada iteración, o si es el propio valor .x (véanse los ejemplos siguientes)La salida al usar map() es una lista - una lista es un tipo de objeto como un vector pero cuyos elementos pueden ser de tipo diferente. Por lo tanto, una lista producida por map() podría contener muchos dataframes, o muchos vectores, muchos valores individuales, ¡o incluso muchas listas! Existen versiones alternativas de map() que se explican continuación y que producen otros tipos de salidas (por ejemplo, map_dfr() para producir un dataframe, map_chr() para producir vectores de caracteres y map_dbl() para producir vectores numéricos).","code":""},{"path":"iteration-loops-and-lists.html","id":"iter_combined","chapter":"16 Iteración, bucles y listas","heading":"Ejemplo: importar y combinar hojas de Excel","text":"Hagamos una demostración con una tarea epidemiológica común: - Quieres importar un libro de Excel con datos de casos, pero los datos están divididos en diferentes hojas en el libro. ¿Cómo puedes importar y combinar eficazmente las hojas en un dataframe?Supongamos que nos envían el siguiente libro de Excel. Cada hoja contiene casos de un determinado hospital.Este es un enfoque que utiliza map():map() la función import() para que se ejecute para cada hoja de ExcelCombinar los dataframes importados en uno solo utilizando bind_rows()lo largo del proceso, conserva el nombre original de la hoja para cada fila, almacenando esta información en una nueva columna en el dataframe finalEn primer lugar, tenemos que extraer los nombres de las hojas y guardarlos. Proporcionamos la ruta del archivo de Excel la función excel_sheets() del paquete readxl, que extrae los nombres de las hojas. Los almacenamos en un vector de caracteres llamado sheet_names.Aquí están los nombres:Ahora que tenemos este vector de nombres, map() puede proporcionarlos uno uno la función import(). En este ejemplo, los sheet_names son .x e import() es la función .f.Recuerda de la página de importación y exportación que cuando se utiliza en libros de Excel, import() puede aceptar el argumento = especificando la hoja importar. Dentro de la función .f en import(), proporcionamos = .x, cuyo valor cambiará con cada iteración través del vector `sheet_names - primero “Hospital Central”, luego “Military Hospital”, etc.Hay que tener en cuenta que, como hemos utilizado map(), los datos de cada hoja de Excel se guardarán como un dataframe separado dentro de una lista. Queremos que cada uno de estos elementos de la lista (dataframes) tenga un elemento names, así que antes de pasar sheet_names map() lo pasamos través de set_names() de purrr, lo que asegura que cada elemento de la lista obtenga el nombre apropiado.Guardamos la lista de salida como combined.Cuando inspeccionamos la salida, vemos que los datos de cada hoja de Excel se guardan en la lista con un nombre. Esto es bueno, pero hemos terminado.Por último, utilizamos la función bind_rows() (de dplyr) que acepta la lista de dataframes de estructura similar y los combina en un dataframe. Para crear una nueva columna partir de los nombres de los elementos de la lista, utilizamos el argumento .id =y le proporcionamos el nombre deseado para la nueva columna.continuación se muestra toda la secuencia de comandos:¡Y ahora tenemos un dataframe con una columna que contiene la hoja de origen!Hay variaciones de map() que debes conocer. Por ejemplo, map_dfr() devuelve un dataframe, una lista. Por lo tanto, podríamos haberla utilizado para la tarea anterior y haber tenido que enlazar filas. Pero entonces habríamos podido capturar de qué hoja (hospital) procedía cada caso.Otras variaciones son map_chr(), map_dbl(). Estas funciones son muy útiles por dos razones. En primer lugar, convierten automáticamente la salida de una función iterativa en un vector (en una lista). En segundo lugar, pueden controlar explícitamente el tipo en el que vuelven los datos - te aseguras de que tus datos vuelven como un vector de caracteres con map_chr(), o vector numérico con map_dbl(). Volveremos esto más adelante en la sección.Las funciones map_at() y map_if() también son muy útiles para la iteración - ¡permiten especificar en qué elementos de una lista se debe iterar! Funcionan simplemente aplicando un vector de índices/nombres (en el caso de map_at()) o una prueba lógica (en el caso de map_if()).Utilicemos un ejemplo en el que queremos leer la primera hoja de datos del hospital. Usamos map_at() en lugar de map(), y especificamos el argumento .= c(-1) que significa usar el primer elemento de .x. Alternativamente, puedes proporcionar un vector de números positivos, o nombres, .= para especificar qué elementos usar.Ten en cuenta que el nombre de la primera hoja seguirá apareciendo como un elemento de la lista de salida, pero es sólo un nombre de un solo carácter (un dataframe). Tendrás que eliminar este elemento antes de vincular las filas. Veremos cómo eliminar y modificar los elementos de la lista en una sección posterior.","code":"\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\nsheet_names## [1] \"Central Hospital\"              \"Military Hospital\"             \"Missing\"                      \n## [4] \"Other\"                         \"Port Hospital\"                 \"St. Mark's Maternity Hospital\"\ncombined <- sheet_names %>% \n  purrr::set_names() %>% \n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x))\nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")  # extract sheet names\n \ncombined <- sheet_names %>%                                     # begin with sheet names\n  purrr::set_names() %>%                                        # set their names\n  map(.f = ~import(\"hospital_linelists.xlsx\", which = .x)) %>%  # iterate, import, save in list\n  bind_rows(.id = \"origin_sheet\") # combine list of data frames, preserving origin in new column  \nsheet_names <- readxl::excel_sheets(\"hospital_linelists.xlsx\")\n\ncombined <- sheet_names %>% \n     purrr::set_names() %>% \n     # exclude the first sheet\n     map_at(.f = ~import( \"hospital_linelists.xlsx\", which = .x),\n            .at = c(-1))"},{"path":"iteration-loops-and-lists.html","id":"dividir-los-datos-y-exportar","chapter":"16 Iteración, bucles y listas","heading":"Dividir los datos y exportar","text":"continuación, damos un ejemplo de cómo dividir unos datos en partes y luego utilizar la iteración map() para exportar cada parte como una hoja de Excel separada, o como un archivo CSV separado.","code":""},{"path":"iteration-loops-and-lists.html","id":"dividir-los-datos","chapter":"16 Iteración, bucles y listas","heading":"Dividir los datos","text":"Digamos que tenemos una lista de casos de casos completa como un dataframe, y ahora queremos crear un listado separado para cada hospital y exportar cada una como un archivo CSV separado. continuación, hacemos los siguientes pasos:Utiliza group_split() (de dplyr) para dividir el dataframe del listado por valores únicos en la columna hospital. La salida es una lista que contiene un dataframe por cada subconjunto de un hospital.Podemos ejecutar View(linelist_split) y ver que esta lista contiene 6 dataframes (“tibbles”), cada uno de los cuales representa los casos de un hospital.Sin embargo, ten en cuenta que los dataframes de la lista tienen nombres por defecto. Queremos que cada uno de ellos tenga un nombre, y luego utilizar ese nombre al guardar el archivo CSV.Un enfoque para extraer los nombres es utilizar pull() (de dplyr) para extraer la columna hospital de cada dataframe de la lista. Luego, para estar seguros, convertimos los valores caracteres y luego usamos unique() para obtener el nombre de ese dataframe en particular. Todos estos pasos se aplican cada dataframe mediante map().Ahora podemos ver que cada uno de los elementos de la lista tiene un nombre. Se puede acceder estos nombres mediante names(linelist_split).","code":"\nlinelist_split <- linelist %>% \n     group_split(hospital)\nnames(linelist_split) <- linelist_split %>%   # Assign to names of listed data frames \n     # Extract the names by doing the following to each data frame: \n     map(.f = ~pull(.x, hospital)) %>%        # Pull out hospital column\n     map(.f = ~as.character(.x)) %>%          # Convert to character, just in case\n     map(.f = ~unique(.x))                    # Take the unique hospital name\nnames(linelist_split)## [1] \"Central Hospital\"                     \"Military Hospital\"                   \n## [3] \"Missing\"                              \"Other\"                               \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\""},{"path":"iteration-loops-and-lists.html","id":"más-de-una-columna-group_split","chapter":"16 Iteración, bucles y listas","heading":"Más de una columna group_split()","text":"Si deseas dividir linelist por más de una columna de agrupación, por ejemplo, para producir un listado de subconjuntos por la intersección de hospital Y género, necesitarás un enfoque diferente para nombrar los elementos de la lista. Esto implica recoger las “claves de grupo” únicas utilizando group_keys() de dplyr - se devuelven como un dataframe. Luego puedes combinar las claves de grupo en valores con unite() como se muestra continuación, y asignar estos nombres conglomerados linelist_split.Ahora combinamos las agrupaciones juntas, separadas por guiones, y las asignamos como los nombres de los elementos de la lista en linelist_split. Esto requiere algunas líneas adicionales, ya que sustituimos NA por “Missing”, utilizamos unite() de dplyr para combinar los valores de las columnas juntos (separados por guiones), y luego los convertimos en un vector sin nombre para poder utilizarlos como nombres de linelist_split.","code":"\n# split linelist by unique hospital-gender combinations\nlinelist_split <- linelist %>% \n     group_split(hospital, gender)\n\n# extract group_keys() as a dataframe\ngroupings <- linelist %>% \n     group_by(hospital, gender) %>%       \n     group_keys()\n\ngroupings      # show unique groupings ## # A tibble: 18 × 2\n##    hospital                             gender\n##    <chr>                                <chr> \n##  1 Central Hospital                     f     \n##  2 Central Hospital                     m     \n##  3 Central Hospital                     <NA>  \n##  4 Military Hospital                    f     \n##  5 Military Hospital                    m     \n##  6 Military Hospital                    <NA>  \n##  7 Missing                              f     \n##  8 Missing                              m     \n##  9 Missing                              <NA>  \n## 10 Other                                f     \n## 11 Other                                m     \n## 12 Other                                <NA>  \n## 13 Port Hospital                        f     \n## 14 Port Hospital                        m     \n## 15 Port Hospital                        <NA>  \n## 16 St. Mark's Maternity Hospital (SMMH) f     \n## 17 St. Mark's Maternity Hospital (SMMH) m     \n## 18 St. Mark's Maternity Hospital (SMMH) <NA>\n# Combine into one name value \nnames(linelist_split) <- groupings %>% \n     mutate(across(everything(), replace_na, \"Missing\")) %>%  # replace NA with \"Missing\" in all columns\n     unite(\"combined\", sep = \"-\") %>%                         # Unite all column values into one\n     setNames(NULL) %>% \n     as_vector() %>% \n     as.list()"},{"path":"iteration-loops-and-lists.html","id":"exportar-como-hojas-de-excel","chapter":"16 Iteración, bucles y listas","heading":"Exportar como hojas de Excel","text":"Para exportar los listados del hospital como un libro de Excel con un listado por hoja, podemos simplemente proporcionar la lista con nombre linelist_split la función write_xlsx() del paquete writexl. Esto tiene la capacidad de guardar un libro de Excel con múltiples hojas. Los nombres de los elementos de la lista se aplican automáticamente como los nombres de las hojas.Ahora puedes abrir el archivo de Excel y ver que cada hospital tiene tu propia hoja.","code":"\nlinelist_split %>% \n     writexl::write_xlsx(path = here(\"data\", \"hospital_linelists.xlsx\"))"},{"path":"iteration-loops-and-lists.html","id":"exportar-como-archivos-csv","chapter":"16 Iteración, bucles y listas","heading":"Exportar como archivos CSV","text":"Es un comando un poco más complejo, pero también puedes exportar cada listado por hospital como un archivo CSV separado, con un nombre de archivo específico para el hospital.De nuevo utilizamos map(): tomamos el vector de nombres de elementos de la lista (mostrado arriba) y utilizamos map() para iterar través de ellos, aplicando export() (del paquete rio, véase la página Importar y exportar) en el dataframe de lista linelist_split que tiene ese nombre. También utilizamos el nombre para crear un nombre de archivo único. Así es como funciona:Comenzamos con el vector de nombres de caracteres, pasado map() como .xLa función .f es export(), que requiere un dataframe y una ruta de archivo para escribirloLa entrada .x (el nombre del hospital) se utiliza dentro de .f para extraer/indexar ese elemento específico de la lista linelist_split. Esto hace que sólo se proporcione un dataframe la vez export().Por ejemplo, cuando map() itera por “Military Hospital”, entonces linelist_split[.x]] es en realidad linelist_split[[\"Military Hospital\"]], devolviendo así el segundo elemento de linelist_split - que son todos los casos del Military Hospital.La ruta del archivo proporcionada export() es dinámica mediante el uso de str_glue() (ver página de caracteres y cadenas):() se utiliza para obtener la base de la ruta del archivo y especificar la carpeta “data” (nótese las comillas simples para interrumpir las comillas dobles de str_glue())continuación, una barra /, y luego de nuevo el .x que imprime el nombre actual del hospital para que el archivo sea identificablePor último, la extensión “.csv” que export() utiliza para crear un archivo CSV¡Ahora puedes ver que cada archivo se guarda en la carpeta “data” del proyecto R “Epi_R_handbook”.”!","code":"\nnames(linelist_split) %>%\n     map(.f = ~export(linelist_split[[.x]], file = str_glue(\"{here('data')}/{.x}.csv\")))"},{"path":"iteration-loops-and-lists.html","id":"funciones-personalizadas","chapter":"16 Iteración, bucles y listas","heading":"Funciones personalizadas","text":"Puedes crear tu propia función para proporcionar map().Digamos que queremos crear curvas epidémicas para los casos de cada hospital. Para hacer esto usando purrr, nuestra función .f puede ser ggplot() y las extensiones con + como de costumbre. Como la salida de map() es siempre una lista, los gráficos se almacenan en una lista. Como son gráficos, pueden ser extraídas y trazadas con la función ggarrange() del paquete ggpubr (documentación).Si este código de map() parece demasiado desordenado, se puede conseguir el mismo resultado guardando el comando específico de ggplot() como una función personalizada definida por el usuario, por ejemplo podemos llamarla make_epicurve()). Esta función se utiliza entonces dentro de la función map(). .x se sustituirá iterativamente por el nombre del hospital, y se utilizará como hosp_name en la función make_epicurve(). Véase la página sobre Escribir funciones.","code":"\n# load package for plotting elements from list\npacman::p_load(ggpubr)\n\n# map across the vector of 6 hospital \"names\" (created earlier)\n# use the ggplot function specified\n# output is a list with 6 ggplots\n\nhospital_names <- unique(linelist$hospital)\n\nmy_plots <- map(\n  .x = hospital_names,\n  .f = ~ggplot(data = linelist %>% filter(hospital == .x)) +\n                geom_histogram(aes(x = date_onset)) +\n                labs(title = .x)\n)\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)\n# Create function\nmake_epicurve <- function(hosp_name){\n  \n  ggplot(data = linelist %>% filter(hospital == hosp_name)) +\n    geom_histogram(aes(x = date_onset)) +\n    theme_classic()+\n    labs(title = hosp_name)\n  \n}\n# mapping\nmy_plots <- map(hospital_names, ~make_epicurve(hosp_name = .x))\n\n# print the ggplots (they are stored in a list)\nggarrange(plotlist = my_plots, ncol = 2, nrow = 3)"},{"path":"iteration-loops-and-lists.html","id":"mapear-una-función-a-través-de-las-columnas","chapter":"16 Iteración, bucles y listas","heading":"Mapear una función a través de las columnas","text":"Otro caso de uso común es asignar una función varias columnas. continuación, map() la función t.test() través de columnas numéricas del dataframe linelist, comparando los valores numéricos por género.Recuerda de la página sobre Test estadísticos simples que t.test() puede tomar entradas en un formato de fórmula, como t.test(columna numérica ~ columna binaria). En este ejemplo, hacemos lo siguiente:Las columnas numéricas de interés se seleccionan del listado - éstas se convierten en las entradas .x de map()La función t.test() se suministra como la función .f, que se aplica cada columna numéricaDentro del paréntesis de t.test():\nel primer ~ precede al .f que map() iterará sobre el .x\nel .x representa la columna actual que se suministra la función t.test()\nel segundo ~ es parte de la ecuación del test-t descrita anteriormente\nla función t.test() espera una columna binaria en el lado derecho de la ecuación. Suministramos el vector linelist$gender de forma independiente y estática (Ten en cuenta que se incluye en select()).\nel primer ~ precede al .f que map() iterará sobre el .xel .x representa la columna actual que se suministra la función t.test()el segundo ~ es parte de la ecuación del test-t descrita anteriormentela función t.test() espera una columna binaria en el lado derecho de la ecuación. Suministramos el vector linelist$gender de forma independiente y estática (Ten en cuenta que se incluye en select()).map() devuelve una lista, por lo que la salida es una lista de resultados del test-t, un elemento de la lista por cada columna numérica analizada.Este es el aspecto de la lista t.test_results cuando se abre (view) en RStudio. Hemos resaltado las partes que son importantes para los ejemplos de esta página.Puedes ver en la parte superior que toda la lista se llama t.test_results y tiene cinco elementos. Esos cinco elementos se denominan age, wt_km, ht_cm, ct_blood, temp después de cada variable que se utilizó en una prueba t con el gender de linelist.Cada uno de esos cinco elementos son su vez listas, con elementos dentro de ellas como p.value y conf.int. Algunos de estos elementos, como p.value, son números individuales, mientras que otros, como conf.int, constan de dos o más elementos (mean group f y mean group m).Nota: Recuerda que si deseas aplicar una función sólo determinadas columnas de un dataframe, puedes utilizar simplemente mutate() y across(), como se explica en la página Limpieza de datos y funciones básicas. continuación se muestra un ejemplo de aplicación de .character() sólo las columnas “age”. Observa la colocación de los paréntesis y las comas.","code":"\n# Results are saved as a list\nt.test_results <- linelist %>% \n  select(age, wt_kg, ht_cm, ct_blood, temp) %>%  # keep only some numeric columns to map across\n  map(.f = ~t.test(.x ~ linelist$gender))        # t.test function, with equation NUMERIC ~ CATEGORICAL\n# convert columns with column name containing \"age\" to class Character\nlinelist <- linelist %>% \n  mutate(across(.cols = contains(\"age\"), .fns = as.character))  "},{"path":"iteration-loops-and-lists.html","id":"extraer-de-las-listas","chapter":"16 Iteración, bucles y listas","heading":"Extraer de las listas","text":"Como map() produce una salida del tipo List, dedicaremos algún tiempo discutir cómo extraer datos de las listas utilizando las funciones purrr que las acompañan. Para mostrar esto, utilizaremos la lista t.test_results de la sección anterior. Esta es una lista de 5 listas - cada una de las 5 listas contiene los resultados de una prueba t entre una columna del dataframe linelist y su columna binaria gender. Consulta la imagen de la sección anterior para ver la estructura de la lista.","code":""},{"path":"iteration-loops-and-lists.html","id":"nombres-de-elementos","chapter":"16 Iteración, bucles y listas","heading":"Nombres de elementos","text":"Para extraer los nombres de los elementos en sí, basta con utilizar names() de R base. En este caso, utilizamos names() en t.test_results para devolver los nombres de cada sublista, que son los nombres de las 5 variables las que se les realizaron test-t.","code":"\nnames(t.test_results)## [1] \"age\"      \"wt_kg\"    \"ht_cm\"    \"ct_blood\" \"temp\""},{"path":"iteration-loops-and-lists.html","id":"elementos-por-nombre-o-posición","chapter":"16 Iteración, bucles y listas","heading":"Elementos por nombre o posición","text":"Para extraer los elementos de la lista por su nombre o su posición se pueden utilizar paréntesis [[ ]] como se describe en la página de fundamentos de R. continuación, utilizamos corchetes dobles para indexar la lista t.test_results y mostrar el primer elemento, que son los resultados del test-t sobre age.Sin embargo, continuación mostraremos el uso de las sencillas y flexibles funciones de purrr map() y pluck() para lograr los mismos resultados.","code":"\nt.test_results[[1]] # first element by position## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results[[1]][\"p.value\"] # return element named \"p.value\" from first element  ## $p.value\n## [1] 2.350374e-96"},{"path":"iteration-loops-and-lists.html","id":"pluck","chapter":"16 Iteración, bucles y listas","heading":"pluck()","text":"pluck() extrae elementos por nombre o por posición. Por ejemplo, para extraer los resultados del test-t para la edad, puedes utilizar pluck() así:Indexa niveles más profundos especificando los niveles adicionales con comas. continuación se extrae el elemento denominado “p.value” de la lista age dentro de la lista t.test_results. También puedes utilizar números en lugar de nombres de caracteres.Puedes extraer estos elementos internos de todos los elementos de primer nivel utilizando map() para ejecutar la función pluck() en cada elemento de primer nivel. Por ejemplo, el siguiente código extrae los elementos “p.value” de todas las listas dentro de t.test_results. La lista de resultados del test-t es el .x que se itera, pluck() es la función .f que se itera, y el valor “p-value” se proporciona la función.Como otra alternativa, map() ofrece una forma abreviada en la que puedes escribir el nombre del elemento entre comillas, y lo extraerá. Si utilizas map() la salida será una lista, mientras que si utilizas map_chr() será un vector de caracteres con nombre y si utilizas map_dbl() será un vector numérico con nombre.Puedes leer más sobre pluck() en la documentación purrr. Tiene una función hermana chuck() que devolverá un error en lugar de NULL si existe un elemento.","code":"\nt.test_results %>% \n  pluck(\"age\")        # alternatively, use pluck(1)## \n##  Welch Two Sample t-test\n## \n## data:  .x by linelist$gender\n## t = -21.3, df = 4902.9, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.544409 -6.272675\n## sample estimates:\n## mean in group f mean in group m \n##        12.66085        19.56939\nt.test_results %>% \n  pluck(\"age\", \"p.value\")## [1] 2.350374e-96\nt.test_results %>%\n  map(pluck, \"p.value\")   # return every p-value## $age\n## [1] 2.350374e-96\n## \n## $wt_kg\n## [1] 2.664367e-182\n## \n## $ht_cm\n## [1] 3.515713e-144\n## \n## $ct_blood\n## [1] 0.4473498\n## \n## $temp\n## [1] 0.5735923\nt.test_results %>% \n  map_dbl(\"p.value\")   # return p-values as a named numeric vector##           age         wt_kg         ht_cm      ct_blood          temp \n##  2.350374e-96 2.664367e-182 3.515713e-144  4.473498e-01  5.735923e-01"},{"path":"iteration-loops-and-lists.html","id":"convertir-una-lista-en-un-dataframe","chapter":"16 Iteración, bucles y listas","heading":"Convertir una lista en un dataframe","text":"Este es un tema complejo - Mira la sección de Recursos para tutoriales más completos. Sin embargo, vamos mostrar la conversión de la lista de resultados del test-t en un dataframe. Crearemos un dataframe con columnas para la variable, su valor-p y las medias de los dos grupos (hombres y mujeres).Estos son algunos de los nuevos enfoques y funciones que se utilizarán:La función tibble() se utilizará para crear un tibble (como un dataframe)\nRodeamos la función tibble() con corchetes { } para evitar que todo el t.test_results se almacene como la primera columna tibble\nRodeamos la función tibble() con corchetes { } para evitar que todo el t.test_results se almacene como la primera columna tibbleDentro de tibble(), cada columna se crea explícitamente, de forma similar la sintaxis de mutate():\nEl . representa t.test_results\nPara crear una columna con los nombres de las variables del test-t (los nombres de cada elemento de la lista) utilizamos names() como se ha descrito anteriormente\nPara crear una columna con los valores p utilizamos map_dbl() como se ha descrito anteriormente para extraer los elementos p.value y convertirlos en un vector numérico\nEl . representa t.test_resultsPara crear una columna con los nombres de las variables del test-t (los nombres de cada elemento de la lista) utilizamos names() como se ha descrito anteriormentePara crear una columna con los valores p utilizamos map_dbl() como se ha descrito anteriormente para extraer los elementos p.value y convertirlos en un vector numéricoPero ahora vamos añadir columnas que contengan las medias de cada grupo (hombres y mujeres).Tendríamos que extraer el elemento estimate, pero éste contiene en realidad dos elementos en su interior (media en el grupo f y media en el grupo m). Por lo tanto, se puede simplificar en un vector con map_chr() o map_dbl(). En su lugar, utilizamos map(), que usado dentro de tibble() creará una columna de tipo lista dentro del tibble! ¡Sí, esto es posible!Una vez que tengas esta columna de lista, hay varias funciones de tidyr (parte de tidyverse) que te ayudan “rectangular” o “desanidar” estas columnas de “lista anidada”. Lee más sobre ellas aquí, o ejecutando vignette(\"rectangle\"). En resumen:unnest_wider() - da cada elemento de una lista-columna tu propia columnaunnest_longer() - da cada elemento de una lista-columna tu propia filahoist() - actúa como unnest_wider() pero se especifica qué elementos se van anularA continuación, pasamos el tibble unnest_wider() especificando la columna means del tibble (que es una lista anidada). El resultado es que means se sustituyen por dos nuevas columnas, cada una de las cuales refleja los dos elementos que había antes en cada celda means.","code":"\nt.test_results %>% {\n  tibble(\n    variables = names(.),\n    p         = map_dbl(., \"p.value\"))\n  }## # A tibble: 5 × 2\n##   variables         p\n##   <chr>         <dbl>\n## 1 age       2.35e- 96\n## 2 wt_kg     2.66e-182\n## 3 ht_cm     3.52e-144\n## 4 ct_blood  4.47e-  1\n## 5 temp      5.74e-  1\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\"))}## # A tibble: 5 × 3\n##   variables         p means       \n##   <chr>         <dbl> <named list>\n## 1 age       2.35e- 96 <dbl [2]>   \n## 2 wt_kg     2.66e-182 <dbl [2]>   \n## 3 ht_cm     3.52e-144 <dbl [2]>   \n## 4 ct_blood  4.47e-  1 <dbl [2]>   \n## 5 temp      5.74e-  1 <dbl [2]>\nt.test_results %>% \n  {tibble(\n    variables = names(.),\n    p = map_dbl(., \"p.value\"),\n    means = map(., \"estimate\")\n    )} %>% \n  unnest_wider(means)## # A tibble: 5 × 4\n##   variables         p `mean in group f` `mean in group m`\n##   <chr>         <dbl>             <dbl>             <dbl>\n## 1 age       2.35e- 96              12.7              19.6\n## 2 wt_kg     2.66e-182              45.8              59.6\n## 3 ht_cm     3.52e-144             109.              142. \n## 4 ct_blood  4.47e-  1              21.2              21.2\n## 5 temp      5.74e-  1              38.6              38.6"},{"path":"iteration-loops-and-lists.html","id":"descartar-conservar-y-compactar-listas","chapter":"16 Iteración, bucles y listas","heading":"Descartar, conservar y compactar listas","text":"Dado que el trabajo con purrr implica menudo listas, exploraremos brevemente algunas funciones de purrr para modificar listas. Consulta la sección de Recursos para ver tutoriales más completos sobre las funciones de purrr.list_modify() tiene muchos usos, uno de los cuales puede ser eliminar un elemento de la listakeep() conserva los elementos especificados .p =, o cuando una función suministrada .p = evalúa TRUEdiscard() elimina los elementos especificados .p, o cuando una función suministrada .p = evalúa TRUEcompact() elimina todos los elementos vacíosAquí hay algunos ejemplos que utilizan la lista combined creada en la sección anterior sobre el uso de map() para importar y combinar múltiples archivos (contiene 6 dataframes de listas de casos):Los elementos pueden ser eliminados por su nombre con list_modify() y estableciendo el nombre igual NULL.También puedes eliminar elementos por criterio, proporcionando una ecuación “predicada” .p = (una ecuación que evalúa TRUE o FALSE). Coloca una tilde ~ antes de la función y utiliza .x para representar el elemento de la lista. Utilizando keep() se conservarán los elementos de la lista que se evalúen como TRUE. la inversa, si se utiliza discard() se eliminarán los elementos de la lista que se evalúen como TRUE.En el siguiente ejemplo, los elementos de la lista se descartan si tu tipo son dataframes.Su función de predicado también puede hacer referencia elementos/columnas dentro de cada elemento de la lista. Por ejemplo, continuación, se descartan los elementos de la lista cuya media de la columna ct_blood sea superior 25.Este comando eliminaría todos los elementos vacíos de la lista:","code":"\ncombined %>% \n  list_modify(\"Central Hospital\" = NULL)   # remove list element by name\n# keep only list elements with more than 500 rows\ncombined %>% \n  keep(.p = ~nrow(.x) > 500)  \n# Discard list elements that are not data frames\ncombined %>% \n  discard(.p = ~class(.x) != \"data.frame\")\n# keep only list elements where ct_blood column mean is over 25\ncombined %>% \n  discard(.p = ~mean(.x$ct_blood) > 25)  \n# Remove all empty list elements\ncombined %>% \n  compact()"},{"path":"iteration-loops-and-lists.html","id":"pmap","chapter":"16 Iteración, bucles y listas","heading":"pmap()","text":"ESTA SECCIÓN ESTÁ EN CONSTRUCCIÓN","code":""},{"path":"iteration-loops-and-lists.html","id":"apply-functions","chapter":"16 Iteración, bucles y listas","heading":"16.4 Funciones Apply","text":"La familia de funciones “apply” es una alternativa de R base purrr para operaciones iterativas. Puedes leer más sobre ellas aquí.","code":""},{"path":"iteration-loops-and-lists.html","id":"resources-8","chapter":"16 Iteración, bucles y listas","heading":"16.5 Recursos","text":"Bucles en Data CarpentryLa página de R Data Science en español sobre la iteraciónViñeta sobre escritura/lectura de archivos ExcelUn tutorial de purrr por jennybcOtro tutorial de purrr por Rebecca BarterUn tutorial de purrr sobre map, pmap e imaphoja de trucos -cheatsheet- de purrrconsejos y trucos de purrr\nguardar y descartar","code":""},{"path":"descriptive-tables.html","id":"descriptive-tables","chapter":"17 Tablas descriptivas","heading":"17 Tablas descriptivas","text":"Esta página muestra el uso de janitor, dplyr, gtsummary, rstatix y R base para resumir datos y crear tablas con estadísticas descriptivas.En esta página se explica cómo crear* las tablas subyacentes, mientras que en la página Tablas para presentaciones se explica cómo darles un buen formato e imprimirlas.*Cada uno de estos paquetes tiene ventajas y desventajas en cuanto la simplicidad del código, la accesibilidad de los resultados y la calidad de los resultados impresos. Utiliza esta página para decidir qué enfoque se ajusta tu situación.Tienes varias opciones para producir tablas de resumen de tabulación y tabulación cruzada. Algunos de los factores tener en cuenta son la simplicidad del código, la posibilidad de personalización, la salida deseada (impresa en la consola de R, como dataframe, o como una imagen .png/.jpeg/.html “bonita”), y la facilidad de posprocesamiento. Ten en cuenta los siguientes puntos la hora de elegir la herramienta para tu situación.Utiliza tabyl() de janitor para producir y “adornar” tabulaciones y tabulaciones cruzadasUtiliza get_summary_stats() de rstatix para generar fácilmente dataframes de estadísticas de resumen numérico para múltiples columnas y/o gruposUtiliza summarise() y count() de dplyr para obtener estadísticas más complejas, ordenar las salidas de los dataframes o preparar los datos para ggplot()Utiliza tbl_summary() de gtsummary para producir tablas detalladas listas para su publicaciónUtiliza table() de R base si tienes acceso los paquetes anteriores","code":""},{"path":"descriptive-tables.html","id":"preparation-8","chapter":"17 Tablas descriptivas","heading":"17.1 Preparación","text":"","code":""},{"path":"descriptive-tables.html","id":"cargar-paquetes-9","chapter":"17 Tablas descriptivas","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics \n  gtsummary,    # summary statistics and tests\n  rstatix,      # summary statistics and statistical tests\n  janitor,      # adding totals and percents to tables\n  scales,       # easily convert proportions to percents  \n  flextable     # converting tables to pretty images\n  )"},{"path":"descriptive-tables.html","id":"importar-datos-8","chapter":"17 Tablas descriptivas","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"descriptive-tables.html","id":"browse-data","chapter":"17 Tablas descriptivas","heading":"17.2 Visualizar datos","text":"","code":""},{"path":"descriptive-tables.html","id":"paquete-skimr","chapter":"17 Tablas descriptivas","heading":"Paquete skimr","text":"Utilizando el paquete skimr, puedes obtener una visión detallada y estéticamente agradable de cada una de las variables de tu conjunto de datos. Lee más sobre skimr en su página de github.continuación, se aplica la función skim() todo el dataframe linelist. Se produce una visión general del dataframe y un resumen de cada columna (por tipo).\nTable 17.1: Data summary\nVariable type: characterVariable type: DateVariable type: factorVariable type: numericTambién puedes utilizar la función summary(), de R base, para obtener información completta sobre unos datos, pero esta salida puede ser más difícil de leer que utilizando skimr. Por eso se muestra continuación esta salida, para ahorrar espacio de la página.","code":"\n## get information about each variable in a dataset \nskim(linelist)\n## get information about each column in a dataset \nsummary(linelist)"},{"path":"descriptive-tables.html","id":"estadísticas-resumidas","chapter":"17 Tablas descriptivas","heading":"Estadísticas resumidas","text":"Puedes utilizar las funciones de R base para producir estadísticas de resumen sobre una columna numérica. Puedes producir la mayoría de las estadísticas de resumen útiles para una columna numérica utilizando summary(), como se indica continuación. Ten en cuenta que también debe especificarse el nombre del dataframe, como se muestra continuación.Puedes acceder y guardar una parte específica de la misma con los corchetes de índice [ ]:Puedes mostrar estadísticas individuales con funciones de R base como max(), min(), median(), mean(), quantile(), sd(), y range(). Consulta la página de Fundamentos de R para obtener una lista completa.PRECAUCIÓN: Si tus datos contienen valores faltantes, R quiere que lo sepas y por ello mostrará NA menos que se especifique en las funciones matemáticas anteriores que quieres que R ignore los valores faltantes, mediante el argumento na.rm = TRUE.Puedes utilizar la función get_summary_stats() de rstatix para producir las estadísticas de resumen en un formato de dataframe. Esto puede ser útil para realizar operaciones posteriores o trazar los números. Consulta la página Tests estadísticos simples para obtener más detalles sobre el paquete rstatix y sus funciones.","code":"\nsummary(linelist$age_years)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    6.00   13.00   16.02   23.00   84.00      86\nsummary(linelist$age_years)[[2]]            # return only the 2nd element## [1] 6\n# equivalent, alternative to above by element name\n# summary(linelist$age_years)[[\"1st Qu.\"]]  \nlinelist %>% \n  get_summary_stats(\n    age, wt_kg, ht_cm, ct_blood, temp,  # columns to calculate for\n    type = \"common\")                    # summary stats to return## # A tibble: 5 × 10\n##   variable     n   min   max median   iqr  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13      17  16.1 12.6   0.166 0.325\n## 2 wt_kg     5888 -11   111     54      25  52.6 18.6   0.242 0.475\n## 3 ht_cm     5888   4   295    129      68 125.  49.5   0.645 1.26 \n## 4 ct_blood  5888  16    26     22       2  21.2  1.69  0.022 0.043\n## 5 temp      5739  35.2  40.8   38.8     1  38.6  0.977 0.013 0.025"},{"path":"descriptive-tables.html","id":"tbl_janitor","chapter":"17 Tablas descriptivas","heading":"17.3 paquete janitor","text":"Los paquetes janitor ofrecen la función tabyl() para producir tabulaciones y tabulaciones cruzadas, que pueden ser “adornadas” o modificadas con funciones de ayuda para mostrar porcentajes, proporciones, recuentos, etc.continuación, enlazamos el dataframe linelist con pipe las funciones de limpieza e imprimimos el resultado. Si lo deseas, también puedes guardar las tablas resultantes con el operador de asignación <-.","code":""},{"path":"descriptive-tables.html","id":"tabyl-simple","chapter":"17 Tablas descriptivas","heading":"Tabyl simple","text":"El uso por defecto de tabyl() en una columna específica produce los valores únicos, los recuentos y sus proporciones por columna. Las proporciones pueden tener muchos dígitos. Puedes ajustar el número de decimales con adorn_rounding() como se describe continuación.Como puedes ver arriba, si hay valores que faltan se muestran en una fila etiquetada como NA. Puedes suprimirlos con show_na = FALSE. Si hay valores faltantes, esta fila aparecerá. Si hay valores faltantes, todas las proporciones se dan como crudas (el denominador incluye los recuentos de NA) y “válidas” (el denominador excluye los recuentos de NA).Si la columna es de tipo factor y sólo hay ciertos niveles en sus datos, todos los niveles seguirán apareciendo en la tabla. Puedes suprimir esta característica especificando show_missing_levels = FALSE. Lee más en la página de Factores.","code":"\nlinelist %>% tabyl(age_cat)##  age_cat    n     percent valid_percent\n##      0-4 1095 0.185971467   0.188728025\n##      5-9 1095 0.185971467   0.188728025\n##    10-14  941 0.159816576   0.162185453\n##    15-19  743 0.126188859   0.128059290\n##    20-29 1073 0.182235054   0.184936229\n##    30-49  754 0.128057065   0.129955188\n##    50-69   95 0.016134511   0.016373664\n##      70+    6 0.001019022   0.001034126\n##     <NA>   86 0.014605978            NA"},{"path":"descriptive-tables.html","id":"tabulación-cruzada","chapter":"17 Tablas descriptivas","heading":"Tabulación cruzada","text":"Los recuentos de tabulación cruzada se consiguen añadiendo una o más columnas adicionales dentro de tabyl(). Ten en cuenta que ahora sólo se muestran los recuentos - Las proporciones y porcentajes se pueden añadir con los pasos adicionales que se muestran continuación.","code":"\nlinelist %>% tabyl(age_cat, gender)##  age_cat   f   m NA_\n##      0-4 640 416  39\n##      5-9 641 412  42\n##    10-14 518 383  40\n##    15-19 359 364  20\n##    20-29 468 575  30\n##    30-49 179 557  18\n##    50-69   2  91   2\n##      70+   0   5   1\n##     <NA>   0   0  86"},{"path":"descriptive-tables.html","id":"tbl_adorn","chapter":"17 Tablas descriptivas","heading":"“Adornando” el tabyl","text":"Utiliza las funciones de “adorno” de janitor para añadir totales o convertir proporciones, porcentajes, o ajustar la visualización de otro modo. menudo, enlazarás el tabyl con pipe través de varias de estas funciones.Se consciente del orden en que se aplican las funciones anteriores. continuación, algunos ejemplos.Una simple tabla unidireccional con porcentajes en lugar de las proporciones por defecto.Una tabulación cruzada con un total de filas y porcentajes de filas.Una tabulación cruzada ajustada para que aparezcan tanto los recuentos como los porcentajes.","code":"\nlinelist %>%               # case linelist\n  tabyl(age_cat) %>%       # tabulate counts and proportions by age category\n  adorn_pct_formatting()   # convert proportions to percents##  age_cat    n percent valid_percent\n##      0-4 1095   18.6%         18.9%\n##      5-9 1095   18.6%         18.9%\n##    10-14  941   16.0%         16.2%\n##    15-19  743   12.6%         12.8%\n##    20-29 1073   18.2%         18.5%\n##    30-49  754   12.8%         13.0%\n##    50-69   95    1.6%          1.6%\n##      70+    6    0.1%          0.1%\n##     <NA>   86    1.5%             -\nlinelist %>%                                  \n  tabyl(age_cat, gender) %>%                  # counts by age and gender\n  adorn_totals(where = \"row\") %>%             # add total row\n  adorn_percentages(denominator = \"row\") %>%  # convert counts to proportions\n  adorn_pct_formatting(digits = 1)            # convert proportions to percents##  age_cat     f     m    NA_\n##      0-4 58.4% 38.0%   3.6%\n##      5-9 58.5% 37.6%   3.8%\n##    10-14 55.0% 40.7%   4.3%\n##    15-19 48.3% 49.0%   2.7%\n##    20-29 43.6% 53.6%   2.8%\n##    30-49 23.7% 73.9%   2.4%\n##    50-69  2.1% 95.8%   2.1%\n##      70+  0.0% 83.3%  16.7%\n##     <NA>  0.0%  0.0% 100.0%\n##    Total 47.7% 47.6%   4.7%\nlinelist %>%                                  # case linelist\n  tabyl(age_cat, gender) %>%                  # cross-tabulate counts\n  adorn_totals(where = \"row\") %>%             # add a total row\n  adorn_percentages(denominator = \"col\") %>%  # convert to proportions\n  adorn_pct_formatting() %>%                  # convert to percents\n  adorn_ns(position = \"front\") %>%            # display as: \"count (percent)\"\n  adorn_title(                                # adjust titles\n    row_name = \"Age Category\",\n    col_name = \"Gender\")##                      Gender                           \n##  Age Category             f             m          NA_\n##           0-4  640  (22.8%)  416  (14.8%)  39  (14.0%)\n##           5-9  641  (22.8%)  412  (14.7%)  42  (15.1%)\n##         10-14  518  (18.5%)  383  (13.7%)  40  (14.4%)\n##         15-19  359  (12.8%)  364  (13.0%)  20   (7.2%)\n##         20-29  468  (16.7%)  575  (20.5%)  30  (10.8%)\n##         30-49  179   (6.4%)  557  (19.9%)  18   (6.5%)\n##         50-69    2   (0.1%)   91   (3.2%)   2   (0.7%)\n##           70+    0   (0.0%)    5   (0.2%)   1   (0.4%)\n##          <NA>    0   (0.0%)    0   (0.0%)  86  (30.9%)\n##         Total 2807 (100.0%) 2803 (100.0%) 278 (100.0%)"},{"path":"descriptive-tables.html","id":"impresión-del-tabyl","chapter":"17 Tablas descriptivas","heading":"Impresión del tabyl","text":"Por defecto, el tabyl se imprimirá en crudo en la consola de R.Alternativamente, puedes pasar el tabyl flextable o un paquete similar para imprimirlo como una imagen “bonita” en el visor de RStudio, que podría exportarse como .png, .jpeg, .html, etc. Esto se discute en la página Tablas para presentaciones. Ten en cuenta que si imprimes de esta manera y utilizas adorn_titles(), debes especificar placement = \"combined\".Age Category/GenderfmNA_Total0-4640 (22.8%)416 (14.8%)39 (14.0%)1095 (18.6%)5-9641 (22.8%)412 (14.7%)42 (15.1%)1095 (18.6%)10-14518 (18.5%)383 (13.7%)40 (14.4%) 941 (16.0%)15-19359 (12.8%)364 (13.0%)20  (7.2%) 743 (12.6%)20-29468 (16.7%)575 (20.5%)30 (10.8%)1073 (18.2%)30-49179  (6.4%)557 (19.9%)18  (6.5%) 754 (12.8%)50-69  2  (0.1%) 91  (3.2%) 2  (0.7%)  95  (1.6%)70+  0  (0.0%)  5  (0.2%) 1  (0.4%)   6  (0.1%)  0  (0.0%)  0  (0.0%)86 (30.9%)  86  (1.5%)","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% # this is necessary to print as image\n  flextable::flextable() %>%    # convert to pretty image\n  flextable::autofit()          # format to one line per row "},{"path":"descriptive-tables.html","id":"uso-en-otras-tablas","chapter":"17 Tablas descriptivas","heading":"Uso en otras tablas","text":"Puedes utilizar las funciones adorn_() de janitor en otras tablas, como las creadas por summarise() y count() de dplyr, o table() de R base. Por ejemplo:","code":"\nlinelist %>% \n  count(hospital) %>%   # dplyr function\n  adorn_totals()        # janitor function##                              hospital    n\n##                      Central Hospital  454\n##                     Military Hospital  896\n##                               Missing 1469\n##                                 Other  885\n##                         Port Hospital 1762\n##  St. Mark's Maternity Hospital (SMMH)  422\n##                                 Total 5888"},{"path":"descriptive-tables.html","id":"guardar-el-tabyl","chapter":"17 Tablas descriptivas","heading":"Guardar el tabyl","text":"Si conviertes la tabla en una imagen “bonita” con un paquete como flextable, puedes guardarla con funciones de ese paquete - como save_as_html(), save_as_word(), save_as_ppt(), y save_as_image() de flextable (como se discute más ampliamente en la página Tablas para presentaciones). continuación, la tabla se guarda como un documento de Word, en el que se puede seguir editando mano.","code":"\nlinelist %>%\n  tabyl(age_cat, gender) %>% \n  adorn_totals(where = \"col\") %>% \n  adorn_percentages(denominator = \"col\") %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\") %>% \n  adorn_title(\n    row_name = \"Age Category\",\n    col_name = \"Gender\",\n    placement = \"combined\") %>% \n  flextable::flextable() %>%                     # convert to image\n  flextable::autofit() %>%                       # ensure only one line per row\n  flextable::save_as_docx(path = \"tabyl.docx\")   # save as Word document to filepath"},{"path":"descriptive-tables.html","id":"janitor_age_out_stats","chapter":"17 Tablas descriptivas","heading":"Estadísticas","text":"Puedes aplicar las tabyl tests estadísticos como chisq.test() o fisher.test() del paquete stats, como se muestra continuación. Ten en cuenta que los valores faltantes están permitidos, por lo que se excluyen de la tabulación con show_na = FALSE.Consulta la página sobre Tests estadísticos sencillos para obtener más código y consejos sobre estadística.","code":"\nage_by_outcome <- linelist %>% \n  tabyl(age_cat, outcome, show_na = FALSE) \n\nchisq.test(age_by_outcome)## \n##  Pearson's Chi-squared test\n## \n## data:  age_by_outcome\n## X-squared = 6.4931, df = 7, p-value = 0.4835"},{"path":"descriptive-tables.html","id":"otros-consejos","chapter":"17 Tablas descriptivas","heading":"Otros consejos","text":"Incluye el argumento na.rm = TRUE para excluir los valores faltantes de cualquiera de los cálculos anteriores.Si aplicas cualquier función de ayuda adorn_*() tablas creadas por tabyl(), puedes especificar una(s) columna(s) particular(es) para aplicarlas como adorn_percentage(,,,c(cases,deaths)) (especifícalos en el cuarto argumento sin nombre). La sintaxis es sencilla. Considera la posibilidad de utilizar summarise() en su lugar.Puedes leer más detalles en la página de janitor y en esta viñeta de tabyl.","code":""},{"path":"descriptive-tables.html","id":"dplyr-package","chapter":"17 Tablas descriptivas","heading":"17.4 paquete dplyr","text":"dplyr forma parte de los paquetes tidyverse y es una herramienta de gestión de datos muy común. La creación de tablas con las funciones de dplyr summarise() y count() es un enfoque útil para calcular estadísticas de resumen, resumir por grupos o pasar tablas ggplot().summarise() crea un nuevo dataframe de resumen. Si los datos están agrupados, se producirá un dataframe de una fila con las estadísticas de resumen especificadas de todo el dataframe. Si los datos están agrupados, el nuevo dataframe tendrá una fila por grupo (véase la página Agrupar datos).Dentro del paréntesis de summarise(), se proporcionan los nombres de cada nueva columna de resumen, seguidos de un signo de igualdad y de una función estadística aplicar.SUGERENCIA: La función summarise funciona tanto con la ortografía británica como con la estadounidense (summarise() y summarize()). ","code":""},{"path":"descriptive-tables.html","id":"obtener-recuentos","chapter":"17 Tablas descriptivas","heading":"Obtener recuentos","text":"La función más sencilla de aplicar dentro de summarise() es n(). Deja los paréntesis vacíos para contar el número de filas.Esto se vuelve más interesante si hemos agrupado los datos de antemano.El comando anterior se puede acortar utilizando la función count() en su lugar. count() hace lo siguiente:Agrupa los datos por las columnas que se le proporcionanLos resume con n() (creando la columna n)Desagrupa los datosPuedes cambiar el nombre de la columna de recuentos de la n por defecto otra cosa especificando name =.Los recuentos tabulados de dos o más columnas de agrupación se siguen devolviendo en formato “largo”, con los recuentos en la columna n. Consulta la página sobre Pivotar datos para conocer los formatos de datos “long” y “wide”.","code":"\nlinelist %>%                 # begin with linelist\n  summarise(n_rows = n())    # return new summary dataframe with column n_rows##   n_rows\n## 1   5888\nlinelist %>% \n  group_by(age_cat) %>%     # group data by unique values in column age_cat\n  summarise(n_rows = n())   # return number of rows *per group*## # A tibble: 9 × 2\n##   age_cat n_rows\n##   <fct>    <int>\n## 1 0-4       1095\n## 2 5-9       1095\n## 3 10-14      941\n## 4 15-19      743\n## 5 20-29     1073\n## 6 30-49      754\n## 7 50-69       95\n## 8 70+          6\n## 9 <NA>        86\nlinelist %>% \n  count(age_cat)##   age_cat    n\n## 1     0-4 1095\n## 2     5-9 1095\n## 3   10-14  941\n## 4   15-19  743\n## 5   20-29 1073\n## 6   30-49  754\n## 7   50-69   95\n## 8     70+    6\n## 9    <NA>   86\nlinelist %>% \n  count(age_cat, outcome)##    age_cat outcome   n\n## 1      0-4   Death 471\n## 2      0-4 Recover 364\n## 3      0-4    <NA> 260\n## 4      5-9   Death 476\n## 5      5-9 Recover 391\n## 6      5-9    <NA> 228\n## 7    10-14   Death 438\n## 8    10-14 Recover 303\n## 9    10-14    <NA> 200\n## 10   15-19   Death 323\n## 11   15-19 Recover 251\n## 12   15-19    <NA> 169\n## 13   20-29   Death 477\n## 14   20-29 Recover 367\n## 15   20-29    <NA> 229\n## 16   30-49   Death 329\n## 17   30-49 Recover 238\n## 18   30-49    <NA> 187\n## 19   50-69   Death  33\n## 20   50-69 Recover  38\n## 21   50-69    <NA>  24\n## 22     70+   Death   3\n## 23     70+ Recover   3\n## 24    <NA>   Death  32\n## 25    <NA> Recover  28\n## 26    <NA>    <NA>  26"},{"path":"descriptive-tables.html","id":"mostrar-todos-los-niveles","chapter":"17 Tablas descriptivas","heading":"Mostrar todos los niveles","text":"Si estás tabulando una columna de tipo factor, puedes asegurarte de que se muestren todos los niveles (sólo los niveles con valores en los datos) añadiendo .drop = FALSE en el comando summarise() o count().Esta técnica es útil para estandarizar sus tablas/gráficos. Por ejemplo, si está creando cifras para varios subgrupos, o creando repetidamente la cifra para informes de rutina. En cada una de estas circunstancias, la presencia de valores en los datos puede fluctuar, pero puedes definir niveles que permanezcan constantes.Para más información, consulta la página sobre factores.","code":""},{"path":"descriptive-tables.html","id":"tbl_dplyr_prop","chapter":"17 Tablas descriptivas","heading":"Proporciones","text":"Las proporciones pueden añadirse pasando la tabla por mutate() para crear una nueva columna. Define la nueva columna como la columna de recuentos (n por defecto) dividida por la sum() de la columna de recuentos (esto producirá una proporción).Ten en cuenta que en este caso, sum() en el comando mutate() producirá la suma de toda la columna n para utilizarla como denominador de la proporción. Como se explica en la página Agrupar datos, si sum() se utiliza en datos agrupados (por ejemplo, si el comando mutate() sigue inmediatamente un comando group_by()), producirá sumas por grupo. Como se acaba de indicar, count() termina sus acciones desagrupando. Por lo tanto, en este escenario obtenemos proporciones de columnas completas.Para mostrar fácilmente los porcentajes, puedes envolver la proporción en la función percent() del paquete scales (Ten en cuenta que se convierte en tipo carácter).continuación se presenta un método para calcular las proporciones dentro de los grupos. Se basa en diferentes niveles de agrupación de datos que se aplican y eliminan selectivamente. En primer lugar, los datos se agrupan en función del outcome mediante group_by(). continuación, se aplica count(). Esta función agrupa además los datos por age_cat y devuelve los recuentos para cada combinación de outcome-age-cat. Es importante destacar que, al finalizar tu proceso, count() también desagrupa la agrupación age_cat, por lo que la única agrupación de datos que queda es la agrupación original por outcome. Por lo tanto, el paso final del cálculo de las proporciones (denominador sum(n)) sigue estando agrupado por outcome.","code":"\nage_summary <- linelist %>% \n  count(age_cat) %>%                     # group and count by gender (produces \"n\" column)\n  mutate(                                # create percent of column - note the denominator\n    percent = scales::percent(n / sum(n))) \n\n# print\nage_summary##   age_cat    n percent\n## 1     0-4 1095  18.60%\n## 2     5-9 1095  18.60%\n## 3   10-14  941  15.98%\n## 4   15-19  743  12.62%\n## 5   20-29 1073  18.22%\n## 6   30-49  754  12.81%\n## 7   50-69   95   1.61%\n## 8     70+    6   0.10%\n## 9    <NA>   86   1.46%\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group"},{"path":"descriptive-tables.html","id":"gráficas","chapter":"17 Tablas descriptivas","heading":"Gráficas","text":"Mostrar una tabla “larga” como la anterior con ggplot() es relativamente sencillo. Los datos están naturalmente en formato “largo”, que es aceptado naturalmente por ggplot(). Mira más ejemplos en las páginas Conceptos básicos de ggplot y consejos de ggplot.","code":"\nlinelist %>%                      # begin with linelist\n  count(age_cat, outcome) %>%     # group and tabulate counts by two columns\n  ggplot()+                       # pass new data frame to ggplot\n    geom_col(                     # create bar plot\n      mapping = aes(   \n        x = outcome,              # map outcome to x-axis\n        fill = age_cat,           # map age_cat to the fill\n        y = n))                   # map the counts column `n` to the height"},{"path":"descriptive-tables.html","id":"estadísticas-resumidas-1","chapter":"17 Tablas descriptivas","heading":"Estadísticas resumidas","text":"Una de las principales ventajas de dplyr y de summarise() es la capacidad de producir resúmenes estadísticos más avanzados como median(), mean(), max(), min(), sd() (desviación estándar) y percentiles. También puedes utilizar sum() para mostrar el número de filas que cumplen ciertos criterios lógicos. Al igual que en el caso anterior, estas salidas pueden producirse para todo el conjunto de dataframes o por grupos.La sintaxis es la misma: dentro de los paréntesis de summarise() se proporcionan los nombres de cada nueva columna de resumen, seguidos de un signo de igualdad y de una función estadística para aplicar. Dentro de la función estadística, indica la(s) columna(s) con la(s) que se va operar y cualquier argumento relevante (por ejemplo, na.rm = TRUE para la mayoría de las funciones matemáticas).También puedes utilizar sum() para mostrar el número de filas que cumplen un criterio lógico. La expresión que contiene se cuenta si se evalúa como TRUE. Por ejemplo:sum(age_years < 18, na.rm=T)sum(gender == \"male\", na.rm=T)sum(response %% c(\"Likely\", \"Likely\"))continuación, se resumen los datos de linelist para describir los días de retraso desde el inicio de los síntomas hasta el ingreso en el hospital (columna days_onset_hosp), por hospital.Algunos consejos:Utilizar sum() con una sentencia lógica para “contar” las filas que cumplen ciertos criterios (==)Ten en cuenta el uso de na.rm = TRUE dentro de funciones matemáticas como sum(), de lo contrario se mostrará NA si hay algún valor faltanteUtiliza la función percent() del paquete scales para convertir fácilmente porcentajesAjusta la accuracy = (precisión) 0,1 o 0,01 para garantizar 1 o 2 decimales respectivamenteUtilizar round() de R base para especificar los decimalesPara calcular estas estadísticas en todo el set de datos, utiliza summarise() sin group_by()Puedes crear columnas para los propósitos de cálculos posteriores (por ejemplo, denominadores) que eventualmente se eliminan de tu dataframe con select().","code":"\nsummary_table <- linelist %>%                                        # begin with linelist, save out as new object\n  group_by(hospital) %>%                                             # group all calculations by hospital\n  summarise(                                                         # only the below summary columns will be returned\n    cases       = n(),                                                # number of rows per group\n    delay_max   = max(days_onset_hosp, na.rm = T),                    # max delay\n    delay_mean  = round(mean(days_onset_hosp, na.rm=T), digits = 1),  # mean delay, rounded\n    delay_sd    = round(sd(days_onset_hosp, na.rm = T), digits = 1),  # standard deviation of delays, rounded\n    delay_3     = sum(days_onset_hosp >= 3, na.rm = T),               # number of rows with delay of 3 or more days\n    pct_delay_3 = scales::percent(delay_3 / cases)                    # convert previously-defined delay column to percent \n  )\n\nsummary_table  # print## # A tibble: 6 × 7\n##   hospital                             cases delay_max delay_mean delay_sd delay_3 pct_delay_3\n##   <chr>                                <int>     <dbl>      <dbl>    <dbl>   <int> <chr>      \n## 1 Central Hospital                       454        12        1.9      1.9     108 24%        \n## 2 Military Hospital                      896        15        2.1      2.4     253 28%        \n## 3 Missing                               1469        22        2.1      2.3     399 27%        \n## 4 Other                                  885        18        2        2.2     234 26%        \n## 5 Port Hospital                         1762        16        2.1      2.2     470 27%        \n## 6 St. Mark's Maternity Hospital (SMMH)   422        18        2.1      2.3     116 27%"},{"path":"descriptive-tables.html","id":"estadísticas-condicionales","chapter":"17 Tablas descriptivas","heading":"Estadísticas condicionales","text":"Es posible que desees producir estadísticas condicionales, por ejemplo, el máximo de filas que cumplen ciertos criterios. Esto se puede hacer sub-configurando la columna con corchetes [ ]. El ejemplo siguiente devuelve la temperatura máxima de los pacientes clasificados con o sin fiebre. Sin embargo, ten en cuenta que puede ser más adecuado añadir otra columna al comando group_by() y pivot_wider() (como se demuestra continuación).","code":"\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    max_temp_fvr = max(temp[fever == \"yes\"], na.rm = T),\n    max_temp_no = max(temp[fever == \"no\"], na.rm = T)\n  )## # A tibble: 6 × 3\n##   hospital                             max_temp_fvr max_temp_no\n##   <chr>                                       <dbl>       <dbl>\n## 1 Central Hospital                             40.4        38  \n## 2 Military Hospital                            40.5        38  \n## 3 Missing                                      40.6        38  \n## 4 Other                                        40.8        37.9\n## 5 Port Hospital                                40.6        38  \n## 6 St. Mark's Maternity Hospital (SMMH)         40.6        37.9"},{"path":"descriptive-tables.html","id":"pegar-valores","chapter":"17 Tablas descriptivas","heading":"Pegar valores","text":"La función str_glue() de stringr es útil para combinar valores de varias columnas en una nueva columna. En este contexto, se suele utilizar después del comando summarise().En la página Caracteres y cadenas, se discuten varias opciones para combinar columnas, incluyendo unite(), y paste0(). En este caso de uso, abogamos por str_glue() porque es más flexible que unite() y tiene una sintaxis más sencilla que paste0().continuación, el dataframe de summary_table (creado anteriormente) se muta de manera que las columnas delay_mean y delay_sd se combinan, se añade el formato de paréntesis la nueva columna y se eliminan sus respectivas columnas antiguas.Luego, para hacer la tabla más presentable, se añade una fila de totales con adorn_totals() de janitor (que ignora las columnas numéricas). Por último, utilizamos select() de dplyr para reordenar y renombrar los nombres de las columnas.Ahora puedes pasar flextable e imprimir la tabla Word, .png, .jpeg, .html, Powerpoint, RMarkdown, etc. (ver la página de Tablas para presentaciones).","code":"\nsummary_table %>% \n  mutate(delay = str_glue(\"{delay_mean} ({delay_sd})\")) %>%  # combine and format other values\n  select(-c(delay_mean, delay_sd)) %>%                       # remove two old columns   \n  adorn_totals(where = \"row\") %>%                            # add total row\n  select(                                                    # order and rename cols\n    \"Hospital Name\"   = hospital,\n    \"Cases\"           = cases,\n    \"Max delay\"       = delay_max,\n    \"Mean (sd)\"       = delay,\n    \"Delay 3+ days\"   = delay_3,\n    \"% delay 3+ days\" = pct_delay_3\n    )##                         Hospital Name Cases Max delay Mean (sd) Delay 3+ days % delay 3+ days\n##                      Central Hospital   454        12 1.9 (1.9)           108             24%\n##                     Military Hospital   896        15 2.1 (2.4)           253             28%\n##                               Missing  1469        22 2.1 (2.3)           399             27%\n##                                 Other   885        18   2 (2.2)           234             26%\n##                         Port Hospital  1762        16 2.1 (2.2)           470             27%\n##  St. Mark's Maternity Hospital (SMMH)   422        18 2.1 (2.3)           116             27%\n##                                 Total  5888       101         -          1580               -"},{"path":"descriptive-tables.html","id":"percentiles","chapter":"17 Tablas descriptivas","heading":"Percentiles","text":"Los percentiles y cuartiles en dplyr merecen una mención especial. Para mostrar los cuantiles, utiliza quantile() con los valores predeterminados o especifica el valor o los valores que deseas con probs =.Si deseas mostrar cuantiles por grupo, puedes encontrar salidas largas y menos útiles si simplemente añades otra columna group_by(). Por lo tanto, prueba este enfoque en su lugar: crea una columna para cada nivel de cuantil deseado.Aunque summarise() de dplyr ofrece ciertamente un control más fino, puedes encontrar que todas las estadísticas de resumen que necesitas pueden producirse con get_summary_stat() del paquete rstatix. Si se opera con datos agrupados, mostrará 0%, 25%, 50%, 75% y 100%. Si se aplica datos agrupados, puedes especificar los percentiles con probs = c(.05, .5, .75, .98).","code":"\n# get default percentile values of age (0%, 25%, 50%, 75%, 100%)\nlinelist %>% \n  summarise(age_percentiles = quantile(age_years, na.rm = TRUE))##   age_percentiles\n## 1               0\n## 2               6\n## 3              13\n## 4              23\n## 5              84\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  summarise(\n    age_percentiles = quantile(\n      age_years,\n      probs = c(.05, 0.5, 0.75, 0.98), \n      na.rm=TRUE)\n    )##   age_percentiles\n## 1               1\n## 2              13\n## 3              23\n## 4              48\n# get manually-specified percentile values of age (5%, 50%, 75%, 98%)\nlinelist %>% \n  group_by(hospital) %>% \n  summarise(\n    p05 = quantile(age_years, probs = 0.05, na.rm=T),\n    p50 = quantile(age_years, probs = 0.5, na.rm=T),\n    p75 = quantile(age_years, probs = 0.75, na.rm=T),\n    p98 = quantile(age_years, probs = 0.98, na.rm=T)\n    )## # A tibble: 6 × 5\n##   hospital                               p05   p50   p75   p98\n##   <chr>                                <dbl> <dbl> <dbl> <dbl>\n## 1 Central Hospital                         1    12    21  48  \n## 2 Military Hospital                        1    13    24  45  \n## 3 Missing                                  1    13    23  48.2\n## 4 Other                                    1    13    23  50  \n## 5 Port Hospital                            1    14    24  49  \n## 6 St. Mark's Maternity Hospital (SMMH)     2    12    22  50.2\nlinelist %>% \n  group_by(hospital) %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 6 × 8\n##   hospital                             variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <chr>                                <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 Central Hospital                     age        445     0     6    12    21     58\n## 2 Military Hospital                    age        884     0     6    14    24     72\n## 3 Missing                              age       1441     0     6    13    23     76\n## 4 Other                                age        873     0     6    13    23     69\n## 5 Port Hospital                        age       1739     0     6    14    24     68\n## 6 St. Mark's Maternity Hospital (SMMH) age        420     0     7    12    22     84\nlinelist %>% \n  rstatix::get_summary_stats(age, type = \"quantile\")## # A tibble: 1 × 7\n##   variable     n  `0%` `25%` `50%` `75%` `100%`\n##   <fct>    <dbl> <dbl> <dbl> <dbl> <dbl>  <dbl>\n## 1 age       5802     0     6    13    23     84"},{"path":"descriptive-tables.html","id":"resumir-datos-agregados","chapter":"17 Tablas descriptivas","heading":"Resumir datos agregados","text":"Si comienza con datos agregados, al utilizar n() devuelve el número de filas, la suma de los recuentos agregados. Para obtener sumas, utiliza sum() en la columna de recuentos de los datos.Por ejemplo, digamos que se empieza con el dataframe de recuentos que se muestra continuación, llamado linelist_agg - muestra en formato “largo” los recuentos de casos por resultado y género.continuación creamos este dataframe de ejemplo de recuentos de casos de linelist por resultado y sexo (se eliminan los valores faltantes para mayor claridad).Para sumar los recuentos (en la columna n) por grupo, puedes utilizar summarise() pero establecer la nueva columna igual sum(n, na.rm=T)`. Para añadir un elemento condicional la operación de suma, puedes utilizar la sintaxis del subconjunto [ ] en la columna de recuentos.","code":"\nlinelist_agg <- linelist %>% \n  drop_na(gender, outcome) %>% \n  count(outcome, gender)\n\nlinelist_agg##   outcome gender    n\n## 1   Death      f 1227\n## 2   Death      m 1228\n## 3 Recover      f  953\n## 4 Recover      m  950\nlinelist_agg %>% \n  group_by(outcome) %>% \n  summarise(\n    total_cases  = sum(n, na.rm=T),\n    male_cases   = sum(n[gender == \"m\"], na.rm=T),\n    female_cases = sum(n[gender == \"f\"], na.rm=T))## # A tibble: 2 × 4\n##   outcome total_cases male_cases female_cases\n##   <chr>         <int>      <int>        <int>\n## 1 Death          2455       1228         1227\n## 2 Recover        1903        950          953"},{"path":"descriptive-tables.html","id":"across-varias-columnas","chapter":"17 Tablas descriptivas","heading":"across() varias columnas","text":"Puedes utilizar summarise() en varias columnas utilizando across(). Esto facilita la vida cuando se desea calcular las mismas estadísticas para muchas columnas. Escribe across() dentro de summarise() y especifica lo siguiente:.cols = como un vector de nombres de columnas c() o funciones de ayuda “tidyselect” (explicadas más adelante).cols = como un vector de nombres de columnas c() o funciones de ayuda “tidyselect” (explicadas más adelante).fns = la función realizar (sin paréntesis) - puedes proporcionar varias dentro de una list().fns = la función realizar (sin paréntesis) - puedes proporcionar varias dentro de una list()continuación, mean() se aplica varias columnas numéricas. Se nombra explícitamente un vector de columnas .cols = y se especifica una única función mean (sin paréntesis) .fns =. Cualquier argumento adicional para la función (por ejemplo, na.rm=TRUE) se proporciona después de .fns =, separado por una coma.Puede ser difícil conseguir el orden correcto de los paréntesis y las comas cuando se utiliza across(). Recuerda que dentro de across() debes incluir las columnas, las funciones y cualquier argumento extra necesario para las funciones.Se pueden ejecutar varias funciones la vez. continuación se proporcionan las funciones mean y sd .fns = dentro de una list(). Tienes la oportunidad de proporcionar nombres de caracteres (por ejemplo, “mean” y “sd”) que se añaden en los nuevos nombres de columna.Aquí están esas funciones de ayuda “tidyselect” que puedes proporcionar .cols = para seleccionar columnas:everything() - todas las demás columnas mencionadaslast_col() - la última columnawhere() - aplica una función todas las columnas y selecciona las que son TRUEstarts_with() - coincide con un prefijo especificado. Ejemplo: starts_with(\"date\")ends_with() - coincide con un sufijo especificado. Ejemplo: ends_with(\"_end\")contains() - columnas que contienen una cadena de caracteres. Ejemplo: contains(\"time\")matches() - para aplicar una expresión regular (regex). Ejemplo: contains(\"[pt]al\")num_range() -any_of() - coincide con el nombre de la columna. Es útil si el nombre puede existir. Ejemplo: any_of(date_onset, date_death, cardiac_arrest)Por ejemplo, para producir la media de cada columna numérica utiliza () y proporciona la función .numeric() (sin paréntesis). Todo esto queda dentro del comando across().","code":"\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm),  # columns\n                   .fns = mean,                               # function\n                   na.rm=T))                                  # extra arguments## # A tibble: 3 × 5\n##   outcome age_years  temp wt_kg ht_cm\n##   <chr>       <dbl> <dbl> <dbl> <dbl>\n## 1 Death        15.9  38.6  52.6  125.\n## 2 Recover      16.1  38.6  52.5  125.\n## 3 <NA>         16.2  38.6  53.0  125.\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(.cols = c(age_years, temp, wt_kg, ht_cm), # columns\n                   .fns = list(\"mean\" = mean, \"sd\" = sd),    # multiple functions \n                   na.rm=T))                                 # extra arguments## # A tibble: 3 × 9\n##   outcome age_years_mean age_years_sd temp_mean temp_sd wt_kg_mean wt_kg_sd ht_cm_mean ht_cm_sd\n##   <chr>            <dbl>        <dbl>     <dbl>   <dbl>      <dbl>    <dbl>      <dbl>    <dbl>\n## 1 Death             15.9         12.3      38.6   0.962       52.6     18.4       125.     48.7\n## 2 Recover           16.1         13.0      38.6   0.997       52.5     18.6       125.     50.1\n## 3 <NA>              16.2         12.8      38.6   0.976       53.0     18.9       125.     50.4\nlinelist %>% \n  group_by(outcome) %>% \n  summarise(across(\n    .cols = where(is.numeric),  # all numeric columns in the data frame\n    .fns = mean,\n    na.rm=T))## # A tibble: 3 × 12\n##   outcome generation   age age_years   lon   lat wt_kg ht_cm ct_blood  temp   bmi days_onset_hosp\n##   <chr>        <dbl> <dbl>     <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> <dbl>           <dbl>\n## 1 Death         16.7  15.9      15.9 -13.2  8.47  52.6  125.     21.3  38.6  45.6            1.84\n## 2 Recover       16.4  16.2      16.1 -13.2  8.47  52.5  125.     21.1  38.6  47.7            2.34\n## 3 <NA>          16.5  16.3      16.2 -13.2  8.47  53.0  125.     21.2  38.6  48.3            2.07"},{"path":"descriptive-tables.html","id":"tbls_pivot_wider","chapter":"17 Tablas descriptivas","heading":"Pivote más amplio","text":"Si prefieres tu tabla en formato “ancho” puedes transformarla utilizando la función pivot_wider() de tidyr. Es probable que tengas que renombrar las columnas con rename(). Para más información, consulta la página sobre Pivotar datos.El ejemplo siguiente comienza con la tabla “larga” age_by_outcome de la sección de proporciones. La creamos de nuevo y la imprimimos, para mayor claridad:Para pivotar más ampliamente, creamos las nuevas columnas partir de los valores de la columna existente age_cat (estableciendo names_from = age_cat). También especificamos que los nuevos valores de la tabla provendrán de la columna existente n, con values_from = n. Las columnas mencionadas en nuestro comando de pivoteo (outcome) permanecerán sin cambios en el extremo izquierdo.","code":"\nage_by_outcome <- linelist %>%                  # begin with linelist\n  group_by(outcome) %>%                         # group by outcome \n  count(age_cat) %>%                            # group and count by age_cat, and then remove age_cat grouping\n  mutate(percent = scales::percent(n / sum(n))) # calculate percent - note the denominator is by outcome group\nage_by_outcome %>% \n  select(-percent) %>%   # keep only counts for simplicity\n  pivot_wider(names_from = age_cat, values_from = n)  ## # A tibble: 3 × 10\n## # Groups:   outcome [3]\n##   outcome `0-4` `5-9` `10-14` `15-19` `20-29` `30-49` `50-69` `70+`  `NA`\n##   <chr>   <int> <int>   <int>   <int>   <int>   <int>   <int> <int> <int>\n## 1 Death     471   476     438     323     477     329      33     3    32\n## 2 Recover   364   391     303     251     367     238      38     3    28\n## 3 <NA>      260   228     200     169     229     187      24    NA    26"},{"path":"descriptive-tables.html","id":"tbl_dplyr_totals","chapter":"17 Tablas descriptivas","heading":"Total de filas","text":"Cuando summarise() opera con datos agrupados produce automáticamente estadísticas “totales”. continuación, se presentan dos enfoques para añadir una fila de totales:","code":""},{"path":"descriptive-tables.html","id":"adorn_totals-de-janitor","chapter":"17 Tablas descriptivas","heading":"adorn_totals() de janitor","text":"Si tu tabla consiste sólo en recuentos o proporciones/porcentajes que pueden sumarse en un total, entonces puedes añadir totales de suma usando adorn_totals() de janitor como se describe en la sección anterior. Ten en cuenta que esta función sólo puede sumar las columnas numéricas - si deseas calcular otras estadísticas de resumen total, mira el siguiente enfoque con dplyr.continuación, linelist se agrupa por género y se resume en una tabla que describe el número de casos con resultado conocido, los fallecidos y los recuperados. Al pasar la tabla por adorn_totals() se añade una fila total en la parte inferior que refleja la suma de cada columna. Las funciones posteriores adorn_*() ajustan la visualización como se indica en el código.","code":"\nlinelist %>% \n  group_by(gender) %>%\n  summarise(\n    known_outcome = sum(!is.na(outcome)),           # Number of rows in group where outcome is not missing\n    n_death  = sum(outcome == \"Death\", na.rm=T),    # Number of rows in group where outcome is Death\n    n_recover = sum(outcome == \"Recover\", na.rm=T), # Number of rows in group where outcome is Recovered\n  ) %>% \n  adorn_totals() %>%                                # Adorn total row (sums of each numeric column)\n  adorn_percentages(\"col\") %>%                      # Get column proportions\n  adorn_pct_formatting() %>%                        # Convert proportions to percents\n  adorn_ns(position = \"front\")                      # display % and counts (with counts in front)##  gender known_outcome       n_death     n_recover\n##       f 2180  (47.8%) 1227  (47.5%)  953  (48.1%)\n##       m 2178  (47.7%) 1228  (47.6%)  950  (47.9%)\n##    <NA>  207   (4.5%)  127   (4.9%)   80   (4.0%)\n##   Total 4565 (100.0%) 2582 (100.0%) 1983 (100.0%)"},{"path":"descriptive-tables.html","id":"summarise-en-los-datos-totales-y-luego-bind_rows","chapter":"17 Tablas descriptivas","heading":"summarise() en los datos “totales” y luego bind_rows()","text":"Si tu tabla consta de estadísticas de resumen como median(), mean(),, etc., el enfoque adorn_totals() mostrado anteriormente será suficiente. En tu lugar, para obtener los estadísticos de resumen de todo el set de datos debe calcularlos con un comando summarise() separado y luego vincular los resultados la tabla de resumen agrupada original. Para hacer el enlace puedes utilizar bind_rows() de dplyr descrito en la página de unión de datos. continuación se muestra un ejemplo:Se puede hacer una tabla resumen de resultados por hospital con group_by() y summarise() así:Para obtener los totales, ejecuta el mismo comando summarise() pero agrupando los datos sólo por resultado (por hospital), de la siguiente manera:Podemos unir estos dos dataframes. Ten en cuenta que by_hospital tiene 4 columnas, mientras que totals tiene 3 columnas. Al utilizar bind_rows(), las columnas se combinan por nombre, y cualquier espacio extra se rellena con NA (por ejemplo, los valores de la columna hospital para las dos nuevas filas de totals). Después de enlazar las filas, convertimos estos espacios vacíos en “Total” utilizando replace_na() (véase la página de limpieza de datos y funciones básicas).Aquí está la nueva tabla con las filas “Total” en la parte inferior.Esta tabla tiene un formato “largo”, que puede ser lo que quieres. Opcionalmente, puedes pivotar esta tabla más ampliamente para hacerla más legible. Mira la sección sobre pivoteo más amplio arriba, y la página Pivotar datos. También puedes añadir más columnas, y organizarla de forma agradable. Este código está abajo.Y luego puedes imprimir esto muy bien como una imagen - abajo está la salida impresa con flextable. Puedes leer más en profundidad sobre este ejemplo y cómo lograr esta tabla “bonita” en la página Tablas para presentaciones.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nby_hospital <- linelist %>% \n  filter(!is.na(outcome) & hospital != \"Missing\") %>%  # Remove cases with missing outcome or hospital\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T))               # median CT value per group\n  \nby_hospital # print table## # A tibble: 10 × 4\n## # Groups:   hospital [5]\n##    hospital                             outcome     N ct_value\n##    <chr>                                <chr>   <int>    <dbl>\n##  1 Central Hospital                     Death     193       22\n##  2 Central Hospital                     Recover   165       22\n##  3 Military Hospital                    Death     399       21\n##  4 Military Hospital                    Recover   309       22\n##  5 Other                                Death     395       22\n##  6 Other                                Recover   290       21\n##  7 Port Hospital                        Death     785       22\n##  8 Port Hospital                        Recover   579       21\n##  9 St. Mark's Maternity Hospital (SMMH) Death     199       22\n## 10 St. Mark's Maternity Hospital (SMMH) Recover   126       22\ntotals <- linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # These statistics are now by outcome only     \n        ct_value = median(ct_blood, na.rm=T))\n\ntotals # print table## # A tibble: 2 × 3\n##   outcome     N ct_value\n##   <chr>   <int>    <dbl>\n## 1 Death    1971       22\n## 2 Recover  1469       22\ntable_long <- bind_rows(by_hospital, totals) %>% \n  mutate(hospital = replace_na(hospital, \"Total\"))\ntable_long %>% \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known)                                  # Arrange rows from lowest to highest (Total row at bottom)## # A tibble: 6 × 8\n## # Groups:   hospital [6]\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_…¹ N_Death Pct_D…² ct_va…³\n##   <chr>                                  <int>     <int> <chr>             <dbl>   <int> <chr>     <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126 38.8%                22     199 61.2%        22\n## 2 Central Hospital                         358       165 46.1%                22     193 53.9%        22\n## 3 Other                                    685       290 42.3%                21     395 57.7%        22\n## 4 Military Hospital                        708       309 43.6%                22     399 56.4%        21\n## 5 Port Hospital                           1364       579 42.4%                21     785 57.6%        22\n## 6 Total                                   3440      1469 42.7%                22    1971 57.3%        22\n## # … with abbreviated variable names ¹​ct_value_Recover, ²​Pct_Death, ³​ct_value_Death"},{"path":"descriptive-tables.html","id":"tbl_gt","chapter":"17 Tablas descriptivas","heading":"17.5 Paquete gtsummary","text":"Si deseas imprimir tus estadísticas de resumen en un gráfico bonito y listo para tu publicación, puedes utilizar el paquete gtsummary y tu función tbl_summary(). El código puede parecer complejo al principio, pero los resultados se ven muy bien y se imprimen en tu panel de RStudio Viewer como una imagen HTML. Lea esta viñeta.También puedes añadir los resultados de las pruebas estadísticas las tablas de gtsummary. Este proceso se describe en la sección gtsummary de la página Tests estadísticos simples.Para introducir tbl_summary() mostraremos primero el comportamiento más básico, que realmente produce una tabla grande y bonita. Luego, examinaremos en detalle cómo hacer ajustes y tablas más medida.","code":""},{"path":"descriptive-tables.html","id":"tabla-resumen","chapter":"17 Tablas descriptivas","heading":"Tabla resumen","text":"El comportamiento por defecto de tbl_summary() es bastante increíble: toma las columnas que proporcionas y crea una tabla de resumen en un solo comando. La función imprime las estadísticas apropiadas para el tipo de columna: mediana y rango intercuartil (IQR) para las columnas numéricas, y recuentos (%) para las columnas categóricas. Los valores faltantes se convierten en “Missing”. Se añaden notas pie de página para explicar las estadísticas, mientras que el N total se muestra en la parte superior.","code":"\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>%  # keep only the columns of interest\n  tbl_summary()                                                  # default"},{"path":"descriptive-tables.html","id":"ajustes-1","chapter":"17 Tablas descriptivas","heading":"Ajustes","text":"Ahora explicaremos cómo trabaja la función y cómo hacer los ajustes. Los argumentos clave se detallan continuación:=\nPuedes estratificar tu tabla por una columna (por ejemplo, por resultado), creando una tabla de dos vías.statistic = \nUsa una ecuación para especificar qué estadísticas mostrar y cómo mostrarlas. La ecuación tiene dos lados, separados por una tilde ~. En el lado derecho, entre comillas, está la visualización estadística deseada, y en el izquierdo están las columnas las que se aplicará esa visualización.El lado derecho de la ecuación utiliza la sintaxis de str_glue() de stringr (véase Caracteres y cadenas), con la cadena de visualización deseada entre comillas y los propios estadísticos entre llaves. Puedes incluir estadísticas como “n” (para los recuentos), “N” (para el denominador), “mean”, “median”, “sd”, “max”, “min”, percentiles como “p##” como “p25”, o porcentaje del total como “p”. Consulta ?tbl_summary para obtener más detalles.Para el lado izquierdo de la ecuación, puedes especificar las columnas por su nombre (por ejemplo, age o c(age, gender)) o utilizando ayudantes como all_continuous(), all_categorical(), contains(), starts_with(), etc.Un ejemplo sencillo de una ecuación statistic = podría ser como el siguiente, para imprimir sólo la media de la columna age_years:Una ecuación un poco más compleja podría tener el aspecto de \"({min}, {max})\", incorporando los valores máximo y mínimo entre paréntesis y separados por una coma:También puedes diferenciar la sintaxis para columnas separadas o tipos de columnas. En el ejemplo más complejo de abajo, el valor proporcionado statistc = es una lista que indica que para todas las columnas continuas la tabla debe imprimir la media con la desviación estándar entre paréntesis, mientras que para todas las columnas categóricas debe imprimir el n, el denominador y el porcentaje.digits =\nAjusta los dígitos y el redondeo. Opcionalmente, se puede especificar que sea sólo para columnas continuas (como continuación).label =\nAjustar cómo debe mostrarse el nombre de la columna. Proporciona el nombre de la columna y la etiqueta deseada separados por una tilde. El valor por defecto es el nombre de la columna.missing_text =\nAjustar cómo se muestran los valores faltantes. El valor por defecto es “Unknown”.type =\nSe utiliza para ajustar cuántos niveles de la estadística se muestran. La sintaxis es similar statistic = en el sentido de que se proporciona una ecuación con columnas la izquierda y un valor la derecha. Dos escenarios comunes incluyen:type = all_categorical() ~ \"categorical\" Fuerza las columnas dicotómicas (por ejemplo, fever sí/) mostrar todos los niveles en lugar de sólo la fila “sí”type = all_categorical() ~ \"categorical\" Fuerza las columnas dicotómicas (por ejemplo, fever sí/) mostrar todos los niveles en lugar de sólo la fila “sí”type = all_continuous() ~ \"continuous2\" Permite estadísticas de varias líneas por variable, como se muestra en una sección posteriortype = all_continuous() ~ \"continuous2\" Permite estadísticas de varias líneas por variable, como se muestra en una sección posteriorEn el siguiente ejemplo, cada uno de estos argumentos se utiliza para modificar la tabla resumen original:","code":"\nlinelist %>% \n  select(age_years) %>%         # keep only columns of interest \n  tbl_summary(                  # create summary table\n    statistic = age_years ~ \"{mean}\") # print mean of age\nlinelist %>% \n  select(age_years) %>%                       # keep only columns of interest \n  tbl_summary(                                # create summary table\n    statistic = age_years ~ \"({min}, {max})\") # print min and max of age\nlinelist %>% \n  select(age_years, gender, outcome, fever, temp, hospital) %>% # keep only columns of interest\n  tbl_summary(     \n    by = outcome,                                               # stratify entire table by outcome\n    statistic = list(all_continuous() ~ \"{mean} ({sd})\",        # stats and format for continuous columns\n                     all_categorical() ~ \"{n} / {N} ({p}%)\"),   # stats and format for categorical columns\n    digits = all_continuous() ~ 1,                              # rounding for continuous columns\n    type   = all_categorical() ~ \"categorical\",                 # force all categorical levels to display\n    label  = list(                                              # display labels for column names\n      outcome   ~ \"Outcome\",                           \n      age_years ~ \"Age (years)\",\n      gender    ~ \"Gender\",\n      temp      ~ \"Temperature\",\n      hospital  ~ \"Hospital\"),\n    missing_text = \"Missing\"                                    # how missing values should display\n  )## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"descriptive-tables.html","id":"estadísticas-de-varias-líneas-para-variables-continuas","chapter":"17 Tablas descriptivas","heading":"Estadísticas de varias líneas para variables continuas","text":"Si deseas imprimir varias líneas de estadísticas para variables continuas, puedes indicarlo estableciendo type = “continuous2”. Puedes combinar todos los elementos mostrados anteriormente en una tabla eligiendo qué estadísticas quiere mostrar. Para ello, debes indicar la función que deseas obtener una tabla escribiendo el tipo como “continuous2”. El número de valores faltantes se muestra como “Desconocido”.Hay muchas otras formas de modificar estas tablas, incluyendo la adición de valores p, el ajuste del color y los títulos, etc. Muchas de ellas se describen en la documentación (escribe ?tbl_summary en la Consola), y algunas se dan en la sección de Tests estadísticos sencillos.","code":"\nlinelist %>% \n  select(age_years, temp) %>%                      # keep only columns of interest\n  tbl_summary(                                     # create summary table\n    type = all_continuous() ~ \"continuous2\",       # indicate that you want to print multiple statistics \n    statistic = all_continuous() ~ c(\n      \"{mean} ({sd})\",                             # line 1: mean and SD\n      \"{median} ({p25}, {p75})\",                   # line 2: median and IQR\n      \"{min}, {max}\")                              # line 3: min and max\n    )"},{"path":"descriptive-tables.html","id":"base-r-1","chapter":"17 Tablas descriptivas","heading":"17.6 R base","text":"Puedes utilizar la función table() para tabular y cruzar las columnas. diferencia de las opciones anteriores, debes especificar el dataframe cada vez que haga referencia un nombre de columna, como se muestra continuación.ATENCIÓN: Los valores NA (missing) se tabularán menos que se incluya el argumento useNA = \"always\" (que también podría establecerse como “” o “ifany”). .CONSEJO: Puedes utilizar el %$% de magrittr para eliminar la necesidad de repetir las llamadas al dataframe dentro de las funciones de R base. Por ejemplo, lo siguiente podría escribirse linelist %$% table(outcome, useNA = \"always\") Se pueden cruzar varias columnas enumerándolas una tras otra, separadas por comas. Opcionalmente, se puede asignar cada columna un “nombre” como Outcome = linelist$outcome.","code":"\ntable(linelist$outcome, useNA = \"always\")## \n##   Death Recover    <NA> \n##    2582    1983    1323\nage_by_outcome <- table(linelist$age_cat, linelist$outcome, useNA = \"always\") # save table as object\nage_by_outcome   # print table##        \n##         Death Recover <NA>\n##   0-4     471     364  260\n##   5-9     476     391  228\n##   10-14   438     303  200\n##   15-19   323     251  169\n##   20-29   477     367  229\n##   30-49   329     238  187\n##   50-69    33      38   24\n##   70+       3       3    0\n##   <NA>     32      28   26"},{"path":"descriptive-tables.html","id":"proporciones","chapter":"17 Tablas descriptivas","heading":"Proporciones","text":"Para producir las proporciones, pasa la tabla anterior la función prop.table(). Utiliza el argumento margins = para especificar si deseas que las proporciones sean de filas (1), de columnas (2) o de toda la tabla (3). Para mayor claridad, eniazamos la tabla con pipe la función round() de R base, especificando 2 dígitos.","code":"\n# get proportions of table defined above, by rows, rounded\nprop.table(age_by_outcome, 1) %>% round(2)##        \n##         Death Recover <NA>\n##   0-4    0.43    0.33 0.24\n##   5-9    0.43    0.36 0.21\n##   10-14  0.47    0.32 0.21\n##   15-19  0.43    0.34 0.23\n##   20-29  0.44    0.34 0.21\n##   30-49  0.44    0.32 0.25\n##   50-69  0.35    0.40 0.25\n##   70+    0.50    0.50 0.00\n##   <NA>   0.37    0.33 0.30"},{"path":"descriptive-tables.html","id":"totales","chapter":"17 Tablas descriptivas","heading":"Totales","text":"Para añadir los totales de filas y columnas, pasa la tabla addmargins(). Esto funciona tanto para recuentos como para proporciones.","code":"\naddmargins(age_by_outcome)##        \n##         Death Recover <NA>  Sum\n##   0-4     471     364  260 1095\n##   5-9     476     391  228 1095\n##   10-14   438     303  200  941\n##   15-19   323     251  169  743\n##   20-29   477     367  229 1073\n##   30-49   329     238  187  754\n##   50-69    33      38   24   95\n##   70+       3       3    0    6\n##   <NA>     32      28   26   86\n##   Sum    2582    1983 1323 5888"},{"path":"descriptive-tables.html","id":"convertir-en-dataframe","chapter":"17 Tablas descriptivas","heading":"Convertir en dataframe","text":"Convertir un objeto table() directamente en un dataframe es sencillo. continuación se muestra un enfoque:Crea la tabla, sin utilizar useNA = \"always\". En su lugar, convierte los valores NA en “(Missing)” con fct_explicit_na() de forcats.Añade los totales (opcional) pasando por addmargins()Pipe la función R base .data.frame.matrix()Enviar la tabla la función rownames_to_column() de tibble, especificando el nombre de la primera columnaImprime, visualiza o exporta según desees. En este ejemplo utilizamos flextable() del paquete flextable como se describe en la página Tablas para presentaciones. Esto imprimirá en el panel de visualización de RStudio como una bonita imagen HTML.Age CategoryDeathRecover(Missing)Sum0-44713642601,0955-94763912281,09510-1443830320094115-1932325116974320-294773672291,07330-4932923818775450-693338249570+3306(Missing)32282686Sum2,5821,9831,3235,888","code":"\ntable(fct_explicit_na(linelist$age_cat), fct_explicit_na(linelist$outcome)) %>% \n  addmargins() %>% \n  as.data.frame.matrix() %>% \n  tibble::rownames_to_column(var = \"Age Category\") %>% \n  flextable::flextable()"},{"path":"descriptive-tables.html","id":"resources-10","chapter":"17 Tablas descriptivas","heading":"17.7 Recursos","text":"Gran parte de la información de esta página está adaptada de estos recursos y viñetas en línea:gtsummarydplyr","code":""},{"path":"simple-statistical-tests.html","id":"simple-statistical-tests","chapter":"18 Tests estadísticos sencillos","heading":"18 Tests estadísticos sencillos","text":"Esta página muestra cómo realizar tests estadísticos sencillos utilizando R base, rstatix y gtsummary.Prueba o Test T de StudentPrueba o Test de Shapiro-WilkPrueba o Test de suma de rangos de WilcoxonPrueba o Test de Kruskal-WallisPrueba o Test de Chi-cuadradoCorrelaciones entre variables numéricas…Se pueden realizar otras muchas pruebas. Solo mostraremos éstas, las más comunes y enlazaremos con más documentación.Cada uno de los paquetes mencionados tienen unos usos específicos:Utiliza las funciones de R base para imprimir una salida estadística en la consola de RUtiliza las funciones rstatix para devolver los resultados en un dataframe, o si deseas que las pruebas se ejecuten por gruposUtiliza gtsummary si tienes interés en rápidamente tablas listas para su publicación","code":""},{"path":"simple-statistical-tests.html","id":"preparation-9","chapter":"18 Tests estadísticos sencillos","heading":"18.1 Preparación","text":"","code":""},{"path":"simple-statistical-tests.html","id":"cargar-paquetes-10","chapter":"18 Tests estadísticos sencillos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos la función p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes ya instalados con el comando library() de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  skimr,        # get overview of data\n  tidyverse,    # data management + ggplot2 graphics, \n  gtsummary,    # summary statistics and tests\n  rstatix,      # statistics\n  corrr,        # correlation analayis for numeric variables\n  janitor,      # adding totals and percents to tables\n  flextable     # converting tables to HTML\n  )"},{"path":"simple-statistical-tests.html","id":"importar-datos-9","chapter":"18 Tests estadísticos sencillos","heading":"Importar datos","text":"Importaremos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (archivo linelist_cleaned.rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"simple-statistical-tests.html","id":"base-r-2","chapter":"18 Tests estadísticos sencillos","heading":"18.2 ** R base**","text":"Puedes utilizar las funciones de ** R base** para realizar pruebas estadísticas. Los comandos son relativamente sencillos y los resultados se imprimen en la consola de R para su visualización. Sin embargo, las salidas suelen ser listas y, por lo tanto, son más difíciles de manipular en el caso que se desee utilizar los resultados en operaciones posteriores.","code":""},{"path":"simple-statistical-tests.html","id":"tests-t","chapter":"18 Tests estadísticos sencillos","heading":"Tests-T","text":"Un test-t, también llamado “Test t de Student” o “Prueba t de Student”, se utiliza normalmente para determinar si existe una diferencia significativa entre las medias de alguna variable numérica entre dos grupos. Aquí mostraremos la sintaxis para hacer esta prueba dependiendo de si las columnas se encuentran o en el mismo dataframe.Sintaxis 1: Esta es la sintaxis cuando las columnas numéricas y categóricas están en el mismo dataframe. Sitúa la columna numérica en el lado izquierdo de la ecuación y la columna categórica en el lado derecho. Especifica los datos en data =. Opcionalmente, establece paired = TRUE, conf.level = (0.95 por defecto), y alternative = (ya sea “two.sided”, “less”, o “greater”). Escribe ?t.test para obtener más detalles.Sintaxis 2: Puedes comparar dos vectores numéricos separados utilizando esta sintaxis alternativa. Por ejemplo, si las dos columnas están en dataframes diferentes.También se puede utilizar una prueba t de Student para determinar si la media de una muestra es significativamente diferente de algún valor específico. Aquí realizamos una prueba t de una muestra con la media poblacional conocida/hipotética como mu =:","code":"\n## compare mean age by outcome group with a t-test\nt.test(age_years ~ gender, data = linelist)## \n##  Welch Two Sample t-test\n## \n## data:  age_years by gender\n## t = -21.344, df = 4902.3, p-value < 2.2e-16\n## alternative hypothesis: true difference in means between group f and group m is not equal to 0\n## 95 percent confidence interval:\n##  -7.571920 -6.297975\n## sample estimates:\n## mean in group f mean in group m \n##        12.60207        19.53701\nt.test(df1$age_years, df2$age_years)\nt.test(linelist$age_years, mu = 45)"},{"path":"simple-statistical-tests.html","id":"prueba-de-shapiro-wilk","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de Shapiro-Wilk","text":"El test de Shapiro-Wilk puede utilizarse para determinar si una muestra procede de una población distribuida normalmente (un supuesto en muchas otras pruebas y análisis, como la prueba t). Sin embargo, sólo puede utilizarse en una muestra de entre 3 y 5000 observaciones. Para muestras más grandes puede ser útil un gráfico de cuantiles.","code":"\nshapiro.test(linelist$age_years)"},{"path":"simple-statistical-tests.html","id":"test-de-suma-de-rangos-de-wilcoxon","chapter":"18 Tests estadísticos sencillos","heading":"Test de suma de rangos de Wilcoxon","text":"El test de suma de rangos de Wilcoxon, también llamada test U de Mann-Whitney, se utiliza menudo para ayudar determinar si dos muestras numéricas proceden de la misma distribución cuando tus poblaciones se distribuyen normalmente o tienen una varianza desigual.","code":"\n## compare age distribution by outcome group with a wilcox test\nwilcox.test(age_years ~ outcome, data = linelist)## \n##  Wilcoxon rank sum test with continuity correction\n## \n## data:  age_years by outcome\n## W = 2501868, p-value = 0.8308\n## alternative hypothesis: true location shift is not equal to 0"},{"path":"simple-statistical-tests.html","id":"test-de-kruskal-wallis","chapter":"18 Tests estadísticos sencillos","heading":"Test de Kruskal-Wallis","text":"El test de Kruskal-Wallis es una extensión del test de suma de rangos de Wilcoxon. Puede utilizarse para comprobar las diferencias en la distribución de más de dos muestras. Cuando sólo se utilizan dos muestras, los resultados son idénticos los del test de suma de rangos de Wilcoxon.","code":"\n## compare age distribution by outcome group with a kruskal-wallis test\nkruskal.test(age_years ~ outcome, linelist)## \n##  Kruskal-Wallis rank sum test\n## \n## data:  age_years by outcome\n## Kruskal-Wallis chi-squared = 0.045675, df = 1, p-value = 0.8308"},{"path":"simple-statistical-tests.html","id":"test-de-chi-cuadrado","chapter":"18 Tests estadísticos sencillos","heading":"Test de Chi-cuadrado","text":"El test de Chi-cuadrado de Pearson se utiliza para comprobar las diferencias significativas entre grupos categóricos.","code":"\n## compare the proportions in each group with a chi-squared test\nchisq.test(linelist$gender, linelist$outcome)## \n##  Pearson's Chi-squared test with Yates' continuity correction\n## \n## data:  linelist$gender and linelist$outcome\n## X-squared = 0.0011841, df = 1, p-value = 0.9725"},{"path":"simple-statistical-tests.html","id":"rstatix-package","chapter":"18 Tests estadísticos sencillos","heading":"18.3 Paquete rstatix","text":"El paquete rstatix ofrece la posibilidad de ejecutar pruebas estadísticas y recuperar los resultados en un formato “amigable”. Los resultados se encuentran automáticamente en un dataframe para que puedan realizar operaciones posteriores con los resultados. También es fácil agrupar los datos que se pasan las funciones, de modo que las estadísticas se ejecutan para cada grupo.","code":""},{"path":"simple-statistical-tests.html","id":"estadísticas-resumidas-2","chapter":"18 Tests estadísticos sencillos","heading":"Estadísticas resumidas","text":"La función get_summary_stats() es una forma rápida de generar estadísticas de resumen. Únicamente tienes que tienes que seleccionar tu dataframe al aplicar esta función así como especificar las columnas que deseas analizar. Si se especifica ninguna columna, las estadísticas se calculan para todas ellas.Por defecto, la función devuelve una gama completa de estadísticas de resumen: n, max, min, mediana, cuartil 25%, cuartil 75%, IQR, desviación absoluta mediana (mad), media, desviación estándar, error estándar y un intervalo de confianza de la media.Puedes especificar un subconjunto de estadísticas de resumen calcular proporcionando uno de los siguientes valores type =: “full”, “common”, “robust”, “five_number”, “mean_sd”, “mean_se”, “mean_ci”, “median_iqr”, “median_mad”, “quantile”, “mean”, “median”, “min”, “max”.También puede utilizarse con datos agrupados, de forma que se devuelva una fila por cada variable de agrupación:Por último, también se puede utilizar rstatix para realizar las siguientes pruebas estadísticas:","code":"\nlinelist %>%\n  rstatix::get_summary_stats(age, temp)## # A tibble: 2 × 13\n##   variable     n   min   max median    q1    q3   iqr    mad  mean     sd    se    ci\n##   <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl> <dbl> <dbl>\n## 1 age       5802   0    84     13     6    23      17 11.9    16.1 12.6   0.166 0.325\n## 2 temp      5739  35.2  40.8   38.8  38.2  39.2     1  0.741  38.6  0.977 0.013 0.025\nlinelist %>%\n  group_by(hospital) %>%\n  rstatix::get_summary_stats(age, temp, type = \"common\")## # A tibble: 12 × 11\n##    hospital                             variable     n   min   max median   iqr  mean     sd    se    ci\n##    <chr>                                <fct>    <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> <dbl>\n##  1 Central Hospital                     age        445   0    58     12    15    15.7 12.5   0.591 1.16 \n##  2 Central Hospital                     temp       450  35.2  40.4   38.8   1    38.5  0.964 0.045 0.089\n##  3 Military Hospital                    age        884   0    72     14    18    16.1 12.4   0.417 0.818\n##  4 Military Hospital                    temp       873  35.3  40.5   38.8   1    38.6  0.952 0.032 0.063\n##  5 Missing                              age       1441   0    76     13    17    16.0 12.9   0.339 0.665\n##  6 Missing                              temp      1431  35.8  40.6   38.9   1    38.6  0.97  0.026 0.05 \n##  7 Other                                age        873   0    69     13    17    16.0 12.5   0.422 0.828\n##  8 Other                                temp       862  35.7  40.8   38.8   1.1  38.5  1.01  0.034 0.067\n##  9 Port Hospital                        age       1739   0    68     14    18    16.3 12.7   0.305 0.598\n## 10 Port Hospital                        temp      1713  35.5  40.6   38.8   1.1  38.6  0.981 0.024 0.046\n## 11 St. Mark's Maternity Hospital (SMMH) age        420   0    84     12    15    15.7 12.4   0.606 1.19 \n## 12 St. Mark's Maternity Hospital (SMMH) temp       410  35.9  40.6   38.8   1.1  38.5  0.983 0.049 0.095"},{"path":"simple-statistical-tests.html","id":"test-t","chapter":"18 Tests estadísticos sencillos","heading":"Test-T","text":"Utiliza una sintaxis de fórmula para especificar las columnas numéricas y categóricas:Utiliza ~ 1 y especifica mu = para un test-T de una muestra. Esto también puede hacerse por grupo.Si procede, las pruebas estadísticas pueden realizarse por grupos, como se muestra continuación:","code":"\nlinelist %>% \n  t_test(age_years ~ gender)## # A tibble: 1 × 10\n##   .y.       group1 group2    n1    n2 statistic    df        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl> <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803     -21.3 4902. 9.89e-97 9.89e-97 ****\nlinelist %>% \n  t_test(age_years ~ 1, mu = 30)## # A tibble: 1 × 7\n##   .y.       group1 group2         n statistic    df     p\n## * <chr>     <chr>  <chr>      <int>     <dbl> <dbl> <dbl>\n## 1 age_years 1      null model  5802     -84.2  5801     0\nlinelist %>% \n  group_by(gender) %>% \n  t_test(age_years ~ 1, mu = 18)## # A tibble: 3 × 8\n##   gender .y.       group1 group2         n statistic    df         p\n## * <chr>  <chr>     <chr>  <chr>      <int>     <dbl> <dbl>     <dbl>\n## 1 f      age_years 1      null model  2807    -29.8   2806 7.52e-170\n## 2 m      age_years 1      null model  2803      5.70  2802 1.34e-  8\n## 3 <NA>   age_years 1      null model   192     -3.80   191 1.96e-  4"},{"path":"simple-statistical-tests.html","id":"prueba-de-shapiro-wilk-1","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de Shapiro-Wilk","text":"Como ya se ha dicho, el tamaño de la muestra debe estar entre 3 y 5000.","code":"\nlinelist %>% \n  head(500) %>%            # first 500 rows of case linelist, for example only\n  shapiro_test(age_years)## # A tibble: 1 × 3\n##   variable  statistic        p\n##   <chr>         <dbl>    <dbl>\n## 1 age_years     0.917 6.67e-16"},{"path":"simple-statistical-tests.html","id":"prueba-de-suma-de-rangos-de-wilcoxon","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de suma de rangos de Wilcoxon","text":"","code":"\nlinelist %>% \n  wilcox_test(age_years ~ gender)## # A tibble: 1 × 9\n##   .y.       group1 group2    n1    n2 statistic        p    p.adj p.adj.signif\n## * <chr>     <chr>  <chr>  <int> <int>     <dbl>    <dbl>    <dbl> <chr>       \n## 1 age_years f      m       2807  2803   2829274 3.47e-74 3.47e-74 ****"},{"path":"simple-statistical-tests.html","id":"prueba-de-kruskal-wallis","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de Kruskal-Wallis","text":"También conocida como la prueba U de Mann-Whitney.","code":"\nlinelist %>% \n  kruskal_test(age_years ~ outcome)## # A tibble: 1 × 6\n##   .y.           n statistic    df     p method        \n## * <chr>     <int>     <dbl> <int> <dbl> <chr>         \n## 1 age_years  5888    0.0457     1 0.831 Kruskal-Wallis"},{"path":"simple-statistical-tests.html","id":"prueba-de-chi-cuadrado","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de Chi-cuadrado","text":"La función para la prueba de chi-cuadrado funciona con tablas, así que primero creamos una tabulación cruzada. Hay muchas formas de crear una tabulación cruzada (véase Tablas descriptivas), pero aquí utilizamos tabyl() de janitor y eliminamos la columna más la izquierda de las etiquetas de valores antes de pasarla chisq_test().Se pueden ejecutar muchas más funciones y pruebas estadísticas con las funciones de rstatix. Consulta la documentación de rstatix o escribiendo ?rstatix.","code":"\nlinelist %>% \n  tabyl(gender, outcome) %>% \n  select(-1) %>% \n  chisq_test()## # A tibble: 1 × 6\n##       n statistic     p    df method          p.signif\n## * <dbl>     <dbl> <dbl> <int> <chr>           <chr>   \n## 1  5888      3.53 0.473     4 Chi-square test ns"},{"path":"simple-statistical-tests.html","id":"stats_gt","chapter":"18 Tests estadísticos sencillos","heading":"18.4 Paquete gtsummary","text":"Utilizaa gtsummary si quieres añadir los resultados de una prueba estadística una tabla estéticamente presentada, creada con este paquete (como se describe en la sección gtsummary del capítulo Tablas descriptivas).La realización de pruebas estadísticas de comparación con tbl_summary se lleva cabo añadiendo la función add_p una tabla y especificando qué prueba utilizar. Es posible obtener p-valores corregidos para múltiples pruebas utilizando la función add_q. Ejecuta ?tbl_summary para obtener más detalles.","code":""},{"path":"simple-statistical-tests.html","id":"prueba-de-chi-cuadrado-1","chapter":"18 Tests estadísticos sencillos","heading":"Prueba de Chi-cuadrado","text":"Compara las proporciones de una variable categórica en dos grupos. La prueba estadística por defecto de add_p(), cuando se aplica una variable categórica es realizar una prueba de independencia de chi-cuadrado con corrección de continuidad, pero si algúna celda de valores esperados es inferior 5, se utiliza una prueba exacta de Fisher.","code":"\nlinelist %>% \n  select(gender, outcome) %>%    # keep variables of interest\n  tbl_summary(by = outcome) %>%  # produce summary table and specify grouping variable\n  add_p()                        # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"tests-t-1","chapter":"18 Tests estadísticos sencillos","heading":"Tests-T","text":"Compara la diferencia de medias de una variable continua en dos grupos. Por ejemplo, hace la comparación de la media de edad por resultado del paciente.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%             # keep variables of interest\n  tbl_summary(                               # produce summary table\n    statistic = age_years ~ \"{mean} ({sd})\", # specify what statistics to show\n    by = outcome) %>%                        # specify the grouping variable\n  add_p(age_years ~ \"t.test\")                # specify what tests to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"test-de-suma-de-rangos-de-wilcoxon-1","chapter":"18 Tests estadísticos sencillos","heading":"Test de suma de rangos de Wilcoxon","text":"Compara la distribución de una variable continua en dos grupos. Por defecto se utiliza la prueba de suma de rangos de Wilcoxon y la mediana (IQR) cuando se comparan dos grupos. Sin embargo, para datos distribuidos normalmente o para comparar varios grupos, la prueba de Kruskal-wallis es más apropiada.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (this is default so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"wilcox.test\")                     # specify what test to perform (default so could leave brackets empty)## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"test-de-kruskal-wallis-1","chapter":"18 Tests estadísticos sencillos","heading":"Test de Kruskal-Wallis","text":"Se usa para comparar la distribución de una variable continua en dos o más grupos, independientemente de que los datos se distribuyan normalmente.","code":"\nlinelist %>% \n  select(age_years, outcome) %>%                       # keep variables of interest\n  tbl_summary(                                         # produce summary table\n    statistic = age_years ~ \"{median} ({p25}, {p75})\", # specify what statistic to show (default, so could remove)\n    by = outcome) %>%                                  # specify the grouping variable\n  add_p(age_years ~ \"kruskal.test\")                    # specify what test to perform## 1323 observations missing `outcome` have been removed. To include these observations, use `forcats::fct_explicit_na()` on `outcome` column before passing to `tbl_summary()`."},{"path":"simple-statistical-tests.html","id":"correlations","chapter":"18 Tests estadísticos sencillos","heading":"18.5 Correlaciones","text":"La correlación entre variables numéricas puede investigarse con el paquete corrr de tidyverse. Permite calcular las correlaciones mediante los test de Pearson, tau de Kendall o rho de Spearman. El paquete crea una tabla y también tiene una función para representar automáticamente los valores.","code":"\ncorrelation_tab <- linelist %>% \n  select(generation, age, ct_blood, days_onset_hosp, wt_kg, ht_cm) %>%   # keep numeric variables of interest\n  correlate()      # create correlation table (using default pearson)\n\ncorrelation_tab    # print## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp    wt_kg    ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>    <dbl>    <dbl>\n## 1 generation        NA       -0.0222    0.179         -0.288    -0.0302  -0.00942\n## 2 age               -0.0222  NA         0.00849       -0.000635  0.833    0.877  \n## 3 ct_blood           0.179    0.00849  NA             -0.600    -0.00636  0.0181 \n## 4 days_onset_hosp   -0.288   -0.000635 -0.600         NA         0.0153  -0.00953\n## 5 wt_kg             -0.0302   0.833    -0.00636        0.0153   NA        0.884  \n## 6 ht_cm             -0.00942  0.877     0.0181        -0.00953   0.884   NA\n## remove duplicate entries (the table above is mirrored) \ncorrelation_tab <- correlation_tab %>% \n  shave()\n\n## view correlation table \ncorrelation_tab## # A tibble: 6 × 7\n##   term            generation       age ct_blood days_onset_hosp  wt_kg ht_cm\n##   <chr>                <dbl>     <dbl>    <dbl>           <dbl>  <dbl> <dbl>\n## 1 generation        NA       NA        NA              NA       NA        NA\n## 2 age               -0.0222  NA        NA              NA       NA        NA\n## 3 ct_blood           0.179    0.00849  NA              NA       NA        NA\n## 4 days_onset_hosp   -0.288   -0.000635 -0.600          NA       NA        NA\n## 5 wt_kg             -0.0302   0.833    -0.00636         0.0153  NA        NA\n## 6 ht_cm             -0.00942  0.877     0.0181         -0.00953  0.884    NA\n## plot correlations \nrplot(correlation_tab)"},{"path":"simple-statistical-tests.html","id":"resources-11","chapter":"18 Tests estadísticos sencillos","heading":"18.6 Recursos","text":"Gran parte de la información de esta página está adaptada de los siguientes recursos y viñetas en línea:gtsummarydplyrcorrrcorrelaciones en sthda","code":""},{"path":"univariate-and-multivariable-regression.html","id":"univariate-and-multivariable-regression","chapter":"19 Regresión univariante y multivariable","heading":"19 Regresión univariante y multivariable","text":"Esta página muestra como se pueden emplear las funciones de regresión de R base , como glm() y el paquete gtsummary para observar las asociaciones entre variables (por ejemplo, odds ratios, risk ratios y hazard ratios). También utiliza funciones como tidy() del paquete broom para limpiar los resultados de la regresión.Univariante: tablas de dos por dosEstratificado: estimaciones mantel-haenszelMultivariable: selección de variables, selección de modelos, tabla finalForest plotsPara la regresión de riesgos proporcionales de Cox, véase la página de análisis de supervivencia.NOTA: Utilizamos el término multivariable para referirnos una regresión con múltiples variables explicativas. En este sentido, un modelo multivariante sería una regresión con varios resultados - véase este editorial para más detalles.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"preparation-9","chapter":"19 Regresión univariante y multivariable","heading":"19.1 Preparación","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"cargar-paquetes-11","chapter":"19 Regresión univariante y multivariable","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para realizar los análisis. En este manual se hace énfasis en en el empleo de p_load() de pacman, que instala el paquete si es necesario y lo carga para tu uso. Los paquetes ya instalados también pueden cargarse empleando library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # File import\n  here,         # File locator\n  tidyverse,    # data management + ggplot2 graphics, \n  stringr,      # manipulate text strings \n  purrr,        # loop over objects in a tidy way\n  gtsummary,    # summary statistics and tests \n  broom,        # tidy up results from regressions\n  lmtest,       # likelihood-ratio tests\n  parameters,   # alternative to tidy up results from regressions\n  see          # alternative to visualise forest plots\n  )"},{"path":"univariate-and-multivariable-regression.html","id":"importar-datos-10","chapter":"19 Regresión univariante y multivariable","heading":"Importar datos","text":"Importaremos los datos de casos de una epidemia de ébola simulada. Para seguir el proceso, clica aquí para descargar la base de datos linelist “limpia” (como archivo .rds). Importa tus datos con la función import() del paquete rio (la cual acepta múltiples tipos de archivos como .xlsx, .rds, .csv - Checa la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas de la base de datos linelist.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"univariate-and-multivariable-regression.html","id":"datos-limpios","chapter":"19 Regresión univariante y multivariable","heading":"Datos limpios","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"almacenar-las-variables-explicativas","chapter":"19 Regresión univariante y multivariable","heading":"Almacenar las variables explicativas","text":"Almacenamos en un vector de caracteres los nombres de las columnas explicativas. Esto se explicará más adelante.","code":"\n## define variables of interest \nexplanatory_vars <- c(\"gender\", \"fever\", \"chills\", \"cough\", \"aches\", \"vomit\")"},{"path":"univariate-and-multivariable-regression.html","id":"convertir-a-1s-y-0s","chapter":"19 Regresión univariante y multivariable","heading":"Convertir a 1’s y 0’s","text":"continuación convertimos las columnas explicativas de “sí”/“”, “m”/“f”, y “muerto”/“vivo” 1 / 0, para cumplir con las expectativas de los modelos de regresión logística. Para hacer esto de manera eficiente, utilizaremos across() de dplyr para transformar varias columnas la vez. La función que aplicamos cada columna es case_when() (también de dplyr) que aplica la lógica para convertir los valores especificados en 1’s y 0’s. Mira las secciones sobre across() y case_when() en la página de Limpieza de datos y funciones básicas).Nota: el “.” que aparece continuación representa la columna que está siendo procesada por across() en ese momento.","code":"\n## convert dichotomous variables to 0/1 \nlinelist <- linelist %>%  \n  mutate(across(                                      \n    .cols = all_of(c(explanatory_vars, \"outcome\")),  ## for each column listed and \"outcome\"\n    .fns = ~case_when(                              \n      . %in% c(\"m\", \"yes\", \"Death\")   ~ 1,           ## recode male, yes and death to 1\n      . %in% c(\"f\", \"no\",  \"Recover\") ~ 0,           ## female, no and recover to 0\n      TRUE                            ~ NA_real_)    ## otherwise set to missing\n    )\n  )"},{"path":"univariate-and-multivariable-regression.html","id":"eliminar-las-filas-con-valores-perdidos","chapter":"19 Regresión univariante y multivariable","heading":"Eliminar las filas con valores perdidos","text":"Para eliminar las filas con valores perdidos, se puede utilizar la función drop_na() de tidyr. Sin embargo, sólo queremos hacer esto para las filas las que les faltan valores en las columnas de interés.Lo primero que debemos hacer es asegurarnos de que nuestro vector explanatory_vars incluye la columna age (age habría producido un error en la operación anterior case_when(), que sólo era para variables dicotómicas). continuación, escribimos un pipe uniendo linelist con drop_na() para eliminar cualquier fila con valores perdidos en la columna outcome o en cualquiera de las columnas explanatory_vars.Antes de ejecutar el código, podemos comprobar el número de filas inicial de linelist empleando nrow(linelist).Podremos checar el número de filas que quedan en linelist tras la operación empleando nrow(linelist).","code":"\n## add in age_category to the explanatory vars \nexplanatory_vars <- c(explanatory_vars, \"age_cat\")\n\n## drop rows with missing information for variables of interest \nlinelist <- linelist %>% \n  drop_na(any_of(c(\"outcome\", explanatory_vars)))"},{"path":"univariate-and-multivariable-regression.html","id":"univariate","chapter":"19 Regresión univariante y multivariable","heading":"19.2 Univariante","text":"Al igual que en la página sobre Tablas descriptivas, en función de la tarea que vayas realizar, podremos elegir que función emplear. continuación presentamos dos opciones para realizar análisis univariantes:Puedes utilizar las funciones disponibles en R base para imprimir rápidamente los resultados en la consola. Después, puedes utilizar el paquete broom para convertir esos outputs formato tidy.Puedes utilizar las funciones disponibles en R base para imprimir rápidamente los resultados en la consola. Después, puedes utilizar el paquete broom para convertir esos outputs formato tidy.Puedes utilizar el paquete gtsummary para modelar y obtener resultados en tablas listas para su publicación.Puedes utilizar el paquete gtsummary para modelar y obtener resultados en tablas listas para su publicación.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"r-base-1","chapter":"19 Regresión univariante y multivariable","heading":"R base","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"regresión-lineal","chapter":"19 Regresión univariante y multivariable","heading":"Regresión lineal","text":"La función lm() de R base realiza una regresión lineal, evaluando la relación entre la respuesta numérica y las variables explicativas que se supone tienen una relación lineal.Para ello, proporciona la ecuación como una fórmula, con los nombres de las columnas de respuesta y explicativa separados por una tilde ~. Además, especifica la base de datos data =. Finalmente, define los resultados del modelo como un objeto R, para poder utilizarlos más tarde.continuación, puedes ejecutar summary() en los resultados del modelo para ver los coeficientes (estimaciones), el valor P, los residuos y otras medidas.También se puede utilizar la función tidy() del paquete broom para obtener los resultados en una tabla. Lo que nos dicen los resultados es que por cada año de aumento de la edad la altura aumenta 3,5 cm y esto es estadísticamente significativo.También podemos utilizar esta regresión para añadirla un ggplot, para hacer esto, primero juntamos los puntos de los datos observados y la línea ajustada en un dataframe utilizando la función augment() de broom.También es posible añadir una recta de regresión lineal en ggplot utilizando la función geom_smooth().Consulta la sección de recursos al final de este capítulo para consultar tutoriales más detallados.","code":"\nlm_results <- lm(ht_cm ~ age, data = linelist)\nsummary(lm_results)## \n## Call:\n## lm(formula = ht_cm ~ age, data = linelist)\n## \n## Residuals:\n##      Min       1Q   Median       3Q      Max \n## -128.579  -15.854    1.177   15.887  175.483 \n## \n## Coefficients:\n##             Estimate Std. Error t value Pr(>|t|)    \n## (Intercept)  69.9051     0.5979   116.9   <2e-16 ***\n## age           3.4354     0.0293   117.2   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Residual standard error: 23.75 on 4165 degrees of freedom\n## Multiple R-squared:  0.7675, Adjusted R-squared:  0.7674 \n## F-statistic: 1.375e+04 on 1 and 4165 DF,  p-value: < 2.2e-16\ntidy(lm_results)## # A tibble: 2 × 5\n##   term        estimate std.error statistic p.value\n##   <chr>          <dbl>     <dbl>     <dbl>   <dbl>\n## 1 (Intercept)    69.9     0.598       117.       0\n## 2 age             3.44    0.0293      117.       0\n## pull the regression points and observed data in to one dataset\npoints <- augment(lm_results)\n\n## plot the data using age as the x-axis \nggplot(points, aes(x = age)) + \n  ## add points for height \n  geom_point(aes(y = ht_cm)) + \n  ## add your regression line \n  geom_line(aes(y = .fitted), colour = \"red\")\n## add your data to a plot \n ggplot(linelist, aes(x = age, y = ht_cm)) + \n  ## show points\n  geom_point() + \n  ## add a linear regression \n  geom_smooth(method = \"lm\", se = FALSE)## `geom_smooth()` using formula = 'y ~ x'"},{"path":"univariate-and-multivariable-regression.html","id":"regresión-logística","chapter":"19 Regresión univariante y multivariable","heading":"Regresión logística","text":"La función glm() del paquete stats (parte de R base) se utiliza para ajustar los modelos lineales generalizados (GLM).glm() puede utilizarse para la regresión logística univariante y multivariable (por ejemplo, para obtener Odds Ratios). Aquí están las partes principales:formula = El modelo se proporciona glm() como una ecuación, con el resultado la izquierda y las variables explicativas la derecha de una tilde ~.family = Determina el tipo de modelo ejecutar. Para la regresión logística, utiliza family = \"binomial\", para poisson utiliza family = \"poisson\". Otros ejemplos se encuentran en la tabla siguiente.data = Especifica tu base de datos.Si es necesario, también puede especificar la función de enlace mediante la sintaxis family = familytype(link = \"linkfunction\")). Puedes leer más en la documentación sobre otras familias y argumentos opcionales como weights = y subset = (?glm).Cuando se ejecuta glm() lo más habitual es guardar los resultados como un objeto R. continuación, se pueden mostrar los resultados en la consola utilizando summary() como se muestra continuación, o realizar otras operaciones con los resultados (por ejemplo, exponenciar).Si necesitas ejecutar una regresión binomial negativa, puede utilizar el paquete MASS; el cual contiene la función glm.nb() que utiliza la misma sintaxis que glm().Para un recorrido por diferentes regresiones, consulta la página de estadísticas de UCLA.","code":"\n# arguments for glm()\nglm(formula, family, data, weights, subset, ...)"},{"path":"univariate-and-multivariable-regression.html","id":"univariante-glm","chapter":"19 Regresión univariante y multivariable","heading":"Univariante glm()","text":"En este ejemplo estamos evaluando la asociación entre diferentes categorías de edad y el resultado de muerte (codificado como 1 en la sección anterior “Preparación”). continuación se muestra un modelo univariante de outcome por age_cat. Guardamos la salida del modelo como model y luego la imprimimos con summary() en la consola. Observa que las estimaciones proporcionadas son las probabilidades logarítmicas (log odds) y que el nivel de referencia es el primer nivel del factor age_cat (“0-4”).Para modificar el nivel de referencia de una variable determinada, asegúrate de que la columna es del tipo Factor y mueve el nivel deseado la primera posición con fct_relevel() (véase la página sobre Factores). Por ejemplo, continuación tomamos la columna age_cat y establecemos “20-29” como línea de base antes de conectar mediante pipes el dataframe modificado con glm().","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nsummary(model)## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = linelist)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.339  -1.278   1.024   1.080   1.354  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)   \n## (Intercept)   0.233738   0.072805   3.210  0.00133 **\n## age_cat5-9   -0.062898   0.101733  -0.618  0.53640   \n## age_cat10-14  0.138204   0.107186   1.289  0.19726   \n## age_cat15-19 -0.005565   0.113343  -0.049  0.96084   \n## age_cat20-29  0.027511   0.102133   0.269  0.78765   \n## age_cat30-49  0.063764   0.113771   0.560  0.57517   \n## age_cat50-69 -0.387889   0.259240  -1.496  0.13459   \n## age_cat70+   -0.639203   0.915770  -0.698  0.48518   \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4\nlinelist %>% \n  mutate(age_cat = fct_relevel(age_cat, \"20-29\", after = 0)) %>% \n  glm(formula = outcome ~ age_cat, family = \"binomial\") %>% \n  summary()## \n## Call:\n## glm(formula = outcome ~ age_cat, family = \"binomial\", data = .)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.339  -1.278   1.024   1.080   1.354  \n## \n## Coefficients:\n##              Estimate Std. Error z value Pr(>|z|)    \n## (Intercept)   0.26125    0.07163   3.647 0.000265 ***\n## age_cat0-4   -0.02751    0.10213  -0.269 0.787652    \n## age_cat5-9   -0.09041    0.10090  -0.896 0.370220    \n## age_cat10-14  0.11069    0.10639   1.040 0.298133    \n## age_cat15-19 -0.03308    0.11259  -0.294 0.768934    \n## age_cat30-49  0.03625    0.11302   0.321 0.748390    \n## age_cat50-69 -0.41540    0.25891  -1.604 0.108625    \n## age_cat70+   -0.66671    0.91568  -0.728 0.466546    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5705.1  on 4159  degrees of freedom\n## AIC: 5721.1\n## \n## Number of Fisher Scoring iterations: 4"},{"path":"univariate-and-multivariable-regression.html","id":"imprimir-resultados","chapter":"19 Regresión univariante y multivariable","heading":"Imprimir resultados","text":"En la mayoría de los casos, para su empleo posterior, es necesario hacer modificaciones los resultados obtenidos anteriormente. La función tidy() del paquete broom es útil de cara hacer más presentables los resultados de nuestros modelos.Aquí demostramos cómo combinar los resultados del modelo con una tabla de recuento.Obtén las estimaciones de log odds ratio exponenciadas y los intervalos de confianza pasando el modelo tidy() y estableciendo exponentiate = TRUE y conf.int = TRUE.continuación, se muestra el objeto tibble model resultante:Combina estos resultados del modelo con una tabla de recuentos. continuación, creamos la tabla cruzada de recuentos con la función tabyl() de janitor, como se explica en la página de tablas descriptivas.Este es el aspecto de este dataframe counts_table:Ahora podemos unir counts_table y los resultados del model horizontalmente con bind_cols() (dplyr). Recuerda que con bind_cols() las filas de los dos dataframes deben estar perfectamente alineadas. En este código, como estamos enlazando mediante pipes, utilizamos . para representar el objeto counts_table mientras lo enlazamos con el modelo. Para terminar el proceso, utilizamos select() para elegir las columnas deseadas y determinar su orden, y finalmente aplicamos la función round() de R base en todas las columnas numéricas para especificar 2 decimales.Este es el aspecto del dataframe combinado, impreso de forma agradable como una imagen con una función de flextable. En Tablas para presentación se explica cómo personalizar dichas tablas con flextable, o bien puede utilizar otros paquetes como knitr o GT.","code":"\nmodel <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist) %>% \n  tidy(exponentiate = TRUE, conf.int = TRUE) %>%        # exponentiate and produce CIs\n  mutate(across(where(is.numeric), round, digits = 2))  # round all numeric columns\ncounts_table <- linelist %>% \n  janitor::tabyl(age_cat, outcome)\ncombined <- counts_table %>%           # begin with table of counts\n  bind_cols(., model) %>%              # combine with the outputs of the regression \n  select(term, 2:3, estimate,          # select and re-order cols\n         conf.low, conf.high, p.value) %>% \n  mutate(across(where(is.numeric), round, digits = 2)) ## round to 2 decimal places\ncombined <- combined %>% \n  flextable::qflextable()"},{"path":"univariate-and-multivariable-regression.html","id":"loops-con-múltiples-modelos-univariantes","chapter":"19 Regresión univariante y multivariable","heading":"Loops con múltiples modelos univariantes","text":"continuación presentamos un método que utiliza glm() y tidy(). Para un enfoque más sencillo, véase la sección sobre gtsummary.Para ejecutar los modelos en varias variables de exposición para producir odds ratios univariantes (es decir, sin controlar entre sí), se puede utilizar el enfoque siguiente. Utiliza str_c() de stringr para crear fórmulas univariantes (véase Caracteres y cadenas), ejecuta la regresión glm() en cada fórmula, pasa cada resultado de glm() tidy() y finalmente junta todos los resultados de los modelos resultantes con bind_rows() de tidyr. Este enfoque utiliza map() del paquete purrr para iterar - véase la página sobre Iteración, bucles y listas para más información sobre esta herramienta.Crea un vector de nombres de columnas de las variables explicativas. Ya lo tenemos como explanatory_vars de la sección de preparación de esta página.Crea un vector de nombres de columnas de las variables explicativas. Ya lo tenemos como explanatory_vars de la sección de preparación de esta página.Utiliza str_c() para crear múltiples fórmulas de cadena, con el resultado la izquierda, y un nombre de columna de explanatory_vars la derecha. El punto . sustituye al nombre de la columna en explanatory_vars.Utiliza str_c() para crear múltiples fórmulas de cadena, con el resultado la izquierda, y un nombre de columna de explanatory_vars la derecha. El punto . sustituye al nombre de la columna en explanatory_vars.Pasa estas fórmulas de cadena map() y establece ~glm() como la función aplicar cada entrada. Dentro de glm(), establece la fórmula de regresión como .formula(.x), donde .x se sustituirá por la fórmula de cadena definida en el paso anterior. map() realizará un bucle sobre cada una de las fórmulas de cadena, ejecutando regresiones para cada una.Pasa estas fórmulas de cadena map() y establece ~glm() como la función aplicar cada entrada. Dentro de glm(), establece la fórmula de regresión como .formula(.x), donde .x se sustituirá por la fórmula de cadena definida en el paso anterior. map() realizará un bucle sobre cada una de las fórmulas de cadena, ejecutando regresiones para cada una.Los resultados de este primer map() se pasan un segundo comando map(), que aplica tidy() los resultados de la regresión.Los resultados de este primer map() se pasan un segundo comando map(), que aplica tidy() los resultados de la regresión.Por último, la salida de la segunda función map() (una lista de dataframes ordenados) se condensa con bind_rows(), dando lugar un dataframe con todos los resultados univariantes.Por último, la salida de la segunda función map() (una lista de dataframes ordenados) se condensa con bind_rows(), dando lugar un dataframe con todos los resultados univariantes.Esta vez, el objeto final models es más largo porque ahora representa los resultados combinados de varias regresiones univariantes. Clica para ver todas las filas de model.Como antes, podemos crear una tabla de recuentos partir de linelist para cada variable explicativa, vincularla models y hacer una bonita tabla. Comenzamos con las variables, e iteramos través de ellas con map(). Iteramos través de una función definida por el usuario que implica la creación de una tabla de recuentos con funciones dplyr. Luego se combinan los resultados y se vinculan con los resultados del modelo models.continuación se muestra el aspecto del dataframe. Consulta la página sobre Tablas para presentación para obtener ideas sobre cómo convertir esta tabla en una bonita tabla HTML (por ejemplo, con flextable).","code":"\nexplanatory_vars %>% str_c(\"outcome ~ \", .)## [1] \"outcome ~ gender\"  \"outcome ~ fever\"   \"outcome ~ chills\"  \"outcome ~ cough\"   \"outcome ~ aches\"  \n## [6] \"outcome ~ vomit\"   \"outcome ~ age_cat\"\nmodels <- explanatory_vars %>%       # begin with variables of interest\n  str_c(\"outcome ~ \", .) %>%         # combine each variable into formula (\"outcome ~ variable of interest\")\n  \n  # iterate through each univariate formula\n  map(                               \n    .f = ~glm(                       # pass the formulas one-by-one to glm()\n      formula = as.formula(.x),      # within glm(), the string formula is .x\n      family = \"binomial\",           # specify type of glm (logistic)\n      data = linelist)) %>%          # dataset\n  \n  # tidy up each of the glm regression outputs from above\n  map(\n    .f = ~tidy(\n      .x, \n      exponentiate = TRUE,           # exponentiate \n      conf.int = TRUE)) %>%          # return confidence intervals\n  \n  # collapse the list of regression outputs in to one data frame\n  bind_rows() %>% \n  \n  # round all numeric columns\n  mutate(across(where(is.numeric), round, digits = 2))\n## for each explanatory variable\nuniv_tab_base <- explanatory_vars %>% \n  map(.f = \n    ~{linelist %>%                ## begin with linelist\n        group_by(outcome) %>%     ## group data set by outcome\n        count(.data[[.x]]) %>%    ## produce counts for variable of interest\n        pivot_wider(              ## spread to wide format (as in cross-tabulation)\n          names_from = outcome,\n          values_from = n) %>% \n        drop_na(.data[[.x]]) %>%         ## drop rows with missings\n        rename(\"variable\" = .x) %>%      ## change variable of interest column to \"variable\"\n        mutate(variable = as.character(variable))} ## convert to character, else non-dichotomous (categorical) variables come out as factor and cant be merged\n      ) %>% \n  \n  ## collapse the list of count outputs in to one data frame\n  bind_rows() %>% \n  \n  ## merge with the outputs of the regression \n  bind_cols(., models) %>% \n  \n  ## only keep columns interested in \n  select(term, 2:3, estimate, conf.low, conf.high, p.value) %>% \n  \n  ## round decimal places\n  mutate(across(where(is.numeric), round, digits = 2))"},{"path":"univariate-and-multivariable-regression.html","id":"reg_gt_uni","chapter":"19 Regresión univariante y multivariable","heading":"Paquete gtsummary","text":"continuación presentamos el uso de tbl_uvregression() del paquete gtsummary. Al igual que en la página sobre Tablas descriptivas, las funciones de gtsummary hacen un buen trabajo la hora de realizar estadísticas y producir outputs con aspecto profesional. Esta función produce una tabla de resultados de regresión univariante.Seleccionamos sólo las columnas necesarias de linelist (variables explicativas y la variable de resultado) y las introducimos en tbl_uvregression(). Vamos ejecutar una regresión univariante en cada una de las columnas que definimos como explanatory_vars en la sección de preparación de datos (sexo, fiebre, escalofríos, tos, dolores, vómitos y age_cat).Dentro de la propia función, proporcionamos el method = como glm (sin comillas), la columna de resultado y = (outcome), especificamos method.args = que queremos ejecutar la regresión logística través de family = binomial, y le decimos que exponencie los resultados.La salida es HTML y contiene el recuento de cada variable.Hay muchas modificaciones que se pueden hacer al output de esta tabla, como ajustar las etiquetas de texto, poner en negrita las filas por tu valor p, etc. Puedes consultar tutoriales aquí y en internet.","code":"\nuniv_tab <- linelist %>% \n  dplyr::select(explanatory_vars, outcome) %>% ## select variables of interest\n\n  tbl_uvregression(                         ## produce univariate table\n    method = glm,                           ## define regression want to run (generalised linear model)\n    y = outcome,                            ## define outcome variable\n    method.args = list(family = binomial),  ## define what type of glm want to run (logistic)\n    exponentiate = TRUE                     ## exponentiate to produce odds ratios (rather than log odds)\n  )\n\n## view univariate results table \nuniv_tab"},{"path":"univariate-and-multivariable-regression.html","id":"stratified","chapter":"19 Regresión univariante y multivariable","heading":"19.3 Estratificado","text":"Actualmente, el análisis estratificado para gtsummary se está desarrollando. Esta página se actualizará su debido tiempo.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"multivariable","chapter":"19 Regresión univariante y multivariable","heading":"19.4 Multivariable","text":"Para el análisis multivariable, volvemos presentar dos enfoques:glm() y tidy()Paquete gtsummaryEl flujo de trabajo es similar para cada uno de ellos, siendo diferente el último paso al elaborar una tabla final.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"realizar-análisis-multivariable","chapter":"19 Regresión univariante y multivariable","heading":"Realizar análisis multivariable","text":"Aquí utilizamos glm() pero en este caso, añadiremos más variables al lado derecho de la ecuación, separadas por símbolos de suma (+).Para ejecutar el modelo con todas nuestras variables explicativas ejecutaríamos:Si quieres incluir dos variables y una interacción entre ellas puede separarlas con un asterisco * en lugar de un +. Si sólo especifica la interacción, sepáralas con dos puntos :. Por ejemplo:Opcionalmente, puedes utilizar este código para aprovechar el vector predefinido de nombres de columnas y volver crear el comando anterior utilizando str_c(). Esto puede ser útil si los nombres de sus variables explicativas cambian, o si quieres escribirlas todos de nuevo.","code":"\nmv_reg <- glm(outcome ~ gender + fever + chills + cough + aches + vomit + age_cat, family = \"binomial\", data = linelist)\n\nsummary(mv_reg)## \n## Call:\n## glm(formula = outcome ~ gender + fever + chills + cough + aches + \n##     vomit + age_cat, family = \"binomial\", data = linelist)\n## \n## Deviance Residuals: \n##    Min      1Q  Median      3Q     Max  \n## -1.383  -1.279   1.029   1.078   1.346  \n## \n## Coefficients:\n##               Estimate Std. Error z value Pr(>|z|)\n## (Intercept)   0.069054   0.131726   0.524    0.600\n## gender        0.002448   0.065133   0.038    0.970\n## fever         0.004309   0.080522   0.054    0.957\n## chills        0.034112   0.078924   0.432    0.666\n## cough         0.138584   0.089909   1.541    0.123\n## aches        -0.070705   0.104078  -0.679    0.497\n## vomit         0.086098   0.062618   1.375    0.169\n## age_cat5-9   -0.063562   0.101851  -0.624    0.533\n## age_cat10-14  0.136372   0.107275   1.271    0.204\n## age_cat15-19 -0.011074   0.113640  -0.097    0.922\n## age_cat20-29  0.026552   0.102780   0.258    0.796\n## age_cat30-49  0.059569   0.116402   0.512    0.609\n## age_cat50-69 -0.388964   0.262384  -1.482    0.138\n## age_cat70+   -0.647443   0.917375  -0.706    0.480\n## \n## (Dispersion parameter for binomial family taken to be 1)\n## \n##     Null deviance: 5712.4  on 4166  degrees of freedom\n## Residual deviance: 5700.2  on 4153  degrees of freedom\n## AIC: 5728.2\n## \n## Number of Fisher Scoring iterations: 4\nglm(outcome ~ gender + age_cat * fever, family = \"binomial\", data = linelist)\n## run a regression with all variables of interest \nmv_reg <- explanatory_vars %>%  ## begin with vector of explanatory column names\n  str_c(collapse = \"+\") %>%     ## combine all names of the variables of interest separated by a plus\n  str_c(\"outcome ~ \", .) %>%    ## combine the names of variables of interest with outcome in formula style\n  glm(family = \"binomial\",      ## define type of glm as logistic,\n      data = linelist)          ## define your dataset"},{"path":"univariate-and-multivariable-regression.html","id":"construir-el-modelo","chapter":"19 Regresión univariante y multivariable","heading":"Construir el modelo","text":"Puedes construir tu modelo paso paso, guardando varios modelos que incluyan determinadas variables explicativas. Puedes comparar estos modelos con pruebas de razón de verosimilitud utilizando lrtest() del paquete lmtest, como se indica continuación:NOTA: El uso de anova(model1, model2, test = \"Chisq\") de R base produce los mismos resultados Otra opción es tomar el objeto que contiene el modelo y aplicar la función step() del paquete stats. Especifica qué dirección de selección de variables deseas utilizar al construir el modelo.Para mayor claridad, también puedes desactivar la notación científica en tu sesión de R.Como se describe en la sección sobre el análisis univariante, pasamos la salida del modelo tidy() para exponenciar las probabilidades logarítmicas y los IC. Finalmente, redondeamos todas las columnas numéricas dos decimales. Haz scroll para ver el resultado.Este es el aspecto del dataframe resultante:","code":"\nmodel1 <- glm(outcome ~ age_cat, family = \"binomial\", data = linelist)\nmodel2 <- glm(outcome ~ age_cat + gender, family = \"binomial\", data = linelist)\n\nlmtest::lrtest(model1, model2)## Likelihood ratio test\n## \n## Model 1: outcome ~ age_cat\n## Model 2: outcome ~ age_cat + gender\n##   #Df  LogLik Df  Chisq Pr(>Chisq)\n## 1   8 -2852.6                     \n## 2   9 -2852.6  1 0.0002     0.9883\n## choose a model using forward selection based on AIC\n## you can also do \"backward\" or \"both\" by adjusting the direction\nfinal_mv_reg <- mv_reg %>%\n  step(direction = \"forward\", trace = FALSE)\noptions(scipen=999)\nmv_tab_base <- final_mv_reg %>% \n  broom::tidy(exponentiate = TRUE, conf.int = TRUE) %>%  ## get a tidy dataframe of estimates \n  mutate(across(where(is.numeric), round, digits = 2))          ## round "},{"path":"univariate-and-multivariable-regression.html","id":"combinar-regresiones-univariantes-y-multivariables","chapter":"19 Regresión univariante y multivariable","heading":"Combinar regresiones univariantes y multivariables","text":"","code":""},{"path":"univariate-and-multivariable-regression.html","id":"combinar-con-gtsummary","chapter":"19 Regresión univariante y multivariable","heading":"Combinar con gtsummary","text":"El paquete gtsummary proporciona la función tbl_regression(), que toma los resultados de una regresión (glm() en este caso) y produce una bonita tabla resumen.Veamos la tabla:También puedes combinar varias tablas producidas por gtsummary con la función tbl_merge(). En este ejemplo combinaremos los resultados multivariables con los resultados univariantes de gtsummary que creamos anteriormente:","code":"\n## show results table of final regression \nmv_tab <- tbl_regression(final_mv_reg, exponentiate = TRUE)\nmv_tab\n## combine with univariate results \ntbl_merge(\n  tbls = list(univ_tab, mv_tab),                          # combine\n  tab_spanner = c(\"**Univariate**\", \"**Multivariable**\")) # set header names"},{"path":"univariate-and-multivariable-regression.html","id":"combinar-con-dplyr","chapter":"19 Regresión univariante y multivariable","heading":"Combinar con dplyr","text":"Una forma alternativa de combinar los resultados univariables y multivariables de glm()/tidy() es con las funciones join de dplyr.Unimos los resultados univariantes obtenidos anteriormente (univ_tab_base, que contiene los recuentos) con los resultados multivariables en formato tidy de mv_tab_base.Utilizamos select() para mantener sólo las columnas que queremos, especificar su orden y renombrarlasEmpleamos round() con dos decimales en todas las columnas que sean de tipo “Double”.","code":"\n## combine univariate and multivariable tables \nleft_join(univ_tab_base, mv_tab_base, by = \"term\") %>% \n  ## choose columns and rename them\n  select( # new name =  old name\n    \"characteristic\" = term, \n    \"recovered\"      = \"0\", \n    \"dead\"           = \"1\", \n    \"univ_or\"        = estimate.x, \n    \"univ_ci_low\"    = conf.low.x, \n    \"univ_ci_high\"   = conf.high.x,\n    \"univ_pval\"      = p.value.x, \n    \"mv_or\"          = estimate.y, \n    \"mvv_ci_low\"     = conf.low.y, \n    \"mv_ci_high\"     = conf.high.y,\n    \"mv_pval\"        = p.value.y \n  ) %>% \n  mutate(across(where(is.double), round, 2))   ## # A tibble: 20 × 11\n##    characteristic recovered  dead univ_or univ_ci_low univ_ci_high univ_…¹ mv_or mvv_c…² mv_ci…³ mv_pval\n##    <chr>              <dbl> <dbl>   <dbl>       <dbl>        <dbl>   <dbl> <dbl>   <dbl>   <dbl>   <dbl>\n##  1 (Intercept)          909  1168    1.28        1.18         1.4     0     1.07    0.83    1.39    0.6 \n##  2 gender               916  1174    1           0.88         1.13    0.97  1       0.88    1.14    0.97\n##  3 (Intercept)          340   436    1.28        1.11         1.48    0     1.07    0.83    1.39    0.6 \n##  4 fever               1485  1906    1           0.85         1.17    0.99  1       0.86    1.18    0.96\n##  5 (Intercept)         1472  1877    1.28        1.19         1.37    0     1.07    0.83    1.39    0.6 \n##  6 chills               353   465    1.03        0.89         1.21    0.68  1.03    0.89    1.21    0.67\n##  7 (Intercept)          272   309    1.14        0.97         1.34    0.13  1.07    0.83    1.39    0.6 \n##  8 cough               1553  2033    1.15        0.97         1.37    0.11  1.15    0.96    1.37    0.12\n##  9 (Intercept)         1636  2114    1.29        1.21         1.38    0     1.07    0.83    1.39    0.6 \n## 10 aches                189   228    0.93        0.76         1.14    0.51  0.93    0.76    1.14    0.5 \n## 11 (Intercept)          931  1144    1.23        1.13         1.34    0     1.07    0.83    1.39    0.6 \n## 12 vomit                894  1198    1.09        0.96         1.23    0.17  1.09    0.96    1.23    0.17\n## 13 (Intercept)          338   427    1.26        1.1          1.46    0     1.07    0.83    1.39    0.6 \n## 14 age_cat5-9           365   433    0.94        0.77         1.15    0.54  0.94    0.77    1.15    0.53\n## 15 age_cat10-14         273   396    1.15        0.93         1.42    0.2   1.15    0.93    1.41    0.2 \n## 16 age_cat15-19         238   299    0.99        0.8          1.24    0.96  0.99    0.79    1.24    0.92\n## 17 age_cat20-29         345   448    1.03        0.84         1.26    0.79  1.03    0.84    1.26    0.8 \n## 18 age_cat30-49         228   307    1.07        0.85         1.33    0.58  1.06    0.85    1.33    0.61\n## 19 age_cat50-69          35    30    0.68        0.41         1.13    0.13  0.68    0.4     1.13    0.14\n## 20 age_cat70+             3     2    0.53        0.07         3.2     0.49  0.52    0.07    3.19    0.48\n## # … with abbreviated variable names ¹​univ_pval, ²​mvv_ci_low, ³​mv_ci_high"},{"path":"univariate-and-multivariable-regression.html","id":"forest-plot","chapter":"19 Regresión univariante y multivariable","heading":"19.5 Forest plot","text":"Esta sección muestra cómo producir un gráfico con los resultados de tu regresión.\nHay dos opciones, puedes construir un gráfico tú mismo usando ggplot2 o usar un metapaquete llamado easystats (un paquete que incluye muchos paquetes).Consulta la página sobre Conceptos básicos de ggplot si estás familiarizado con el paquete de gráficos ggplot2.","code":""},{"path":"univariate-and-multivariable-regression.html","id":"paquete-ggplot2","chapter":"19 Regresión univariante y multivariable","heading":"Paquete ggplot2","text":"Puedes construir un gráfico de bosque con ggplot() trazando elementos de los resultados de la regresión multivariable. Añade las capas de los gráficos utilizando estos “geoms”:Añadimos estimaciones con geom_point()Añadimos intervalos de confianza con geom_errorbar()Ploteamos una línea vertical en = 1 con geom_vline()Antes de empezar plotear, es posible que sea necesario utilizar fct_relevel() del paquete forcats para establecer el orden de las variables/niveles en el eje y. De establecer un orden en las variables, ggplot() podría mostrar las variables en orden alfanumérico, lo que funcionaría bien para los valores de categoría de edad (“30” aparecería antes de “5”). Mira la página sobre Factores para más detalles.","code":"\n## remove the intercept term from your multivariable results\nmv_tab_base %>% \n  \n  #set order of levels to appear along y-axis\n  mutate(term = fct_relevel(\n    term,\n    \"vomit\", \"gender\", \"fever\", \"cough\", \"chills\", \"aches\",\n    \"age_cat5-9\", \"age_cat10-14\", \"age_cat15-19\", \"age_cat20-29\",\n    \"age_cat30-49\", \"age_cat50-69\", \"age_cat70+\")) %>%\n  \n  # remove \"intercept\" row from plot\n  filter(term != \"(Intercept)\") %>% \n  \n  ## plot with variable on the y axis and estimate (OR) on the x axis\n  ggplot(aes(x = estimate, y = term)) +\n  \n  ## show the estimate as a point\n  geom_point() + \n  \n  ## add in an error bar for the confidence intervals\n  geom_errorbar(aes(xmin = conf.low, xmax = conf.high)) + \n  \n  ## show where OR = 1 is for reference as a dashed line\n  geom_vline(xintercept = 1, linetype = \"dashed\")"},{"path":"univariate-and-multivariable-regression.html","id":"paquetes-easystats","chapter":"19 Regresión univariante y multivariable","heading":"Paquetes easystats","text":"Una alternativa, si deseas el nivel de precisión y control que proporciona ggplot2, es utilizar la combinación de paquetes easystats.La función model_parameters() del paquete parameters hace el equivalente de la función tidy() del paquete broom. El paquete see acepta esos resultados y crea por defecto un forest plot, dándo como output un objeto ggplot().","code":"\npacman::p_load(easystats)\n\n## remove the intercept term from your multivariable results\nfinal_mv_reg %>% \n  model_parameters(exponentiate = TRUE) %>% \n  plot()"},{"path":"univariate-and-multivariable-regression.html","id":"resources-11","chapter":"19 Regresión univariante y multivariable","heading":"19.6 Recursos","text":"El contenido de esta página se ha basado en estos recursos y viñetas:Regresión lineal en RgtsummaryPágina de estadísticas de la UCLAregresión escalonada sthda","code":""},{"path":"missing-data.html","id":"missing-data","chapter":"20 Valores faltantes","heading":"20 Valores faltantes","text":"En esta página se explica cómo:Evaluar la falta de informaciónFiltrar las filas por valores faltantesRepresentar la falta de datos lo largo del tiempoManejar cómo se muestra NA en los gráficosRealizar la imputación de valores faltantes: MCAR, MAR, MNAR","code":""},{"path":"missing-data.html","id":"preparation-11","chapter":"20 Valores faltantes","heading":"20.1 Preparación","text":"","code":""},{"path":"missing-data.html","id":"cargar-paquetes-12","chapter":"20 Valores faltantes","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de de R base Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,           # import/export\n  tidyverse,     # data mgmt and viz\n  naniar,        # assess and visualize missingness\n  mice           # missing data imputation\n)"},{"path":"missing-data.html","id":"importar-datos-11","chapter":"20 Valores faltantes","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpioa” (como archivo .rds). Importa tus datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - Mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas de linelist.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"missing-data.html","id":"convertir-valores-faltantes-en-la-importación","chapter":"20 Valores faltantes","heading":"Convertir valores faltantes en la importación","text":"Al importar los datos, ten en cuenta los valores que deben clasificarse como faltantes. Por ejemplo, 99, 999, “Missing”, celdas en blanco (““) o celdas con un espacio vacío (” “). Puedes convertirlos en NA (la versión de R de los valores faltantes) con el comando de importación de datos.\nConsulta la sección de datos faltantes de la página de Importación para obtener más detalles, ya que la sintaxis exacta varía según el tipo de archivo.","code":""},{"path":"missing-data.html","id":"missing-values-in-r","chapter":"20 Valores faltantes","heading":"20.2 Valores faltantes en R","text":"continuación, exploramos las formas en que se presenta y evalúa los datos faltantes en R, junto con algunos valores y funciones adyacentes.","code":""},{"path":"missing-data.html","id":"na","chapter":"20 Valores faltantes","heading":"NA","text":"En R, los valores faltantes se representan con un valor reservado (especial): NA. Ten en cuenta que se escribe sin comillas. “NA” es diferente y es sólo un valor de carácter normal (también una letra de los Beatles de la canción Hey Jude).Tus datos pueden tener otras formas de representar la falta de información, como “99”, o “Missing”, o “Desconocido” - incluso puedes tener el valor de carácter vacío “” que parece “en blanco”, o un solo espacio ” “. Se consciente de ello y considera la posibilidad de convertirlos en NA durante la importación o durante la limpieza de datos con na_if().En tu limpieza de datos, también puedes convertir en el otro sentido - cambiando todos los NA “Missing” o similar con replace_na() o con fct_explicit_na() para los factores.","code":""},{"path":"missing-data.html","id":"versiones-de-na","chapter":"20 Valores faltantes","heading":"Versiones de NA","text":"La mayoría de las veces, NA representa un valor que falta y todo funciona bien. Sin embargo, en algunas circunstancias puedes encontrar la necesidad de variaciones de NA específicas para un tipo de objeto (carácter, numérico, etc.). Esto será poco frecuente, pero debes tenerlo en cuenta.El escenario típico para esto es cuando se crea una nueva columna con la función dplyr case_when(). Como se describe en la página de Limpieza de datos y funciones básicas, esta función evalúa cada fila del dataframe, valora si las filas cumplen con los criterios lógicos especificados (lado derecho del código), y asigna el nuevo valor correcto (lado izquierdo del código). Importante: todos los valores del lado derecho deben ser del mismo tipo.Si deseas NA en el lado derecho, es posible que tengas que especificar una de las opciones especiales de NA que se indican continuación. Si los otros valores del lado derecho son caracteres, considera usar “Missing” en su lugar o, de lo contrario, usa NA_character_. Si todos son numéricos, utiliza NA_real_. Si todos son fechas o lógicos, puedes utilizar NA.NA - utilizar para fechas o TRUE/FALSE lógicoNA_character_ - utilizar para caracteresNA_real_ - uso para numéricoDe nuevo, es probable que te encuentres con estas variaciones menos que estés utilizando case_when() para crear una nueva columna. Consulta la documentación de R sobre NA para obtener más información.","code":"\nlinelist <- linelist %>% \n  \n  # Create new \"age_years\" column from \"age\" column\n  mutate(age_years = case_when(\n    age_unit == \"years\"  ~ age,       # if age is given in years, assign original value\n    age_unit == \"months\" ~ age/12,    # if age is given in months, divide by 12\n    is.na(age_unit)      ~ age,       # if age UNIT is missing, assume years\n    TRUE                 ~ NA_real_)) # any other circumstance, assign missing"},{"path":"missing-data.html","id":"null","chapter":"20 Valores faltantes","heading":"NULL","text":"NULL es otro valor reservado en R. Es la representación lógica de una declaración que es ni verdadera ni falsa. Es devuelto por expresiones o funciones cuyos valores son indefinidos. Generalmente asignes NULL como valor, menos que escribas funciones o si escribes una aplicación Shiny para devolver NULL en escenarios específicos.La nulidad puedes evaluarse con .null() y la conversión puedes hacerse con .null().Véase esta entrada del blog sobre la diferencia entre NULL y NA.","code":""},{"path":"missing-data.html","id":"nan","chapter":"20 Valores faltantes","heading":"NaN","text":"Los valores imposibles se representan con el valor especial NaN. Un ejemplo de esto es cuando se fuerza R dividir 0 entre 0. Puedes evaluar esto con .nan(). También puedes encontrar funciones complementarias incluyendo .infinite() y .finite().","code":""},{"path":"missing-data.html","id":"inf","chapter":"20 Valores faltantes","heading":"Inf","text":"Inf representa un valor infinito, como cuando se divide un número por 0.Como ejemplo de cómo podría afectar esto tu trabajo: digamos que tienes un vector/columna z que contiene estos valores: z <- c(1, 22, NA, Inf, NaN, 5)Si deseas utilizar max() en la columna para encontrar el valor más alto, puedes utilizar el na.rm = TRUE para eliminar el NA del cálculo, pero el Inf y elNaN permanecen y se devolverá Inf. Para resolver esto, puedes utilizar los corchetes [ ] y .finite() para subconjuntar de manera que sólo se utilicen valores finitos para el cálculo: max(z[.finite(z)]).","code":"\nz <- c(1, 22, NA, Inf, NaN, 5)\nmax(z)                           # returns NA\nmax(z, na.rm=T)                  # returns Inf\nmax(z[is.finite(z)])             # returns 22"},{"path":"missing-data.html","id":"ejemplos","chapter":"20 Valores faltantes","heading":"Ejemplos","text":"“NAs introduced coercion” es un mensaje de aviso común. Esto puede ocurrir si se intenta hacer una conversión ilegal como insertar un valor de carácter en un vector que de otra manera es numérico.NULL se ignora en un vector.La varianza de un número da como resultado NA.","code":"\nas.numeric(c(\"10\", \"20\", \"thirty\", \"40\"))## Warning: NAs introduced by coercion## [1] 10 20 NA 40\nmy_vector <- c(25, NA, 10, NULL)  # define\nmy_vector                         # print## [1] 25 NA 10\nvar(22)## [1] NA"},{"path":"missing-data.html","id":"useful-functions","chapter":"20 Valores faltantes","heading":"20.3 Funciones útiles","text":"Las siguientes funciones de R base son muy útiles la hora de evaluar o manejar los valores faltantes:","code":""},{"path":"missing-data.html","id":"is.na-y-is.na","chapter":"20 Valores faltantes","heading":"is.na() y !is.na()","text":"Utiliza .na() para identificar los valores que faltan, o utiliza su opuesto (con ! delante) para identificar los valores que faltan. Ambos devuelven un valor lógico (TRUE o FALSE). Recuerda que puedes sum() el vector resultante para contar el número de TRUE, por ejemplo, sum(.na(linelist$date_outcome)).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\nis.na(my_vector)## [1] FALSE FALSE FALSE  TRUE FALSE  TRUE FALSE\n!is.na(my_vector)## [1]  TRUE  TRUE  TRUE FALSE  TRUE FALSE  TRUE\nsum(is.na(my_vector))## [1] 2"},{"path":"missing-data.html","id":"na.omit","chapter":"20 Valores faltantes","heading":"na.omit()","text":"Esta función, si se aplica un dataframe, eliminará las filas con valores faltantes. También es de R base. Si se aplica un vector, eliminará los valores NA del vector al que se aplica. Por ejemplo:","code":"\nna.omit(my_vector)## [1]  1  4 56  5 22\n## attr(,\"na.action\")\n## [1] 4 6\n## attr(,\"class\")\n## [1] \"omit\""},{"path":"missing-data.html","id":"drop_na","chapter":"20 Valores faltantes","heading":"drop_na()","text":"Esta es una función tidyr que es útil en un proceso de limpieza de datos. Si se ejecuta con los paréntesis vacíos, elimina las filas con valores faltantes. Si se especifican los nombres de las columnas en los paréntesis, se eliminarán las filas con valores faltantes en esas columnas. También puedes utilizar la sintaxis “tidyselect” para especificar las columnas.","code":"\nlinelist %>% \n  drop_na(case_id, date_onset, age) # drops rows missing values for any of these columns"},{"path":"missing-data.html","id":"na.rm-true","chapter":"20 Valores faltantes","heading":"na.rm = TRUE","text":"Cuando se ejecuta una función matemática como max(), min(), sum() o mean(), si hay algún valor NA presente el valor devuelto será NA. Este comportamiento por defecto es intencionado, para que avise si falta algún dato.Puedes evitarlo eliminando los valores faltantes del cálculo. Para ello, incluye el argumento na.rm = TRUE (“na.rm” significa “eliminar NA”).","code":"\nmy_vector <- c(1, 4, 56, NA, 5, NA, 22)\n\nmean(my_vector)     ## [1] NA\nmean(my_vector, na.rm = TRUE)## [1] 17.6"},{"path":"missing-data.html","id":"assess-missingness-in-a-data-frame","chapter":"20 Valores faltantes","heading":"20.4 Evaluar la ausencia de datos en un dataframe","text":"Puedes utilizar el paquete naniar para evaluar y visualizar la falta de datos del dataframe linelist.","code":"\n# install and/or load package\npacman::p_load(naniar)"},{"path":"missing-data.html","id":"cuantificación-de-la-ausencia-de-datos","chapter":"20 Valores faltantes","heading":"Cuantificación de la ausencia de datos","text":"Para encontrar el porcentaje de todos los valores que faltan utiliza pct_miss(). Utiliza n_miss() para obtener el número de valores faltantes.Las dos funciones siguientes devuelven el porcentaje de filas con algún valor ausente, o que están totalmente completas, respectivamente. Recuerda que NA significa que falta, y que \"\" o \" \" se contarán como faltantes.","code":"\n# percent of ALL data frame values that are missing\npct_miss(linelist)## [1] 6.688745\n# Percent of rows with any value missing\npct_miss_case(linelist)   # use n_complete() for counts## [1] 69.12364\n# Percent of rows that are complete (no values missing)  \npct_complete_case(linelist) # use n_complete() for counts## [1] 30.87636"},{"path":"missing-data.html","id":"visualización-de-faltantes","chapter":"20 Valores faltantes","heading":"Visualización de faltantes","text":"La función gg_miss_var() mostrará el número (o el %) de valores faltantes en cada columna. Algunos matices:Puedes añadir un nombre de columna (entre comillas) al argumento facet = para ver el gráfico por gruposPor defecto, se muestran los recuentos en lugar de los porcentajes, cámbialo con show_pct = TRUEPuedes añadir etiquetas de eje y de título como para un ggplot() normal con + labs(...)Aquí los datos están conectados con %>% en la función. El argumento facet = también se utiliza para dividir los datos.Puedes utilizar vis_miss() para visualizar el dataframe como un mapa de calor, mostrando si cada valor falta o . También puedes select() determinadas columnas del dataframe y proporcionar sólo esas columnas la función.","code":"\ngg_miss_var(linelist, show_pct = TRUE)\nlinelist %>% \n  gg_miss_var(show_pct = TRUE, facet = outcome)\n# Heatplot of missingness across the entire data frame  \nvis_miss(linelist)"},{"path":"missing-data.html","id":"explorar-y-visualizar-las-relaciones-de-datos-faltantes","chapter":"20 Valores faltantes","heading":"Explorar y visualizar las relaciones de datos faltantes","text":"¿Cómo se visualiza algo que existe? Por defecto, ggplot() elimina los puntos con valores faltantes de los gráficos.naniar ofrece una solución mediante geom_miss_point(). Al crear un gráfico de dispersión de dos columnas, los registros con uno de los valores ausentes y el otro valor presente se muestran estableciendo los valores ausentes en un 10% más bajo que el valor más bajo de la columna, y coloreándolos de forma distinta.En el gráfico de dispersión que aparece continuación, los puntos rojos son registros en los que el valor de una columna está presente pero falta el valor de la otra columna. Esto permite ver la distribución de los valores que faltan en relación con los valores que faltan.Para evaluar la ausencia en el dataframe estratificado por otra columna, puedes utilizar gg_miss_fct(), que devuelve un mapa de calor del porcentaje de ausencia en el dataframe por una columna de factor/categoría (o fecha):Esta función también se puede utilizar con una columna de fechas para ver cómo ha cambiado la falta de datos en el tiempo:","code":"\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, y = temp)) +     \n  geom_miss_point()\ngg_miss_fct(linelist, age_cat5)\ngg_miss_fct(linelist, date_onset)## Warning: Removed 29 rows containing missing values (`geom_tile()`)."},{"path":"missing-data.html","id":"sombra-de-las-columnas","chapter":"20 Valores faltantes","heading":"“Sombra” de las columnas","text":"Otra forma de visualizar la ausencia de valores en una columna es mediante una segunda columna que sea como una “sombra” de esta que puede crear naniar. bind_shadow() crea una columna binaria NA/NA para cada columna existente, y vincula todas estas nuevas columnas al conjunto de datos original con el apéndice “_NA”. Esto duplica el número de columnas - ver más abajo:Estas “sombras” de las columnas pueden utilizarse para trazar la proporción de valores que faltan, por cualquier otra columna.Por ejemplo, el siguiente gráfico muestra la proporción de registros que carecen de days_onset_hosp (número de días desde el inicio de los síntomas hasta la hospitalización), según el valor de ese registro en date_hospitalisation. Esencialmente, se está trazando la densidad de la columna del eje x, pero estratificando los resultados (color = ) por una columna de sombra de interés. Este análisis funciona mejor si el eje-x es una columna numérica o de fecha.También puedes utilizar estas columnas “sombra” para estratificar un resumen estadístico, como se muestra continuación:continuación se muestra una forma alternativa de trazar la proporción de los valores de una columna que faltan lo largo del tiempo. implica naniar. Este ejemplo muestra el porcentaje de observaciones semanales que faltan).Agrega los datos en una unidad de tiempo útil (días, semanas, etc.), resumiendo la proporción de observaciones con NA (y cualquier otro valor de interés)Representa la proporción que falta como una línea usando ggplot()continuación, tomamos linelist, añadimos una nueva columna para la semana, agrupamos los datos por semana y luego calculamos el porcentaje de registros de esa semana en los que falta el valor. (Nota: si se desea el porcentaje de 7 días el cálculo sería ligeramente diferente).Entonces, representamos la proporción que falta como una línea, por semana. Si estás familiarizado con el paquete de gráficas ggplot2, consulta la página de fundamentos de ggplot.","code":"\nshadowed_linelist <- linelist %>% \n  bind_shadow()\n\nnames(shadowed_linelist)##  [1] \"case_id\"                 \"generation\"              \"date_infection\"         \n##  [4] \"date_onset\"              \"date_hospitalisation\"    \"date_outcome\"           \n##  [7] \"outcome\"                 \"gender\"                  \"age\"                    \n## [10] \"age_unit\"                \"age_years\"               \"age_cat\"                \n## [13] \"age_cat5\"                \"hospital\"                \"lon\"                    \n## [16] \"lat\"                     \"infector\"                \"source\"                 \n## [19] \"wt_kg\"                   \"ht_cm\"                   \"ct_blood\"               \n## [22] \"fever\"                   \"chills\"                  \"cough\"                  \n## [25] \"aches\"                   \"vomit\"                   \"temp\"                   \n## [28] \"time_admission\"          \"bmi\"                     \"days_onset_hosp\"        \n## [31] \"case_id_NA\"              \"generation_NA\"           \"date_infection_NA\"      \n## [34] \"date_onset_NA\"           \"date_hospitalisation_NA\" \"date_outcome_NA\"        \n## [37] \"outcome_NA\"              \"gender_NA\"               \"age_NA\"                 \n## [40] \"age_unit_NA\"             \"age_years_NA\"            \"age_cat_NA\"             \n## [43] \"age_cat5_NA\"             \"hospital_NA\"             \"lon_NA\"                 \n## [46] \"lat_NA\"                  \"infector_NA\"             \"source_NA\"              \n## [49] \"wt_kg_NA\"                \"ht_cm_NA\"                \"ct_blood_NA\"            \n## [52] \"fever_NA\"                \"chills_NA\"               \"cough_NA\"               \n## [55] \"aches_NA\"                \"vomit_NA\"                \"temp_NA\"                \n## [58] \"time_admission_NA\"       \"bmi_NA\"                  \"days_onset_hosp_NA\"\nggplot(data = shadowed_linelist,          # data frame with shadow columns\n  mapping = aes(x = date_hospitalisation, # numeric or date column\n                colour = age_years_NA)) + # shadow column of interest\n  geom_density()                          # plots the density curves\nlinelist %>%\n  bind_shadow() %>%                # create the shows cols\n  group_by(date_outcome_NA) %>%    # shadow col for stratifying\n  summarise(across(\n    .cols = age_years,             # variable of interest for calculations\n    .fns = list(\"mean\" = mean,     # stats to calculate\n                \"sd\" = sd,\n                \"var\" = var,\n                \"min\" = min,\n                \"max\" = max),  \n    na.rm = TRUE))                 # other arguments for the stat calculations## # A tibble: 2 × 6\n##   date_outcome_NA age_years_mean age_years_sd age_years_var age_years_min age_years_max\n##   <fct>                    <dbl>        <dbl>         <dbl>         <dbl>         <dbl>\n## 1 !NA                       16.0         12.6          158.             0            84\n## 2 NA                        16.2         12.9          167.             0            69\noutcome_missing <- linelist %>%\n  mutate(week = lubridate::floor_date(date_onset, \"week\")) %>%   # create new week column\n  group_by(week) %>%                                             # group the rows by week\n  summarise(                                                     # summarize each week\n    n_obs = n(),                                                  # number of records\n    \n    outcome_missing = sum(is.na(outcome) | outcome == \"\"),        # number of records missing the value\n    outcome_p_miss  = outcome_missing / n_obs,                    # proportion of records missing the value\n  \n    outcome_dead    = sum(outcome == \"Death\", na.rm=T),           # number of records as dead\n    outcome_p_dead  = outcome_dead / n_obs) %>%                   # proportion of records as dead\n  \n  tidyr::pivot_longer(-week, names_to = \"statistic\") %>%         # pivot all columns except week, to long format for ggplot\n  filter(stringr::str_detect(statistic, \"_p_\"))                  # keep only the proportion values\nggplot(data = outcome_missing)+\n    geom_line(\n      mapping = aes(x = week, y = value, group = statistic, color = statistic),\n      size = 2,\n      stat = \"identity\")+\n    labs(title = \"Weekly outcomes\",\n         x = \"Week\",\n         y = \"Proportion of weekly records\") + \n     scale_color_discrete(\n       name = \"\",\n       labels = c(\"Died\", \"Missing outcome\"))+\n    scale_y_continuous(breaks = c(seq(0,1,0.1)))+\n  theme_minimal()+\n  theme(legend.position = \"bottom\")"},{"path":"missing-data.html","id":"using-data-with-missing-values","chapter":"20 Valores faltantes","heading":"20.5 Uso de datos con valores faltantes","text":"","code":""},{"path":"missing-data.html","id":"filtrar-las-filas-con-valores-faltantes","chapter":"20 Valores faltantes","heading":"Filtrar las filas con valores faltantes","text":"Para eliminar rápidamente las filas con valores faltantes, utiliza la función dplyr drop_na().linelist original tiene nrow(linelist) filas. El número ajustado de filas se muestra continuación:Puedes especificar que se eliminen las filas que faltan en determinadas columnas:Puedes listar las columnas una tras otra, o utilizar las funciones de ayuda “tidyselect”:","code":"\nlinelist %>% \n  drop_na() %>%     # remove rows with ANY missing values\n  nrow()## [1] 1818\nlinelist %>% \n  drop_na(date_onset) %>% # remove rows missing date_onset \n  nrow()## [1] 5632\nlinelist %>% \n  drop_na(contains(\"date\")) %>% # remove rows missing values in any \"date\" column \n  nrow()## [1] 3029"},{"path":"missing-data.html","id":"manejo-de-na-en-ggplot","chapter":"20 Valores faltantes","heading":"Manejo de NA en ggplot()","text":"menudo es conveniente informar del número de valores excluidos de un gráfico en un pie de foto. continuación se muestra un ejemplo:En ggplot(), puedes añadir labs() y dentro de él un caption =. En el pie, puedes usar str_glue() del paquete stringr para pegar los valores juntos en una frase de forma dinámica para que se ajusten los datos. Un ejemplo es el siguiente:Observa el uso de \\n para una nueva línea.Ten en cuenta que si varias columnas contribuyen que los valores se muestren (por ejemplo, la edad o el sexo si se reflejan en el gráfico), deberás filtrar también esas columnas para calcular correctamente el número mostrado.veces, puede ser más fácil guardar la cadena como un objeto en comandos anteriores al comando ggplot(), y simplemente referenciar el objeto de cadena nombrado dentro de str_glue().","code":"\nlabs(\n  title = \"\",\n  y = \"\",\n  x = \"\",\n  caption  = stringr::str_glue(\n  \"n = {nrow(central_data)} from Central Hospital;\n  {nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown.\"))  "},{"path":"missing-data.html","id":"na-en-los-factores","chapter":"20 Valores faltantes","heading":"NA en los factores","text":"Si tu columna de interés es un factor, utiliza fct_explicit_na() del paquete forcats para convertir los valores NA en un valor de carácter. Mira más detalles en la página de Factores. Por defecto, el nuevo valor es “(Missing)” pero puede ajustarse mediante el argumento na_level =.","code":"\npacman::p_load(forcats)   # load package\n\nlinelist <- linelist %>% \n  mutate(gender = fct_explicit_na(gender, na_level = \"Missing\"))\n\nlevels(linelist$gender)## [1] \"f\"       \"m\"       \"Missing\""},{"path":"missing-data.html","id":"imputation","chapter":"20 Valores faltantes","heading":"20.6 Imputación","text":"veces, al analizar los datos, será importante “rellenar los huecos” e imputar los datos que faltan Aunque siempre se puede analizar simplemente unos datos después de eliminar todos los valores que faltan, esto puede causar problemas de muchas maneras. aquí dos ejemplos:Al eliminar todas las observaciones con valores faltantes o las variables con una gran cantidad de valores faltantes, podría reducir su potencia o la capacidad para realizar algunos tipos de análisis. Por ejemplo, como descubrimos antes, sólo una pequeña fracción de las observaciones de nuestro conjunto de datos de linelist tiene valores faltantes en todas nuestras variables. Si elimináramos la mayor parte de nuestro conjunto de datos, perderíamos mucha información. Además, la mayoría de nuestras variables tienen una cierta cantidad de valores faltantes; para la mayoría de los análisis, probablemente sea razonable eliminar todas las variables que tienen muchos valores faltantes.Al eliminar todas las observaciones con valores faltantes o las variables con una gran cantidad de valores faltantes, podría reducir su potencia o la capacidad para realizar algunos tipos de análisis. Por ejemplo, como descubrimos antes, sólo una pequeña fracción de las observaciones de nuestro conjunto de datos de linelist tiene valores faltantes en todas nuestras variables. Si elimináramos la mayor parte de nuestro conjunto de datos, perderíamos mucha información. Además, la mayoría de nuestras variables tienen una cierta cantidad de valores faltantes; para la mayoría de los análisis, probablemente sea razonable eliminar todas las variables que tienen muchos valores faltantes.Dependiendo de la razón por la que faltan datos, el análisis de los datos que faltan podría conducir resultados sesgados o engañosos. Por ejemplo, como hemos sabido antes, nos faltan datos de algunos pacientes sobre si han tenido algunos síntomas importantes como fiebre o tos. Pero, como una posibilidad, tal vez esa información se registró para las personas que obviamente estaban muy enfermas. En ese caso, si elimináramos estas observaciones, estaríamos excluyendo algunas de las personas más sanas de nuestro conjunto de datos, lo que podría sesgar los resultados.Dependiendo de la razón por la que faltan datos, el análisis de los datos que faltan podría conducir resultados sesgados o engañosos. Por ejemplo, como hemos sabido antes, nos faltan datos de algunos pacientes sobre si han tenido algunos síntomas importantes como fiebre o tos. Pero, como una posibilidad, tal vez esa información se registró para las personas que obviamente estaban muy enfermas. En ese caso, si elimináramos estas observaciones, estaríamos excluyendo algunas de las personas más sanas de nuestro conjunto de datos, lo que podría sesgar los resultados.Es importante pensar en la razón por la que pueden faltar datos, además de ver cuántos faltan. Esto puede ayudarte decidir la importancia de imputar los datos que faltan, así como el método de imputación de los datos que faltan que pueda ser mejor en esa situación.","code":""},{"path":"missing-data.html","id":"tipos-de-datos-faltantes","chapter":"20 Valores faltantes","heading":"Tipos de datos faltantes","text":"continuación se presentan tres tipos generales de datos faltantes:Falta completamente al azar (MCAR Missing Completely Random). Esto significa que existe ninguna relación entre la probabilidad de que falten datos y cualquiera de las otras variables de los datos. La probabilidad de que falte es la misma para todos los casos. Pero, si tienes una fuerte razón para creer que tus datos son MCAR, analizar sólo los datos ausentes sin imputar sesgará los resultados (aunque puede perder algo de potencia). [PENDIENTE: considerar la discusión de las pruebas estadísticas para MCAR].Falta completamente al azar (MCAR Missing Completely Random). Esto significa que existe ninguna relación entre la probabilidad de que falten datos y cualquiera de las otras variables de los datos. La probabilidad de que falte es la misma para todos los casos. Pero, si tienes una fuerte razón para creer que tus datos son MCAR, analizar sólo los datos ausentes sin imputar sesgará los resultados (aunque puede perder algo de potencia). [PENDIENTE: considerar la discusión de las pruebas estadísticas para MCAR].Falta al azar (MAR Missing Random). Este nombre es, en realidad, un poco engañoso, ya que MAR significa que los datos faltan de forma sistemática y predecible en función del resto de la información que se tiene. Por ejemplo, puede que todas las observaciones de nuestro conjunto de datos con un valor ausente de fiebre se hayan registrado porque se asumió que todos los pacientes con escalofríos y dolores tenían fiebre, por lo que nunca se les tomó la temperatura. Si es cierto, podríamos predecir fácilmente que cada observación que falta con escalofríos y dolores también tiene fiebre y utilizar esta información para imputar nuestros datos que faltan. En la práctica, esto es más bien un espectro. Quizá si un paciente tiene escalofríos y dolores, es más probable que también tenga fiebre si se le toma la temperatura, pero siempre. Esto sigue siendo predecible aunque sea perfectamente predecible. Este es un tipo común de valores faltantesFalta al azar (MAR Missing Random). Este nombre es, en realidad, un poco engañoso, ya que MAR significa que los datos faltan de forma sistemática y predecible en función del resto de la información que se tiene. Por ejemplo, puede que todas las observaciones de nuestro conjunto de datos con un valor ausente de fiebre se hayan registrado porque se asumió que todos los pacientes con escalofríos y dolores tenían fiebre, por lo que nunca se les tomó la temperatura. Si es cierto, podríamos predecir fácilmente que cada observación que falta con escalofríos y dolores también tiene fiebre y utilizar esta información para imputar nuestros datos que faltan. En la práctica, esto es más bien un espectro. Quizá si un paciente tiene escalofríos y dolores, es más probable que también tenga fiebre si se le toma la temperatura, pero siempre. Esto sigue siendo predecible aunque sea perfectamente predecible. Este es un tipo común de valores faltantesDesaparición aleatoria (MNAR Missing Random). veces, también se denomina Falta aleatoria (NMAR). Esto supone que la probabilidad de que falte un valor es sistemática ni predecible utilizando el resto de la información que tenemos, pero tampoco falta al azar. En esta situación, los datos faltan por razones desconocidas o por razones de las que se tiene ninguna información. Por ejemplo, en nuestro conjunto de datos puede faltar información sobre la edad porque algunos pacientes muy mayores saben o se niegan decir su edad. En esta situación, los datos que faltan sobre la edad están relacionados con el propio valor (y, por tanto, son aleatorios) y son predecibles en función del resto de la información que tenemos. El MNAR es complejo y, menudo, la mejor manera de afrontarlo es intentar recopilar más datos o información sobre el motivo por el que faltan los datos en lugar de intentar imputarlos.Desaparición aleatoria (MNAR Missing Random). veces, también se denomina Falta aleatoria (NMAR). Esto supone que la probabilidad de que falte un valor es sistemática ni predecible utilizando el resto de la información que tenemos, pero tampoco falta al azar. En esta situación, los datos faltan por razones desconocidas o por razones de las que se tiene ninguna información. Por ejemplo, en nuestro conjunto de datos puede faltar información sobre la edad porque algunos pacientes muy mayores saben o se niegan decir su edad. En esta situación, los datos que faltan sobre la edad están relacionados con el propio valor (y, por tanto, son aleatorios) y son predecibles en función del resto de la información que tenemos. El MNAR es complejo y, menudo, la mejor manera de afrontarlo es intentar recopilar más datos o información sobre el motivo por el que faltan los datos en lugar de intentar imputarlos.En general, la imputación de datos MCAR suele ser bastante sencilla, mientras que la MNAR es muy difícil, si imposible. Muchos de los métodos comunes de imputación de datos asumen MAR.","code":""},{"path":"missing-data.html","id":"paquetes-útiles","chapter":"20 Valores faltantes","heading":"Paquetes útiles","text":"Algunos paquetes útiles para la imputación de valores faltantes son Mmisc, missForest (que utiliza bosques aleatorios para imputar los valores faltantes) y mice (Imputación multivariada por ecuaciones encadenadas). Para esta sección sólo utilizaremos el paquete mice, que implementa una variedad de técnicas. El mantenedor del paquete mice ha publicado un libro en línea sobre la imputación Flexible de valores faltantes.Este es el código para cargar el paquete mice :","code":"\npacman::p_load(mice)"},{"path":"missing-data.html","id":"imputación-de-la-media","chapter":"20 Valores faltantes","heading":"Imputación de la media","text":"veces, si estás haciendo un análisis simple o tienes una razón de peso para pensar que puede asumir MCAR, puedes simplemente establecer los valores numéricos que faltan la media de esa variable. Tal vez podamos asumir que las mediciones de temperatura que faltan en nuestro conjunto de datos eran MCAR o eran simplemente valores normales. Aquí está el código para crear una nueva variable que reemplaza los valores de temperatura faltantes con el valor medio de la temperatura en nuestro conjunto de datos. Sin embargo, en muchas situaciones reemplazar los datos con la media puede conducir un sesgo, así que ten cuidado.También puedes realizar un proceso similar para sustituir los datos categóricos por un valor específico. Para nuestro conjunto de datos, imagina que sabes que todas las observaciones con un valor faltante para tu resultado (que puede ser “Muerte” o “Recuperación”) son en realidad personas que han muerto (nota: esto es realmente cierto para este conjunto de datos):","code":"\nlinelist <- linelist %>%\n  mutate(temp_replace_na_with_mean = replace_na(temp, mean(temp, na.rm = T)))\nlinelist <- linelist %>%\n  mutate(outcome_replace_na_with_death = replace_na(outcome, \"Death\"))"},{"path":"missing-data.html","id":"imputación-de-la-regresión","chapter":"20 Valores faltantes","heading":"Imputación de la regresión","text":"Un método algo más avanzado consiste en utilizar algún tipo de modelo estadístico para predecir cuál es el valor que falta y sustituirlo por el valor predicho. Este es un ejemplo de creación de valores predichos para todas las observaciones en las que falta la temperatura, pero la edad ni la fiebre, mediante una simple regresión lineal que utiliza el estado de la fiebre y la edad en años como predictores. En la práctica, es conveniente utilizar un modelo mejor que este tipo de enfoque simple.O bien, utilizando el mismo enfoque de modelización través del paquete mice para crear valores imputados para las observaciones de temperatura que faltan:Este es el mismo tipo de enfoque de algunos métodos más avanzados, como el uso del paquete missForest para sustituir los datos que faltan por valores predichos. En ese caso, el modelo de predicción es un bosque aleatorio en lugar de una regresión lineal. También se pueden utilizar otros tipos de modelos para hacer esto. Sin embargo, aunque este enfoque funciona bien con MCAR, debes tener un poco de cuidado si crees que MAR o MNAR describen con más precisión tu situación. La calidad de tu imputación dependerá de lo bueno que sea tu modelo de predicción e incluso con un modelo muy bueno la variabilidad de los datos imputados puede estar subestimada.","code":"\nsimple_temperature_model_fit <- lm(temp ~ fever + age_years, data = linelist)\n\n#using our simple temperature model to predict values just for the observations where temp is missing\npredictions_for_missing_temps <- predict(simple_temperature_model_fit,\n                                        newdata = linelist %>% filter(is.na(temp))) \nmodel_dataset <- linelist %>%\n  select(temp, fever, age_years)  \n\ntemp_imputed <- mice(model_dataset,\n                            method = \"norm.predict\",\n                            seed = 1,\n                            m = 1,\n                            print = F)## Warning: Number of logged events: 1\ntemp_imputed_values <- temp_imputed$imp$temp"},{"path":"missing-data.html","id":"locf-y-bocf","chapter":"20 Valores faltantes","heading":"LOCF y BOCF","text":"La última observación trasladada (LOCF) y la observación de referencia trasladada (BOCF) son métodos de imputación para datos de series temporales/longitudinales. La idea es tomar el valor observado anterior como reemplazo de los datos que faltan. Cuando faltan varios valores sucesivamente, el método busca el último valor observado.La función fill() del paquete tidyr puede utilizarse para la imputación LOCF y BOCF (sin embargo, otros paquetes como HMISC, zoo y data.table también incluyen métodos para hacerlo). Para mostrar la sintaxis de fill(), crearemos un sencillo conjunto de datos de series temporales que contenga el número de casos de una enfermedad para cada trimestre de los años 2000 y 2001. Sin embargo, falta el valor del año para los trimestres posteriores al primero, por lo que tendremos que imputarlos. La unión fill() también se demuestra en la página Pivotar datos.Nota: asegúrate de que tus datos están correctamente ordenados antes de utilizar la función fill(). fill() rellena por defecto “hacia abajo”, pero también puedes imputar valores en diferentes direcciones cambiando el parámetro .direction. Podemos hacer unos datos similares en el que el valor del año se registra sólo al final del año y falta para los trimestres anteriores:En este ejemplo, LOCF y BOCF son claramente lo correcto, pero en situaciones más complicadas puede ser más difícil decidir si estos métodos son apropiados. Por ejemplo, es posible que falten valores de laboratorio para un paciente del hospital después del primer día. veces, esto puede significar que los valores de laboratorio cambiaron… ¡pero también podría significar que el paciente se recuperó y sus valores serían muy diferentes después del primer día! Utiliza estos métodos con precaución.","code":"\n#creating our simple dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",    2000,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",      NA,    21001,\n  \"Q1\",    2001,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",      NA,    50197)\n\n#imputing the missing year values:\ndisease %>% fill(year)## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197\n#creating our slightly different dataset\ndisease <- tibble::tribble(\n  ~quarter, ~year, ~cases,\n  \"Q1\",      NA,    66013,\n  \"Q2\",      NA,    69182,\n  \"Q3\",      NA,    53175,\n  \"Q4\",    2000,    21001,\n  \"Q1\",      NA,    46036,\n  \"Q2\",      NA,    58842,\n  \"Q3\",      NA,    44568,\n  \"Q4\",    2001,    50197)\n\n#imputing the missing year values in the \"up\" direction:\ndisease %>% fill(year, .direction = \"up\")## # A tibble: 8 × 3\n##   quarter  year cases\n##   <chr>   <dbl> <dbl>\n## 1 Q1       2000 66013\n## 2 Q2       2000 69182\n## 3 Q3       2000 53175\n## 4 Q4       2000 21001\n## 5 Q1       2001 46036\n## 6 Q2       2001 58842\n## 7 Q3       2001 44568\n## 8 Q4       2001 50197"},{"path":"missing-data.html","id":"imputación-múltiple","chapter":"20 Valores faltantes","heading":"Imputación múltiple","text":"El libro en línea que mencionamos antes, escrito por el autor del paquete mice contiene una explicación detallada de la imputación múltiple y de los motivos por los que conviene utilizarla. Pero, aquí hay una explicación básica del método:Cuando se realiza una imputación múltiple, se crean múltiples conjuntos de datos con los valores faltantes imputados valores de datos plausibles (dependiendo de los datos de tu investigación, puedes querer crear más o menos de estos conjuntos de datos imputados, pero el paquete mice establece el número por defecto en 5). La diferencia es que, en lugar de un valor único y específico, cada valor imputado se extrae de una distribución estimada (por lo que incluye cierta aleatoriedad). Como resultado, cada uno de estos conjuntos de datos tendrá valores imputados ligeramente diferentes (sin embargo, los datos ausentes serán los mismos en cada uno de estos conjuntos de datos imputados). Todavía se utiliza algún tipo de modelo predictivo para hacer la imputación en cada uno de estos nuevos conjuntos de datos (mice tiene muchas opciones para los métodos de predicción, incluyendo Predictive Mean Matching, regresión logística y random forest), pero el paquete mice puede encargarse de muchos de los detalles del modelado.Entonces, una vez que hayas creado estos nuevos conjuntos de datos imputados, puedes aplicar cualquier modelo estadístico o análisis que estuviera planeando hacer para cada uno de estos nuevos conjuntos de datos imputados y juntar los resultados de estos modelos. Esto funciona muy bien para reducir el sesgo tanto en MCAR como en muchas configuraciones de MAR y menudo resulta en estimaciones de error estándar más precisas.aquí un ejemplo de aplicación del proceso de Imputación Múltiple para predecir la temperatura en nuestro conjunto de datos de linelist utilizando una edad y un estado de fiebre (nuestro conjunto de datos modelo simplificado de arriba):En este caso, utilizamos el método de imputación por defecto de mice, que es el de Coincidencia de Medias Predictivas. continuación, utilizamos estos conjuntos de datos imputados para estimar por separado y luego agrupar los resultados de las regresiones lineales simples en cada uno de estos conjuntos de datos. Hay muchos detalles que hemos pasado por alto y muchas configuraciones que puedes ajustar durante el proceso de Imputación Múltiple mientras utilizas el paquete mice. Por ejemplo, siempre tendrá datos numéricos y podría necesitar utilizar otros métodos de imputación (puedes seguir utilizando el paquete mice para muchos otros tipos de datos y métodos). Pero, para un análisis más robusto cuando los datos faltantes son una preocupación significativa, la Imputación Múltiple es una buena solución que siempre es mucho más trabajo que hacer un análisis de caso completo.","code":"\n# imputing missing values for all variables in our model_dataset, and creating 10 new imputed datasets\nmultiple_imputation = mice(\n  model_dataset,\n  seed = 1,\n  m = 10,\n  print = FALSE) ## Warning: Number of logged events: 1\nmodel_fit <- with(multiple_imputation, lm(temp ~ age_years + fever))\n\nbase::summary(mice::pool(model_fit))##          term     estimate    std.error     statistic        df       p.value\n## 1 (Intercept) 3.703143e+01 0.0270863456 1367.16240465  26.83673  1.583113e-66\n## 2   age_years 3.867829e-05 0.0006090202    0.06350905 171.44363  9.494351e-01\n## 3    feveryes 1.978044e+00 0.0193587115  102.17849544 176.51325 5.666771e-159"},{"path":"missing-data.html","id":"resources-13","chapter":"20 Valores faltantes","heading":"20.7 Recursos","text":"Viñeta sobre el paquete naniarGalería de visualizaciones de valores faltantesLibro en línea sobre imputación múltiple en R por el mantenedor del paquete mice","code":""},{"path":"standardised-rates.html","id":"standardised-rates","chapter":"21 Tasas estandarizadas","heading":"21 Tasas estandarizadas","text":"Esta página te mostrará dos formas de estandarizar un resultado, como las hospitalizaciones o la mortalidad, por características como la edad y el sexo.Uso del paquete dsrUso del paquete PHEindicatormethodsComenzamos demostrando ampliamente los procesos de preparación/limpieza/unión de datos, ya que esto es común cuando se combinan datos de población de múltiples países, datos de población estándar, defunciones, etc.","code":""},{"path":"standardised-rates.html","id":"overview-1","chapter":"21 Tasas estandarizadas","heading":"21.1 Resumen","text":"Hay dos formas principales de estandarizar: la estandarización directa y la indirecta. Supongamos que queremos estandarizar la tasa de mortalidad por edad y sexo para el país y el país B, y comparar las tasas estandarizadas entre estos países.Para la estandarización directa, tendrás que conocer el número de la población de riesgo y el número de defunciones para cada estrato de edad y sexo, para el país y el país B. Un estrato en nuestro ejemplo podría ser el de las mujeres entre 15-44 años.Para la estandarización indirecta, sólo es necesario conocer el número total de defunciones y la estructura por edad y sexo de cada país. Por tanto, esta opción es factible si se dispone de tasas de mortalidad específicas por edad y sexo o de cifras de población. La estandarización indirecta es, además, preferible en caso de números pequeños por estrato, ya que las estimaciones en la estandarización directa estarían influenciadas por una variación sustancial del muestreo.","code":""},{"path":"standardised-rates.html","id":"preparation-12","chapter":"21 Tasas estandarizadas","heading":"21.2 Preparación","text":"Para mostrar cómo se realiza la estandarización, utilizaremos recuentos ficticios de la población y de las defunciones del país y del país B, por edad (en categorías de 5 años) y por sexo (femenino, masculino). Para que los datos estén listos para su uso, realizaremos los siguientes pasos de preparación:Cargar paquetesCargar datosUnir los datos de población y mortalidad de los dos paísesPivotar largo para que haya una fila por estrato de edad y sexoLimpiar la población de referencia (población estándar mundial) y unirla los datos del paísEn tu caso, los datos pueden tener un formato diferente. Tal vez esos datos sean por provincia, ciudad u otra zona de captación. Puede que tengas una fila para cada defunció e información sobre la edad y el sexo de cada una (o de una proporción significativa) de estas defunciones. En este caso, consulta las páginas sobre Agrupar de datos, Pivotar de datos y Tablas descriptivas para crear unos datos con recuentos de eventos y población por estrato de edad y sexo.También necesitamos una población de referencia, la población estándar. Para los fines de este ejercicio utilizaremos la world_standard_population_by_sex. La población estándar mundial se basa en las poblaciones de 46 países y se elaboró en 1960. Hay muchas poblaciones “estándar”; por ejemplo, el sitio web del NHS de Escocia ofrece bastante información sobre la población estándar europea, la población estándar mundial y la población estándar de Escocia.","code":""},{"path":"standardised-rates.html","id":"cargar-paquetes-13","chapter":"21 Tasas estandarizadas","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.PRECAUCIÓN: Si tienes una versión más reciente de R, el paquete dsr puede descargarse directamente de CRAN. Sin embargo, todavía está disponible en el archivo CRAN. Puedes instalar y utilizar éste.Para los que son usuarios de Mac:Para los usuarios de Mac:","code":"\npacman::p_load(\n     rio,                 # import/export data\n     here,                # locate files\n     tidyverse,           # data management and visualization\n     stringr,             # cleaning characters and strings\n     frailtypack,         # needed for dsr, for frailty models\n     dsr,                 # standardise rates\n     PHEindicatormethods) # alternative for rate standardisation\npackageurl <- \"https://cran.r-project.org/src/contrib/Archive/dsr/dsr_0.2.2.tar.gz\"\ninstall.packages(packageurl, repos=NULL, type=\"source\")\n# Other solution that may work\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"http:/cran.us.r.project.org\")\nrequire(devtools)\ndevtools::install_version(\"dsr\", version=\"0.2.2\", repos=\"https://mac.R-project.org\")"},{"path":"standardised-rates.html","id":"cargar-los-datos-de-población","chapter":"21 Tasas estandarizadas","heading":"Cargar los datos de población","text":"Consulta la página de descargando el manual y los datos para obtener instrucciones sobre cómo descargar todos los datos de ejemplo del manual. Puedes importar los datos de la página de estandarización directamente R desde nuestro repositorio de Github ejecutando los siguientes comandos import():En primer lugar, cargamos los datos demográficos (recuentos de hombres y mujeres por categoría de edad de 5 años) de los dos países que vamos comparar, “Country ” y “Country B”.","code":"\n# import demographics for country A directly from Github\nA_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics.csv\")\n\n# import deaths for country A directly from Github\nA_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryA.csv\")\n\n# import demographics for country B directly from Github\nB_demo <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/country_demographics_2.csv\")\n\n# import deaths for country B directly from Github\nB_deaths <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/deaths_countryB.csv\")\n\n# import demographics for country B directly from Github\nstandard_pop_data <- import(\"https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/standardization/world_standard_population_by_sex.csv\")\n# Country A\nA_demo <- import(\"country_demographics.csv\")\n# Country B\nB_demo <- import(\"country_demographics_2.csv\")"},{"path":"standardised-rates.html","id":"cargar-datos-de-defunciones","chapter":"21 Tasas estandarizadas","heading":"Cargar datos de defunciones","text":"Convenientemente, también tenemos los recuentos de las defunciones durante el período de interés, por edad y sexo. Los recuentos de cada país están en un archivo separado, que se muestra continuación.Defunciones en Country ADefunciones en Country B","code":""},{"path":"standardised-rates.html","id":"poblaciones-y-defunciones-limpias","chapter":"21 Tasas estandarizadas","heading":"Poblaciones y defunciones limpias","text":"Necesitamos unir y transformar estos datos de la siguiente manera:Combinar las poblaciones de los países en un solo conjunto de datos y hacer un pivote “largo” para que cada estrato de edad y sexo sea una filaCombinar los recuentos de defunciones por país en un solo conjunto de datos y hacer un pivote “largo” para que cada estrato de edad y sexo sea una filaUnir las defunciones las poblacionesEn primer lugar, combinamos los datos de las poblaciones de los países, los pivotamos “largo” y realizamos una pequeña limpieza. Para más detalles, consulta la página sobre pivotar datos.Los datos de población combinados tienen ahora este aspecto (clica para ver los países y B):Y ahora realizamos operaciones similares en los dos conjuntos de datos de defunciones.Los datos de las defunciones tienen ahora este aspecto, y contienen datos de ambos países:Ahora unimos los datos de defunciones y población basándonos en las columnas comunes Country, age_cat5, y Sex. Esto añade la columna Deaths.Ahora podemos clasificar Sex, age_cat5, y Country como factores y establecer el orden de los niveles utilizando la función fct_relevel() del paquete forcats, como se describe en la página sobre Factores. Ten en cuenta que la clasificación de los niveles de los factores cambia visiblemente los datos, pero el comando arrange() los ordena por Country, age category, y sex.PRECAUCIÓN: Si tienes pocas defunciones por estrato, considera la posibilidad de utilizar categorías de 10 o 15 años, en lugar de categorías de 5 años para la edad.","code":"\npop_countries <- A_demo %>%  # begin with country A dataset\n     bind_rows(B_demo) %>%        # bind rows, because cols are identically named\n     pivot_longer(                       # pivot longer\n          cols = c(m, f),                   # columns to combine into one\n          names_to = \"Sex\",                 # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Population\") %>%     # name for new column containing the numeric values pivoted\n     mutate(Sex = recode(Sex,            # re-code values for clarity\n          \"m\" = \"Male\",\n          \"f\" = \"Female\"))\ndeaths_countries <- A_deaths %>%    # begin with country A deaths dataset\n     bind_rows(B_deaths) %>%        # bind rows with B dataset, because cols are identically named\n     pivot_longer(                  # pivot longer\n          cols = c(Male, Female),        # column to transform into one\n          names_to = \"Sex\",              # name for new column containing the category (\"m\" or \"f\") \n          values_to = \"Deaths\") %>%      # name for new column containing the numeric values pivoted\n     rename(age_cat5 = AgeCat)      # rename for clarity\ncountry_data <- pop_countries %>% \n     left_join(deaths_countries, by = c(\"Country\", \"age_cat5\", \"Sex\"))\ncountry_data <- country_data %>% \n  mutate(\n    Country = fct_relevel(Country, \"A\", \"B\"),\n      \n    Sex = fct_relevel(Sex, \"Male\", \"Female\"),\n        \n    age_cat5 = fct_relevel(\n      age_cat5,\n      \"0-4\", \"5-9\", \"10-14\", \"15-19\",\n      \"20-24\", \"25-29\",  \"30-34\", \"35-39\",\n      \"40-44\", \"45-49\", \"50-54\", \"55-59\",\n      \"60-64\", \"65-69\", \"70-74\",\n      \"75-79\", \"80-84\", \"85\")) %>% \n          \n  arrange(Country, age_cat5, Sex)"},{"path":"standardised-rates.html","id":"carga-de-la-población-de-referencia","chapter":"21 Tasas estandarizadas","heading":"Carga de la población de referencia","text":"Por último, para la estandarización directa, importamos la población de referencia (la “población estándar” mundial por sexo)","code":"\n# Reference population\nstandard_pop_data <- import(\"world_standard_population_by_sex.csv\")"},{"path":"standardised-rates.html","id":"población-de-referencia-limpia","chapter":"21 Tasas estandarizadas","heading":"Población de referencia limpia","text":"Los valores de la categoría de edad en los dataframes country_data y standard_pop_data tendrán que estar alineados.Actualmente, los valores de la columna age_cat5 del dataframe standard_pop_data contienen la palabra “years” y “plus”, mientras que los del dataframe country_data . Tendremos que hacer coincidir los valores de la categoría de edad. Usamos str_replace_all() del paquete stringr, como se describe en la página sobre Caracteres y cadenas, para reemplazar estos patrones sin espacio \"\".Además, el paquete dsr espera que en la población estándar, la columna que contiene los recuentos se llame \"pop\". Así que cambiaremos el nombre de esa columna.PRECAUCIÓN: Si intentas utilizar str_replace_all() para eliminar un símbolo de suma, funcionará porque es un símbolo especial. “Escapa” de los símbolos especiales poniendo dos barras invertidas delante, como en str_replace_call(columna, \"\\\\+\", \"\"). ","code":"\n# Remove specific string from column values\nstandard_pop_clean <- standard_pop_data %>%\n     mutate(\n          age_cat5 = str_replace_all(age_cat5, \"years\", \"\"),   # remove \"year\"\n          age_cat5 = str_replace_all(age_cat5, \"plus\", \"\"),    # remove \"plus\"\n          age_cat5 = str_replace_all(age_cat5, \" \", \"\")) %>%   # remove \" \" space\n     \n     rename(pop = WorldStandardPopulation)   # change col name to \"pop\", as this is expected by dsr package"},{"path":"standardised-rates.html","id":"standard_all","chapter":"21 Tasas estandarizadas","heading":"Crear un conjunto de datos con una población estándar","text":"Por último, el paquete PHEindicatormethods, que se detalla continuación, espera que las poblaciones estándar se unan los recuentos de eventos y poblaciones del país. Por lo tanto, crearemos un conjunto de datos all_data con ese fin.Este conjunto de datos completo tiene el siguiente aspecto:","code":"\nall_data <- left_join(country_data, standard_pop_clean, by=c(\"age_cat5\", \"Sex\"))"},{"path":"standardised-rates.html","id":"dsr-package","chapter":"21 Tasas estandarizadas","heading":"21.3 paquete dsr","text":"continuación mostramos el cálculo y la comparación de tasas estandarizadas directamente utilizando el paquete dsr. El paquete dsr permite calcular y comparar tasas estandarizadas directamente (¡hay tasas estandarizadas indirectamente!).En la sección de preparación de datos, hemos creado conjuntos de datos separados para los recuentos de países y la población estándar:el objeto country_data, que es una tabla de población con el número de habitantes y el número de defunciones por estrato por paísel objeto standard_pop_clean, que contiene el número de población por estrato para nuestra población de referencia, la población estándar mundialUtilizaremos estos conjuntos de datos separados para el enfoque dsr.","code":""},{"path":"standardised-rates.html","id":"tasas-estandarizadas","chapter":"21 Tasas estandarizadas","heading":"Tasas estandarizadas","text":"continuación, calculamos las tasas por país directamente estandarizadas por edad y sexo. Utilizamos la función dsr().Cabe destacar que dsr() espera un dataframe para las poblaciones de los países y los recuentos de eventos (defunciones), y un dataframe separado con la población de referencia. También espera que en este conjunto de datos de la población de referencia el nombre de la columna de la unidad de tiempo sea “pop” (lo aseguramos en la sección de preparación de datos).Hay muchos argumentos, como se anota en el código siguiente. En particular, el event = se establece en la columna Deaths, y fu = (“seguimiento”) con la columna Population. Establecemos los subgrupos de comparación como la columna Country y estandarizamos en base age_cat5 y Sex. estas dos últimas columnas se les asigna un argumento con nombre concreto. Consulta ?dsr para obtener más detalles.Arriba, vemos que mientras Country tenía una tasa de mortalidad bruta más baja que Country B, ahora tiene una tasa estandarizada más alta después de la estandarización directa por edad y sexo.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_rate <- dsr::dsr(\n     data = country_data,  # specify object containing number of deaths per stratum\n     event = Deaths,       # column containing number of deaths per stratum \n     fu = Population,      # column containing number of population per stratum\n     subgroup = Country,   # units we would like to compare\n     age_cat5,             # other columns - rates will be standardized by these\n     Sex,\n     refdata = standard_pop_clean, # reference population data frame, with column called pop\n     method = \"gamma\",      # method to calculate 95% CI\n     sig = 0.95,            # significance level\n     mp = 100000,           # we want rates per 100.000 population\n     decimals = 2)          # number of decimals)\n\n\n# Print output as nice-looking HTML table\nknitr::kable(mortality_rate) # show mortality rate before and after direct standardization"},{"path":"standardised-rates.html","id":"razón-de-tasas-estandarizadas","chapter":"21 Tasas estandarizadas","heading":"Razón de tasas estandarizadas","text":"La tasa de mortalidad estandarizada es 1,22 veces mayor en Country en comparación con Country B (IC del 95%: 1,17-1,27).","code":"\n# Calculate RR\nmortality_rr <- dsr::dsrr(\n     data = country_data, # specify object containing number of deaths per stratum\n     event = Deaths,      # column containing number of deaths per stratum \n     fu = Population,     # column containing number of population per stratum\n     subgroup = Country,  # units we would like to compare\n     age_cat5,\n     Sex,                 # characteristics to which we would like to standardize \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",      # reference for comparison\n     estimate = \"ratio\",  # type of estimate\n     sig = 0.95,          # significance level\n     mp = 100000,         # we want rates per 100.000 population\n     decimals = 2)        # number of decimals\n\n# Print table\nknitr::kable(mortality_rr) "},{"path":"standardised-rates.html","id":"diferencia-de-tasas-estandarizadas","chapter":"21 Tasas estandarizadas","heading":"Diferencia de tasas estandarizadas","text":"El país tiene 4,24 defunciones adicionales por cada 100.000 habitantes (IC del 95%: 3,24-5,24) en comparación con el país .","code":"\n# Calculate RD\nmortality_rd <- dsr::dsrr(\n     data = country_data,       # specify object containing number of deaths per stratum\n     event = Deaths,            # column containing number of deaths per stratum \n     fu = Population,           # column containing number of population per stratum\n     subgroup = Country,        # units we would like to compare\n     age_cat5,                  # characteristics to which we would like to standardize\n     Sex,                        \n     refdata = standard_pop_clean, # reference population, with numbers in column called pop\n     refgroup = \"B\",            # reference for comparison\n     estimate = \"difference\",   # type of estimate\n     sig = 0.95,                # significance level\n     mp = 100000,               # we want rates per 100.000 population\n     decimals = 2)              # number of decimals\n\n# Print table\nknitr::kable(mortality_rd) "},{"path":"standardised-rates.html","id":"standard_phe","chapter":"21 Tasas estandarizadas","heading":"21.4 Paquete PHEindicatormethods","text":"Otra forma de calcular las tasas estandarizadas es con el paquete PHEindicatormethods. Este paquete permite calcular las tasas estandarizadas tanto directa como indirectamente. Mostraremos ambos métodos.En esta sección se utilizará el dataframe all_data creado al final de la sección Preparación. Este dataframe incluye las poblaciones de los países, los eventos de defunciones y la población de referencia mundial estándar. Puedes verlo aquí.","code":""},{"path":"standardised-rates.html","id":"tasas-estandarizadas-directamente","chapter":"21 Tasas estandarizadas","heading":"Tasas estandarizadas directamente","text":"continuación, primero agrupamos los datos por país y luego los pasamos la función phe_dsr() para obtener directamente las tasas estandarizadas por país.Cabe destacar que la población de referencia (estándar) puede proporcionarse como una columna dentro del dataframe específico del país o como un vector separado. Si se proporciona dentro del dataframe específico del país, hay que establecer stdpoptype = \"field\". Si se proporciona como un vector, hay que establecer stdpoptype = \"vector\". En este último caso, hay que asegurarse de que el orden de las filas por estratos es similar tanto en el dataframe específico del país como en la población de referencia, ya que los registros se emparejarán por posición. En nuestro ejemplo siguiente, proporcionamos la población de referencia como una columna dentro del dataframe específico del país.Consulta la ayuda de ?phr_dsr o los enlaces de la sección Referencias para obtener más información.","code":"\n# Calculate rates per country directly standardized for age and sex\nmortality_ds_rate_phe <- all_data %>%\n     group_by(Country) %>%\n     PHEindicatormethods::phe_dsr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          stdpop = pop,               # standard populations for each stratum\n          stdpoptype = \"field\")       # either \"vector\" for a standalone vector or \"field\" meaning std populations are in the data  \n\n# Print table\nknitr::kable(mortality_ds_rate_phe)"},{"path":"standardised-rates.html","id":"standard_indirect","chapter":"21 Tasas estandarizadas","heading":"Tasas estandarizadas indirectamente","text":"Para la estandarización indirecta, se necesita una población de referencia con el número de defunciones y el número de población por estrato. En este ejemplo, calcularemos las tasas del país utilizando el país B como población de referencia, ya que la población de referencia de standard_pop_clean incluye el número de defunciones por estrato.continuación, creamos primero la población de referencia del país B. Luego, pasamos los datos de mortalidad y población del país , los combinamos con la población de referencia y los pasamos la función phe_isr(), para obtener tasas estandarizadas indirectamente. Por supuesto, también se puede hacer la inversa.En nuestro ejemplo, la población de referencia se proporciona como un dataframe separado. En este caso, nos aseguraremos que los vectores x =, n =, x_ref = y n_ref = estén ordenados por los mismos valores de categoría de normalización (estrato) que los de nuestro dataframe específico del país, ya que los registros se emparejarán por posición.Consulta la ayuda de ?phr_isr o los enlaces de la sección Referencias para obtener más información.","code":"\n# Create reference population\nrefpopCountryB <- country_data %>% \n  filter(Country == \"B\") \n\n# Calculate rates for country A indirectly standardized by age and sex\nmortality_is_rate_phe_A <- country_data %>%\n     filter(Country == \"A\") %>%\n     PHEindicatormethods::phe_isr(\n          x = Deaths,                 # column with observed number of events\n          n = Population,             # column with non-standard pops for each stratum\n          x_ref = refpopCountryB$Deaths,  # reference number of deaths for each stratum\n          n_ref = refpopCountryB$Population)  # reference population for each stratum\n\n# Print table\nknitr::kable(mortality_is_rate_phe_A)"},{"path":"standardised-rates.html","id":"resources-14","chapter":"21 Tasas estandarizadas","heading":"21.5 Recursos","text":"Si deseas ver otro ejemplo reproducible utilizando dsr, consulta esta viñetaSi deseas ver otro ejemplo en el que se utilizan los métodos de PHEindicator, visita este sitio webVer el archivo pdf de referencia de PHEindicatormethods","code":""},{"path":"moving-averages.html","id":"moving-averages","chapter":"22 Medias Móviles","heading":"22 Medias Móviles","text":"Esta página cubrirá dos métodos para calcular y visualizar las medias móviles:Calcular con el paquete slider.Calcular dentro de un comando ggplot() con el paquete tidyquant.","code":""},{"path":"moving-averages.html","id":"preparation-12","chapter":"22 Medias Móviles","heading":"22.1 Preparación","text":"","code":""},{"path":"moving-averages.html","id":"cargar-paquetes-14","chapter":"22 Medias Móviles","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  tidyverse,      # for data management and viz\n  slider,         # for calculating moving averages\n  tidyquant       # for calculating moving averages within ggplot\n)"},{"path":"moving-averages.html","id":"importar-datos-12","chapter":"22 Medias Móviles","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"moving-averages.html","id":"calculate-with-slider","chapter":"22 Medias Móviles","heading":"22.2 Calcular con slider","text":"Utiliza este enfoque para calcular una media móvil en un dataframe antes de representarlaEl paquete slider proporciona varias funciones de “ventana deslizante” para calcular medias móviles, sumas acumulativas, regresiones móviles, etc. Trata un dataframe como un vector de filas, permitiendo la iteración por filas sobre un dataframe.Estas son algunas de las funciones más comunes:slide_dbl() - itera través de una columna numérica (de ahí “_dbl”) realizando una operación mediante una ventana deslizante\nslide_sum() - función abreviada de suma móvil para slide_dbl()\nslide_mean() - función abreviada de media móvil para slide_dbl()\nslide_sum() - función abreviada de suma móvil para slide_dbl()slide_mean() - función abreviada de media móvil para slide_dbl()slide_index_dbl() - aplica la ventana móvil en una columna numérica utilizando una columna separada para indexar la progresión de la ventana (útil si se rueda por fecha con algunas fechas ausentes)\nslide_index_sum() - Función abreviada de suma móvil con indexación\nslide_index_mean() - Función de acceso directo la media móvil con indexación\nslide_index_sum() - Función abreviada de suma móvil con indexaciónslide_index_mean() - Función de acceso directo la media móvil con indexaciónEl paquete slider tiene muchas otras funciones que se tratan en la sección de Recursos de esta página. Tocamos brevemente las más comunes.Argumentos básicos.x, el primer argumento por defecto, es el vector sobre el que iterar y al que aplicar la función.= para las versiones de “índice” de las funciones de deslizamiento - proporciona una columna para “indexar” el rollo (véase la sección siguiente).f = , el segundo argumento por defecto, bien:\nUna función, escrita sin paréntesis, como mean, o\nUna fórmula, que se convertirá en una función. Por ejemplo ~ .x - mean(.x) devolverá el resultado del valor actual menos la media del valor de la ventana\nUna función, escrita sin paréntesis, como mean, oUna fórmula, que se convertirá en una función. Por ejemplo ~ .x - mean(.x) devolverá el resultado del valor actual menos la media del valor de la ventanaPara más detalles, consulta este material de referenciaTamaño de la ventanaEspecifica el tamaño de la ventana utilizando los argumentos ., ., o ambos:.= - Proporcionar un número entero.=- Proporcionar un número entero.complete =- Pon este valor TRUE si sólo quieres que se realicen cálculos en ventanas completasPor ejemplo, para conseguir una ventana de 7 días que incluya el valor actual y los seis anteriores, utiliza .= 6. Para conseguir una ventana “centrada” proporciona el mismo número tanto .= como .=.Por defecto, .complete = será FALSE por lo que si la ventana completa de filas existe, las funciones utilizarán las filas disponibles para realizar el cálculo. Si se ajusta TRUE, los cálculos sólo se realizan en ventanas completas.Ventana expansivaPara lograr operaciones acumulativas, establece el argumento .= en Inf. Esto realizará la operación sobre el valor actual y todos los que vengan antes.","code":""},{"path":"moving-averages.html","id":"roll_index","chapter":"22 Medias Móviles","heading":"Balancear por fecha","text":"El caso más probable de uso de un cálculo rotativo en epidemiología aplicada es examinar una medida lo largo del tiempo. Por ejemplo, una medición continua de la incidencia de casos, basada en el recuento diario de casos.Si tienes datos de series temporales limpios con valores para cada fecha, puede estar bien utilizar slide_dbl(), como se demuestra aquí en la página de series temporales y detección de brotes.Sin embargo, en muchas circunstancias de epidemiología aplicada puede haber fechas ausentes en los datos, donde hay eventos registrados. En estos casos, es mejor utilizar las versiones “index” de las funciones slider.","code":""},{"path":"moving-averages.html","id":"datos-indexados","chapter":"22 Medias Móviles","heading":"Datos indexados","text":"continuación, mostramos un ejemplo utilizando slide_index_dbl() en la lista de casos. Digamos que nuestro objetivo es calcular una incidencia acumulada de 7 días - la suma de casos utilizando una ventana móvil de 7 días. Si estás buscando un ejemplo de media móvil, mira la sección de abajo sobre balanceo agrupado.Para empezar, se crean los datos daily_counts para reflejar los recuentos diarios de casos de linelist, calculados con count() de dplyr.Aquí está el dataframe daily_counts - hay nrow(daily_counts) filas, cada día está representado por una fila, pero especialmente al principio de la epidemia algunos días están presentes (hubo casos admitidos en esos días).Es crucial reconocer que una función estándar de balanceo (como slide_dbl() utilizaría una ventana de 7 filas, de 7 días. Por lo tanto, si hay fechas ausentes, ¡algunas ventanas se extenderán realmente más de 7 días naturales!Se puede conseguir una ventana móvil “inteligente” con slide_index_dbl(). El “índex” significa que la función utiliza una columna independiente como “index” para la ventana móvil. La ventana se basa simplemente en las filas del dataframe.Si la columna índex es una fecha, tienes la posibilidad añadida de especificar la extensión de la ventana .= y/o .= en unidades de days() o months() de lubridate. Si haces estas cosas, la función incluirá los días ausentes en las ventanas como si estuvieran allí (como valores NA).Mostremos una comparación. continuación, calculamos la incidencia móvil de casos de 7 días con ventanas regulares e indexadas.Fíjate cómo en la columna normal de las 7 primeras filas el recuento aumenta constantemente pesar de que las filas tienen 7 días de diferencia. La columna adyacente “indexada” tiene en cuenta estos días naturales ausentes, por lo que la suma de 7 días son mucho menores, al menos en este periodo de la epidemia en el que los casos están más alejados.Ahora puede trazar estos datos utilizando ggplot():","code":"\n# make dataset of daily counts\ndaily_counts <- linelist %>% \n  count(date_hospitalisation, name = \"new_cases\")\nrolling <- daily_counts %>% \n  mutate(                                # create new columns\n    # Using slide_dbl()\n    ###################\n    reg_7day = slide_dbl(\n      new_cases,                         # calculate on new_cases\n      .f = ~sum(.x, na.rm = T),          # function is sum() with missing values removed\n      .before = 6),                      # window is the ROW and 6 prior ROWS\n    \n    # Using slide_index_dbl()\n    #########################\n    indexed_7day = slide_index_dbl(\n        new_cases,                       # calculate on new_cases\n        .i = date_hospitalisation,       # indexed with date_onset \n        .f = ~sum(.x, na.rm = TRUE),     # function is sum() with missing values removed\n        .before = days(6))               # window is the DAY and 6 prior DAYS\n    )\nggplot(data = rolling)+\n  geom_line(mapping = aes(x = date_hospitalisation, y = indexed_7day), size = 1)"},{"path":"moving-averages.html","id":"roll_slider_group","chapter":"22 Medias Móviles","heading":"Balanceando por grupo","text":"Si agrupas los datos antes de utilizar una función slider, las ventanas deslizantes se aplicarán por grupo. Ten cuidado de organizar las filas en el orden deseado por grupo.Cada vez que se inicia un nuevo grupo, la ventana deslizante se reinicia. Por lo tanto, un matiz tener en cuenta es que si tus datos están agrupados y establecido .complete = TRUE, tendrás valores vacíos en cada transición entre grupos. medida que la función se desplaza hacia abajo través de las filas, cada transición en la columna de agrupación reiniciará la acumulación del tamaño mínimo de la ventana para permitir un cálculo.Consulta la página del manual sobre Agrupar datos para obtener detalles sobre la agrupación de datos.continuación, contamos los casos del listado por fecha y por hospital. Luego ordenamos las filas en orden ascendente, primero ordenando por hospital y luego dentro de éste por fecha. continuación establecemos group_by(). Entonces podemos crear nuestra nueva media móvil.Aquí está el nuevo conjunto de datos:Ahora podemos trazar las medias móviles, mostrando los datos por grupo especificando ~ hospital facet_wrap() en ggplot(). Para divertirnos, trazamos dos geometrías: una geom_col() que muestra los recuentos de casos diarios y una geom_line() que muestra la media móvil de 7 días.PELIGRO: Si obtienes un error que dice “slide() deprecated tsibble 0.9.0 now defunct. Please use slider::slide() instead.”, significa que la función slide() del paquete tsibble está enmascarando la función slide() del paquete slider. Soluciona esto especificando el paquete en el comando, como slider::slide_dbl().","code":"\ngrouped_roll <- linelist %>%\n\n  count(hospital, date_hospitalisation, name = \"new_cases\") %>% \n\n  arrange(hospital, date_hospitalisation) %>%   # arrange rows by hospital and then by date\n  \n  group_by(hospital) %>%              # group by hospital \n    \n  mutate(                             # rolling average  \n    mean_7day_hosp = slide_index_dbl(\n      .x = new_cases,                 # the count of cases per hospital-day\n      .i = date_hospitalisation,      # index on date of admission\n      .f = mean,                      # use mean()                   \n      .before = days(6)               # use the day and the 6 days prior\n      )\n  )\nggplot(data = grouped_roll)+\n  geom_col(                       # plot daly case counts as grey bars\n    mapping = aes(\n      x = date_hospitalisation,\n      y = new_cases),\n    fill = \"grey\",\n    width = 1)+\n  geom_line(                      # plot rolling average as line colored by hospital\n    mapping = aes(\n      x = date_hospitalisation,\n      y = mean_7day_hosp,\n      color = hospital),\n    size = 1)+\n  facet_wrap(~hospital, ncol = 2)+ # create mini-plots per hospital\n  theme_classic()+                 # simplify background  \n  theme(legend.position = \"none\")+ # remove legend\n  labs(                            # add plot labels\n    title = \"7-day rolling average of daily case incidence\",\n    x = \"Date of admission\",\n    y = \"Case incidence\")"},{"path":"moving-averages.html","id":"calcular-con-tidyquant-dentro-de-ggplot","chapter":"22 Medias Móviles","heading":"22.3 Calcular con tidyquant dentro de ggplot()","text":"El paquete tidyquant ofrece otro enfoque para calcular las medias móviles, esta vez dentro del comando ggplot().Bajo linelist, los datos se cuentan por fecha de inicio, y esto se traza como una línea descolorida (alpha < 1). Encima hay una línea creada con geom_ma() del paquete tidyquant, con una ventana de 7 días (n = 7) con el color y el grosor especificados.Por defecto geom_ma() utiliza una media móvil simple (ma_fun = \"SMA\"), pero se pueden especificar otros tipos, como:“EMA” - media móvil exponencial (más peso las observaciones recientes)“WMA” - media móvil ponderada (los wts se utilizan para ponderar las observaciones en la media móvil)Otros se pueden encontrar en la documentación de la funciónConsulta esta viñeta para obtener más detalles sobre las opciones disponibles en tidyquant.","code":"\nlinelist %>% \n  count(date_onset) %>%                 # count cases per day\n  drop_na(date_onset) %>%               # remove cases missing onset date\n  ggplot(aes(x = date_onset, y = n))+   # start ggplot\n    geom_line(                          # plot raw values\n      size = 1,\n      alpha = 0.2                       # semi-transparent line\n      )+             \n    tidyquant::geom_ma(                 # plot moving average\n      n = 7,           \n      size = 1,\n      color = \"blue\")+ \n  theme_minimal()                       # simple background"},{"path":"moving-averages.html","id":"resources-14","chapter":"22 Medias Móviles","heading":"22.4 Recursos","text":"Consulta la útil viñeta en línea del paquete sliderLa página github del sliderUna viñeta sliderviñeta tidyquantSi tu caso de uso requiere que te “saltes” los fines de semana e incluso los días festivos, puede que te guste el paquete almanac.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"time-series-and-outbreak-detection","chapter":"23 Series temporales y detección de brotes","heading":"23 Series temporales y detección de brotes","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"overview-2","chapter":"23 Series temporales y detección de brotes","heading":"23.1 Resumen","text":"Esta página muestra el uso de varios paquetes para el análisis de series temporales. Principalmente se basa en paquetes de la familia tidyverts, pero también utilizará el paquete de RECON trending para ajustar modelos más apropiados para la epidemiología de enfermedades infecciosas.Ten en cuenta que en el siguiente ejemplo utilizamos unos datos del paquete surveillance sobre Campylobacter en Alemania (véase el capítulo Descargando el manual y los datoss del manual para más detalles). Sin embargo, si deseas ejecutar el mismo código en unos datos con múltiples países u otros estratos, hay una plantilla de código de ejemplo para esto en el repo de github de r4epis.Los temas que se tratan son:Datos de series temporalesAnálisis descriptivoAjuste de regresionesRelación de dos series temporalesDetección de brotesSeries temporales interrumpidas","code":""},{"path":"time-series-and-outbreak-detection.html","id":"preparation-14","chapter":"23 Series temporales y detección de brotes","heading":"23.2 Preparación","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"paquetes-1","chapter":"23 Series temporales y detección de brotes","heading":"Paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets \n               slider,       # for calculating moving averages\n               imputeTS,     # for filling in missing values\n               feasts,       # for time series decomposition and autocorrelation\n               forecast,     # fit sin and cosin terms to data (note: must load after feasts)\n               trending,     # fit and assess models \n               tmaptools,    # for getting geocoordinates (lon/lat) based on place names\n               ecmwfr,       # for interacting with copernicus sateliate CDS API\n               stars,        # for reading in .nc (climate data) files\n               units,        # for defining units of measurement (climate data)\n               yardstick,    # for looking at model accuracy\n               surveillance  # for aberration detection\n               )"},{"path":"time-series-and-outbreak-detection.html","id":"cargar-datos","chapter":"23 Series temporales y detección de brotes","heading":"Cargar datos","text":"Puedes descargar todos los datos utilizados en este manual mediante las instrucciones de la página de descargando el manual y los datos.Los datos de ejemplo utilizado en esta sección son los recuentos semanales de casos de campylobacter notificados en Alemania entre 2001 y 2011. Puedes clicar aquí para descargar este archivo de datos (.xlsx).Este conjunto de datos es una versión reducida de los datos disponibles en el paquete surveillance. (para más detalles, carga el paquete surveillance y consulta ?campyDE)Importa estos datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).continuación se muestran las 10 primeras filas de los recuentos.","code":"\n# import the counts into R\ncounts <- rio::import(\"campylobacter_germany.xlsx\")"},{"path":"time-series-and-outbreak-detection.html","id":"limpiar-datos","chapter":"23 Series temporales y detección de brotes","heading":"Limpiar datos","text":"El código siguiente se asegura de que la columna de la fecha tenga el formato adecuado. Para esta sección utilizaremos el paquete tsibble y la función yearweek se utilizará para crear una variable de semana de calendario. Hay otras maneras de hacer esto (ver la página de Trabajar con fechas para más detalles), sin embargo para las series temporales es mejor mantenerse dentro de un marco (tsibble).","code":"\n## ensure the date column is in the appropriate format\ncounts$date <- as.Date(counts$date)\n\n## create a calendar week variable \n## fitting ISO definitons of weeks starting on a monday\ncounts <- counts %>% \n     mutate(epiweek = yearweek(date, week_start = 1))"},{"path":"time-series-and-outbreak-detection.html","id":"descargar-datos-climáticos","chapter":"23 Series temporales y detección de brotes","heading":"Descargar datos climáticos","text":"En la sección de relación de dos series temporales, compararemos los recuentos de casos de campylobacter con los datos climáticos.Los datos climáticos de cualquier parte del mundo pueden descargarse del satélite Copérnico de la UE. se trata de mediciones exactas, sino que se basan en un modelo (similar la interpolación), pero la ventaja es la cobertura horaria global, así como las previsiones.Puedes descargar cada uno de estos archivos de datos climáticos en la página descargando el manual y los datos.Para propósitos de demostración aquí, mostraremos el código R para usar el paquete ecmwfr para extraer estos datos del almacén de datos climáticos de Copernicus. Es necesario crear una cuenta gratuita para que esto funcione. El sitio web del paquete tiene una guía útil de cómo hacerlo. continuación se muestra un código de ejemplo de cómo hacer esto, una vez que tienes las claves de la API adecuada. Tienes que sustituir las X de abajo por los ID de tu cuenta. Tendrás que descargar un año de datos la vez, de lo contrario el servidor se queda sin tiempo.Si estás seguro de las coordenadas de un lugar del que quieres descargar datos, puedes utilizar el paquete tmaptools para obtener las coordenadas de OpenStreetMaps. Una opción alternativa es el paquete photon, aunque todavía se ha publicado en CRAN; lo bueno de photon es que proporciona más datos contextuales para cuando hay varias coincidencias en la búsqueda.","code":"\n## retrieve location coordinates\ncoords <- geocode_OSM(\"Germany\", geometry = \"point\")\n\n## pull together long/lats in format for ERA-5 querying (bounding box) \n## (as just want a single point can repeat coords)\nrequest_coords <- str_glue_data(coords$coords, \"{y}/{x}/{y}/{x}\")\n\n\n## Pulling data modelled from copernicus satellite (ERA-5 reanalysis)\n## https://cds.climate.copernicus.eu/cdsapp#!/software/app-era5-explorer?tab=app\n## https://github.com/bluegreen-labs/ecmwfr\n\n## set up key for weather data \nwf_set_key(user = \"XXXXX\",\n           key = \"XXXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXX\",\n           service = \"cds\") \n\n## run for each year of interest (otherwise server times out)\nfor (i in 2002:2011) {\n  \n  ## pull together a query \n  ## see here for how to do: https://bluegreen-labs.github.io/ecmwfr/articles/cds_vignette.html#the-request-syntax\n  ## change request to a list using addin button above (python to list)\n  ## Target is the name of the output file!!\n  request <- request <- list(\n    product_type = \"reanalysis\",\n    format = \"netcdf\",\n    variable = c(\"2m_temperature\", \"total_precipitation\"),\n    year = c(i),\n    month = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"),\n    day = c(\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\",\n            \"13\", \"14\", \"15\", \"16\", \"17\", \"18\", \"19\", \"20\", \"21\", \"22\", \"23\", \"24\",\n            \"25\", \"26\", \"27\", \"28\", \"29\", \"30\", \"31\"),\n    time = c(\"00:00\", \"01:00\", \"02:00\", \"03:00\", \"04:00\", \"05:00\", \"06:00\", \"07:00\",\n             \"08:00\", \"09:00\", \"10:00\", \"11:00\", \"12:00\", \"13:00\", \"14:00\", \"15:00\",\n             \"16:00\", \"17:00\", \"18:00\", \"19:00\", \"20:00\", \"21:00\", \"22:00\", \"23:00\"),\n    area = request_coords,\n    dataset_short_name = \"reanalysis-era5-single-levels\",\n    target = paste0(\"germany_weather\", i, \".nc\")\n  )\n  \n  ## download the file and store it in the current working directory\n  file <- wf_request(user     = \"XXXXX\",  # user ID (for authentication)\n                     request  = request,  # the request\n                     transfer = TRUE,     # download the file\n                     path     = here::here(\"data\", \"Weather\")) ## path to save the data\n  }"},{"path":"time-series-and-outbreak-detection.html","id":"cargar-datos-climáticos","chapter":"23 Series temporales y detección de brotes","heading":"Cargar datos climáticos","text":"Tanto si descargado los datos climáticos través de nuestro manual, como si utilizado el código anterior, ahora deberías tener 10 años de archivos de datos climáticos “.nc” almacenados en la misma carpeta de tu ordenador.Utiliza el siguiente código para importar estos archivos en R con el paquete stars.Una vez importados estos archivos como datos del objeto, los convertiremos en un dataframe.","code":"\n## define path to weather folder \nfile_paths <- list.files(\n  here::here(\"data\", \"time_series\", \"weather\"), # replace with your own file path \n  full.names = TRUE)\n\n## only keep those with the current name of interest \nfile_paths <- file_paths[str_detect(file_paths, \"germany\")]\n\n## read in all the files as a stars object \ndata <- stars::read_stars(file_paths)## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp, \n## t2m, tp,\n## change to a data frame \ntemp_data <- as_tibble(data) %>% \n  ## add in variables and correct units\n  mutate(\n    ## create an calendar week variable \n    epiweek = tsibble::yearweek(time), \n    ## create a date variable (start of calendar week)\n    date = as.Date(epiweek),\n    ## change temperature from kelvin to celsius\n    t2m = set_units(t2m, celsius), \n    ## change precipitation from metres to millimetres \n    tp  = set_units(tp, mm)) %>% \n  ## group by week (keep the date too though)\n  group_by(epiweek, date) %>% \n  ## get the average per week\n  summarise(t2m = as.numeric(mean(t2m)), \n            tp = as.numeric(mean(tp)))## `summarise()` has grouped output by 'epiweek'. You can override using the `.groups` argument."},{"path":"time-series-and-outbreak-detection.html","id":"time-series-data","chapter":"23 Series temporales y detección de brotes","heading":"23.3 Datos de series temporales","text":"Existen varios paquetes para estructurar y manejar los datos de las series temporales. Como ya hemos dicho, nos centraremos en la familia de paquetes tidyverts y, por tanto, utilizaremos el paquete tsibble para definir nuestro objeto de serie temporal. Tener unos datos definidos como objeto de serie temporal significa que es mucho más fácil estructurar nuestro análisis.Para ello utilizamos la función tsibble() y especificamos el “índex”, es decir, la variable que especifica la unidad de tiempo de interés. En nuestro caso se trata de la variable epiweek.Si tuviéramos unos datos con recuentos semanales por provincia, por ejemplo, también podríamos especificar la variable de agrupación utilizando el argumento key =. Esto nos permitiría hacer un análisis para cada grupo.Si observamos el tipo class(counts), veremos que, además de ser un dataframe ordenado (“tbl_df”, “tbl”, “data.frame”), tiene las propiedades adicionales de un dataframe de series temporales (“tbl_ts”).Se puede echar un vistazo rápido los datos utilizando ggplot2. En el gráfico vemos que hay un claro patrón estacional y que hay pérdidas. Sin embargo, parece haber un problema con la notificación al principio de cada año; los casos descienden en la última semana del año y luego aumentan en la primera semana del año siguiente.PELIGRO: La mayoría de los conjuntos de datos están tan limpios como este ejemplo. Tendrás que comprobar si hay duplicados y faltas como se indica continuación.","code":"\n## define time series object \ncounts <- tsibble(counts, index = epiweek)\n## plot a line graph of cases by week\nggplot(counts, aes(x = epiweek, y = case)) + \n     geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"duplicados","chapter":"23 Series temporales y detección de brotes","heading":"Duplicados","text":"tsibble permite observaciones duplicadas. Así que cada fila deberá ser única, o única dentro del grupo (variable key). El paquete tiene algunas funciones que ayudan identificar los duplicados. Entre ellas se encuentran are_duplicated(), que proporciona un vector TRUE/FALSE para saber si la fila es un duplicado, y duplicates(), que proporciona un dataframe de las filas duplicadas.Consulta la página sobre De-duplicación para obtener más detalles sobre cómo seleccionar las filas que desees.","code":"\n## get a vector of TRUE/FALSE whether rows are duplicates\nare_duplicated(counts, index = epiweek) \n\n## get a data frame of any duplicated rows \nduplicates(counts, index = epiweek) "},{"path":"time-series-and-outbreak-detection.html","id":"valores-faltantes-1","chapter":"23 Series temporales y detección de brotes","heading":"Valores faltantes","text":"En nuestra breve inspección anterior hemos visto que hay faltas, pero también hemos visto que parece haber un problema de retraso en la notificación en torno al año nuevo. Una forma de abordar este problema podría ser establecer estos valores como faltantes y luego imputar los valores. La forma más sencilla de imputación de series temporales consiste en trazar una línea recta entre el último valor faltante y el siguiente valor faltante. Para ello, utilizaremos la función na_interpolation() del paquete imputeTS.Consulta la página de datos faltantes para conocer otras opciones de imputación.Otra alternativa sería calcular una media móvil para intentar suavizar estos aparentes problemas de información (véase la siguiente sección y la página sobre medias móviles.","code":"\n## create a variable with missings instead of weeks with reporting issues\ncounts <- counts %>% \n     mutate(case_miss = if_else(\n          ## if epiweek contains 52, 53, 1 or 2\n          str_detect(epiweek, \"W51|W52|W53|W01|W02\"), \n          ## then set to missing \n          NA_real_, \n          ## otherwise keep the value in case\n          case\n     ))\n\n## alternatively interpolate missings by linear trend \n## between two nearest adjacent points\ncounts <- counts %>% \n  mutate(case_int = imputeTS::na_interpolation(case_miss)\n         )\n\n## to check what values have been imputed compared to the original\nggplot_na_imputations(counts$case_miss, counts$case_int) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"descriptive-analysis","chapter":"23 Series temporales y detección de brotes","heading":"23.4 Análisis descriptivo","text":"","code":""},{"path":"time-series-and-outbreak-detection.html","id":"timeseries_moving","chapter":"23 Series temporales y detección de brotes","heading":"Medias móviles","text":"Si los datos tienen mucho ruido (los recuentos suben y bajan), puede ser útil calcular una media móvil. En el ejemplo siguiente, para cada semana se calcula la media de casos de las cuatro semanas anteriores. Esto suaviza los datos para hacerlos más interpretables. En nuestro caso esto aporta mucho, así que nos quedaremos con los datos interpolados para el análisis posterior. Véase la página de medias móviles para más detalles.","code":"\n## create a moving average variable (deals with missings)\ncounts <- counts %>% \n     ## create the ma_4w variable \n     ## slide over each row of the case variable\n     mutate(ma_4wk = slider::slide_dbl(case, \n                               ## for each row calculate the name\n                               ~ mean(.x, na.rm = TRUE),\n                               ## use the four previous weeks\n                               .before = 4))\n\n## make a quick visualisation of the difference \nggplot(counts, aes(x = epiweek)) + \n     geom_line(aes(y = case)) + \n     geom_line(aes(y = ma_4wk), colour = \"red\")"},{"path":"time-series-and-outbreak-detection.html","id":"periodicidad","chapter":"23 Series temporales y detección de brotes","heading":"Periodicidad","text":"continuación definimos una función personalizada para crear un periodograma. Consulta la página Escribir funciones para obtener información sobre cómo escribir funciones en R.En primer lugar, se define la función. Sus argumentos incluyen unos datos con las columnas counts, start_week = que es la primera semana de los datos, un número para indicar cuántos períodos por año (por ejemplo, 52, 12) y, por último, el estilo de salida (véanse los detalles en el código siguiente).NOTA: Es posible utilizar las semanas anteriores para añadirlas los términos del seno y del coseno, sin embargo, utilizaremos una función para generar estos términos (véase la sección de regresión más adelante) ","code":"\n## Function arguments\n#####################\n## x is a dataset\n## counts is variable with count data or rates within x \n## start_week is the first week in your dataset\n## period is how many units in a year \n## output is whether you want return spectral periodogram or the peak weeks\n  ## \"periodogram\" or \"weeks\"\n\n# Define function\nperiodogram <- function(x, \n                        counts, \n                        start_week = c(2002, 1), \n                        period = 52, \n                        output = \"weeks\") {\n  \n\n    ## make sure is not a tsibble, filter to project and only keep columns of interest\n    prepare_data <- dplyr::as_tibble(x)\n    \n    # prepare_data <- prepare_data[prepare_data[[strata]] == j, ]\n    prepare_data <- dplyr::select(prepare_data, {{counts}})\n    \n    ## create an intermediate \"zoo\" time series to be able to use with spec.pgram\n    zoo_cases <- zoo::zooreg(prepare_data, \n                             start = start_week, frequency = period)\n    \n    ## get a spectral periodogram not using fast fourier transform \n    periodo <- spec.pgram(zoo_cases, fast = FALSE, plot = FALSE)\n    \n    ## return the peak weeks \n    periodo_weeks <- 1 / periodo$freq[order(-periodo$spec)] * period\n    \n    if (output == \"weeks\") {\n      periodo_weeks\n    } else {\n      periodo\n    }\n    \n}\n\n## get spectral periodogram for extracting weeks with the highest frequencies \n## (checking of seasonality) \nperiodo <- periodogram(counts, \n                       case_int, \n                       start_week = c(2002, 1),\n                       output = \"periodogram\")\n\n## pull spectrum and frequence in to a dataframe for plotting\nperiodo <- data.frame(periodo$freq, periodo$spec)\n\n## plot a periodogram showing the most frequently occuring periodicity \nggplot(data = periodo, \n                aes(x = 1/(periodo.freq/52),  y = log(periodo.spec))) + \n  geom_line() + \n  labs(x = \"Period (Weeks)\", y = \"Log(density)\")\n## get a vector weeks in ascending order \npeak_weeks <- periodogram(counts, \n                          case_int, \n                          start_week = c(2002, 1), \n                          output = \"weeks\")"},{"path":"time-series-and-outbreak-detection.html","id":"descomposición","chapter":"23 Series temporales y detección de brotes","heading":"Descomposición","text":"La descomposición clásica se utiliza para desglosar una serie temporal en varias partes, que en conjunto conforman el patrón que se observa. Estas diferentes partes son:La tendencia-ciclo (la dirección largo plazo de los datos)La estacionalidad (patrones repetitivos)El azar (lo que queda después de quitar la tendencia y la estacionalidad)","code":"\n## decompose the counts dataset \ncounts %>% \n  # using an additive classical decomposition model\n  model(classical_decomposition(case_int, type = \"additive\")) %>% \n  ## extract the important information from the model\n  components() %>% \n  ## generate a plot \n  autoplot()"},{"path":"time-series-and-outbreak-detection.html","id":"autocorrelación","chapter":"23 Series temporales y detección de brotes","heading":"Autocorrelación","text":"La autocorrelación informa de la relación entre los recuentos de cada semana y las semanas anteriores (denominadas retrasos o retardos).Utilizando la función ACF(), podemos producir un gráfico que nos muestre un número de líneas para la relación en diferentes retrasos. Cuando el retardo es 0 (x = 0), esta línea sería siempre 1, ya que muestra la relación entre una observación y ella misma (se muestra aquí). La primera línea mostrada aquí (x = 1) muestra la relación entre cada observación y la observación anterior (retardo de 1), la segunda muestra la relación entre cada observación y la observación anterior (retardo de 2) y así sucesivamente hasta el retardo de 52 que muestra la relación entre cada observación y la observación de 1 año (52 semanas antes).El uso de la función PACF() (para la autocorrelación parcial) muestra el mismo tipo de relación pero ajustada para todas las demás semanas intermedias. Esto es menos informativo para determinar la periodicidad.Puedes probar formalmente la hipótesis nula de independencia en una serie temporal (es decir, que está autocorrelacionada) utilizando la prueba de Ljung-Box (en el paquete stats). Un valor-p significativo sugiere que hay autocorrelación en los datos.","code":"\n## using the counts dataset\ncounts %>% \n  ## calculate autocorrelation using a full years worth of lags\n  ACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## using the counts data set \ncounts %>% \n  ## calculate the partial autocorrelation using a full years worth of lags\n  PACF(case_int, lag_max = 52) %>% \n  ## show a plot\n  autoplot()\n## test for independance \nBox.test(counts$case_int, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  counts$case_int\n## X-squared = 462.65, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"fitting-regressions","chapter":"23 Series temporales y detección de brotes","heading":"23.5 Ajuste de regresiones","text":"Es posible ajustar un gran número de regresiones diferentes una serie temporal, sin embargo, aquí mostraremos cómo ajustar una regresión binomial negativa, ya que suele ser la más apropiada para los datos de recuento en las enfermedades infecciosas.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"términos-de-fourier","chapter":"23 Series temporales y detección de brotes","heading":"Términos de Fourier","text":"Los términos de Fourier son el equivalente las curvas seno y coseno. La diferencia es que éstos se ajustan basándose en la búsqueda de la combinación de curvas más adecuada para explicar los datos.Si sólo se ajusta un término de fourier, esto equivaldría ajustar un seno y un coseno para el desfase más frecuente que se ve en el periodograma (en nuestro caso, 52 semanas). Utilizamos la función fourier() del paquete forecast.En el código de abajo asignamos usando el $, ya que fourier() devuelve dos columnas (una para seno y otra para el coseno) y así se añaden al conjunto de datos como una lista, llamada “fourier” - pero esta lista se puede usar como una variable normal en la regresión.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  fourier(K = 1)"},{"path":"time-series-and-outbreak-detection.html","id":"binomial-negativa","chapter":"23 Series temporales y detección de brotes","heading":"Binomial negativa","text":"Es posible ajustar las regresiones utilizando las funciones básicas de stats o MASS (por ejemplo, lm(), glm() y glm.nb()). Sin embargo, utilizaremos las del paquete trending, ya que esto permite calcular intervalos de confianza y predicción adecuados (que de otro modo están disponibles). La sintaxis es la misma, y se especifica una variable de resultado, luego una tilde (~) y luego se añaden las diversas variables de exposición de interés separadas por un signo más (+).La otra diferencia es que primero definimos el modelo y luego lo ajustamos los datos (fit()). Esto es útil porque permite comparar varios modelos diferentes con la misma sintaxis.SUGERENCIA: Si deseas utilizar tasas, en lugar de recuentos, puedes incluir la variable de población como un término de compensación logarítmica, añadiendo offset(log(population). Entonces tendría que establecerse que la población es 1, antes de usar predict() para producir una tasa. SUGERENCIA: Para ajustar modelos más complejos, como ARIMA o prophet, consulta el paquete fable","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier)\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuos","chapter":"23 Series temporales y detección de brotes","heading":"Residuos","text":"Para ver si nuestro modelo se ajusta los datos observados, tenemos que observar los residuos. Los residuos son la diferencia entre los recuentos observados y los recuentos estimados partir del modelo. Podríamos calcularlo simplemente utilizando case_int - estimate, pero la función residuals() lo extrae directamente de la regresión por nosotros.Lo que vemos continuación es que estamos explicando toda la variación que podríamos con el modelo. Es posible que debamos ajustar más términos de Fourier y abordar la amplitud. Sin embargo, para este ejemplo lo dejaremos como está. Los gráficos muestran que nuestro modelo es peor en los picos y en los valles (cuando los recuentos son los más altos y los más bajos) y que es más probable que subestime los recuentos observados.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = residuals(fitted_model$fitted_model, type = \"response\"))\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") \n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  observed$resid\n## X-squared = 346.64, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"relation-of-two-time-series","chapter":"23 Series temporales y detección de brotes","heading":"23.6 Relación de dos series temporales","text":"En este caso, analizamos el uso de los datos meteorológicos (concretamente la temperatura) para explicar los recuentos de casos de campylobacter.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"fusión-de-conjuntos-de-datos","chapter":"23 Series temporales y detección de brotes","heading":"Fusión de conjuntos de datos","text":"Podemos unir nuestros conjuntos de datos utilizando la variable semana (epiweek). Para obtener más información sobre la fusión, consulta la página del manual sobre unir datos","code":"\n## left join so that we only have the rows already existing in counts\n## drop the date variable from temp_data (otherwise is duplicated)\ncounts <- left_join(counts, \n                    select(temp_data, -date),\n                    by = \"epiweek\")"},{"path":"time-series-and-outbreak-detection.html","id":"análisis-descriptivo","chapter":"23 Series temporales y detección de brotes","heading":"Análisis descriptivo","text":"En primer lugar, traza los datos para ver si hay alguna relación evidente. El siguiente gráfico muestra que hay una clara relación en la estacionalidad de las dos variables, y que la temperatura puede alcanzar su punto máximo unas semanas antes que el número de casos. Para más información sobre pivotar datos, consulta la sección del manual sobre pivotar datos.","code":"\ncounts %>% \n  ## keep the variables we are interested \n  select(epiweek, case_int, t2m) %>% \n  ## change your data in to long format\n  pivot_longer(\n    ## use epiweek as your key\n    !epiweek,\n    ## move column names to the new \"measure\" column\n    names_to = \"measure\", \n    ## move cell values to the new \"values\" column\n    values_to = \"value\") %>% \n  ## create a plot with the dataset above\n  ## plot epiweek on the x axis and values (counts/celsius) on the y \n  ggplot(aes(x = epiweek, y = value)) + \n    ## create a separate plot for temperate and case counts \n    ## let them set their own y-axes\n    facet_grid(measure ~ ., scales = \"free_y\") +\n    ## plot both as a line\n    geom_line()"},{"path":"time-series-and-outbreak-detection.html","id":"retrasos-y-correlación-cruzada","chapter":"23 Series temporales y detección de brotes","heading":"Retrasos y correlación cruzada","text":"Para comprobar formalmente qué semanas están más relacionadas entre los casos y la temperatura. Podemos utilizar la función de correlación cruzada (CCF()) del paquete de feats. También se podría visualizar (en lugar de utilizar arrange) utilizando la función autoplot().Vemos que un desfase de 4 semanas es el más correlacionado, por lo que creamos una variable de temperatura retardada para incluirla en nuestra regresión.PELIGRO: Ten en cuenta que las primeras cuatro semanas de nuestros datos en la variable de temperatura retardada faltan (NA) - ya que hay cuatro semanas anteriores para obtener datos. Para utilizar este conjunto de datos con la función predict() de trending, necesitamos utilizar el argumento simulate_pi = FALSE dentro de predict() más abajo. Si quisiéramos utilizar la opción de simulación, entonces tenemos que eliminar estas pérdidas y almacenarlas como un nuevo conjunto de datos añadiendo drop_na(t2m_lag4) al fragmento de código que aparece continuación.","code":"\ncounts %>% \n  ## calculate cross-correlation between interpolated counts and temperature\n  CCF(case_int, t2m,\n      ## set the maximum lag to be 52 weeks\n      lag_max = 52, \n      ## return the correlation coefficient \n      type = \"correlation\") %>% \n  ## arange in decending order of the correlation coefficient \n  ## show the most associated lags\n  arrange(-ccf) %>% \n  ## only show the top ten \n  slice_head(n = 10)## # A tsibble: 10 x 2 [1W]\n##         lag   ccf\n##    <cf_lag> <dbl>\n##  1      -4W 0.749\n##  2      -5W 0.745\n##  3      -3W 0.735\n##  4      -6W 0.729\n##  5      -2W 0.727\n##  6      -7W 0.704\n##  7      -1W 0.695\n##  8      -8W 0.671\n##  9       0W 0.649\n## 10      47W 0.638\ncounts <- counts %>% \n  ## create a new variable for temperature lagged by four weeks\n  mutate(t2m_lag4 = lag(t2m, n = 4))"},{"path":"time-series-and-outbreak-detection.html","id":"binomial-negativa-con-dos-variables","chapter":"23 Series temporales y detección de brotes","heading":"Binomial negativa con dos variables","text":"Ajustamos una regresión binomial negativa como se hizo anteriormente. Esta vez añadimos la variable de temperatura con un retraso de cuatro semanas.PRECAUCIóN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe que el comportamiento por defecto de trending es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles. Para investigar los términos individuales, podemos sacar la regresión binomial negativa original del formato de trending utilizando get_model() y pasarla la función tidy() del paquete broom para recuperar las estimaciones exponenciadas y los intervalos de confianza asociados.Lo que esto nos muestra es que la temperatura retardada, tras controlar la tendencia y la estacionalidad, es similar los recuentos de casos (estimación ~ 1) y está significativamente asociada. Esto sugiere que podría ser una buena variable para predecir el número de casos futuros (ya que las previsiones climáticas están disponibles).Una rápida inspección visual del modelo muestra que se podría hacer un mejor trabajo de estimación de los recuentos de casos observados.","code":"\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the fourier terms to account for seasonality\n    fourier + \n    ## use the temperature lagged by four weeks \n    t2m_lag4\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, data.frame(counts))\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE)## # A tibble: 5 × 7\n##   term         estimate  std.error statistic  p.value conf.low conf.high\n##   <chr>           <dbl>      <dbl>     <dbl>    <dbl>    <dbl>     <dbl>\n## 1 (Intercept)   339.    0.108          53.8  0         274.      419.   \n## 2 epiweek         1.00  0.00000774     10.9  8.13e-28    1.00      1.00 \n## 3 fourierS1-52    0.752 0.0214        -13.3  1.84e-40    0.721     0.784\n## 4 fourierC1-52    0.823 0.0200         -9.78 1.35e-22    0.791     0.855\n## 5 t2m_lag4        1.01  0.00269         2.48 1.30e- 2    1.00      1.01\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"Red\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()"},{"path":"time-series-and-outbreak-detection.html","id":"residuos-1","chapter":"23 Series temporales y detección de brotes","heading":"Residuos","text":"Volvemos investigar los residuos para ver si nuestro modelo se ajusta los datos observados. Los resultados y la interpretación aquí son similares los de la regresión anterior, por lo que puede ser más factible quedarse con el modelo más simple sin temperatura.","code":"\n## calculate the residuals \nobserved <- observed %>% \n  mutate(resid = case_int - estimate)\n\n## are the residuals fairly constant over time (if not: outbreaks? change in practice?)\nobserved %>%\n  ggplot(aes(x = epiweek, y = resid)) +\n  geom_line() +\n  geom_point() + \n  labs(x = \"epiweek\", y = \"Residuals\")## Warning: Removed 4 rows containing missing values (`geom_line()`).## Warning: Removed 4 rows containing missing values (`geom_point()`).\n## is there autocorelation in the residuals (is there a pattern to the error?)  \nobserved %>% \n  as_tsibble(index = epiweek) %>% \n  ACF(resid, lag_max = 52) %>% \n  autoplot()\n## are residuals normally distributed (are under or over estimating?)  \nobserved %>%\n  ggplot(aes(x = resid)) +\n  geom_histogram(binwidth = 100) +\n  geom_rug() +\n  labs(y = \"count\") ## Warning: Removed 4 rows containing non-finite values (`stat_bin()`).\n## compare observed counts to their residuals \n  ## should also be no pattern \nobserved %>%\n  ggplot(aes(x = estimate, y = resid)) +\n  geom_point() +\n  labs(x = \"Fitted\", y = \"Residuals\")## Warning: Removed 4 rows containing missing values (`geom_point()`).\n## formally test autocorrelation of the residuals\n## H0 is that residuals are from a white-noise series (i.e. random)\n## test for independence \n## if p value significant then non-random\nBox.test(observed$resid, type = \"Ljung-Box\")## \n##  Box-Ljung test\n## \n## data:  observed$resid\n## X-squared = 339.52, df = 1, p-value < 2.2e-16"},{"path":"time-series-and-outbreak-detection.html","id":"outbreak-detection","chapter":"23 Series temporales y detección de brotes","heading":"23.7 Detección de brotes","text":"Aquí mostraremos dos métodos (similares) de detección de brotes. El primero se basa en las secciones anteriores. Utilizamos el paquete trending para ajustar las regresiones los años anteriores, y luego predecir lo que esperamos ver en el año siguiente. Si los recuentos observados están por encima de lo que esperamos, esto podría sugerir que hay un brote. El segundo método se basa en principios similares, pero utiliza el paquete surveillance, que tiene varios algoritmos diferentes para la detección de aberraciones.ATENCIÓN: Normalmente, estás interesado en el año actual (donde sólo se conocen los recuentos hasta la semana actual). Así que en este ejemplo pretendemos estar en la semana 39 de 2011.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"paquete-trending","chapter":"23 Series temporales y detección de brotes","heading":"Paquete trending","text":"Para este método definimos una línea base (que normalmente debería ser de unos 5 años de datos). Ajustamos una regresión los datos de referencia y la utilizamos para predecir las estimaciones del año siguiente.","code":""},{"path":"time-series-and-outbreak-detection.html","id":"fecha-de-corte","chapter":"23 Series temporales y detección de brotes","heading":"Fecha de corte","text":"Es más fácil definir las fechas en un lugar y luego utilizarlas en el resto del código.Aquí definimos una fecha de inicio (cuando comenzaron nuestras observaciones) y una fecha de corte (el final de nuestro período de referencia - y cuando comienza el período que queremos predecir). ~También definimos cuántas semanas hay en nuestro año de interés (el que vamos predecir)~. También definimos cuántas semanas hay entre nuestra fecha límite de referencia y la fecha final para la que nos interesa predecir.NOTA: En este ejemplo pretendemos estar actualmente finales de septiembre de 2011 (“2011 W39”).","code":"\n## define start date (when observations began)\nstart_date <- min(counts$epiweek)\n\n## define a cut-off week (end of baseline, start of prediction period)\ncut_off <- yearweek(\"2010-12-31\")\n\n## define the last date interested in (i.e. end of prediction)\nend_date <- yearweek(\"2011-12-31\")\n\n## find how many weeks in period (year) of interest\nnum_weeks <- as.numeric(end_date - cut_off)"},{"path":"time-series-and-outbreak-detection.html","id":"añadir-filas","chapter":"23 Series temporales y detección de brotes","heading":"Añadir filas","text":"Para poder pronosticar en un formato tidyverse, necesitamos tener el número correcto de filas en nuestro conjunto de datos, es decir, una fila por cada semana hasta la end_date (fecha de corte) definida anteriormente. El código siguiente permite añadir estas filas por una variable de agrupación - por ejemplo, si tuviéramos varios países en unos datos, podríamos agrupar por país y luego añadir filas apropiadas para cada uno. La función group_by_key() de tsibble nos permite hacer esta agrupación y luego pasar los datos agrupados las funciones de dplyr, group_modify() y add_row(). Luego especificamos la secuencia de semanas entre una después de la semana máxima disponible actualmente en los datos y la semana final.","code":"\n## add in missing weeks till end of year \ncounts <- counts %>%\n  ## group by the region\n  group_by_key() %>%\n  ## for each group add rows from the highest epiweek to the end of year\n  group_modify(~add_row(.,\n                        epiweek = seq(max(.$epiweek) + 1, \n                                      end_date,\n                                      by = 1)))"},{"path":"time-series-and-outbreak-detection.html","id":"términos-de-fourier-1","chapter":"23 Series temporales y detección de brotes","heading":"Términos de Fourier","text":"Tenemos que redefinir nuestros términos de fourier, ya que queremos ajustarlos sólo la fecha de referencia y luego predecir (extrapolar) esos términos para el año siguiente. Para ello tenemos que combinar dos listas de salida de la función fourier() juntas; la primera es para los datos de referencia, y la segunda predice para el año de interés (definiendo el argumento h).N.b. para enlazar filas tenemos que usar rbind() (en lugar de bind_rows de tidyverse) ya que las columnas de fourier son una lista (por lo que se nombran individualmente).","code":"\n## define fourier terms (sincos) \ncounts <- counts %>% \n  mutate(\n    ## combine fourier terms for weeks prior to  and after 2010 cut-off date\n    ## (nb. 2011 fourier terms are predicted)\n    fourier = rbind(\n      ## get fourier terms for previous years\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for 2011 (using baseline data)\n      fourier(\n        ## only keep the rows before 2011\n        filter(counts, \n               epiweek <= cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = num_weeks\n        )\n      )\n    )"},{"path":"time-series-and-outbreak-detection.html","id":"dividir-los-datos-y-ajustar-la-regresión","chapter":"23 Series temporales y detección de brotes","heading":"Dividir los datos y ajustar la regresión","text":"Ahora tenemos que dividir nuestro conjunto de datos en el período de referencia y el período de predicción. Esto se hace utilizando la función group_split() de dplyr después de group_by(), y creará una lista con dos dataframes, uno para antes de tu corte y otro para después.continuación, utilizamos la función pluck() del paquete purrr para extraer los datos del listado (lo que equivale utilizar corchetes, por ejemplo, dat[1]]), y podemos ajustar nuestro modelo los datos de referencia, y luego utilizar la función predict() para nuestros datos de interés después del corte.Consulta la página sobre Iteración, bucles y listas para saber más sobre purrr.ATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe que el comportamiento por defecto de trending es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles. Como anteriormente, podemos visualizar nuestro modelo con ggplot. Resaltamos las alertas con puntos rojos para los recuentos observados por encima del intervalo de predicción del 95%. Esta vez también añadimos una línea vertical para etiquetar cuándo empieza la predicción.","code":"\n# split data for fitting and prediction\ndat <- counts %>% \n  group_by(epiweek <= cut_off) %>%\n  group_split()\n\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier\n)\n\n# define which data to use for fitting and which for predicting\nfitting_data <- pluck(dat, 2)\npred_data <- pluck(dat, 1) %>% \n  select(case_int, epiweek, fourier)\n\n# fit model \nfitted_model <- trending::fit(model, data.frame(fitting_data))\n\n# get confint and estimates for fitted data\nobserved <- fitted_model %>% \n  predict(simulate_pi = FALSE)\n\n# forecast with data want to predict with \nforecasts <- fitted_model %>% \n  predict(data.frame(pred_data), simulate_pi = FALSE)\n\n## combine baseline and predicted datasets\nobserved <- bind_rows(observed, forecasts)\n## plot your regression \nggplot(data = observed, aes(x = epiweek)) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate),\n            col = \"grey\") + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add in a line for your observed case counts\n  geom_line(aes(y = case_int), \n            col = \"black\") + \n  ## plot in points for the observed counts above expected\n  geom_point(\n    data = filter(observed, case_int > upper_pi), \n    aes(y = case_int), \n    colour = \"red\", \n    size = 2) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(cut_off), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Forecast\", \n           x = cut_off, \n           y = max(observed$upper_pi) - 250, \n           angle = 90, \n           vjust = 1\n           ) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 rows containing missing values (`geom_line()`)."},{"path":"time-series-and-outbreak-detection.html","id":"validación-de-la-predicción","chapter":"23 Series temporales y detección de brotes","heading":"Validación de la predicción","text":"Más allá de la inspección de los residuos, es importante investigar lo bueno que es tu modelo para predecir casos en el futuro. Esto te da una idea de la fiabilidad de tus umbrales de alerta.La forma tradicional de validar es ver lo bien que se puede predecir el último año anterior al actual (porque aún se conocen los recuentos del “año actual”). Por ejemplo, en nuestro conjunto de datos, utilizaríamos los datos de 2002 2009 para predecir 2010, y luego veríamos la precisión de esas predicciones. continuación, volveríamos ajustar el modelo para incluir los datos de 2010 y los utilizaríamos para predecir los recuentos de 2011.Como puede verse en la siguiente figura de Hyndman et al en “Forecasting principles practice”.figura reproducida con permiso de los autoresLa desventaja de esto es que estás usando todos los datos disponibles, y es el modelo final que estás usando para la predicción.Una alternativa es utilizar un método llamado validación cruzada. En este caso, se pasan todos los datos disponibles para ajustar múltiples modelos de predicción un año vista. Se utilizan cada vez más datos en cada modelo, como se ve en la siguiente figura del mismo [texto de Hyndman et al]((https://otexts.com/fpp3/). Por ejemplo, el primer modelo utiliza 2002 para predecir 2003, el segundo utiliza 2002 y 2003 para predecir 2004, y así sucesivamente.\nfigura reproducida con permiso de los autoresA continuación, utilizamos la función map() del paquete purrr para recorrer cada conjunto de datos. Luego, ponemos las estimaciones conjunto de datos y las fusionamos con los recuentos de casos originales, para utilizar el paquete yardstick para calcular las medidas de precisión. Calculamos cuatro medidas que incluyen: Error medio cuadrático (RMSE), Error medio absoluto (MAE), Error medio absoluto escala (MASE), Error medio porcentual absoluto (MAPE).ATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento predict(). Esto se debe que el comportamiento por defecto de la tendencia es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles.","code":"\n## Cross validation: predicting week(s) ahead based on sliding window\n\n## expand your data by rolling over in 52 week windows (before + after) \n## to predict 52 week ahead\n## (creates longer and longer chains of observations - keeps older data)\n\n## define window want to roll over\nroll_window <- 52\n\n## define weeks ahead want to predict \nweeks_ahead <- 52\n\n## create a data set of repeating, increasingly long data\n## label each data set with a unique id\n## only use cases before year of interest (i.e. 2011)\ncase_roll <- counts %>% \n  filter(epiweek < cut_off) %>% \n  ## only keep the week and case counts variables\n  select(epiweek, case_int) %>% \n    ## drop the last x observations \n    ## depending on how many weeks ahead forecasting \n    ## (otherwise will be an actual forecast to \"unknown\")\n    slice(1:(n() - weeks_ahead)) %>%\n    as_tsibble(index = epiweek) %>% \n    ## roll over each week in x after windows to create grouping ID \n    ## depending on what rolling window specify\n    stretch_tsibble(.init = roll_window, .step = 1) %>% \n  ## drop the first couple - as have no \"before\" cases\n  filter(.id > roll_window)\n\n\n## for each of the unique data sets run the code below\nforecasts <- purrr::map(unique(case_roll$.id), \n                        function(i) {\n  \n  ## only keep the current fold being fit \n  mini_data <- filter(case_roll, .id == i) %>% \n    as_tibble()\n  \n  ## create an empty data set for forecasting on \n  forecast_data <- tibble(\n    epiweek = seq(max(mini_data$epiweek) + 1,\n                  max(mini_data$epiweek) + weeks_ahead,\n                  by = 1),\n    case_int = rep.int(NA, weeks_ahead),\n    .id = rep.int(i, weeks_ahead)\n  )\n  \n  ## add the forecast data to the original \n  mini_data <- bind_rows(mini_data, forecast_data)\n  \n  ## define the cut off based on latest non missing count data \n  cv_cut_off <- mini_data %>% \n    ## only keep non-missing rows\n    drop_na(case_int) %>% \n    ## get the latest week\n    summarise(max(epiweek)) %>% \n    ## extract so is not in a dataframe\n    pull()\n  \n  ## make mini_data back in to a tsibble\n  mini_data <- tsibble(mini_data, index = epiweek)\n  \n  ## define fourier terms (sincos) \n  mini_data <- mini_data %>% \n    mutate(\n    ## combine fourier terms for weeks prior to  and after cut-off date\n    fourier = rbind(\n      ## get fourier terms for previous years\n      forecast::fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off), \n        ## include one set of sin cos terms \n        K = 1\n        ), \n      ## predict the fourier terms for following year (using baseline data)\n      fourier(\n        ## only keep the rows before cut-off\n        filter(mini_data, \n               epiweek <= cv_cut_off),\n        ## include one set of sin cos terms \n        K = 1, \n        ## predict 52 weeks ahead\n        h = weeks_ahead\n        )\n      )\n    )\n  \n  \n  # split data for fitting and prediction\n  dat <- mini_data %>% \n    group_by(epiweek <= cv_cut_off) %>%\n    group_split()\n\n  ## define the model you want to fit (negative binomial) \n  model <- glm_nb_model(\n    ## set number of cases as outcome of interest\n    case_int ~\n      ## use epiweek to account for the trend\n      epiweek +\n      ## use the furier terms to account for seasonality\n      fourier\n  )\n\n  # define which data to use for fitting and which for predicting\n  fitting_data <- pluck(dat, 2)\n  pred_data <- pluck(dat, 1)\n  \n  # fit model \n  fitted_model <- trending::fit(model, fitting_data)\n  \n  # forecast with data want to predict with \n  forecasts <- fitted_model %>% \n    predict(data.frame(pred_data), simulate_pi = FALSE) %>% \n    ## only keep the week and the forecast estimate\n    select(epiweek, estimate)\n    \n  }\n  )\n\n## make the list in to a data frame with all the forecasts\nforecasts <- bind_rows(forecasts)\n\n## join the forecasts with the observed\nforecasts <- left_join(forecasts, \n                       select(counts, epiweek, case_int),\n                       by = \"epiweek\")\n\n## using {yardstick} compute metrics\n  ## RMSE: Root mean squared error\n  ## MAE:  Mean absolute error  \n  ## MASE: Mean absolute scaled error\n  ## MAPE: Mean absolute percent error\nmodel_metrics <- bind_rows(\n  ## in your forcasted dataset compare the observed to the predicted\n  rmse(forecasts, case_int, estimate), \n  mae( forecasts, case_int, estimate),\n  mase(forecasts, case_int, estimate),\n  mape(forecasts, case_int, estimate),\n  ) %>% \n  ## only keep the metric type and its output\n  select(Metric  = .metric, \n         Measure = .estimate) %>% \n  ## make in to wide format so can bind rows after\n  pivot_wider(names_from = Metric, values_from = Measure)\n\n## return model metrics \nmodel_metrics## # A tibble: 1 × 4\n##    rmse   mae  mase  mape\n##   <dbl> <dbl> <dbl> <dbl>\n## 1  252.  199.  1.96  17.3"},{"path":"time-series-and-outbreak-detection.html","id":"paquete-surveillance","chapter":"23 Series temporales y detección de brotes","heading":"paquete surveillance","text":"En esta sección utilizamos el paquete surveillance para crear umbrales de alerta basados en algoritmos de detección de brotes. Hay varios métodos diferentes disponibles en el paquete, aunque aquí nos centraremos en dos opciones. Para más detalles, consulta estos documentos sobre la aplicación y la teoría de los algoritmos utilizados.La primera opción utiliza el método Farrington mejorado. Este método ajusta un glm binomial negativo (incluyendo la tendencia) y pondera la baja los brotes pasados (valores atípicos) para crear un nivel de umbral.La segunda opción utiliza el método glrnb. Esto también se ajusta un glm binomial negativo, pero incluye la tendencia y los términos de fourier (por lo que se favorece aquí). La regresión se utiliza para calcular la “media de control” (~valores ajustados), y continuación se utiliza un estadístico de relación de verosimilitud generalizada para evaluar si hay un cambio en la media de cada semana. Ten en cuenta que el umbral de cada semana tiene en cuenta las semanas anteriores, por lo que si hay un cambio sostenido se activará una alarma. (También hay que tener en cuenta que después de cada alarma el algoritmo se reinicia)Para trabajar con el paquete surveillance, primero tenemos que definir un objeto “surveillance time series” (utilizando la función sts()) para que encaje en el marco de trabajo.","code":"\n## define surveillance time series object\n## nb. you can include a denominator with the population object (see ?sts)\ncounts_sts <- sts(observed = counts$case_int[!is.na(counts$case_int)],\n                  start = c(\n                    ## subset to only keep the year from start_date \n                    as.numeric(str_sub(start_date, 1, 4)), \n                    ## subset to only keep the week from start_date\n                    as.numeric(str_sub(start_date, 7, 8))), \n                  ## define the type of data (in this case weekly)\n                  freq = 52)\n\n## define the week range that you want to include (ie. prediction period)\n## nb. the sts object only counts observations without assigning a week or \n## year identifier to them - so we use our data to define the appropriate observations\nweekrange <- cut_off - start_date"},{"path":"time-series-and-outbreak-detection.html","id":"método-farrington","chapter":"23 Series temporales y detección de brotes","heading":"Método Farrington","text":"continuación, definimos cada uno de nuestros parámetros para el método Farrington en una list. continuación, ejecutamos el algoritmo utilizando farringtonFlexible() y luego podemos extraer el umbral de una alerta utilizando farringtonmethod@upperbound para incluirlo en nuestro conjunto de datos. También es posible extraer un TRUE/FALSE para cada semana si se activó una alerta (estaba por encima del umbral) utilizando farringtonmethod@alarm.continuación, podemos visualizar los resultados en ggplot como se hizo anteriormente.","code":"\n## define control\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  b = 9, ## how many years backwards for baseline\n  w = 2, ## rolling window size in weeks\n  weightsThreshold = 2.58, ## reweighting past outbreaks (improved noufaily method - original suggests 1)\n  ## pastWeeksNotIncluded = 3, ## use all weeks available (noufaily suggests drop 26)\n  trend = TRUE,\n  pThresholdTrend = 1, ## 0.05 normally, however 1 is advised in the improved method (i.e. always keep)\n  thresholdMethod = \"nbPlugin\",\n  populationOffset = TRUE\n  )\n\n## apply farrington flexible method\nfarringtonmethod <- farringtonFlexible(counts_sts, ctrl)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from farrington \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold\"] <- farringtonmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"método-glrnb","chapter":"23 Series temporales y detección de brotes","heading":"Método GLRNB","text":"Del mismo modo, para el método GLRNB definimos cada uno de nuestros parámetros en una list, luego ajustamos el algoritmo y extraemos los límites superiores.ATENCIÓN: Este método utiliza la “fuerza bruta” (similar al bootstrapping) para calcular los umbrales, por lo que puede llevar mucho tiempo.Consulta la viñeta GLRNB para más detalles.Visualiza los resultados como antes.","code":"\n## define control options\nctrl <- list(\n  ## define what time period that want threshold for (i.e. 2011)\n  range = which(counts_sts@epoch > weekrange),\n  mu0 = list(S = 1,    ## number of fourier terms (harmonics) to include\n  trend = TRUE,   ## whether to include trend or not\n  refit = FALSE), ## whether to refit model after each alarm\n  ## cARL = threshold for GLR statistic (arbitrary)\n     ## 3 ~ middle ground for minimising false positives\n     ## 1 fits to the 99%PI of glm.nb - with changes after peaks (threshold lowered for alert)\n   c.ARL = 2,\n   # theta = log(1.5), ## equates to a 50% increase in cases in an outbreak\n   ret = \"cases\"     ## return threshold upperbound as case counts\n  )\n\n## apply the glrnb method\nglrnbmethod <- glrnb(counts_sts, control = ctrl, verbose = FALSE)\n\n## create a new variable in the original dataset called threshold\n## containing the upper bound from glrnb \n## nb. this is only for the weeks in 2011 (so need to subset rows)\ncounts[which(counts$epiweek >= cut_off & \n               !is.na(counts$case_int)),\n              \"threshold_glrnb\"] <- glrnbmethod@upperbound\nggplot(counts, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in upper bound of aberration algorithm\n  geom_line(aes(y = threshold_glrnb, colour = \"Alert threshold\"), \n            linetype = \"dashed\", \n            size = 1.5) +\n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Alert threshold\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic() + \n  ## remove title of legend \n  theme(legend.title = element_blank())"},{"path":"time-series-and-outbreak-detection.html","id":"interrupted-timeseries","chapter":"23 Series temporales y detección de brotes","heading":"23.8 Series temporales interrumpidas","text":"Las series temporales interrumpidas (también llamadas análisis de regresión segmentada o de intervención), se utilizan menudo para evaluar el impacto de las vacunas en la incidencia de la enfermedad. Pero puede utilizarse para evaluar el impacto de una amplia gama de intervenciones o introducciones. Por ejemplo, cambios en los procedimientos hospitalarios o la introducción de una nueva cepa de enfermedad en una población.En este ejemplo, supondremos que se introdujo una nueva cepa de Campylobacter en Alemania finales de 2008, y veremos si eso afecta al número de casos. Volveremos utilizar la regresión binomial negativa. Esta vez, la regresión se dividirá en dos partes, una antes de la intervención (o introducción de la nueva cepa en este caso) y otra después (los períodos anterior y posterior). Esto nos permite calcular una tasa de incidencia comparando los dos periodos de tiempo. Explicar la ecuación podría aclararlo (si es así, ignórala).La regresión binomial negativa puede definirse como sigue:\\[\\log(Y_t)= β_0 + β_1 \\times t+ β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+ + log(pop_t) + e_t\\]Donde:\n\\((Y_t\\)) es el número de casos observados en el momento \\((t\\))\n\\((pop_t\\)) es el tamaño de la población en 100.000s en el momento \\((t\\)) (se utiliza aquí)\n\\((t_0\\)) es el último año del preperíodo (incluyendo el tiempo de transición si lo hay)\n\\((δ(x\\)) es la función indicadora (es 0 si x≤0 y 1 si x$>0)\n\\(((x)\\)^+\\() es el operador de corte (es x si x\\)>0 y 0 en caso contrario)\n\\((e_t\\)) denota el residuoSe pueden añadir los términos adicionales tendencia y estación según sea necesario.\\(β_2 \\times δ(t-t_0) + β_3\\times(t-t_0 )^+\\) es la parte lineal generalizada del periodo posterior y es cero en el periodo anterior. Esto significa que las estimaciones \\(β_2\\) y \\(β_3\\) son los efectos de la intervención.Aquí tenemos que volver calcular los términos de Fourier sin previsión, ya que utilizaremos todos los datos de que disponemos (es decir, posteriori). Además, tenemos que calcular los términos adicionales necesarios para la regresión.continuación, utilizamos estos términos para ajustar una regresión binomial negativa y elaboramos una tabla con el porcentaje de cambio. Lo que muestra este ejemplo es que hubo ningún cambio significativo.ATENCIÓN: Observa el uso de simulate_pi = FALSE dentro del argumento de predict(). Esto se debe que el comportamiento por defecto de la tendencia es utilizar el paquete ciTools para estimar un intervalo de predicción. Esto funciona si hay recuentos NA, y también produce intervalos más granulares. Véase ?trending::predict.trending_model_fit para más detalles.Como en el caso anterior, podemos visualizar los resultados de la regresión.","code":"\n## add in fourier terms using the epiweek and case_int variabless\ncounts$fourier <- select(counts, epiweek, case_int) %>% \n  as_tsibble(index = epiweek) %>% \n  fourier(K = 1)\n\n## define intervention week \nintervention_week <- yearweek(\"2008-12-31\")\n\n## define variables for regression \ncounts <- counts %>% \n  mutate(\n    ## corresponds to t in the formula\n      ## count of weeks (could probably also just use straight epiweeks var)\n    # linear = row_number(epiweek), \n    ## corresponds to delta(t-t0) in the formula\n      ## pre or post intervention period\n    intervention = as.numeric(epiweek >= intervention_week), \n    ## corresponds to (t-t0)^+ in the formula\n      ## count of weeks post intervention\n      ## (choose the larger number between 0 and whatever comes from calculation)\n    time_post = pmax(0, epiweek - intervention_week + 1))\n## define the model you want to fit (negative binomial) \nmodel <- glm_nb_model(\n  ## set number of cases as outcome of interest\n  case_int ~\n    ## use epiweek to account for the trend\n    epiweek +\n    ## use the furier terms to account for seasonality\n    fourier + \n    ## add in whether in the pre- or post-period \n    intervention + \n    ## add in the time post intervention \n    time_post\n    )\n\n## fit your model using the counts dataset\nfitted_model <- trending::fit(model, counts)\n\n## calculate confidence intervals and prediction intervals \nobserved <- predict(fitted_model, simulate_pi = FALSE)\n\n\n\n## show estimates and percentage change in a table\nfitted_model %>% \n  ## extract original negative binomial regression\n  get_model() %>% \n  ## get a tidy dataframe of results\n  tidy(exponentiate = TRUE, \n       conf.int = TRUE) %>% \n  ## only keep the intervention value \n  filter(term == \"intervention\") %>% \n  ## change the IRR to percentage change for estimate and CIs \n  mutate(\n    ## for each of the columns of interest - create a new column\n    across(\n      all_of(c(\"estimate\", \"conf.low\", \"conf.high\")), \n      ## apply the formula to calculate percentage change\n            .f = function(i) 100 * (i - 1), \n      ## add a suffix to new column names with \"_perc\"\n      .names = \"{.col}_perc\")\n    ) %>% \n  ## only keep (and rename) certain columns \n  select(\"IRR\" = estimate, \n         \"95%CI low\" = conf.low, \n         \"95%CI high\" = conf.high,\n         \"Percentage change\" = estimate_perc, \n         \"95%CI low (perc)\" = conf.low_perc, \n         \"95%CI high (perc)\" = conf.high_perc,\n         \"p-value\" = p.value)## # A tibble: 1 × 7\n##     IRR `95%CI low` `95%CI high` `Percentage change` `95%CI low (perc)` `95%CI high (perc)` `p-value`\n##   <dbl>       <dbl>        <dbl>               <dbl>              <dbl>               <dbl>     <dbl>\n## 1 0.936       0.874         1.00               -6.40              -12.6               0.306    0.0645\nggplot(observed, aes(x = epiweek)) + \n  ## add in observed case counts as a line\n  geom_line(aes(y = case_int, colour = \"Observed\")) + \n  ## add in a line for the model estimate\n  geom_line(aes(y = estimate, col = \"Estimate\")) + \n  ## add in a band for the prediction intervals \n  geom_ribbon(aes(ymin = lower_pi, \n                  ymax = upper_pi), \n              alpha = 0.25) + \n  ## add vertical line and label to show where forecasting started\n  geom_vline(\n           xintercept = as.Date(intervention_week), \n           linetype = \"dashed\") + \n  annotate(geom = \"text\", \n           label = \"Intervention\", \n           x = intervention_week, \n           y = max(observed$upper_pi), \n           angle = 90, \n           vjust = 1\n           ) + \n  ## define colours\n  scale_colour_manual(values = c(\"Observed\" = \"black\", \n                                 \"Estimate\" = \"red\")) + \n  ## make a traditional plot (with black axes and white background)\n  theme_classic()## Warning: Removed 13 rows containing missing values (`geom_line()`)."},{"path":"time-series-and-outbreak-detection.html","id":"resources-16","chapter":"23 Series temporales y detección de brotes","heading":"23.9 Recursos","text":"Forecasting: principles practice. Libro de textoEstudios de casos de análisis de series temporales de EPIETCurso de Penn StateManuscrito del paquete Surveillance","code":""},{"path":"epidemic-modeling.html","id":"epidemic-modeling","chapter":"24 Modelización de epidemias","heading":"24 Modelización de epidemias","text":"","code":""},{"path":"epidemic-modeling.html","id":"overview-3","chapter":"24 Modelización de epidemias","heading":"24.1 Resumen","text":"Existe un conjunto creciente de herramientas para la modelización de epidemias que nos permite realizar análisis bastante complejos con un esfuerzo mínimo. En esta sección se ofrece una visión general de cómo utilizar estas herramientas para:estimar el número de reproducción efectivo Rt y las estadísticas relacionadas, como el tiempo de duplicaciónestimar el número de reproducción efectivo Rt y las estadísticas relacionadas, como el tiempo de duplicaciónelaborar proyecciones corto plazo de la incidencia futuraelaborar proyecciones corto plazo de la incidencia futuraNo pretende ser una visión general de las metodologías y los métodos estadísticos en los que se basan estas herramientas, así que consulta la sección de Recursos para ver los enlaces algunos documentos que cubren esto. Asegúrese de que conoce los métodos antes de utilizar estas herramientas, ya que así podrá interpretar con precisión sus resultados.continuación se muestra un ejemplo de uno de los resultados que produciremos en esta sección.","code":""},{"path":"epidemic-modeling.html","id":"preparation-15","chapter":"24 Modelización de epidemias","heading":"24.2 Preparación","text":"Utilizaremos dos métodos y paquetes diferentes para la estimación de Rt, saber, EpiNow y EpiEstim, así como el paquete projections para la previsión de la incidencia de casos.Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.Utilizaremos la lista de casos limpia para todos los análisis de esta sección. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Consulta la página de descargando el manual y los datos para descargar todos los datos de ejemplo utilizados en este manual.","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   epicontacts,  # Analysing transmission networks\n   EpiNow2,      # Rt estimation\n   EpiEstim,     # Rt estimation\n   projections,  # Incidence projections\n   incidence2,   # Handling incidence data\n   epitrix,      # Useful epi functions\n   distcrete     # Discrete delay distributions\n)\n# import the cleaned linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"epidemic-modeling.html","id":"estimating-rt","chapter":"24 Modelización de epidemias","heading":"24.3 Estimación de Rt","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-vs.-epiestim","chapter":"24 Modelización de epidemias","heading":"EpiNow2 vs. EpiEstim","text":"El número de reproducción R es una medida de la transmisibilidad de una enfermedad y se define como el número esperado de casos secundarios por cada caso infectado. En una población totalmente susceptible, este valor representa el número básico de reproducción R0. Sin embargo, como el número de individuos susceptibles en una población cambia en el transcurso de un brote o pandemia, y como se aplican diversas medidas de respuesta, la medida de transmisibilidad más utilizada es el número de reproducción efectivo Rt; éste se define como el número esperado de casos secundarios por caso infectado en un tiempo t determinado.El paquete EpiNow2 proporciona el marco más sofisticado para estimar Rt. Tiene dos ventajas clave sobre el otro paquete comúnmente utilizado, EpiEstim:Tiene en cuenta los retrasos en la notificación y, por lo tanto, puede estimar la Rt incluso cuando los datos recientes son incompletos.Tiene en cuenta los retrasos en la notificación y, por lo tanto, puede estimar la Rt incluso cuando los datos recientes son incompletos.Estima la Rt en función de las fechas de infección y de las fechas de inicio de la notificación, lo que significa que el efecto de una intervención se reflejará inmediatamente en un cambio en la Rt, en lugar de con un retraso.Estima la Rt en función de las fechas de infección y de las fechas de inicio de la notificación, lo que significa que el efecto de una intervención se reflejará inmediatamente en un cambio en la Rt, en lugar de con un retraso.Sin embargo, también tiene dos desventajas fundamentales:Requiere conocer la distribución del tiempo de generación (es decir, la distribución de los retrasos entre la infección de un caso primario y uno secundario), la distribución del periodo de incubación (es decir, la distribución de los retrasos entre la infección y el inicio de los síntomas) y cualquier otra distribución de los retrasos que sea relevante para sus datos (por ejemplo, si tiene fechas de notificación, necesita la distribución de los retrasos desde el inicio de los síntomas hasta la notificación). Aunque esto permitirá una estimación más precisa de Rt, EpiEstim sólo requiere la distribución de intervalos en serie (es decir, la distribución de retrasos entre el inicio de los síntomas de un caso primario y uno secundario), que puede ser la única distribución disponible para usted.Requiere conocer la distribución del tiempo de generación (es decir, la distribución de los retrasos entre la infección de un caso primario y uno secundario), la distribución del periodo de incubación (es decir, la distribución de los retrasos entre la infección y el inicio de los síntomas) y cualquier otra distribución de los retrasos que sea relevante para sus datos (por ejemplo, si tiene fechas de notificación, necesita la distribución de los retrasos desde el inicio de los síntomas hasta la notificación). Aunque esto permitirá una estimación más precisa de Rt, EpiEstim sólo requiere la distribución de intervalos en serie (es decir, la distribución de retrasos entre el inicio de los síntomas de un caso primario y uno secundario), que puede ser la única distribución disponible para usted.EpiNow2 es significativamente más lento que EpiEstim, anecdóticamente por un factor de 100-1000. Por ejemplo, la estimación de Rt para el brote de la muestra considerada en esta sección tarda unas cuatro horas (esto se ejecutó para un gran número de iteraciones para asegurar una alta precisión y probablemente podría reducirse si fuera necesario, sin embargo los puntos son que el algoritmo es lento en general). Esto puede ser inviable si se actualizan regularmente las estimaciones de Rt.EpiNow2 es significativamente más lento que EpiEstim, anecdóticamente por un factor de 100-1000. Por ejemplo, la estimación de Rt para el brote de la muestra considerada en esta sección tarda unas cuatro horas (esto se ejecutó para un gran número de iteraciones para asegurar una alta precisión y probablemente podría reducirse si fuera necesario, sin embargo los puntos son que el algoritmo es lento en general). Esto puede ser inviable si se actualizan regularmente las estimaciones de Rt.Por tanto, el paquete que elijas utilizar dependerá de los datos, el tiempo y los recursos informáticos de que disponga.","code":""},{"path":"epidemic-modeling.html","id":"epinow2","chapter":"24 Modelización de epidemias","heading":"EpiNow2","text":"","code":""},{"path":"epidemic-modeling.html","id":"estimación-de-las-distribuciones-de-los-retrasos","chapter":"24 Modelización de epidemias","heading":"Estimación de las distribuciones de los retrasos","text":"Las distribuciones de retraso necesarias para ejecutar EpiNow2 dependen de los datos que tengas. Esencialmente, necesita poder describir el retraso desde la fecha de la infección hasta la fecha del evento que quieres usar para estimar Rt. Si estás usando fechas de inicio, esto sería simplemente la distribución del periodo de incubación. Si se utilizan las fechas de notificación, se requiere el retraso desde la infección hasta la notificación. Como es poco probable que esta distribución se conozca directamente, EpiNow2 permite encadenar varias distribuciones de retraso; en este caso, el retraso desde la infección hasta el inicio de los síntomas (por ejemplo, el periodo de incubación, que probablemente se conoce) y desde el inicio de los síntomas hasta la notificación (que menudo se puede estimar partir de los datos).Como tenemos las fechas de inicio de todos nuestros casos en nuestro linelist de ejemplo, sólo necesitaremos la distribución del periodo de incubación para relacionar nuestros datos (por ejemplo, las fechas de inicio de los síntomas) con la fecha de la infección. Podemos estimar esta distribución partir de los datos o utilizar valores de la literatura.Una estimación bibliográfica del periodo de incubación del ébola (tomada de este documento) con una media de 9,1, una desviación estándar de 7,3 y un valor máximo de 30 se especificaría como sigue:Ten en cuenta que EpiNow2 requiere que estas distribuciones de retardo se proporcionen en una escala logarítmica, de ahí la llamada log alrededor de cada valor (excepto el parámetro max que, confusamente, tiene que proporcionarse en una escala natural). Los parámetros mean_sd y sd_sd definen la desviación estándar de las estimaciones de la media y la desviación estándar. Como se conocen en este caso, elegimos el valor bastante arbitrario de 0,1.En este análisis, en cambio, estimamos la distribución del periodo de incubación partir del propio listado utilizando la función bootstrapped_dist_fit, que ajustará una distribución lognormal los retrasos observados entre la infección y el inicio en linelist.La otra distribución que necesitamos es el tiempo de generación. Como tenemos datos sobre los tiempos de infección y los enlaces de transmisión, podemos estimar esta distribución partir de linelist calculando el retraso entre los tiempos de infección de los pares infector-infectado. Para ello, utilizamos la práctica función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):continuación, ajustamos la diferencia de tiempos de infección entre pares de transmisión, calculada mediante get_pairwise, una distribución gamma:","code":"\nincubation_period_lit <- list(\n  mean = log(9.1),\n  mean_sd = log(0.1),\n  sd = log(7.3),\n  sd_sd = log(0.1),\n  max = 30\n)\n## estimate incubation period\nincubation_period <- bootstrapped_dist_fit(\n  linelist$date_onset - linelist$date_infection,\n  dist = \"lognormal\",\n  max_value = 100,\n  bootstraps = 1\n)\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma generation time\ngeneration_time <- bootstrapped_dist_fit(\n  get_pairwise(epic, \"date_infection\"),\n  dist = \"gamma\",\n  max_value = 20,\n  bootstraps = 1\n)"},{"path":"epidemic-modeling.html","id":"ejecución-de-epinow2","chapter":"24 Modelización de epidemias","heading":"Ejecución de EpiNow2","text":"Ahora sólo tenemos que calcular la incidencia diaria de linelist, lo que podemos hacer fácilmente con las funciones group_by() y n() de dplyr. Ten en cuenta que EpiNow2 requiere que los nombres de las columnas sean date y confirm.can estimate Rt using epinow function. notes \ninputs:can provide number ‘chained’ delay distributions delays\nargument; simply insert alongside incubation_period object\nwithin delay_opts function.return_output ensures output returned within R just saved \nfile.verbose specifies want readout progress.horizon indicates many days want project future incidence .pass additional options stan argument specify long\nwant run inference . Increasing samples chains give\naccurate estimate better characterises uncertainty, however\ntake longer run.Podemos entonces estimar Rt utilizando la función epinow. Algunas notas sobre\nlas entradas:Podemos proporcionar cualquier número de distribuciones de retraso “encadenadas” al argumento delays:\nsimplemente las insertaríamos junto al objeto incubation_period dentro de la función delay_opts.El objeto return_output asegura que la salida se devuelve dentro de R y solo se guarda en un archivo.verbose especifica que queremos una lectura del progreso.horizonte indica para cuántos días queremos proyectar la incidencia futura.Pasamos opciones adicionales al argumento stan para especificar durante cuánto tiempo\nqueremos ejecutar la inferencia. Aumentando samples y chains obtendremos\nuna estimación más precisa que caracteriza mejor la incertidumbre, sin embargo\ntardará más en ejecutarse.","code":"\n## get incidence from onset dates\ncases <- linelist %>%\n  group_by(date = date_onset) %>%\n  summarise(confirm = n())\n## run epinow\nepinow_res <- epinow(\n  reported_cases = cases,\n  generation_time = generation_time,\n  delays = delay_opts(incubation_period),\n  return_output = TRUE,\n  verbose = TRUE,\n  horizon = 21,\n  stan = stan_opts(samples = 750, chains = 4)\n)"},{"path":"epidemic-modeling.html","id":"análisis-de-los-resultados","chapter":"24 Modelización de epidemias","heading":"Análisis de los resultados","text":"Una vez que el código ha terminado de ejecutarse, podemos trazar un resumen muy fácilmente, como se indica continuación. Desplaza la imagen para ver la extensión completa.También podemos consultar varias estadísticas resumidas:Para otros análisis y trazados personalizados, puedes acceder las estimaciones diarias resumidas través de $estimates$summarised. Convertiremos esto desde data.table por defecto un tibble para facilitar su uso con dplyr.modo de ejemplo, hagamos un gráfico del tiempo de duplicación y Rt. Sólo nos fijaremos en los primeros meses del brote, cuando Rt es muy superior uno, para evitar trazar tiempos de duplicación extremadamente altos.Utilizamos la fórmula log(2)/growth_rate para calcular el tiempo de duplicación partir de la tasa de crecimiento estimada.","code":"\n## plot summary figure\nplot(epinow_res)\n## summary table\nepinow_res$summary##                                  measure                  estimate  numeric_estimate\n## 1: New confirmed cases by infection date                4 (2 -- 6) <data.table[1x9]>\n## 2:        Expected change in daily cases                    Unsure              0.56\n## 3:            Effective reproduction no.        0.88 (0.73 -- 1.1) <data.table[1x9]>\n## 4:                        Rate of growth -0.012 (-0.028 -- 0.0052) <data.table[1x9]>\n## 5:          Doubling/halving time (days)          -60 (130 -- -25) <data.table[1x9]>\n## extract summary and convert to tibble\nestimates <- as_tibble(epinow_res$estimates$summarised)\nestimates\n## make wide df for median plotting\ndf_wide <- estimates %>%\n  filter(\n    variable %in% c(\"growth_rate\", \"R\"),\n    date < as.Date(\"2014-09-01\")\n  ) %>%\n  ## convert growth rates to doubling times\n  mutate(\n    across(\n      c(median, lower_90:upper_90),\n      ~ case_when(\n        variable == \"growth_rate\" ~ log(2)/.x,\n        TRUE ~ .x\n      )\n    ),\n    ## rename variable to reflect transformation\n    variable = replace(variable, variable == \"growth_rate\", \"doubling_time\")\n  )\n\n## make long df for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(R = \"R[t]\", doubling_time = \"Doubling~time\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credibel\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"epiestim","chapter":"24 Modelización de epidemias","heading":"EpiEstim","text":"Para ejecutar EpiEstim, necesitamos proporcionar datos sobre la incidencia diaria y especificar el intervalo de serie (es decir, la distribución de los retrasos entre el inicio de los síntomas de los casos primarios y secundarios).Los datos de incidencia pueden proporcionarse EpiEstim como un vector, un dataframe o un objeto incidence del paquete incidence original. Incluso se puede distinguir entre infecciones importadas y adquiridas localmente; consulta la documentación en ?estimate_R para más detalles.Crearemos la entrada utilizando incidence2. Consulta la página sobre curvas epidémicas para ver más ejemplos con el paquete incidence2. Dado que ha habido actualizaciones en el paquete incidence2 que se alinean completamente con la entrada esperada de estimate_R(), hay algunos pasos adicionales menores necesarios. El objeto incidence consiste en un tibble con fechas y sus respectivos recuentos de casos. Usamos complete() de tidyr para asegurarnos que se incluyen todas las fechas (incluso las que tienen casos), y luego rename() las columnas para alinearlas con lo que espera estimate_R() en un paso posterior.El paquete proporciona varias opciones para especificar el intervalo en serie, cuyos detalles se proporcionan en la documentación en ?estimate_R. Aquí cubriremos dos de ellas.","code":"\n## get incidence from onset date\ncases <- incidence2::incidence(linelist, date_index = date_onset) %>% # get case counts by day\n  tidyr::complete(date_index = seq.Date(                              # ensure all dates are represented\n    from = min(date_index, na.rm = T),\n    to = max(date_index, na.rm=T),\n    by = \"day\"),\n    fill = list(count = 0)) %>%                                       # convert NA counts to 0\n  rename(I = count,                                                   # rename to names expected by estimateR\n         dates = date_index)"},{"path":"epidemic-modeling.html","id":"utilizando-estimaciones-de-intervalos-de-serie-de-la-literatura","chapter":"24 Modelización de epidemias","heading":"Utilizando estimaciones de intervalos de serie de la literatura","text":"Utilizando la opción method = \"parametric_si\", podemos especificar manualmente la media y la desviación estándar del intervalo en serie en un objeto config creado con la función make_config. Utilizamos una media y una desviación estándar de 12,0 y 5,2, respectivamente, definidas en este documento:Entonces podemos estimar Rt con la función estimate_R:y trazar un resumen de los resultados:","code":"\n## make config\nconfig_lit <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2\n)\nepiestim_res_lit <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_lit\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\nplot(epiestim_res_lit)"},{"path":"epidemic-modeling.html","id":"utilización-de-estimaciones-de-intervalos-de-serie-a-partir-de-los-datos","chapter":"24 Modelización de epidemias","heading":"Utilización de estimaciones de intervalos de serie a partir de los datos","text":"Como tenemos datos sobre las fechas de inicio de los síntomas y los vínculos de transmisión, también podemos estimar el intervalo de serie partir de linelist calculando el retraso entre las fechas de inicio de los pares infector-infectado. Como hicimos en la sección EpiNow2, utilizaremos la función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):continuación, ajustamos la diferencia de fechas de inicio entre los pares de transmisión, calculada mediante get_pairwise, una distribución gamma. Utilizamos el práctico fit_disc_gamma del paquete epitrix para este procedimiento de ajuste, ya que necesitamos una distribución discreta.continuación, pasamos esta información al objeto config, ejecutamos de nuevo EpiEstim y trazamos los resultados:","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n## make config\nconfig_emp <- make_config(\n  mean_si = serial_interval$mu,\n  std_si = serial_interval$sd\n)\n\n## run epiestim\nepiestim_res_emp <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_emp\n)## Default config will estimate R on weekly sliding windows.\n##     To change this change the t_start and t_end arguments.\n## plot outputs\nplot(epiestim_res_emp)"},{"path":"epidemic-modeling.html","id":"especificación-de-las-ventanas-de-tiempo-de-estimación","chapter":"24 Modelización de epidemias","heading":"Especificación de las ventanas de tiempo de estimación","text":"Estas opciones por defecto proporcionarán una estimación deslizante semanal y podrían actuar como una advertencia de que está estimando Rt demasiado pronto en el brote para una estimación precisa. Puedes cambiar esto estableciendo una fecha de inicio posterior para la estimación, como se muestra continuación. Lamentablemente, EpiEstim sólo proporciona una forma muy tosca de especificar estos tiempos de estimación, ya que tiene que proporcionar un vector de enteros que se refieran las fechas de inicio y fin de cada ventana temporal.Ahora volvemos ejecutar EpiEstim y podemos ver que las estimaciones sólo comienzan partir de junio:","code":"\n## define a vector of dates starting on June 1st\nstart_dates <- seq.Date(\n  as.Date(\"2014-06-01\"),\n  max(cases$dates) - 7,\n  by = 1\n) %>%\n  ## subtract the starting date to convert to numeric\n  `-`(min(cases$dates)) %>%\n  ## convert to integer\n  as.integer()\n\n## add six days for a one week sliding window\nend_dates <- start_dates + 6\n  \n## make config\nconfig_partial <- make_config(\n  mean_si = 12.0,\n  std_si = 5.2,\n  t_start = start_dates,\n  t_end = end_dates\n)\n## run epiestim\nepiestim_res_partial <- estimate_R(\n  incid = cases,\n  method = \"parametric_si\",\n  config = config_partial\n)\n\n## plot outputs\nplot(epiestim_res_partial)"},{"path":"epidemic-modeling.html","id":"análisis-de-los-resultados-1","chapter":"24 Modelización de epidemias","heading":"Análisis de los resultados","text":"Se puede acceder los principales resultados través de $R. Como ejemplo, crearemos un gráfico de Rt y una medida de “potencial de transmisión” dada por el producto de Rt y el número de casos notificados en ese día; esto representa el número esperado de casos en la siguiente generación de infección.","code":"\n## make wide dataframe for median\ndf_wide <- epiestim_res_lit$R %>%\n  rename_all(clean_labels) %>%\n  rename(\n    lower_95_r = quantile_0_025_r,\n    lower_90_r = quantile_0_05_r,\n    lower_50_r = quantile_0_25_r,\n    upper_50_r = quantile_0_75_r,\n    upper_90_r = quantile_0_95_r,\n    upper_95_r = quantile_0_975_r,\n    ) %>%\n  mutate(\n    ## extract the median date from t_start and t_end\n    dates = epiestim_res_emp$dates[round(map2_dbl(t_start, t_end, median))],\n    var = \"R[t]\"\n  ) %>%\n  ## merge in daily incidence data\n  left_join(cases, \"dates\") %>%\n  ## calculate risk across all r estimates\n  mutate(\n    across(\n      lower_95_r:upper_95_r,\n      ~ .x*I,\n      .names = \"{str_replace(.col, '_r', '_risk')}\"\n    )\n  ) %>%\n  ## seperate r estimates and risk estimates\n  pivot_longer(\n    contains(\"median\"),\n    names_to = c(\".value\", \"variable\"),\n    names_pattern = \"(.+)_(.+)\"\n  ) %>%\n  ## assign factor levels\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make long dataframe from quantiles\ndf_long <- df_wide %>%\n  select(-variable, -median) %>%\n  ## seperate r/risk estimates and quantile levels\n  pivot_longer(\n    contains(c(\"lower\", \"upper\")),\n    names_to = c(\".value\", \"quantile\", \"variable\"),\n    names_pattern = \"(.+)_(.+)_(.+)\"\n  ) %>%\n  mutate(variable = factor(variable, c(\"risk\", \"r\")))\n\n## make plot\nggplot() +\n  geom_ribbon(\n    data = df_long,\n    aes(x = dates, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = dates, y = median),\n    alpha = 0.2\n  ) +\n  ## use label_parsed to allow subscript label\n  facet_wrap(\n    ~ variable,\n    ncol = 1,\n    scales = \"free_y\",\n    labeller = as_labeller(c(r = \"R[t]\", risk = \"Transmission~potential\"), label_parsed),\n    strip.position = 'left'\n  ) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`50` = 0.7, `90` = 0.4, `95` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = NULL,\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    strip.background = element_blank(),\n    strip.placement = 'outside'\n  )"},{"path":"epidemic-modeling.html","id":"projecting-incidence","chapter":"24 Modelización de epidemias","heading":"24.4 Proyección de la incidencia","text":"","code":""},{"path":"epidemic-modeling.html","id":"epinow2-1","chapter":"24 Modelización de epidemias","heading":"EpiNow2","text":"Además de la estimación de Rt, EpiNow2 también admite la previsión de Rt y las proyecciones del número de casos mediante la integración con el paquete EpiSoon por debajo. Todo lo que hay que hacer es especificar el argumento de horizon en la llamada la función epinow, indicando cuántos días se quiere proyectar en el futuro; véase EpiNow2 en la sección “Estimación de Rt” para obtener detalles sobre cómo poner en marcha EpiNow2. En esta sección, sólo vamos trazar los resultados de ese análisis, almacenados en el objeto epinow_res.","code":"\n## define minimum date for plot\nmin_date <- as.Date(\"2015-03-01\")\n\n## extract summarised estimates\nestimates <-  as_tibble(epinow_res$estimates$summarised)\n\n## extract raw data on case incidence\nobservations <- as_tibble(epinow_res$estimates$observations) %>%\n  filter(date > min_date)\n\n## extract forecasted estimates of case numbers\ndf_wide <- estimates %>%\n  filter(\n    variable == \"reported_cases\",\n    type == \"forecast\",\n    date > min_date\n  )\n\n## convert to even longer format for quantile plotting\ndf_long <- df_wide %>%\n  ## here we match matching quantiles (e.g. lower_90 to upper_90)\n  pivot_longer(\n    lower_90:upper_90,\n    names_to = c(\".value\", \"quantile\"),\n    names_pattern = \"(.+)_(.+)\"\n  )\n\n## make plot\nggplot() +\n  geom_histogram(\n    data = observations,\n    aes(x = date, y = confirm),\n    stat = 'identity',\n    binwidth = 1\n  ) +\n  geom_ribbon(\n    data = df_long,\n    aes(x = date, ymin = lower, ymax = upper, alpha = quantile),\n    color = NA\n  ) +\n  geom_line(\n    data = df_wide,\n    aes(x = date, y = median)\n  ) +\n  geom_vline(xintercept = min(df_long$date), linetype = 2) +\n  ## manually define quantile transparency\n  scale_alpha_manual(\n    values = c(`20` = 0.7, `50` = 0.4, `90` = 0.2),\n    labels = function(x) paste0(x, \"%\")\n  ) +\n  labs(\n    x = NULL,\n    y = \"Daily reported cases\",\n    alpha = \"Credible\\ninterval\"\n  ) +\n  scale_x_date(\n    date_breaks = \"1 month\",\n    date_labels = \"%b %d\\n%Y\"\n  ) +\n  theme_minimal(base_size = 14)"},{"path":"epidemic-modeling.html","id":"proyecciones","chapter":"24 Modelización de epidemias","heading":"Proyecciones","text":"El paquete projections desarrollado por RECON hace que sea muy fácil hacer previsiones de incidencia corto plazo, requiriendo sólo el conocimiento del número de reproducción efectivo Rt y el intervalo serial. Aquí cubriremos cómo utilizar las estimaciones del intervalo de serie de la literatura y cómo utilizar nuestras propias estimaciones de linelist.","code":""},{"path":"epidemic-modeling.html","id":"utilizando-estimaciones-de-intervalos-de-serie-de-la-literatura-1","chapter":"24 Modelización de epidemias","heading":"Utilizando estimaciones de intervalos de serie de la literatura","text":"Las proyecciones requieren una distribución de intervalos seriales discretizados del tipo distcrete del paquete distcrete. Utilizaremos una distribución gamma con una media de 12,0 y una desviación estándar de 5,2 definida en este documento. Para convertir estos valores en los parámetros de forma y escala necesarios para una distribución gamma, utilizaremos la función gamma_mucv2shapescale del paquete epitrix.Aquí tenemos una comprobación rápida para asegurarnos que el intervalo de la serie parece correcto. Accedemos la densidad de la distribución gamma que acabamos de definir mediante $d, lo que equivale llamar dgamma:","code":"\n## get shape and scale parameters from the mean mu and the coefficient of\n## variation (e.g. the ratio of the standard deviation to the mean)\nshapescale <- epitrix::gamma_mucv2shapescale(mu = 12.0, cv = 5.2/12)\n\n## make distcrete object\nserial_interval_lit <- distcrete::distcrete(\n  name = \"gamma\",\n  interval = 1,\n  shape = shapescale$shape,\n  scale = shapescale$scale\n)\n## check to make sure the serial interval looks correct\nqplot(\n  x = 0:50, y = serial_interval_lit$d(0:50), geom = \"area\",\n  xlab = \"Serial interval\", ylab = \"Density\"\n)"},{"path":"epidemic-modeling.html","id":"utilización-de-estimaciones-de-intervalos-de-serie-a-partir-de-los-datos-1","chapter":"24 Modelización de epidemias","heading":"Utilización de estimaciones de intervalos de serie a partir de los datos","text":"Como tenemos datos sobre las fechas de inicio de los síntomas y los vínculos de transmisión, también podemos estimar el intervalo de serie partir de linelist calculando el retraso entre las fechas de inicio de los pares infector-infectado. Como hicimos en la sección EpiNow2, utilizaremos la función get_pairwise del paquete epicontacts, que nos permite calcular las diferencias por pares de las propiedades de linelist entre los pares de transmisión. Primero creamos un objeto epicontacts (ver la página de cadenas de transmisión para más detalles):continuación, ajustamos la diferencia de fechas de inicio entre los pares de transmisión, calculada mediante get_pairwise, una distribución gamma. Utilizamos el práctico fit_disc_gamma del paquete epitrix para este procedimiento de ajuste, ya que necesitamos una distribución discreta.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    from = infector,\n    to = case_id\n  ) %>%\n  drop_na()\n\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts, \n  directed = TRUE\n)\n## estimate gamma serial interval\nserial_interval <- fit_disc_gamma(get_pairwise(epic, \"date_onset\"))\n\n## inspect estimate\nserial_interval[c(\"mu\", \"sd\")]## $mu\n## [1] 11.51242\n## \n## $sd\n## [1] 7.700005"},{"path":"epidemic-modeling.html","id":"proyección-de-la-incidencia","chapter":"24 Modelización de epidemias","heading":"Proyección de la incidencia","text":"Para proyectar la incidencia futura, todavía tenemos que proporcionar la incidencia histórica en forma de un objeto de incidence, así como una muestra de valores de Rt plausibles. Generaremos estos valores utilizando las estimaciones de Rt generadas por EpiEstim en la sección anterior (en “Estimación de Rt”) y almacenadas en el objeto epiestim_res_emp. En el código siguiente, extraemos las estimaciones de la media y la desviación estándar de Rt para la última ventana temporal del brote (utilizando la función tail para acceder al último elemento de un vector), y simulamos 1000 valores partir de una distribución gamma utilizando rgamma. También puedes proporcionar un vector propio de valores de Rt que desees utilizar para las proyecciones futuro.continuación, utilizamos la función project() para realizar la previsión real. Especificamos para cuántos días queremos proyectar mediante los argumentos n_days, y especificamos el número de simulaciones utilizando el argumento n_sim.continuación, podemos trazar fácilmente la incidencia y las proyecciones utilizando las funciones plot() y add_projections(). Podemos fácilmente subconjuntar el objeto de incidencia para mostrar sólo los casos más recientes utilizando el operador de corchetes.También puedes extraer fácilmente las estimaciones brutas del número de casos diarios convirtiendo la salida en un dataframe.","code":"\n## create incidence object from dates of onset\ninc <- incidence::incidence(linelist$date_onset)## 256 missing observations were removed.\n## extract plausible r values from most recent estimate\nmean_r <- tail(epiestim_res_emp$R$`Mean(R)`, 1)\nsd_r <- tail(epiestim_res_emp$R$`Std(R)`, 1)\nshapescale <- gamma_mucv2shapescale(mu = mean_r, cv = sd_r/mean_r)\nplausible_r <- rgamma(1000, shape = shapescale$shape, scale = shapescale$scale)\n\n## check distribution\nqplot(x = plausible_r, geom = \"histogram\", xlab = expression(R[t]), ylab = \"Counts\")## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n## make projection\nproj <- project(\n  x = inc,\n  R = plausible_r,\n  si = serial_interval$distribution,\n  n_days = 21,\n  n_sim = 1000\n)\n## plot incidence and projections\nplot(inc[inc$dates > as.Date(\"2015-03-01\")]) %>%\n  add_projections(proj)\n## convert to data frame for raw data\nproj_df <- as.data.frame(proj)\nproj_df"},{"path":"epidemic-modeling.html","id":"resources-16","chapter":"24 Modelización de epidemias","heading":"24.5 Recursos","text":"Aquí está el documento que describe la metodología implementada en EpiEstim.Aquí está el documento que describe la metodología implementada en EpiEstim.Aquí está el documento que describe la metodología implementada en EpiNow2.Aquí está el documento que describe la metodología implementada en EpiNow2.Aquí hay un documento que describe varias consideraciones metodológicas y prácticas para estimar el Rt.Aquí hay un documento que describe varias consideraciones metodológicas y prácticas para estimar el Rt.","code":""},{"path":"contact-tracing-1.html","id":"contact-tracing-1","chapter":"25 Rastreo de contactos","heading":"25 Rastreo de contactos","text":"Esta página muestra el análisis descriptivo de los datos de rastreo de contactos, abordando algunas consideraciones clave y enfoques exclusivos de este tipo de datos.Esta página hace referencia muchas de las competencias básicas de gestión y visualización de datos de R tratadas en otras páginas (por ejemplo, limpieza de datos, pivoteo, tablas, análisis de series temporales), pero destacaremos ejemplos específicos del rastreo de contactos que han sido útiles para la toma de decisiones operativas. Por ejemplo, esto incluye la visualización de los datos de seguimiento del rastreo de contactos lo largo del tiempo o través de áreas geográficas, o la producción de tablas limpias de Indicadores Clave de Rendimiento (KPI) para los supervisores del rastreo de contactos.Para la demostración utilizaremos datos de rastreo de contactos de la plataforma Go.Data. Los principios que aquí se exponen son válidos para los datos de rastreo de contactos de otras plataformas, sólo que puede ser necesario realizar diferentes pasos de preprocesamiento de datos en función de la estructura de los mismos.Puedes leer más sobre el proyecto Go.Data en el sitio de documentación de Github o en su Comunidad de Prácticas.","code":""},{"path":"contact-tracing-1.html","id":"preparation-16","chapter":"25 Rastreo de contactos","heading":"25.1 Preparation","text":"","code":""},{"path":"contact-tracing-1.html","id":"cargar-paquetes-15","chapter":"25 Rastreo de contactos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # importing data  \n  here,         # relative file pathways  \n  janitor,      # data cleaning and tables\n  lubridate,    # working with dates\n  epikit,       # age_categories() function\n  apyramid,     # age pyramids\n  tidyverse,    # data manipulation and visualization\n  RColorBrewer, # color palettes\n  formattable,  # fancy tables\n  kableExtra    # table formatting\n)"},{"path":"contact-tracing-1.html","id":"importar-datos-13","chapter":"25 Rastreo de contactos","heading":"Importar datos","text":"Importaremos conjuntos de datos de muestra de contactos y de su “seguimiento”. Estos datos se han recuperado y desanidado de la API Go.Data y se han almacenado como archivos “.rds”.Puedes descargar todos los datos de ejemplo de este manual en la página de descarga de manuales y datos.Si deseas descargar los datos de seguimiento de contactos de ejemplo específicos de esta página, utiliza los tres enlaces de descarga que aparecen continuación:Clica para descargar los datos de casos de la investigación (archivo .rds)Clica para descargar los datos del registro de contactos (archivo .rds)Clica para descargar los datos de seguimiento de los contactos (archivo .rds)En su formato original los archivos descargables, reflejan los datos proporcionados por la API de Go.Data (puedes aprender sobre las API aquí). modo de ejemplo, aquí limpiaremos los datos para que sean más fáciles de leer en esta página. Si estás utilizando una instancia de Go.Data, puedes ver las instrucciones completas sobre cómo recuperar sus datos aquí.continuación, los conjuntos de datos se importan utilizando la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos. Utilizamos () para especificar la ruta del archivo - debes escribir la ruta del archivo específica de tu ordenador. continuación, utilizamos select() para seleccionar sólo ciertas columnas de los datos, para simplificar la demostración.","code":""},{"path":"contact-tracing-1.html","id":"datos-de-casos","chapter":"25 Rastreo de contactos","heading":"Datos de casos","text":"Estos datos son una tabla de los casos, y la información sobre ellos.Aquí están los casos nrow(cases):","code":"\ncases <- import(here(\"data\", \"godata\", \"cases_clean.rds\")) %>% \n  select(case_id, firstName, lastName, gender, age, age_class,\n         occupation, classification, was_contact, hospitalization_typeid)"},{"path":"contact-tracing-1.html","id":"datos-de-contactos","chapter":"25 Rastreo de contactos","heading":"Datos de contactos","text":"Estos datos son una tabla de todos los contactos e información sobre ellos. De nuevo, proporciona tu propia ruta de acceso al archivo. Después de la importación, realizamos algunos pasos preliminares de limpieza de datos que incluyen:Establecer age_class como factor e invertir el orden de los niveles para que las edades más jóvenes sean las primerasSeleccionar sólo una columna determinada, renombrando una de ellasAsignar artificialmente “Djembe” las filas las que les falta el nivel 2 de administración, para mejorar la claridad de algunas visualizaciones de ejemploAquí están las filas de los datos de contactos (nrow(contacts)):","code":"\ncontacts <- import(here(\"data\", \"godata\", \"contacts_clean.rds\")) %>% \n  mutate(age_class = forcats::fct_rev(age_class)) %>% \n  select(contact_id, contact_status, firstName, lastName, gender, age,\n         age_class, occupation, date_of_reporting, date_of_data_entry,\n         date_of_last_exposure = date_of_last_contact,\n         date_of_followup_start, date_of_followup_end, risk_level, was_case, admin_2_name) %>% \n  mutate(admin_2_name = replace_na(admin_2_name, \"Djembe\"))"},{"path":"contact-tracing-1.html","id":"datos-de-seguimiento","chapter":"25 Rastreo de contactos","heading":"Datos de seguimiento","text":"Estos datos son registros de las interacciones de “seguimiento” con los contactos. Se supone que cada contacto tiene un encuentro diario durante los 14 días siguientes su exposición.Importamos y realizamos algunos pasos de limpieza. Seleccionamos ciertas columnas y también convertimos una columna de caracteres todos los valores en minúsculas.Aquí están las primeras 50 filas de followups (cada fila es una interacción de seguimiento, con el estado del resultado en la columna followup_status):","code":"\nfollowups <- rio::import(here::here(\"data\", \"godata\", \"followups_clean.rds\")) %>% \n  select(contact_id, followup_status, followup_number,\n         date_of_followup, admin_2_name, admin_1_name) %>% \n  mutate(followup_status = str_to_lower(followup_status))"},{"path":"contact-tracing-1.html","id":"datos-de-las-relaciones","chapter":"25 Rastreo de contactos","heading":"Datos de las relaciones","text":"Aquí importamos datos que muestran la relación entre casos y contactos. Seleccionamos cierta columna para mostrarlos.continuación se muestran las primeras 50 filas de los datos de relaciones (relationships), cuyos registros son todas las relaciones entre casos y contactos.","code":"\nrelationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_visualid, source_gender, source_age, date_of_last_contact,\n         date_of_data_entry, target_visualid, target_gender,\n         target_age, exposure_type)"},{"path":"contact-tracing-1.html","id":"descriptive-analyses","chapter":"25 Rastreo de contactos","heading":"25.2 Análisis descriptivo","text":"Puedes utilizar las técnicas tratadas en otras páginas de este manual para realizar análisis descriptivos de los casos, contactos y sus relaciones. continuación se ofrecen algunos ejemplos.","code":""},{"path":"contact-tracing-1.html","id":"datos-demográficos","chapter":"25 Rastreo de contactos","heading":"Datos demográficos","text":"Como se muestra en la página dedicada las pirámides demográficas, se puede visualizar la distribución por edades y por sexos (aquí utilizamos el paquete apyramid).","code":""},{"path":"contact-tracing-1.html","id":"edad-y-sexo-de-los-contactos","chapter":"25 Rastreo de contactos","heading":"Edad y sexo de los contactos","text":"La pirámide que se muestra continuación compara la distribución de la edad de los contactos, por género. Observa que los contactos los que les falta la edad se incluyen en su propia barra en la parte superior. Puedes cambiar este comportamiento por defecto, pero entonces considera listar el número que falta en una leyenda.Con la estructura de datos Go.Data, los datos relationships contienen las edades tanto de los casos como de los contactos, por lo que podrías utilizar ese conjunto de datos y crear una pirámide de edades que muestre las diferencias entre estos dos grupos de personas. El dataframe relationships será mutado para transformar las columnas numéricas de edad en categorías (véase la página de limpieza de datos y funciones básicas). También pivotamos el dataframe largo para facilitar el trazado con ggplot2 (ver Pivotar datos).Ahora podemos representar este conjunto de datos transformado con age_pyramid() como antes, pero sustituyendo gender con la category (contacto, o caso).También podemos ver otras características como el desglose profesional (por ejemplo, en forma de gráfico circular).","code":"\napyramid::age_pyramid(\n  data = contacts,                                   # use contacts dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"gender\") +                             # gender for halfs of pyramid\n  labs(\n    fill = \"Gender\",                                 # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts\")+ # title of the plot\n  theme_minimal()                                    # simple background\nrelation_age <- relationships %>% \n  select(source_age, target_age) %>% \n  transmute(                              # transmute is like mutate() but removes all other columns not mentioned\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5)),\n    ) %>% \n  pivot_longer(cols = contains(\"class\"), names_to = \"category\", values_to = \"age_class\")  # pivot longer\n\n\nrelation_age## # A tibble: 200 × 2\n##    category         age_class\n##    <chr>            <fct>    \n##  1 source_age_class 80+      \n##  2 target_age_class 15-19    \n##  3 source_age_class <NA>     \n##  4 target_age_class 50-54    \n##  5 source_age_class <NA>     \n##  6 target_age_class 20-24    \n##  7 source_age_class 30-34    \n##  8 target_age_class 45-49    \n##  9 source_age_class 40-44    \n## 10 target_age_class 30-34    \n## # … with 190 more rows\napyramid::age_pyramid(\n  data = relation_age,                               # use modified relationship dataset\n  age_group = \"age_class\",                           # categorical age column\n  split_by = \"category\") +                           # by cases and contacts\n  scale_fill_manual(\n    values = c(\"orange\", \"purple\"),                  # to specify colors AND labels\n    labels = c(\"Case\", \"Contact\"))+\n  labs(\n    fill = \"Legend\",                                           # title of legend\n    title = \"Age/Sex Pyramid of COVID-19 contacts and cases\")+ # title of the plot\n  theme_minimal()                                              # simple background\n# Clean dataset and get counts by occupation\nocc_plot_data <- cases %>% \n  mutate(occupation = forcats::fct_explicit_na(occupation),  # make NA missing values a category\n         occupation = forcats::fct_infreq(occupation)) %>%   # order factor levels in order of frequency\n  count(occupation)                                          # get counts by occupation\n  \n# Make pie chart\nggplot(data = occ_plot_data, mapping = aes(x = \"\", y = n, fill = occupation))+\n  geom_bar(width = 1, stat = \"identity\") +\n  coord_polar(\"y\", start = 0) +\n  labs(\n    fill = \"Occupation\",\n    title = \"Known occupations of COVID-19 cases\")+\n  theme_minimal() +                    \n  theme(axis.line = element_blank(),\n        axis.title = element_blank(),\n        axis.text = element_blank())"},{"path":"contact-tracing-1.html","id":"contactos-por-caso","chapter":"25 Rastreo de contactos","heading":"Contactos por caso","text":"El número de contactos por caso puede ser una métrica importante para evaluar la calidad de la enumeración de los contactos y la conformidad de la población con la respuesta de salud pública.Dependiendo de la estructura de datos, esto puede evaluarse con un juego de datos que contenga todos los casos y contactos. En el conjunto de datos de Go.Data, los vínculos entre los casos (“fuentes”) y los contactos (“objetivos”) se almacenan en relationships.En este conjunto de datos, cada fila es un contacto, y el caso de origen aparece en la fila. hay contactos que tengan relaciones con múltiples casos, pero si esto existiese, puede ser necesario tenerlos en cuenta antes de representarlo (¡y explorarlos también!).Comenzamos contando el número de filas (contactos) por caso de origen. Esto se guarda como un dataframe.Utilizamos geom_histogram() para trazar estos datos como un histograma.","code":"\ncontacts_per_case <- relationships %>% \n  count(source_visualid)\n\ncontacts_per_case## # A tibble: 23 × 2\n##    source_visualid     n\n##    <chr>           <int>\n##  1 CASE-2020-0001     13\n##  2 CASE-2020-0002      5\n##  3 CASE-2020-0003      2\n##  4 CASE-2020-0004      4\n##  5 CASE-2020-0005      5\n##  6 CASE-2020-0006      3\n##  7 CASE-2020-0008      3\n##  8 CASE-2020-0009      3\n##  9 CASE-2020-0010      3\n## 10 CASE-2020-0012      3\n## # … with 13 more rows\nggplot(data = contacts_per_case)+        # begin with count data frame created above\n  geom_histogram(mapping = aes(x = n))+  # print histogram of number of contacts per case\n  scale_y_continuous(expand = c(0,0))+   # remove excess space below 0 on y-axis\n  theme_light()+                         # simplify background\n  labs(\n    title = \"Number of contacts per case\",\n    y = \"Cases\",\n    x = \"Contacts per case\"\n  )"},{"path":"contact-tracing-1.html","id":"contact-follow-up","chapter":"25 Rastreo de contactos","heading":"25.3 Seguimiento de contactos","text":"Los datos de rastreo de contactos suelen contener datos de “seguimiento”, que registran los resultados de los controles diarios de los síntomas de las personas en cuarentena. El análisis de estos datos puede servir de base para la estrategia de respuesta e identificar los contactos con riesgo de pérdida de seguimiento o con riesgo de desarrollar la enfermedad.","code":""},{"path":"contact-tracing-1.html","id":"limpieza-de-datos","chapter":"25 Rastreo de contactos","heading":"Limpieza de datos","text":"Estos datos pueden existir en una variedad de formatos. Pueden existir como una hoja de Excel de formato “ancho” con una fila por contacto y una columna por “día” de seguimiento. Consulta Pivotar datos para ver las descripciones de los datos “largos” y “anchos” y cómo pivotar los datos anchos o largos.En nuestro ejemplo de Go.Data, estos datos se almacenan en el dataframe followups, que tiene un formato “largo” con una fila por interacción de seguimiento. Las primeras 50 filas tienen este aspecto:PRECAUCIÓN: Ten cuidado con los duplicados al tratar los datos de seguimiento, ya que podría haber varios seguimientos erróneos en el mismo día para un contacto determinado. Tal vez parezca un error, pero refleja la realidad: por ejemplo, un rastreador de contactos podría enviar un formulario de seguimiento primera hora del día cuando pudo contactar con el contacto, y enviar un segundo formulario cuando se le pudo contactar más tarde. Dependerá del contexto operativo la forma en que desees gestionar los duplicados, pero asegúrate de documentar claramente tu enfoque. Veamos cuántos casos de filas “duplicadas” tenemos:En nuestros datos de ejemplo, los únicos registros los que se aplica esto son los que carecen de ID. Podemos eliminarlos. Pero, efectos de demostración, mostraremos los pasos para la eliminación de la duplicación de modo que sólo haya un registro de seguimiento por persona y por día. Para más detalles, consulta la página de De-duplicación. Asumiremos que el registro de encuentro más reciente es el correcto. También aprovechamos la oportunidad para limpiar la columna followup_number (el “día” de seguimiento que debe ir de 1 14).Para cada encuentro de seguimiento, tenemos un estado de seguimiento (como si el encuentro se produjo y, si es así, el contacto tuvo síntomas o ). Para ver todos los valores podemos ejecutar un tabyl() rápido (de janitor) o table() (de R base) (ver Tablas descriptivas) por followup_status para ver la frecuencia de cada uno de los resultados.En este conjunto de datos, “seen_not_ok” significa “visto con síntomas”, y “seen_ok” significa “visto sin síntomas”.","code":"\nfollowups %>% \n  count(contact_id, date_of_followup) %>%   # get unique contact_days\n  filter(n > 1)                             # view records where count is more than 1  ## # A tibble: 3 × 3\n##   contact_id date_of_followup     n\n##   <chr>      <date>           <int>\n## 1 <NA>       2020-09-03           2\n## 2 <NA>       2020-09-04           2\n## 3 <NA>       2020-09-05           2\nfollowups_clean <- followups %>%\n  \n  # De-duplicate\n  group_by(contact_id, date_of_followup) %>%        # group rows per contact-day\n  arrange(contact_id, desc(date_of_followup)) %>%   # arrange rows, per contact-day, by date of follow-up (most recent at top)\n  slice_head() %>%                                  # keep only the first row per unique contact id  \n  ungroup() %>% \n  \n  # Other cleaning\n  mutate(followup_number = replace(followup_number, followup_number > 14, NA)) %>% # clean erroneous data\n  drop_na(contact_id)                               # remove rows with missing contact_id\nfollowups_clean %>% \n  tabyl(followup_status)##  followup_status   n    percent\n##           missed  10 0.02325581\n##    not_attempted   5 0.01162791\n##    not_performed 319 0.74186047\n##      seen_not_ok   6 0.01395349\n##          seen_ok  90 0.20930233"},{"path":"contact-tracing-1.html","id":"gráfica-en-el-tiempo","chapter":"25 Rastreo de contactos","heading":"Gráfica en el tiempo","text":"Como los datos de las fechas son continuos, utilizaremos un histograma para representarlos con date_of_followup asignado al eje-x. Podemos conseguir un histograma “apilado” especificando un argumento fill = dentro de aes(), que asignamos la columna followup_status. En consecuencia, se puede establecer el título de la leyenda utilizando el argumento fill = de labs().Podemos ver que los contactos se identificaron en oleadas (presumiblemente correspondientes las oleadas epidémicas de casos), y que la finalización del seguimiento parece haber mejorado lo largo de la epidemia.PRECAUCIÓN: Si estás preparando muchos gráficos (por ejemplo, para múltiples jurisdicciones) querrás que las leyendas aparezcan de forma idéntica incluso con diferentes niveles de finalización o composición de los datos. Puede haber gráficos para los cuales todos los estados de seguimiento están presentes, pero todavía quieres que esas categorías aparezcan en las leyendas. En ggplot (como arriba), puedes especificar el argumento drop = FALSE de scale_fill_discrete(). En las tablas, utiliza tabyl() que muestra los recuentos de todos los niveles de los factores, o si utilizas count() de dplyr añade el argumento .drop = FALSE para incluir los recuentos de todos los niveles de los factores.","code":"\nggplot(data = followups_clean)+\n  geom_histogram(mapping = aes(x = date_of_followup, fill = followup_status)) +\n  scale_fill_discrete(drop = FALSE)+   # show all factor levels (followup_status) in the legend, even those not used\n  theme_classic() +\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Daily Contact Followup Status\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups$date_of_followup, na.rm=T)}\"))   # dynamic subtitle"},{"path":"contact-tracing-1.html","id":"seguimiento-individual-diario","chapter":"25 Rastreo de contactos","heading":"Seguimiento individual diario","text":"Si tu brote es lo suficientemente pequeño, es posible que quieras mirar cada contacto individualmente y ver su estado lo largo del seguimiento. Afortunadamente, este conjunto de datos de seguimiento ya contiene una columna con el “número” de día de seguimiento (1-14). Si existe en tus datos, puedes crearla calculando la diferencia entre la fecha de encuentro y la fecha en la que el seguimiento debía comenzar para el contacto.Un mecanismo de visualización conveniente (si el número de casos es demasiado grande) puede ser un gráfico de calor, hecho con geom_tile(). Mira más detalles en la página Gráficos de calor.","code":"\nggplot(data = followups_clean)+\n  geom_tile(mapping = aes(x = followup_number, y = contact_id, fill = followup_status),\n            color = \"grey\")+       # grey gridlines\n  scale_fill_manual( values = c(\"yellow\", \"grey\", \"orange\", \"darkred\", \"darkgreen\"))+\n  theme_minimal()+\n  scale_x_continuous(breaks = seq(from = 1, to = 14, by = 1))"},{"path":"contact-tracing-1.html","id":"analizar-por-grupos","chapter":"25 Rastreo de contactos","heading":"Analizar por grupos","text":"Tal vez estos datos de seguimiento se consulten diaria o semanalmente para la toma de decisiones operativas. Es posible que desees desgloses más significativos por zona geográfica o por equipo de seguimiento de contactos. Podemos hacerlo ajustando las columnas proporcionadas group_by().","code":"\nplot_by_region <- followups_clean %>%                                        # begin with follow-up dataset\n  count(admin_1_name, admin_2_name, followup_status) %>%   # get counts by unique region-status (creates column 'n' with counts)\n  \n  # begin ggplot()\n  ggplot(                                         # begin ggplot\n    mapping = aes(x = reorder(admin_2_name, n),     # reorder admin factor levels by the numeric values in column 'n'\n                  y = n,                            # heights of bar from column 'n'\n                  fill = followup_status,           # color stacked bars by their status\n                  label = n))+                      # to pass to geom_label()              \n  geom_col()+                                     # stacked bars, mapping inherited from above \n  geom_text(                                      # add text, mapping inherited from above\n    size = 3,                                         \n    position = position_stack(vjust = 0.5), \n    color = \"white\",           \n    check_overlap = TRUE,\n    fontface = \"bold\")+\n  coord_flip()+\n  labs(\n    x = \"\",\n    y = \"Number of contacts\",\n    title = \"Contact Followup Status, by Region\",\n    fill = \"Followup Status\",\n    subtitle = str_glue(\"Data as of {max(followups_clean$date_of_followup, na.rm=T)}\")) +\n  theme_classic()+                                                                      # Simplify background\n  facet_wrap(~admin_1_name, strip.position = \"right\", scales = \"free_y\", ncol = 1)      # introduce facets \n\nplot_by_region"},{"path":"contact-tracing-1.html","id":"kpi-tables","chapter":"25 Rastreo de contactos","heading":"25.4 Tablas KPI","text":"Hay una serie de Indicadores Clave de Rendimiento (KPI) que pueden calcularse y seguirse distintos niveles de desagregación y lo largo de diferentes períodos de tiempo para supervisar el rendimiento del rastreo de contactos. Una vez que se tienen los cálculos y el formato básico de la tabla, es bastante fácil cambiar los diferentes KPI.Existen numerosas fuentes de KPI de rastreo de contactos, como ésta de ResolveToSaveLives.org. La mayor parte del trabajo consistirá en recorrer la estructura de datos y pensar en todos los criterios de inclusión/exclusión. continuación mostramos algunos ejemplos, utilizando la estructura de metadatos de Go.Data:continuación veremos un ejercicio de ejemplo para crear una bonita tabla visual para mostrar el seguimiento de los contactos en las áreas de administración. Al final, lo haremos apto para la presentación con el paquete formattable (pero podrías usar otros paquetes como flextable - ver Tablas para presentaciones).La forma de crear una tabla como ésta dependerá de la estructura de los datos de seguimiento de contactos. Utiliza la página de tablas descriptivas para aprender resumir los datos utilizando las funciones de dplyr.Crearemos una tabla que será dinámica y cambiará medida que cambien los datos. Para que los resultados sean interesantes, estableceremos una report_date que nos permita simular la ejecución de la tabla en un día determinado (elegimos el 10 de junio de 2020). Los datos se filtran por esa fecha.Ahora, basándonos en nuestra estructura de datos, haremos lo siguiente:Comienza con los datos de followups y resúmelos para contener, para cada contacto único:La fecha del último registro (sin importar el estado del encuentro)La fecha del último encuentro en el que el contacto fue “visto”El estado del encuentro en ese último encuentro “visto” (por ejemplo, con síntomas, sin síntomas)Uniremos estos datos los de los contactos, que contienen otra información como el estado general del contacto, la fecha de la última exposición un caso, etc. También calcularemos las métricas de interés para cada contacto, como los días desde la última exposiciónAgrupamos los datos de contacto mejorados por región geográfica (`admin_2_name) y calculamos las estadísticas resumidas por regiónPor último, damos un buen formato la tabla para su presentaciónPrimero resumimos los datos de seguimiento para obtener la información de interés:Así es como se ven estos datos:Ahora añadiremos esta información los datos de contacts y calcularemos algunas columnas adicionales.Así es como se ven estos datos. Observa la columna contacts la derecha, y la nueva columna calculada en el extremo derecho.continuación, resumimos los datos de los contactos por región, para conseguir un dataframe conciso de columnas de estadísticas resumidas.Y ahora aplicamos el estilo de los paquetes formattable y knitr, incluyendo una nota pie de página que muestra la fecha “partir de”.","code":"\n# Set \"Report date\" to simulate running the report with data \"as of\" this date\nreport_date <- as.Date(\"2020-06-10\")\n\n# Create follow-up data to reflect the report date.\ntable_data <- followups_clean %>% \n  filter(date_of_followup <= report_date)\nfollowup_info <- table_data %>% \n  group_by(contact_id) %>% \n  summarise(\n    date_last_record   = max(date_of_followup, na.rm=T),\n    date_last_seen     = max(date_of_followup[followup_status %in% c(\"seen_ok\", \"seen_not_ok\")], na.rm=T),\n    status_last_record = followup_status[which(date_of_followup == date_last_record)]) %>% \n  ungroup()\ncontacts_info <- followup_info %>% \n  right_join(contacts, by = \"contact_id\") %>% \n  mutate(\n    database_date       = max(date_last_record, na.rm=T),\n    days_since_seen     = database_date - date_last_seen,\n    days_since_exposure = database_date - date_of_last_exposure\n    )\ncontacts_table <- contacts_info %>% \n  \n  group_by(`Admin 2` = admin_2_name) %>%\n  \n  summarise(\n    `Registered contacts` = n(),\n    `Active contacts`     = sum(contact_status == \"UNDER_FOLLOW_UP\", na.rm=T),\n    `In first week`       = sum(days_since_exposure < 8, na.rm=T),\n    `In second week`      = sum(days_since_exposure >= 8 & days_since_exposure < 15, na.rm=T),\n    `Became case`         = sum(contact_status == \"BECAME_CASE\", na.rm=T),\n    `Lost to follow up`   = sum(days_since_seen >= 3, na.rm=T),\n    `Never seen`          = sum(is.na(date_last_seen)),\n    `Followed up - signs` = sum(status_last_record == \"Seen_not_ok\" & date_last_record == database_date, na.rm=T),\n    `Followed up - no signs` = sum(status_last_record == \"Seen_ok\" & date_last_record == database_date, na.rm=T),\n    `Not Followed up`     = sum(\n      (status_last_record == \"NOT_ATTEMPTED\" | status_last_record == \"NOT_PERFORMED\") &\n        date_last_record == database_date, na.rm=T)) %>% \n    \n  arrange(desc(`Registered contacts`))\ncontacts_table %>%\n  mutate(\n    `Admin 2` = formatter(\"span\", style = ~ formattable::style(\n      color = ifelse(`Admin 2` == NA, \"red\", \"grey\"),\n      font.weight = \"bold\",font.style = \"italic\"))(`Admin 2`),\n    `Followed up - signs`= color_tile(\"white\", \"orange\")(`Followed up - signs`),\n    `Followed up - no signs`= color_tile(\"white\", \"#A0E2BD\")(`Followed up - no signs`),\n    `Became case`= color_tile(\"white\", \"grey\")(`Became case`),\n    `Lost to follow up`= color_tile(\"white\", \"grey\")(`Lost to follow up`), \n    `Never seen`= color_tile(\"white\", \"red\")(`Never seen`),\n    `Active contacts` = color_tile(\"white\", \"#81A4CE\")(`Active contacts`)\n  ) %>%\n  kable(\"html\", escape = F, align =c(\"l\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\",\"c\")) %>%\n  kable_styling(\"hover\", full_width = FALSE) %>%\n  add_header_above(c(\" \" = 3, \n                     \"Of contacts currently under follow up\" = 5,\n                     \"Status of last visit\" = 3)) %>% \n  kableExtra::footnote(general = str_glue(\"Data are current to {format(report_date, '%b %d %Y')}\"))"},{"path":"contact-tracing-1.html","id":"transmission-matrices","chapter":"25 Rastreo de contactos","heading":"25.5 Matrices de transmisión","text":"Como se discutió en la página de Gráficos de calor, puedes crear una matriz de “quién infectó quién” utilizando geom_tile().Cuando se crean nuevos contactos, Go.Data almacena esta información de relación en el punto final de la API relationships; y podemos ver las primeras 50 filas de este conjunto de datos continuación. Esto significa que podemos crear un gráfico de calor con relativamente pocos pasos, dado que cada contacto ya está unido su caso de origen.Al igual que en el caso de la pirámide de edad que compara casos y contactos, podemos seleccionar las pocas variables que necesitamos y crear columnas con agrupaciones categóricas de edad tanto para las fuentes (casos) como para los objetivos (contactos).Como se ha descrito anteriormente, creamos una tabulación cruzada;convertimos en formato largo con proporciones;y creamos un mapa de calor para la edad.","code":"\nheatmap_ages <- relationships %>% \n  select(source_age, target_age) %>% \n  mutate(                              # transmute is like mutate() but removes all other columns\n    source_age_class = epikit::age_categories(source_age, breakers = seq(0, 80, 5)),\n    target_age_class = epikit::age_categories(target_age, breakers = seq(0, 80, 5))) \ncross_tab <- table(\n  source_cases = heatmap_ages$source_age_class,\n  target_cases = heatmap_ages$target_age_class)\n\ncross_tab##             target_cases\n## source_cases 0-4 5-9 10-14 15-19 20-24 25-29 30-34 35-39 40-44 45-49 50-54 55-59 60-64 65-69 70-74\n##        0-4     0   0     0     0     0     0     0     0     0     1     0     1     0     0     0\n##        5-9     0   0     1     0     0     0     0     1     0     0     0     1     0     0     0\n##        10-14   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        15-19   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        20-24   1   1     0     1     2     0     2     1     0     0     0     1     0     0     0\n##        25-29   1   2     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        30-34   0   0     0     0     0     0     0     0     1     1     0     1     0     0     0\n##        35-39   0   2     0     0     0     0     0     0     0     1     0     0     0     0     0\n##        40-44   0   0     0     0     1     0     2     1     0     3     1     1     0     0     0\n##        45-49   1   2     2     0     0     0     3     0     1     0     3     2     1     0     0\n##        50-54   1   2     1     2     0     0     1     0     0     3     4     1     0     1     0\n##        55-59   0   1     0     0     1     1     2     0     0     0     0     0     0     0     0\n##        60-64   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        65-69   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        70-74   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        75-79   0   0     0     0     0     0     0     0     0     0     0     0     0     0     0\n##        80+     1   0     0     2     1     0     0     0     1     0     0     0     0     0     0\n##             target_cases\n## source_cases 75-79 80+\n##        0-4       0   0\n##        5-9       0   0\n##        10-14     0   0\n##        15-19     0   0\n##        20-24     0   1\n##        25-29     0   0\n##        30-34     0   0\n##        35-39     0   0\n##        40-44     1   1\n##        45-49     0   1\n##        50-54     0   1\n##        55-59     0   0\n##        60-64     0   0\n##        65-69     0   0\n##        70-74     0   0\n##        75-79     0   0\n##        80+       0   0\nlong_prop <- data.frame(prop.table(cross_tab))\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = target_cases,         # x-axis is case age\n      y = source_cases,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  theme(axis.text.x = element_text(angle = 90))+\n  labs(                         # labels\n    x = \"Target case age\",\n    y = \"Source case age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"contact-tracing-1.html","id":"resources-18","chapter":"25 Rastreo de contactos","heading":"25.6 Recursos","text":"https://github.com/WorldHealthOrganization/godata/tree/master/analytics/r-reportinghttps://worldhealthorganization.github.io/godata/https://community-godata..int/","code":""},{"path":"survey-analysis.html","id":"survey-analysis","chapter":"26 Análisis de encuestas","heading":"26 Análisis de encuestas","text":"","code":""},{"path":"survey-analysis.html","id":"overview-4","chapter":"26 Análisis de encuestas","heading":"26.1 Resumen","text":"Esta página muestra el uso de varios paquetes para el análisis de encuestas.La mayoría de los paquetes R de encuestas se basan en el paquete survey para realizar análisis ponderados. Utilizaremos survey, así como srvyr (una envoltura para survey que permite la codificación al estilo tidyverse) y gtsummary (una envoltura para survey que permite obtener tablas listas para su publicación). Aunque el paquete original survey permite la codificación al estilo tidyverse, tiene la ventaja añadida de permitir modelos lineales generalizados ponderados por la encuesta (que se añadirán esta página más adelante). También demostraremos el uso de una función del paquete sitrep para crear ponderaciones de muestreo (n.b. este paquete está todavía en CRAN, pero se puede instalar desde github).La mayor parte de esta página se basa en el trabajo realizado para el proyecto “R4Epis”; para ver el código detallado y las plantillas R-markdown del mismo, consulta la página github de “R4Epis”. Parte del código basado en el paquete de encuestas se basa en las primeras versiones de los estudios de caso de EPIET.Actualmente, esta página aborda el cálculo del tamaño de la muestra ni el muestreo. Para una calculadora del tamaño muestral fácil de usar, consulta OpenEpi. La página de conceptos básicos de los SIG del manual tendrá eventualmente una sección sobre muestreo aleatorio espacial, y esta página tendrá eventualmente una sección sobre marcos de muestreo así como cálculos del tamaño de la muestra.Datos de encuestasTiempo de observaciónPonderaciónObjetos de diseño de la encuestaAnálisis descriptivoProporciones ponderadasTasas ponderadas","code":""},{"path":"survey-analysis.html","id":"preparation-17","chapter":"26 Análisis de encuestas","heading":"26.2 Preparación","text":"","code":""},{"path":"survey-analysis.html","id":"paquetes-2","chapter":"26 Análisis de encuestas","heading":"Paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() de R base . Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.\nAquí también mostramos el uso de la función p_load_gh() de pacman para instalar y cargar un paquete de github que aún ha sido publicado en CRAN.","code":"\n## load packages from CRAN\npacman::p_load(rio,          # File import\n               here,         # File locator\n               tidyverse,    # data management + ggplot2 graphics\n               tsibble,      # handle time series datasets\n               survey,       # for survey functions\n               srvyr,        # dplyr wrapper for survey package\n               gtsummary,    # wrapper for survey package to produce tables\n               apyramid,     # a package dedicated to creating age pyramids\n               patchwork,    # for combining ggplots\n               ggforce       # for alluvial/sankey plots\n              \n               ) \n## load packages from github\n\npacman::p_load_gh(\n  \n  \"r4epi/sitrep\" # for observation time / weighting functions\n\n)"},{"path":"survey-analysis.html","id":"carga-de-datos","chapter":"26 Análisis de encuestas","heading":"Carga de datos","text":"El conjunto de datos de ejemplo utilizado en esta sección:datos de encuesta de mortalidad ficticia.recuentos de población ficticios para la zona de la encuesta.diccionario de datos para los datos de la encuesta de mortalidad ficticia.Se basa en la encuesta pre-aprobada por la junta de revisión ética de MSF OCA. Los datos ficticios se produjeron como parte del proyecto “R4Epis”. Todo ello se basa en los datos recopilados mediante KoboToolbox, un software de recopilación de datos basado en Open Data Kit.Kobo permite exportar tanto los datos recogidos como el diccionario de datos para ese conjunto de datos. Recomendamos encarecidamente hacer esto, ya que simplifica la limpieza de los datos y es útil para buscar variables/preguntas.CONSEJO: El diccionario de datos de Kobo tiene nombres de variables en la columna “name” de la hoja de la encuesta. Los valores posibles para cada variable se especifican en la hoja de opciones. En la hoja de opciones, “name” tiene el valor acortado y las columnas “label::english” y “label::french” tienen las versiones largas correspondientes. Si utilizas la función msf_dict_survey() del paquete epidict para importar un archivo excel del diccionario Kobo, éste se reformulará para que pueda utilizarse fácilmente para recodificar. PRECAUCIÓN: El conjunto de datos de ejemplo es lo mismo que una exportación (ya que en Kobo se exportan los diferentes niveles del cuestionario de forma individual) - Mira la sección de datos de la encuesta más abajo para fusionar los diferentes niveles.Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.Más abajo se muestran las primeras 10 filas de la encuestaTambién queremos importar los datos de la población de muestreo para poder elaborar las ponderaciones adecuadas. Estos datos pueden estar en diferentes formatos, sin embargo sugerimos tenerlos como se ve continuación (esto puede ser simplemente escrito en un Excel).continuación se muestran las 10 primeras filas de la encuesta.En el caso de las encuestas por conglomerados, es posible que desees añadir ponderaciones de la encuesta nivel de conglomerado. Puedes introducir estos datos como se indica más arriba. Alternativamente, si sólo hay unos pocos recuentos, éstos podrían introducirse como se indica continuación en un tibble. En cualquier caso, tendrá que tener una columna con un identificador de conglomerado que coincida con los datos de tu encuesta, y otra columna con el número de hogares en cada conglomerado.","code":"\n# import the survey data\nsurvey_data <- rio::import(\"survey_data.xlsx\")\n\n# import the dictionary into R\nsurvey_dict <- rio::import(\"survey_dict.xlsx\") \n# import the population data\npopulation <- rio::import(\"population.xlsx\")\n## define the number of households in each cluster\ncluster_counts <- tibble(cluster = c(\"village_1\", \"village_2\", \"village_3\", \"village_4\", \n                                     \"village_5\", \"village_6\", \"village_7\", \"village_8\",\n                                     \"village_9\", \"village_10\"), \n                         households = c(700, 400, 600, 500, 300, \n                                        800, 700, 400, 500, 500))"},{"path":"survey-analysis.html","id":"limpieza-de-datos-1","chapter":"26 Análisis de encuestas","heading":"Limpieza de datos","text":"continuación se asegura que la columna de fechas tenga el formato adecuado. Hay varias otras maneras de hacer esto (ver la página Trabajar con fechas para más detalles), sin embargo, usar el diccionario para definir las fechas es rápido y fácil.También creamos una variable de grupo de edad utilizando la función age_categories() de epikit - véase la sección del manual de limpieza de datos para más detalles. Además, creamos una variable de carácter que define en qué distrito se encuentran las distintas agrupaciones.Por último, recodificamos todas las variables sí/en variables VERDADERO/FALSO, ya que de lo contrario pueden ser utilizadas por las funciones de proporción de survey.","code":"\n## select the date variable names from the dictionary \nDATEVARS <- survey_dict %>% \n  filter(type == \"date\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select date vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(DATEVARS), as.Date))\n\n\n## add those with only age in months to the year variable (divide by twelve)\nsurvey_data <- survey_data %>% \n  mutate(age_years = if_else(is.na(age_years), \n                             age_months / 12, \n                             age_years))\n\n## define age group variable\nsurvey_data <- survey_data %>% \n     mutate(age_group = age_categories(age_years, \n                                    breakers = c(0, 3, 15, 30, 45)\n                                    ))\n\n\n## create a character variable based off groups of a different variable \nsurvey_data <- survey_data %>% \n  mutate(health_district = case_when(\n    cluster_number %in% c(1:5) ~ \"district_a\", \n    TRUE ~ \"district_b\"\n  ))\n\n\n## select the yes/no variable names from the dictionary \nYNVARS <- survey_dict %>% \n  filter(type == \"yn\") %>% \n  filter(name %in% names(survey_data)) %>% \n  ## filter to match the column names of your data\n  pull(name) # select yn vars\n  \n## change to dates \nsurvey_data <- survey_data %>%\n  mutate(across(all_of(YNVARS), \n                str_detect, \n                pattern = \"yes\"))"},{"path":"survey-analysis.html","id":"survey-data","chapter":"26 Análisis de encuestas","heading":"26.3 Datos de encuestas","text":"Existen numerosos diseños de muestreo que pueden utilizarse para las encuestas. Aquí mostraremos el código para:\n- Estratificado\n- Conglomerado\n- Estratificado y conglomeradoComo se ha descrito anteriormente (dependiendo de cómo se diseñe el cuestionario) los datos de cada nivel se exportarían como unos datos separados desde Kobo. En nuestro ejemplo hay un nivel para los hogares y un nivel para los individuos dentro de esos hogares.Estos dos niveles están vinculados por un identificador único. Para unos datos de Kobo, esta variable es “_index” en el nivel del hogar, que coincide con “_parent_index” en el nivel individual. Esto creará nuevas filas para el hogar con cada individuo que coincida, véase la sección del manual sobre unir datos para más detalles.","code":"\n## join the individual and household data to form a complete data set\nsurvey_data <- left_join(survey_data_hh, \n                         survey_data_indiv,\n                         by = c(\"_index\" = \"_parent_index\"))\n\n\n## create a unique identifier by combining indeces of the two levels \nsurvey_data <- survey_data %>% \n     mutate(uid = str_glue(\"{index}_{index_y}\"))"},{"path":"survey-analysis.html","id":"observation-time","chapter":"26 Análisis de encuestas","heading":"26.4 Tiempo de observación","text":"En el caso de las encuestas de mortalidad, queremos saber cuánto tiempo ha estado presente cada individuo en el lugar para poder calcular una tasa de mortalidad adecuada para nuestro periodo de interés. Esto es relevante para todas las encuestas, pero en particular para las encuestas de mortalidad es importante, ya que se realizan con frecuencia entre poblaciones móviles o desplazadas.Para ello, primero definimos nuestro periodo de interés, también conocido como periodo de recuerdo (es decir, el tiempo sobre el que se pide los participantes que informen al responder las preguntas). continuación, podemos utilizar este periodo para establecer las fechas inadecuadas como ausentes, es decir, si las muertes se notifican fuera del periodo de interés.Entonces podemos utilizar nuestras variables de fecha para definir las fechas de inicio y fin de cada individuo. Podemos utilizar la función find_start_date() de sitrep para afinar la elección de las fechas y luego utilizarla para calcular la diferencia entre días (persona-tiempo).Fecha de inicio:\nEvento de llegada más temprano dentro del período de recogida O bien el inicio del período de recogida (definidas de antemano), o una fecha posterior al inicio de la recogida, si procede (por ejemplo, llegadas o nacimientos)Fecha de finalización:\nEvento de salida más temprano dentro del periodo de recogida O bien el final del periodo de recogida, o una fecha anterior al final de la recogida si procede (por ejemplo, salidas, fallecimientos)","code":"\n## set the start/end of recall period\n## can be changed to date variables from dataset \n## (e.g. arrival date & date questionnaire)\nsurvey_data <- survey_data %>% \n  mutate(recall_start = as.Date(\"2018-01-01\"), \n         recall_end   = as.Date(\"2018-05-01\")\n  )\n\n\n# set inappropriate dates to NA based on rules \n## e.g. arrivals before start, departures departures after end\nsurvey_data <- survey_data %>%\n      mutate(\n           arrived_date = if_else(arrived_date < recall_start, \n                                 as.Date(NA),\n                                  arrived_date),\n           birthday_date = if_else(birthday_date < recall_start,\n                                  as.Date(NA),\n                                  birthday_date),\n           left_date = if_else(left_date > recall_end,\n                              as.Date(NA),\n                               left_date),\n           death_date = if_else(death_date > recall_end,\n                               as.Date(NA),\n                               death_date)\n           )\n## create new variables for start and end dates/causes\nsurvey_data <- survey_data %>% \n     ## choose earliest date entered in survey\n     ## from births, household arrivals, and camp arrivals \n     find_start_date(\"birthday_date\",\n                  \"arrived_date\",\n                  period_start = \"recall_start\",\n                  period_end   = \"recall_end\",\n                  datecol      = \"startdate\",\n                  datereason   = \"startcause\" \n                 ) %>%\n     ## choose earliest date entered in survey\n     ## from camp departures, death and end of the study\n     find_end_date(\"left_date\",\n                \"death_date\",\n                period_start = \"recall_start\",\n                period_end   = \"recall_end\",\n                datecol      = \"enddate\",\n                datereason   = \"endcause\" \n               )\n\n\n## label those that were present at the start/end (except births/deaths)\nsurvey_data <- survey_data %>% \n     mutate(\n       ## fill in start date to be the beginning of recall period (for those empty) \n       startdate = if_else(is.na(startdate), recall_start, startdate), \n       ## set the start cause to present at start if equal to recall period \n       ## unless it is equal to the birth date \n       startcause = if_else(startdate == recall_start & startcause != \"birthday_date\",\n                              \"Present at start\", startcause), \n       ## fill in end date to be end of recall period (for those empty) \n       enddate = if_else(is.na(enddate), recall_end, enddate), \n       ## set the end cause to present at end if equall to recall end \n       ## unless it is equal to the death date\n       endcause = if_else(enddate == recall_end & endcause != \"death_date\", \n                            \"Present at end\", endcause))\n\n\n## Define observation time in days\nsurvey_data <- survey_data %>% \n  mutate(obstime = as.numeric(enddate - startdate))"},{"path":"survey-analysis.html","id":"weighting","chapter":"26 Análisis de encuestas","heading":"26.5 Ponderación","text":"Es importante que elimines las observaciones erróneas antes de añadir los pesos de la encuesta. Por ejemplo, si hay observaciones con tiempo de observación negativo, tendrás que comprobarlas (puedes hacerlo con la función assert_positive_timespan() de sitrep. Otra cosa es si quieres eliminar las filas vacías (por ejemplo, con drop_na(uid)) o eliminar los duplicados (véase la sección del manual sobre De-duplicación para más detalles). También hay que eliminar las que tienen consentimiento.En este ejemplo, filtramos los casos que queremos eliminar y los almacenamos en un dataframe separado, de forma que podamos describir los que fueron excluidos de la encuesta. continuación, utilizamos la función anti_join() de dplyr para eliminar estos casos descartados de los datos de nuestra encuesta.PELIGRO: puede haber valores faltantes en la variable de peso, ni en ninguna de las variables relevantes para el diseño de la encuesta (por ejemplo, edad, sexo, estratos o variables de agrupación).Como se ha mencionado anteriormente, demostramos cómo añadir ponderaciones para tres diseños de estudio diferentes (estratificado, conglomerado y conglomerado estratificado). Estos requieren información sobre la población de origen y/o los conglomerados encuestados. Utilizaremos el código de conglomerado estratificado para este ejemplo, pero utiliza el que sea más apropiado para tu diseño de estudio.","code":"\n## store the cases that you drop so you can describe them (e.g. non-consenting \n## or wrong village/cluster)\ndropped <- survey_data %>% \n  filter(!consent | is.na(startdate) | is.na(enddate) | village_name == \"other\")\n\n## use the dropped cases to remove the unused rows from the survey data set  \nsurvey_data <- anti_join(survey_data, dropped, by = names(dropped))\n# stratified ------------------------------------------------------------------\n# create a variable called \"surv_weight_strata\"\n# contains weights for each individual - by age group, sex and health district\nsurvey_data <- add_weights_strata(x = survey_data,\n                                         p = population,\n                                         surv_weight = \"surv_weight_strata\",\n                                         surv_weight_ID = \"surv_weight_ID_strata\",\n                                         age_group, sex, health_district)\n\n## cluster ---------------------------------------------------------------------\n\n# get the number of people of individuals interviewed per household\n# adds a variable with counts of the household (parent) index variable\nsurvey_data <- survey_data %>%\n  add_count(index, name = \"interviewed\")\n\n\n## create cluster weights\nsurvey_data <- add_weights_cluster(x = survey_data,\n                                          cl = cluster_counts,\n                                          eligible = member_number,\n                                          interviewed = interviewed,\n                                          cluster_x = village_name,\n                                          cluster_cl = cluster,\n                                          household_x = index,\n                                          household_cl = households,\n                                          surv_weight = \"surv_weight_cluster\",\n                                          surv_weight_ID = \"surv_weight_ID_cluster\",\n                                          ignore_cluster = FALSE,\n                                          ignore_household = FALSE)\n\n\n# stratified and cluster ------------------------------------------------------\n# create a survey weight for cluster and strata\nsurvey_data <- survey_data %>%\n  mutate(surv_weight_cluster_strata = surv_weight_strata * surv_weight_cluster)"},{"path":"survey-analysis.html","id":"survey-design-objects","chapter":"26 Análisis de encuestas","heading":"26.6 Objetos de diseño de la encuesta","text":"Crea un objeto de encuesta de acuerdo con el diseño de tu estudio. Se utiliza de la misma manera que los dataframes para calcular las proporciones ponderadas, etc. Asegúrate que todas las variables necesarias están creadas antes de esto.Hay cuatro opciones, comenta las que utilizas:\n- Aleatorio simple\n- Estratificado\n- Conglomerado\n- Conglomerado estratificadoPara esta plantilla, supondremos que agrupamos las encuestas en dos estratos distintos (distritos sanitarios y B). Por lo tanto, para obtener las estimaciones globales necesitamos haber combinado las ponderaciones de los grupos y de los estratos.Como se ha mencionado anteriormente, hay dos paquetes disponibles para hacer esto. El clásico es survey y luego hay un paquete envolvente llamado srvyr que hace objetos y funciones amigables con tidyverse. Mostraremos ambos, pero ten en cuenta que la mayor parte del código de este capítulo utilizará objetos basados en srvyr. La única excepción es que el paquete gtsummary sólo acepta objetos de survey.","code":""},{"path":"survey-analysis.html","id":"paquete-survey","chapter":"26 Análisis de encuestas","heading":"Paquete survey","text":"El paquete survey utiliza efectivamente la codificación de R base, por lo que es posible utilizar pipes (%>%) u otra sintaxis de dplyr. Con el paquete de survey utilizamos la función svydesign() para definir un objeto de encuesta con clusters, pesos y estratos adecuados.NOTA: necesitamos utilizar la tilde (~) delante de las variables, esto es porque el paquete utiliza la sintaxis de R base de asignación de variables basadas en fórmulas.","code":"\n# simple random ---------------------------------------------------------------\nbase_survey_design_simple <- svydesign(ids = ~1, # 1 for no cluster ids\n                   weights = NULL,               # No weight added\n                   strata = NULL,                # sampling was simple (no strata)\n                   data = survey_data            # have to specify the dataset\n                  )\n\n## stratified ------------------------------------------------------------------\nbase_survey_design_strata <- svydesign(ids = ~1,  # 1 for no cluster ids\n                   weights = ~surv_weight_strata, # weight variable created above\n                   strata = ~health_district,     # sampling was stratified by district\n                   data = survey_data             # have to specify the dataset\n                  )\n\n# cluster ---------------------------------------------------------------------\nbase_survey_design_cluster <- svydesign(ids = ~village_name, # cluster ids\n                   weights = ~surv_weight_cluster, # weight variable created above\n                   strata = NULL,                 # sampling was simple (no strata)\n                   data = survey_data              # have to specify the dataset\n                  )\n\n# stratified cluster ----------------------------------------------------------\nbase_survey_design <- svydesign(ids = ~village_name,      # cluster ids\n                   weights = ~surv_weight_cluster_strata, # weight variable created above\n                   strata = ~health_district,             # sampling was stratified by district\n                   data = survey_data                     # have to specify the dataset\n                  )"},{"path":"survey-analysis.html","id":"paquete-srvyr","chapter":"26 Análisis de encuestas","heading":"Paquete Srvyr","text":"Con el paquete srvyr podemos utilizar la función as_survey_design(), que tiene los mismos argumentos que la anterior pero permite los pipes (%>%), por lo que es necesario utilizar la tilde (~).","code":"\n## simple random ---------------------------------------------------------------\nsurvey_design_simple <- survey_data %>% \n  as_survey_design(ids = 1, # 1 for no cluster ids \n                   weights = NULL, # No weight added\n                   strata = NULL # sampling was simple (no strata)\n                  )\n## stratified ------------------------------------------------------------------\nsurvey_design_strata <- survey_data %>%\n  as_survey_design(ids = 1, # 1 for no cluster ids\n                   weights = surv_weight_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )\n## cluster ---------------------------------------------------------------------\nsurvey_design_cluster <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster, # weight variable created above\n                   strata = NULL # sampling was simple (no strata)\n                  )\n\n## stratified cluster ----------------------------------------------------------\nsurvey_design <- survey_data %>%\n  as_survey_design(ids = village_name, # cluster ids\n                   weights = surv_weight_cluster_strata, # weight variable created above\n                   strata = health_district # sampling was stratified by district\n                  )"},{"path":"survey-analysis.html","id":"descriptive-analysis-2","chapter":"26 Análisis de encuestas","heading":"26.7 Análisis descriptivo","text":"El análisis descriptivo básico y la visualización se tratan extensamente en otros capítulos del manual, por lo que nos detendremos en ellos aquí. Para más detalles, consulta los capítulos sobre tablas descriptivas, pruebas estadísticas, tablas para presentaciones, conceptos básicos de ggplot e informes con R markdown.En este apartado nos centraremos en cómo investigar el sesgo de la muestra y visualizarlo. También veremos cómo visualizar el flujo de la población en un entorno de encuesta utilizando diagramas aluviales/sankey.En general, debes considerar incluir los siguientes análisis descriptivos:Número final de agrupaciones, hogares e individuos incluidosNúmero de personas excluidas y motivos de la exclusiónMediana (rango) del número de hogares por grupo y de individuos por hogar","code":""},{"path":"survey-analysis.html","id":"sesgo-de-muestreo","chapter":"26 Análisis de encuestas","heading":"Sesgo de muestreo","text":"Compara las proporciones de cada grupo de edad entre tu muestra y la población de origen. Esto es importante para poder resaltar el posible sesgo de muestreo. También puedes repetir esta operación para ver las distribuciones por sexo.Ten en cuenta que estos valores-p son sólo indicativos, y que una discusión descriptiva (o la visualización con las pirámides de edad que aparecen continuación) de las distribuciones en tu muestra de estudio en comparación con la población de origen es más importante que la prueba binomial en sí. Esto se debe que el aumento del tamaño de la muestra suele dar lugar diferencias que pueden ser irrelevantes después de ponderar los datos.","code":"\n## counts and props of the study population\nag <- survey_data %>% \n  group_by(age_group) %>% \n  drop_na(age_group) %>% \n  tally() %>% \n  mutate(proportion = n / sum(n), \n         n_total = sum(n))\n\n## counts and props of the source population\npropcount <- population %>% \n  group_by(age_group) %>%\n    tally(population) %>%\n    mutate(proportion = n / sum(n))\n\n## bind together the columns of two tables, group by age, and perform a \n## binomial test to see if n/total is significantly different from population\n## proportion.\n  ## suffix here adds to text to the end of columns in each of the two datasets\nleft_join(ag, propcount, by = \"age_group\", suffix = c(\"\", \"_pop\")) %>%\n  group_by(age_group) %>%\n  ## broom::tidy(binom.test()) makes a data frame out of the binomial test and\n  ## will add the variables p.value, parameter, conf.low, conf.high, method, and\n  ## alternative. We will only use p.value here. You can include other\n  ## columns if you want to report confidence intervals\n  mutate(binom = list(broom::tidy(binom.test(n, n_total, proportion_pop)))) %>%\n  unnest(cols = c(binom)) %>% # important for expanding the binom.test data frame\n  mutate(proportion_pop = proportion_pop * 100) %>%\n  ## Adjusting the p-values to correct for false positives \n  ## (because testing multiple age groups). This will only make \n  ## a difference if you have many age categories\n  mutate(p.value = p.adjust(p.value, method = \"holm\")) %>%\n                      \n  ## Only show p-values over 0.001 (those under report as <0.001)\n  mutate(p.value = ifelse(p.value < 0.001, \n                          \"<0.001\", \n                          as.character(round(p.value, 3)))) %>% \n  \n  ## rename the columns appropriately\n  select(\n    \"Age group\" = age_group,\n    \"Study population (n)\" = n,\n    \"Study population (%)\" = proportion,\n    \"Source population (n)\" = n_pop,\n    \"Source population (%)\" = proportion_pop,\n    \"P-value\" = p.value\n  )## # A tibble: 5 × 6\n## # Groups:   Age group [5]\n##   `Age group` `Study population (n)` `Study population (%)` `Source population (n)` Source pop…¹ P-val…²\n##   <chr>                        <int>                  <dbl>                   <dbl>        <dbl> <chr>  \n## 1 0-2                             12                 0.0256                    1360          6.8 <0.001 \n## 2 3-14                            42                 0.0896                    7244         36.2 <0.001 \n## 3 15-29                           64                 0.136                     5520         27.6 <0.001 \n## 4 30-44                           52                 0.111                     3232         16.2 0.002  \n## 5 45+                            299                 0.638                     2644         13.2 <0.001 \n## # … with abbreviated variable names ¹​`Source population (%)`, ²​`P-value`"},{"path":"survey-analysis.html","id":"pirámides-demográficas","chapter":"26 Análisis de encuestas","heading":"Pirámides demográficas","text":"Las pirámides demográficas (o de edad y sexo) son una forma sencilla de visualizar la distribución de la población de la encuesta. También vale la pena considerar la creación de tablas descriptivas de edad y sexo por estratos de la encuesta. Demostraremos el uso del paquete apyramid, ya que permite las proporciones ponderadas utilizando nuestro objeto de diseño de la encuesta creado anteriormente. Otras opciones para crear pirámides demográficas se tratan ampliamente en ese capítulo del manual. También utilizaremos una función envolvente de sitrep llamada age_pyramid() que ahorra algunas líneas de codificación para producir un gráfico con proporciones.Al igual que con el test binomial formal de la diferencia, vista anteriormente en la sección de sesgo de muestreo, aquí estamos interesados en visualizar si nuestra población muestreada es sustancialmente diferente de la población de origen y si la ponderación corrige esta diferencia. Para ello, utilizaremos el paquete patchwork para mostrar nuestras visualizaciones ggplot una al lado de la otra; para más detalles, consulta la sección sobre la combinación de gráficos en el capítulo de consejos de ggplot del manual. Visualizaremos nuestra población de origen, nuestra población de encuesta ponderada y nuestra población de encuesta ponderada. También puedes considerar la posibilidad de visualizar por cada estrato de tu encuesta - en nuestro ejemplo aquí sería utilizando el argumento stack_by = \"health_district\" (ver ?plot_age_pyramid para más detalles).NOTA: Los ejes-x e y están invertidos en las pirámides","code":"\n## define x-axis limits and labels ---------------------------------------------\n## (update these numbers to be the values for your graph)\nmax_prop <- 35      # choose the highest proportion you want to show \nstep <- 5           # choose the space you want beween labels \n\n## this part defines vector using the above numbers with axis breaks\nbreaks <- c(\n    seq(max_prop/100 * -1, 0 - step/100, step/100), \n    0, \n    seq(0 + step / 100, max_prop/100, step/100)\n    )\n\n## this part defines vector using the above numbers with axis limits\nlimits <- c(max_prop/100 * -1, max_prop/100)\n\n## this part defines vector using the above numbers with axis labels\nlabels <-  c(\n      seq(max_prop, step, -step), \n      0, \n      seq(step, max_prop, step)\n    )\n\n\n## create plots individually  --------------------------------------------------\n\n## plot the source population \n## nb: this needs to be collapsed for the overall population (i.e. removing health districts)\nsource_population <- population %>%\n  ## ensure that age and sex are factors\n  mutate(age_group = factor(age_group, \n                            levels = c(\"0-2\", \n                                       \"3-14\", \n                                       \"15-29\",\n                                       \"30-44\", \n                                       \"45+\")), \n         sex = factor(sex)) %>% \n  group_by(age_group, sex) %>% \n  ## add the counts for each health district together \n  summarise(population = sum(population)) %>% \n  ## remove the grouping so can calculate overall proportion\n  ungroup() %>% \n  mutate(proportion = population / sum(population)) %>% \n  ## plot pyramid \n  age_pyramid(\n            age_group = age_group, \n            split_by = sex, \n            count = proportion, \n            proportional = TRUE) +\n  ## only show the y axis label (otherwise repeated in all three plots)\n  labs(title = \"Source population\", \n       y = \"\", \n       x = \"Age group (years)\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n  \n  \n## plot the unweighted sample population \nsample_population <- age_pyramid(survey_data, \n                 age_group = \"age_group\", \n                 split_by = \"sex\",\n                 proportion = TRUE) + \n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Unweighted sample population\", \n       y = \"Proportion (%)\", \n       x = \"\") + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n\n## plot the weighted sample population \nweighted_population <- survey_design %>% \n  ## make sure the variables are factors\n  mutate(age_group = factor(age_group), \n         sex = factor(sex)) %>%\n  age_pyramid( \n    age_group = \"age_group\",\n    split_by = \"sex\", \n    proportion = TRUE) +\n  ## only show the x axis label (otherwise repeated in all three plots)\n  labs(title = \"Weighted sample population\", \n       y = \"\", \n       x = \"\")  + \n  ## make the x axis the same for all plots \n  scale_y_continuous(breaks = breaks, \n    limits = limits, \n    labels = labels)\n\n## combine all three plots  ----------------------------------------------------\n## combine three plots next to eachother using + \nsource_population + sample_population + weighted_population + \n  ## only show one legend and define theme \n  ## note the use of & for combining theme with plot_layout()\n  plot_layout(guides = \"collect\") & \n  theme(legend.position = \"bottom\",                    # move legend to bottom\n        legend.title = element_blank(),                # remove title\n        text = element_text(size = 18),                # change text size\n        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1) # turn x-axis text\n       )"},{"path":"survey-analysis.html","id":"diagrama-aluvialsankey","chapter":"26 Análisis de encuestas","heading":"Diagrama aluvial/sankey","text":"Visualizar los puntos de partida y los resultados de los individuos puede ser muy útil para obtener una visión general. Su aplicación es bastante obvia en el caso de las poblaciones móviles, pero hay muchas otras aplicaciones, como las cohortes o cualquier otra situación en la que haya transiciones de estados para los individuos. Estos diagramas tienen varios nombres diferentes, como diagramas aluviales, de sankey y paralelos; los detalles se encuentran en el capítulo del manual sobre diagramas y gráficos.","code":"\n## summarize data\nflow_table <- survey_data %>%\n  count(startcause, endcause, sex) %>%  # get counts \n  gather_set_data(x = c(\"startcause\", \"endcause\"))     # change format for plotting\n\n\n## plot your dataset \n  ## on the x axis is the start and end causes\n  ## gather_set_data generates an ID for each possible combination\n  ## splitting by y gives the possible start/end combos\n  ## value as n gives it as counts (could also be changed to proportion)\nggplot(flow_table, aes(x, id = id, split = y, value = n)) +\n  ## colour lines by sex \n  geom_parallel_sets(aes(fill = sex), alpha = 0.5, axis.width = 0.2) +\n  ## fill in the label boxes grey\n  geom_parallel_sets_axes(axis.width = 0.15, fill = \"grey80\", color = \"grey80\") +\n  ## change text colour and angle (needs to be adjusted)\n  geom_parallel_sets_labels(color = \"black\", angle = 0, size = 5) +\n  ## remove axis labels\n  theme_void()+\n  ## move legend to bottom\n  theme(legend.position = \"bottom\")              "},{"path":"survey-analysis.html","id":"weighted-proportions","chapter":"26 Análisis de encuestas","heading":"26.8 Proporciones ponderadas","text":"Esta sección detallará cómo producir tablas para recuentos y proporciones ponderadas, con los intervalos de confianza asociados y el efecto del diseño. Hay cuatro opciones diferentes que utilizan funciones de los siguientes paquetes: survey, srvyr, sitrep y gtsummary. Para una codificación mínima que produzca una tabla de estilo epidemiológico estándar, recomendaríamos la función sitrep - que es una envoltura para el código srvyr; Ten en cuenta, sin embargo, que esto está todavía en CRAN y puede cambiar en el futuro. Por lo demás, es probable que el código de survey sea el más estable largo plazo, mientras que srvyr se adaptará mejor los flujos de trabajo de tidyverse. Aunque las funciones de gtsummary tienen mucho potencial, parecen ser experimentales e incompletas en el momento de escribir este artículo.","code":""},{"path":"survey-analysis.html","id":"paquete-survey-1","chapter":"26 Análisis de encuestas","heading":"Paquete survey","text":"Podemos utilizar la función svyciprop() de survey para obtener las proporciones ponderadas y los correspondientes intervalos de confianza del 95%. Se puede extraer un efecto de diseño apropiado utilizando la función svymean() en lugar de svyprop(). Cabe señalar que svyprop() sólo parece aceptar variables entre 0 y 1 (o TRUE/FALSE), por lo que las variables categóricas funcionarán.NOTA: Las funciones de survey también aceptan objetos de diseño srvyr, pero aquí hemos utilizado el objeto de diseño de survey sólo por coherenciaPodemos combinar las funciones de survey mostradas arriba en una función que definimos nosotros mismos continuación, llamada svy_prop; y podemos entonces usar esa función junto con map() del paquete purrr para iterar sobre varias variables y crear una tabla. Consulta el capítulo de iteración del manual para obtener más detalles sobre purrr.","code":"\n## produce weighted counts \nsvytable(~died, base_survey_design)## died\n##      FALSE       TRUE \n## 1406244.43   76213.01\n## produce weighted proportions\nsvyciprop(~died, base_survey_design, na.rm = T)##               2.5% 97.5%\n## died 0.0514 0.0208  0.12\n## get the design effect \nsvymean(~died, base_survey_design, na.rm = T, deff = T) %>% \n  deff()## diedFALSE  diedTRUE \n##  3.755508  3.755508\n# Define function to calculate weighted counts, proportions, CI and design effect\n# x is the variable in quotation marks \n# design is your survey design object\n\nsvy_prop <- function(design, x) {\n  \n  ## put the variable of interest in a formula \n  form <- as.formula(paste0( \"~\" , x))\n  ## only keep the TRUE column of counts from svytable\n  weighted_counts <- svytable(form, design)[[2]]\n  ## calculate proportions (multiply by 100 to get percentages)\n  weighted_props <- svyciprop(form, design, na.rm = TRUE) * 100\n  ## extract the confidence intervals and multiply to get percentages\n  weighted_confint <- confint(weighted_props) * 100\n  ## use svymean to calculate design effect and only keep the TRUE column\n  design_eff <- deff(svymean(form, design, na.rm = TRUE, deff = TRUE))[[TRUE]]\n  \n  ## combine in to one data frame\n  full_table <- cbind(\n    \"Variable\"        = x,\n    \"Count\"           = weighted_counts,\n    \"Proportion\"      = weighted_props,\n    weighted_confint, \n    \"Design effect\"   = design_eff\n    )\n  \n  ## return table as a dataframe\n  full_table <- data.frame(full_table, \n             ## remove the variable names from rows (is a separate column now)\n             row.names = NULL)\n  \n  ## change numerics back to numeric\n  full_table[ , 2:6] <- as.numeric(full_table[, 2:6])\n  \n  ## return dataframe\n  full_table\n}\n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  svy_prop, design = base_survey_design) %>% \n  ## collapse list in to a single data frame\n  bind_rows() %>% \n  ## round \n  mutate(across(where(is.numeric), round, digits = 1))##   Variable    Count Proportion X2.5. X97.5. Design.effect\n## 1     left 701199.1       47.3  39.2   55.5           2.4\n## 2     died  76213.0        5.1   2.1   12.1           3.8\n## 3  arrived 761799.0       51.4  40.9   61.7           3.9"},{"path":"survey-analysis.html","id":"paquete-srvyr-1","chapter":"26 Análisis de encuestas","heading":"Paquete Srvyr","text":"Con srvyr podemos utilizar la sintaxis de dplyr para crear una tabla. Observa que se utiliza la función survey_mean() y se especifica el argumento de la proporción, y también que se utiliza la misma función para calcular el efecto del diseño. Esto se debe que srvyr envuelve las dos funciones del paquete survey, svyciprop() y svymean(), que se utilizan en la sección anterior.NOTA: Tampoco parece posible obtener proporciones partir de variables categóricas utilizando srvyr, si lo necesitas, consulta la sección siguiente utilizando sitrep Aquí también podríamos escribir una función para iterar sobre múltiples variables utilizando el paquete purrr. Consulta el capítulo de iteración del manual para obtener más detalles sobre purrr.","code":"\n## use the srvyr design object\nsurvey_design %>% \n  summarise(\n    ## produce the weighted counts \n    counts = survey_total(died), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(died, \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(died, deff = TRUE)) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(counts, props, props_low, props_upp, deff_deff)## # A tibble: 1 × 5\n##   counts props props_low props_upp deff_deff\n##    <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 76213.  5.14      2.08      12.1      3.76\n# Define function to calculate weighted counts, proportions, CI and design effect\n# design is your survey design object\n# x is the variable in quotation marks \n\n\nsrvyr_prop <- function(design, x) {\n  \n  summarise(\n    ## using the survey design object\n    design, \n    ## produce the weighted counts \n    counts = survey_total(.data[[x]]), \n    ## produce weighted proportions and confidence intervals \n    ## multiply by 100 to get a percentage \n    props = survey_mean(.data[[x]], \n                        proportion = TRUE, \n                        vartype = \"ci\") * 100, \n    ## produce the design effect \n    deff = survey_mean(.data[[x]], deff = TRUE)) %>% \n  ## add in the variable name\n  mutate(variable = x) %>% \n  ## only keep the rows of interest\n  ## (drop standard errors and repeat proportion calculation)\n  select(variable, counts, props, props_low, props_upp, deff_deff)\n  \n}\n  \n\n## iterate over several variables to create a table \npurrr::map(\n  ## define variables of interest\n  c(\"left\", \"died\", \"arrived\"), \n  ## state function using and arguments for that function (design)\n  ~srvyr_prop(.x, design = survey_design)) %>% \n  ## collapse list in to a single data frame\n  bind_rows()## # A tibble: 3 × 6\n##   variable  counts props props_low props_upp deff_deff\n##   <chr>      <dbl> <dbl>     <dbl>     <dbl>     <dbl>\n## 1 left     701199. 47.3      39.2       55.5      2.38\n## 2 died      76213.  5.14      2.08      12.1      3.76\n## 3 arrived  761799. 51.4      40.9       61.7      3.93"},{"path":"survey-analysis.html","id":"paquete-sitrep","chapter":"26 Análisis de encuestas","heading":"Paquete Sitrep","text":"La función tab_survey() de sitrep es una envoltura para srvyr, que permite crear tablas ponderadas con una codificación mínima. También permite calcular proporciones ponderadas para variables categóricas.","code":"\n## using the survey design object\nsurvey_design %>% \n  ## pass the names of variables of interest unquoted\n  tab_survey(arrived, left, died, education_level,\n             deff = TRUE,   # calculate the design effect\n             pretty = TRUE  # merge the proportion and 95%CI\n             )## Warning: removing 257 missing value(s) from `education_level`## # A tibble: 9 × 5\n##   variable        value            n  deff ci                \n##   <chr>           <chr>        <dbl> <dbl> <chr>             \n## 1 arrived         TRUE       761799.  3.93 51.4% (40.9--61.7)\n## 2 arrived         FALSE      720658.  3.93 48.6% (38.3--59.1)\n## 3 left            TRUE       701199.  2.38 47.3% (39.2--55.5)\n## 4 left            FALSE      781258.  2.38 52.7% (44.5--60.8)\n## 5 died            TRUE        76213.  3.76 5.1% (2.1--12.1)  \n## 6 died            FALSE     1406244.  3.76 94.9% (87.9--97.9)\n## 7 education_level higher     171644.  4.70 42.4% (26.9--59.7)\n## 8 education_level primary    102609.  2.37 25.4% (16.2--37.3)\n## 9 education_level secondary  130201.  6.68 32.2% (16.5--53.3)"},{"path":"survey-analysis.html","id":"paquete-gtsummary","chapter":"26 Análisis de encuestas","heading":"Paquete Gtsummary","text":"Con gtsummary parece haber todavía funciones incorporadas para añadir intervalos de confianza o efecto de diseño. Aquí mostramos cómo definir una función para añadir intervalos de confianza y luego añadir intervalos de confianza una tabla gtsummary creada con la función tbl_svysummary().","code":"\nconfidence_intervals <- function(data, variable, by, ...) {\n  \n  ## extract the confidence intervals and multiply to get percentages\n  props <- svyciprop(as.formula(paste0( \"~\" , variable)),\n              data, na.rm = TRUE)\n  \n  ## extract the confidence intervals \n  as.numeric(confint(props) * 100) %>% ## make numeric and multiply for percentage\n    round(., digits = 1) %>%           ## round to one digit\n    c(.) %>%                           ## extract the numbers from matrix\n    paste0(., collapse = \"-\")          ## combine to single character\n}\n\n## using the survey package design object\ntbl_svysummary(base_survey_design, \n               include = c(arrived, left, died),   ## define variables want to include\n               statistic = list(everything() ~ c(\"{n} ({p}%)\"))) %>% ## define stats of interest\n  add_n() %>%  ## add the weighted total \n  add_stat(fns = everything() ~ confidence_intervals) %>% ## add CIs\n  ## modify the column headers\n  modify_header(\n    list(\n      n ~ \"**Weighted total (N)**\",\n      stat_0 ~ \"**Weighted Count**\",\n      add_stat_1 ~ \"**95%CI**\"\n    )\n    )"},{"path":"survey-analysis.html","id":"weighted-ratios","chapter":"26 Análisis de encuestas","heading":"26.9 Razones ponderadas","text":"Del mismo modo, para los ratios ponderados (como los ratios de mortalidad) puedes utilizar el paquete survey o srvyr. También se pueden escribir funciones (similares las anteriores) para iterar sobre varias variables. También se podría crear una función para gtsummary como la anterior, pero actualmente tiene una funcionalidad incorporada.","code":""},{"path":"survey-analysis.html","id":"paquete-survey-2","chapter":"26 Análisis de encuestas","heading":"Paquete survey","text":"","code":"\nratio <- svyratio(~died, \n         denominator = ~obstime, \n         design = base_survey_design)\n\nci <- confint(ratio)\n\ncbind(\n  ratio$ratio * 10000, \n  ci * 10000\n)##       obstime    2.5 %   97.5 %\n## died 5.981922 1.194294 10.76955"},{"path":"survey-analysis.html","id":"paquete-srvyr-2","chapter":"26 Análisis de encuestas","heading":"Paquete Srvyr","text":"","code":"\nsurvey_design %>% \n  ## survey ratio used to account for observation time \n  summarise(\n    mortality = survey_ratio(\n      as.numeric(died) * 10000, \n      obstime, \n      vartype = \"ci\")\n    )## # A tibble: 1 × 3\n##   mortality mortality_low mortality_upp\n##       <dbl>         <dbl>         <dbl>\n## 1      5.98         0.349          11.6"},{"path":"survey-analysis.html","id":"resources-18","chapter":"26 Análisis de encuestas","heading":"26.10 Recursos","text":"Página de estadísticas de la UCLAAnalizar datos de encuestas gratissrvyr packgepaquete gtsummaryEstudios de caso de la encuesta EPIET","code":""},{"path":"survival-analysis.html","id":"survival-analysis","chapter":"27 Análisis de supervivencia","heading":"27 Análisis de supervivencia","text":"","code":""},{"path":"survival-analysis.html","id":"overview-5","chapter":"27 Análisis de supervivencia","heading":"27.1 Resumen","text":"El análisis de supervivencia se centra en la descripción, para un individuo o grupo de individuos determinado, de un acontecimiento puntual denominado evento (aparición de una enfermedad, curación de una enfermedad, muerte, recaída tras la respuesta al tratamiento…) que se produce tras un periodo de tiempo denominado tiempo del evento (o tiempo de seguimiento (tiempo de seguimiento en los estudios basados en cohortes/poblaciones) durante el cual se observa los individuos. Para determinar el tiempo de fracaso, es necesario definir un tiempo de origen (que puede ser la fecha de inclusión, la fecha de diagnóstico…).El objetivo de la inferencia para el análisis de supervivencia es entonces el tiempo entre un origen y un evento. En la investigación médica actual, se utiliza ampliamente en los estudios clínicos para evaluar el efecto de un tratamiento, por ejemplo, o en la epidemiología del cáncer para evaluar una gran variedad de medidas de supervivencia del cáncer.Suele expresarse mediante la probabilidad de supervivencia (survival probability), que es la probabilidad de que el suceso de interés haya ocurrido en una duración t.Censura: La censura se produce cuando al final del seguimiento, algunos de los individuos han tenido el evento de interés, y por lo tanto su verdadero tiempo hasta el evento es desconocido. Aquí nos centraremos principalmente en la censura derecha, pero para más detalles sobre la censura y el análisis de supervivencia en general, puedes consultar las referencias.","code":""},{"path":"survival-analysis.html","id":"preparation-18","chapter":"27 Análisis de supervivencia","heading":"27.2 Preparación","text":"","code":""},{"path":"survival-analysis.html","id":"cargar-paquetes-16","chapter":"27 Análisis de supervivencia","heading":"Cargar paquetes","text":"Para realizar análisis de supervivencia en R, uno de los paquetes más utilizados es el de survival. Primero lo instalamos y luego lo cargamos, así como los demás paquetes que se utilizarán en esta sección:En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.Esta página explora los análisis de supervivencia sobre el archivo linelist utilizado en la mayoría de las páginas anteriores y sobre el que aplicamos algunos cambios para tener unos datos de supervivencia adecuados.","code":""},{"path":"survival-analysis.html","id":"importar-los-datos","chapter":"27 Análisis de supervivencia","heading":"Importar los datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).","code":"\n# import linelist\nlinelist_case_data <- rio::import(\"linelist_cleaned.rds\")"},{"path":"survival-analysis.html","id":"gestión-y-transformación-de-datos","chapter":"27 Análisis de supervivencia","heading":"Gestión y transformación de datos","text":"En resumen, los datos de supervivencia pueden describirse con las tres características siguientes:la variable dependiente o respuesta es el tiempo de espera hasta la ocurrencia de un evento bien definido,observaciones censuradas, en el sentido de que para algunas unidades el evento de interés ha ocurrido en el momento en que se analizan los datos, yexisten predictores o variables explicativas cuyo efecto sobre el tiempo de espera queremos evaluar o controlar.Así, crearemos las diferentes variables necesarias para respetar esa estructura y ejecutaremos el análisis de supervivencia.Definiremos:un nuevo dataframe linelist_surv para este análisisnuestro evento de interés como “death” (por lo tanto, nuestra probabilidad de supervivencia será la probabilidad de estar vivo después de un cierto tiempo después del momento de origen),el tiempo de seguimiento (futime) como el tiempo transcurrido entre el momento del inicio y el momento del desenlace en días,pacientes censurados son aquellos que se recuperaron o para los que se conoce el resultado final, es decir, se observó el evento “muerte” (evento=0).PRECAUCIÓN: Dado que en un estudio de cohortes real, la información sobre el momento de origen y el final del seguimiento se conoce dado que los individuos son observados, eliminaremos las observaciones en las que se desconozca la fecha de inicio o la fecha de desenlace. También se eliminarán los casos en los que la fecha de inicio sea posterior la fecha de desenlace, ya que se consideran erróneos.CONSEJO: Dado que el filtrado mayor (>) o menor (<) de una fecha puede eliminar las filas con valores faltantes, la aplicación del filtro en las fechas incorrectas también eliminará las filas con fechas faltantes.continuación, utilizamos case_when() para crear una columna age_cat_small en la que sólo hay 3 categorías de edad.CONSEJO: Podemos verificar las nuevas columnas que hemos creado haciendo un resumen sobre futime y una tabulación cruzada entre event y outcome partir del cual se ha creado. Además de esta verificación, es un buen hábito comunicar la mediana del tiempo de seguimiento al interpretar los resultados del análisis de supervivencia.Ahora cruzamos la nueva var de age_cat_small y la antigua columna age_cat para asegurarnos de que las asignaciones son correctasAhora revisamos las 10 primeras observaciones de los datos de linelist_surv mirando las variables específicas (incluyendo las de nueva creación).También podemos cruzar las columnas age_cat_small y gender para tener más detalles sobre la distribución de esta nueva columna por género. Utilizamos tabyl() y las funciones de adorno de janitor como se describe en la página de tablas descriptivas.","code":"\n#create a new data called linelist_surv from the linelist_case_data\n\nlinelist_surv <-  linelist_case_data %>% \n     \n  dplyr::filter(\n       # remove observations with wrong or missing dates of onset or date of outcome\n       date_outcome > date_onset) %>% \n  \n  dplyr::mutate(\n       # create the event var which is 1 if the patient died and 0 if he was right censored\n       event = ifelse(is.na(outcome) | outcome == \"Recover\", 0, 1), \n    \n       # create the var on the follow-up time in days\n       futime = as.double(date_outcome - date_onset), \n    \n       # create a new age category variable with only 3 strata levels\n       age_cat_small = dplyr::case_when( \n            age_years < 5  ~ \"0-4\",\n            age_years >= 5 & age_years < 20 ~ \"5-19\",\n            age_years >= 20   ~ \"20+\"),\n       \n       # previous step created age_cat_small var as character.\n       # now convert it to factor and specify the levels.\n       # Note that the NA values remain NA's and are not put in a level \"unknown\" for example,\n       # since in the next analyses they have to be removed.\n       age_cat_small = fct_relevel(age_cat_small, \"0-4\", \"5-19\", \"20+\")\n       )\nsummary(linelist_surv$futime)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##    1.00    6.00   10.00   11.98   16.00   64.00\n# cross tabulate the new event var and the outcome var from which it was created\n# to make sure the code did what it was intended to\nlinelist_surv %>% \n  tabyl(outcome, event)##  outcome    0    1\n##    Death    0 1952\n##  Recover 1547    0\n##     <NA> 1040    0\nlinelist_surv %>% \n  tabyl(age_cat_small, age_cat)##  age_cat_small 0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+ NA_\n##            0-4 834   0     0     0     0     0     0   0   0\n##           5-19   0 852   717   575     0     0     0   0   0\n##            20+   0   0     0     0   862   554    69   5   0\n##           <NA>   0   0     0     0     0     0     0   0  71\nlinelist_surv %>% \n  select(case_id, age_cat_small, date_onset, date_outcome, outcome, event, futime) %>% \n  head(10)##    case_id age_cat_small date_onset date_outcome outcome event futime\n## 1   8689b7           0-4 2014-05-13   2014-05-18 Recover     0      5\n## 2   11f8ea           20+ 2014-05-16   2014-05-30 Recover     0     14\n## 3   893f25           0-4 2014-05-21   2014-05-29 Recover     0      8\n## 4   be99c8          5-19 2014-05-22   2014-05-24 Recover     0      2\n## 5   07e3e8          5-19 2014-05-27   2014-06-01 Recover     0      5\n## 6   369449           0-4 2014-06-02   2014-06-07   Death     1      5\n## 7   f393b4           20+ 2014-06-05   2014-06-18 Recover     0     13\n## 8   1389ca           20+ 2014-06-05   2014-06-09   Death     1      4\n## 9   2978ac          5-19 2014-06-06   2014-06-15   Death     1      9\n## 10  fc15ef          5-19 2014-06-16   2014-07-09 Recover     0     23\nlinelist_surv %>% \n  tabyl(gender, age_cat_small, show_na = F) %>% \n  adorn_totals(where = \"both\") %>% \n  adorn_percentages() %>% \n  adorn_pct_formatting() %>% \n  adorn_ns(position = \"front\")##  gender         0-4         5-19          20+         Total\n##       f 482 (22.4%) 1184 (54.9%)  490 (22.7%) 2156 (100.0%)\n##       m 325 (15.0%)  880 (40.6%)  960 (44.3%) 2165 (100.0%)\n##   Total 807 (18.7%) 2064 (47.8%) 1450 (33.6%) 4321 (100.0%)"},{"path":"survival-analysis.html","id":"basics-of-survival-analysis","chapter":"27 Análisis de supervivencia","heading":"27.3 Fundamentos del análisis de supervivencia","text":"","code":""},{"path":"survival-analysis.html","id":"construir-un-objeto-de-tipo-surv-type","chapter":"27 Análisis de supervivencia","heading":"Construir un objeto de tipo surv-type","text":"Primero utilizaremos Surv() de survival para construir un objeto de supervivencia partir de las columnas de tiempo de seguimiento y evento.El resultado de este paso es producir un objeto de tipo Surv que condensa la información de tiempo y si fue observado el evento de interés (muerte). Este objeto se utilizará en última instancia en el lado derecho de las fórmulas posteriores del modelo (véase la documentación).Puedes revisar las primeras 10 filas de los datos de linelist_surv, viendo sólo algunas columnas importantes.Y aquí están los primeros 10 elementos de survobj. Se imprime esencialmente como un vector de tiempo de seguimiento, con “+” la derecha para representar si una observación fue censurada. Mira cómo los números se alinean arriba y abajo.","code":"\n# Use Suv() syntax for right-censored data\nsurvobj <- Surv(time = linelist_surv$futime,\n                event = linelist_surv$event)\nlinelist_surv %>% \n  select(case_id, date_onset, date_outcome, futime, outcome, event) %>% \n  head(10)##    case_id date_onset date_outcome futime outcome event\n## 1   8689b7 2014-05-13   2014-05-18      5 Recover     0\n## 2   11f8ea 2014-05-16   2014-05-30     14 Recover     0\n## 3   893f25 2014-05-21   2014-05-29      8 Recover     0\n## 4   be99c8 2014-05-22   2014-05-24      2 Recover     0\n## 5   07e3e8 2014-05-27   2014-06-01      5 Recover     0\n## 6   369449 2014-06-02   2014-06-07      5   Death     1\n## 7   f393b4 2014-06-05   2014-06-18     13 Recover     0\n## 8   1389ca 2014-06-05   2014-06-09      4   Death     1\n## 9   2978ac 2014-06-06   2014-06-15      9   Death     1\n## 10  fc15ef 2014-06-16   2014-07-09     23 Recover     0\n#print the 50 first elements of the vector to see how it presents\nhead(survobj, 10)##  [1]  5+ 14+  8+  2+  5+  5  13+  4   9  23+"},{"path":"survival-analysis.html","id":"realización-de-los-primeros-análisis","chapter":"27 Análisis de supervivencia","heading":"Realización de los primeros análisis","text":"continuación, iniciamos nuestro análisis utilizando la función survfit() para producir un objeto survfit, que se ajusta los cálculos por defecto para las estimaciones de Kaplan Meier (KM) de la curva de supervivencia global (marginal), que son de hecho una función escalonada con saltos en los tiempos de los eventos observados. El objeto survfit final contiene una o más curvas de supervivencia y se crea utilizando el objeto Surv como variable de respuesta en la fórmula del modelo.NOTA: La estimación de Kaplan-Meier es una estimación paramétrica de máxima verosimilitud (MLE) de la función de supervivencia. (ver recursos para más información).El resumen de este objeto survfit dará lo que se llama una tabla de vida. Para cada paso de tiempo de seguimiento (time) en el que ocurrió un evento (en orden ascendente):el número de personas que estaban en riesgo de desarrollar el evento (personas que aún tenían el evento ni estaban censuradas: (n.risk)los que sí desarrollaron el evento (n.event)y de lo anterior: la probabilidad de desarrollar el evento (probabilidad de morir, o de sobrevivir más allá de ese tiempo específico)por último, se obtienen y muestran el error estándar y el intervalo de confianza de esa probabilidadAjustamos las estimaciones de KM mediante la fórmula en la que el objeto Surv “survobj” anterior es la variable de respuesta. “~ 1” precisa que ejecutamos el modelo para la supervivencia global.Al utilizar summary() podemos añadir la opción times y especificar ciertos tiempos en los que queremos ver la información de supervivenciaTambién podemos utilizar la función print(). El argumento print.rmean = TRUE se utiliza para obtener el tiempo medio de supervivencia y su error estándar (se).NOTA: El tiempo medio de supervivencia restringido (RMST) es una medida de supervivencia específica cada vez más utilizada en el análisis de supervivencia del cáncer y que suele definirse como el área bajo la curva de supervivencia, dado que observamos los pacientes hasta el tiempo restringido T (más detalles en la sección Recursos).CONSEJO: Podemos crear el objeto surv directamente en la función survfit() y ahorrarnos una línea de código. Esto se verá como: linelistsurv_quick <- survfit(Surv(futime, event) ~ 1, data=linelist_surv).","code":"\n# fit the KM estimates using a formula where the Surv object \"survobj\" is the response variable.\n# \"~ 1\" signifies that we run the model for the overall survival  \nlinelistsurv_fit <-  survival::survfit(survobj ~ 1)\n\n#print its summary for more details\nsummary(linelistsurv_fit)## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     1   4539      30    0.993 0.00120        0.991        0.996\n##     2   4500      69    0.978 0.00217        0.974        0.982\n##     3   4394     149    0.945 0.00340        0.938        0.952\n##     4   4176     194    0.901 0.00447        0.892        0.910\n##     5   3899     214    0.852 0.00535        0.841        0.862\n##     6   3592     210    0.802 0.00604        0.790        0.814\n##     7   3223     179    0.757 0.00656        0.745        0.770\n##     8   2899     167    0.714 0.00700        0.700        0.728\n##     9   2593     145    0.674 0.00735        0.660        0.688\n##    10   2311     109    0.642 0.00761        0.627        0.657\n##    11   2081     119    0.605 0.00788        0.590        0.621\n##    12   1843      89    0.576 0.00809        0.560        0.592\n##    13   1608      55    0.556 0.00823        0.540        0.573\n##    14   1448      43    0.540 0.00837        0.524        0.556\n##    15   1296      31    0.527 0.00848        0.511        0.544\n##    16   1152      48    0.505 0.00870        0.488        0.522\n##    17   1002      29    0.490 0.00886        0.473        0.508\n##    18    898      21    0.479 0.00900        0.462        0.497\n##    19    798       7    0.475 0.00906        0.457        0.493\n##    20    705       4    0.472 0.00911        0.454        0.490\n##    21    626      13    0.462 0.00932        0.444        0.481\n##    22    546       8    0.455 0.00948        0.437        0.474\n##    23    481       5    0.451 0.00962        0.432        0.470\n##    24    436       4    0.447 0.00975        0.428        0.466\n##    25    378       4    0.442 0.00993        0.423        0.462\n##    26    336       3    0.438 0.01010        0.419        0.458\n##    27    297       1    0.436 0.01017        0.417        0.457\n##    29    235       1    0.435 0.01030        0.415        0.455\n##    38     73       1    0.429 0.01175        0.406        0.452\n#print its summary at specific times\nsummary(linelistsurv_fit, times = c(5,10,20,30,60))## Call: survfit(formula = survobj ~ 1)\n## \n##  time n.risk n.event survival std.err lower 95% CI upper 95% CI\n##     5   3899     656    0.852 0.00535        0.841        0.862\n##    10   2311     810    0.642 0.00761        0.627        0.657\n##    20    705     446    0.472 0.00911        0.454        0.490\n##    30    210      39    0.435 0.01030        0.415        0.455\n##    60      2       1    0.429 0.01175        0.406        0.452\n# print linelistsurv_fit object with mean survival time and its se. \nprint(linelistsurv_fit, print.rmean = TRUE)## Call: survfit(formula = survobj ~ 1)\n## \n##         n events rmean* se(rmean) median 0.95LCL 0.95UCL\n## [1,] 4539   1952   33.1     0.539     17      16      18\n##     * restricted mean with upper limit =  64"},{"path":"survival-analysis.html","id":"riesgo-acumulado","chapter":"27 Análisis de supervivencia","heading":"Riesgo acumulado","text":"Además de la función summary(), también podemos utilizar la función str() que da más detalles sobre la estructura del objeto survfit(). Se trata de una lista de 16 elementos.Entre estos elementos hay uno importante: el cumhaz, que es un vector numérico. Se puede trazar para mostrar el riesgo acumulado, siendo el riesgo la tasa instantánea de ocurrencia del evento (ver referencias).","code":"\nstr(linelistsurv_fit)## List of 16\n##  $ n        : int 4539\n##  $ time     : num [1:59] 1 2 3 4 5 6 7 8 9 10 ...\n##  $ n.risk   : num [1:59] 4539 4500 4394 4176 3899 ...\n##  $ n.event  : num [1:59] 30 69 149 194 214 210 179 167 145 109 ...\n##  $ n.censor : num [1:59] 9 37 69 83 93 159 145 139 137 121 ...\n##  $ surv     : num [1:59] 0.993 0.978 0.945 0.901 0.852 ...\n##  $ std.err  : num [1:59] 0.00121 0.00222 0.00359 0.00496 0.00628 ...\n##  $ cumhaz   : num [1:59] 0.00661 0.02194 0.05585 0.10231 0.15719 ...\n##  $ std.chaz : num [1:59] 0.00121 0.00221 0.00355 0.00487 0.00615 ...\n##  $ type     : chr \"right\"\n##  $ logse    : logi TRUE\n##  $ conf.int : num 0.95\n##  $ conf.type: chr \"log\"\n##  $ lower    : num [1:59] 0.991 0.974 0.938 0.892 0.841 ...\n##  $ upper    : num [1:59] 0.996 0.982 0.952 0.91 0.862 ...\n##  $ call     : language survfit(formula = survobj ~ 1)\n##  - attr(*, \"class\")= chr \"survfit\""},{"path":"survival-analysis.html","id":"representar-curvas-de-kaplan-meir","chapter":"27 Análisis de supervivencia","heading":"Representar curvas de Kaplan-Meir","text":"Una vez ajustadas las estimaciones de KM, podemos visualizar la probabilidad de estar vivo lo largo de un tiempo determinado utilizando la función básica plot() que dibuja la “curva de Kaplan-Meier”. En otras palabras, la curva de abajo es una ilustración convencional de la experiencia de supervivencia en todo el grupo de pacientes.Podemos verificar rápidamente el tiempo de seguimiento mínimo y máximo en la curva.Una forma fácil de interpretarlo es decir que en el momento cero, todos los participantes están vivos y la probabilidad de supervivencia es entonces del 100%. Esta probabilidad disminuye con el tiempo medida que los pacientes mueren. La proporción de participantes que sobreviven más allá de los 60 días de seguimiento se sitúa en torno al 40%.El intervalo de confianza de las estimaciones de supervivencia de KM también se representa por defecto y puede descartarse añadiendo la opción conf.int = FALSE al comando plot().Dado que el evento de interés es “death”, dibujar una curva que describa los complementos de las proporciones de supervivencia llevará dibujar las proporciones de mortalidad acumulada. Esto puede hacerse con lines(), que añade información un gráfico existente.","code":"\nplot(linelistsurv_fit, \n     xlab = \"Days of follow-up\",    # x-axis label\n     ylab=\"Survival Probability\",   # y-axis label\n     main= \"Overall survival curve\" # figure title\n     )\n# original plot\nplot(\n  linelistsurv_fit,\n  xlab = \"Days of follow-up\",       \n  ylab = \"Survival Probability\",       \n  mark.time = TRUE,              # mark events on the curve: a \"+\" is printed at every event\n  conf.int = FALSE,              # do not plot the confidence interval\n  main = \"Overall survival curve and cumulative mortality\"\n  )\n\n# draw an additional curve to the previous plot\nlines(\n  linelistsurv_fit,\n  lty = 3,             # use different line type for clarity\n  fun = \"event\",       # draw the cumulative events instead of the survival \n  mark.time = FALSE,\n  conf.int = FALSE\n  )\n\n# add a legend to the plot\nlegend(\n  \"topright\",                               # position of legend\n  legend = c(\"Survival\", \"Cum. Mortality\"), # legend text \n  lty = c(1, 3),                            # line types to use in the legend\n  cex = .85,                                # parametes that defines size of legend text\n  bty = \"n\"                                 # no box type to be drawn for the legend\n  )"},{"path":"survival-analysis.html","id":"comparison-of-survival-curves","chapter":"27 Análisis de supervivencia","heading":"27.4 Comparación de las curvas de supervivencia","text":"Para comparar la supervivencia dentro de los diferentes grupos de nuestros participantes o pacientes observados, es posible que tengamos que observar primero sus respectivas curvas de supervivencia y luego realizar pruebas para evaluar la diferencia entre grupos independientes. Esta comparación puede referirse grupos basados en el género, la edad, el tratamiento, la comorbilidad…","code":""},{"path":"survival-analysis.html","id":"test-log-rank","chapter":"27 Análisis de supervivencia","heading":"Test Log rank","text":"El test Log rank (de rango logarítmico) es una prueba popular que compara toda la experiencia de supervivencia entre dos o más grupos independientes y puede considerarse como una prueba de si las curvas de supervivencia son idénticas (se superponen) o (hipótesis nula de diferencia de supervivencia entre los grupos). La función survdiff() del paquete survival permite ejecutar el test Log rank cuando especificamos rho = 0 (que es el valor predeterminado). Los resultados de la prueba dan un estadístico chi-cuadrado junto con un valor-p, ya que el estadístico log rank se distribuye aproximadamente como un test estadístico de chi-cuadrado.En primer lugar, tratamos de comparar las curvas de supervivencia por grupos de género. Para ello, primero intentamos visualizarlo (comprobar si las dos curvas de supervivencia se superponen). Se creará un nuevo objeto survfit con una fórmula ligeramente diferente. Luego se creará el objeto survdiff.Al suministrar ~ gender como lado derecho de la fórmula, ya trazamos la supervivencia global sino por género.Ahora podemos trazar las curvas de supervivencia por género. Observa el orden de los niveles de los estratos en la columna de género antes de definir los colores y la leyenda.Y ahora podemos calcular la prueba de la diferencia entre las curvas de supervivencia utilizando survdiff()Vemos que la curva de supervivencia de las mujeres y la de los hombres se superponen y la prueba de rango logarítmico da pruebas de una diferencia de supervivencia entre mujeres y hombres.Algunos otros paquetes de R permiten ilustrar curvas de supervivencia para diferentes grupos y probar la diferencia de una sola vez. Utilizando la función ggsurvplot() del paquete survminer, también podemos incluir en nuestra curva las tablas de riesgo impresas para cada grupo, así como el valor p del test log-rank.PRECAUCIÓN: las funciones de survminer requieren que especifiques el objeto de supervivencia y que vuelvas especificar los datos utilizados para ajustar el objeto de supervivencia. Recuerda hacer esto para evitar mensajes de error específicos. También podemos comprobar si hay diferencias en la supervivencia según la fuente de infección (fuente de contaminación).En este caso, la prueba de rango logarítmico da pruebas suficientes de una diferencia en las probabilidades de supervivencia alfa= 0,005. Las probabilidades de supervivencia de los pacientes que se infectaron en los funerales son mayores que las de los pacientes que se infectaron en otros lugares, lo que sugiere un beneficio para la supervivencia.","code":"\n# create the new survfit object based on gender\nlinelistsurv_fit_sex <-  survfit(Surv(futime, event) ~ gender, data = linelist_surv)\n# set colors\ncol_sex <- c(\"lightgreen\", \"darkgreen\")\n\n# create plot\nplot(\n  linelistsurv_fit_sex,\n  col = col_sex,\n  xlab = \"Days of follow-up\",\n  ylab = \"Survival Probability\")\n\n# add legend\nlegend(\n  \"topright\",\n  legend = c(\"Female\",\"Male\"),\n  col = col_sex,\n  lty = 1,\n  cex = .9,\n  bty = \"n\")\n#compute the test of the difference between the survival curves\nsurvival::survdiff(\n  Surv(futime, event) ~ gender, \n  data = linelist_surv\n  )## Call:\n## survival::survdiff(formula = Surv(futime, event) ~ gender, data = linelist_surv)\n## \n## n=4321, 218 observations deleted due to missingness.\n## \n##             N Observed Expected (O-E)^2/E (O-E)^2/V\n## gender=f 2156      924      909     0.255     0.524\n## gender=m 2165      929      944     0.245     0.524\n## \n##  Chisq= 0.5  on 1 degrees of freedom, p= 0.5\nsurvminer::ggsurvplot(\n    linelistsurv_fit_sex, \n    data = linelist_surv,          # again specify the data used to fit linelistsurv_fit_sex \n    conf.int = FALSE,              # do not show confidence interval of KM estimates\n    surv.scale = \"percent\",        # present probabilities in the y axis in %\n    break.time.by = 10,            # present the time axis with an increment of 10 days\n    xlab = \"Follow-up days\",\n    ylab = \"Survival Probability\",\n    pval = T,                      # print p-value of Log-rank test \n    pval.coord = c(40,.91),        # print p-value at these plot coordinates\n    risk.table = T,                # print the risk table at bottom \n    legend.title = \"Gender\",       # legend characteristics\n    legend.labs = c(\"Female\",\"Male\"),\n    font.legend = 10, \n    palette = \"Dark2\",             # specify color palette \n    surv.median.line = \"hv\",       # draw horizontal and vertical lines to the median survivals\n    ggtheme = theme_light()        # simplify plot background\n)\nlinelistsurv_fit_source <-  survfit(\n  Surv(futime, event) ~ source,\n  data = linelist_surv\n  )\n\n# plot\nggsurvplot( \n  linelistsurv_fit_source,\n  data = linelist_surv,\n  size = 1, linetype = \"strata\",   # line types\n  conf.int = T,\n  surv.scale = \"percent\",  \n  break.time.by = 10, \n  xlab = \"Follow-up days\",\n  ylab= \"Survival Probability\",\n  pval = T,\n  pval.coord = c(40,.91),\n  risk.table = T,\n  legend.title = \"Source of \\ninfection\",\n  legend.labs = c(\"Funeral\", \"Other\"),\n  font.legend = 10,\n  palette = c(\"#E7B800\",\"#3E606F\"),\n  surv.median.line = \"hv\", \n  ggtheme = theme_light()\n)"},{"path":"survival-analysis.html","id":"cox-regression-analysis","chapter":"27 Análisis de supervivencia","heading":"27.5 Análisis de regresión de Cox","text":"La regresión de riesgos proporcionales de Cox es una de las técnicas de regresión más populares para el análisis de supervivencia. También se pueden utilizar otros modelos, ya que el modelo de Cox requiere supuestos importantes que deben verificarse para un uso adecuado, como el supuesto de riesgos proporcionales: véanse las referencias.En un modelo de regresión de riesgos proporcionales de Cox, la medida del efecto es la tasa de riesgo (HR), que es el riesgo de fracaso (o el riesgo de muerte en nuestro ejemplo), dado que el participante ha sobrevivido hasta un momento específico. Normalmente, nos interesa comparar grupos independientes con respecto sus riesgos, y utilizamos una razón de riesgo, que es análoga una razón de probabilidades en el entorno del análisis de regresión logística múltiple. La función cox.ph() del paquete de supervivencia se utiliza para ajustar el modelo. La función cox.zph() del paquete survival puede utilizarse para probar la suposición de riesgos proporcionales para un ajuste del modelo de regresión de Cox.NOTA: Una probabilidad debe estar en el rango de 0 1. Sin embargo, el peligro representa el número esperado de eventos por una unidad de tiempo.Si la razón de riesgo (RR)de un predictor es cercana 1, entonces ese predictor afecta la supervivencia,Si la RR es inferior 1, entonces el predictor es protector (es decir, está asociado una mejor supervivencia),y si la RR es mayor que 1, entonces el predictor se asocia un mayor riesgo (o una menor supervivencia).","code":""},{"path":"survival-analysis.html","id":"ajuste-de-un-modelo-de-cox","chapter":"27 Análisis de supervivencia","heading":"Ajuste de un modelo de Cox","text":"Primero podemos ajustar un modelo para evaluar el efecto de la edad y el sexo en la supervivencia. Con sólo imprimir el modelo, tenemos la información sobre:los coeficientes de regresión estimados coef que cuantifican la asociación entre los predictores y el resultado,su exponencial (para su interpretación, exp(coef)) que produce la razón de riesgo,su error estándar se(coef),la puntuación z: cuántos errores estándar se aleja el coeficiente estimado de 0,y el valor- p: la probabilidad de que el coeficiente estimado sea 0.La función summary() aplicada al objeto del modelo de Cox ofrece más información, como el intervalo de confianza de la RR estimada y las diferentes puntuaciones de la prueba.El efecto de la primera covariable, gender, se presenta en la primera fila. Se imprime genderm (masculino), lo que implica que el primer nivel de estrato (“f”), es decir, el grupo femenino, es el grupo de referencia para el género. Por lo tanto, la interpretación del parámetro de la prueba es la de los hombres en comparación con las mujeres. El valor p indica que hay pruebas suficientes de un efecto del género sobre el peligro esperado o de una asociación entre el género y la mortalidad por todas las causas.La misma falta de pruebas se observa en relación con el grupo de edad.Fue interesante ejecutar el modelo y observar los resultados, pero un primer vistazo para verificar si se respetan los supuestos de riesgos proporcionales podría ayudar ahorrar tiempo.NOTA: Se puede especificar un segundo argumento llamado método cuando se calcula el modelo de Cox, que determina cómo se manejan los empates. El valor por defecto es “efron”, y las otras opciones son “breslow” y “exact”.En otro modelo añadimos más factores de riesgo, como el origen de la infección y el número de días entre la fecha de inicio y el ingreso. Esta vez, primero verificamos la hipótesis de riesgos proporcionales antes de seguir adelante.En este modelo, hemos incluido un predictor continuo (days_onset_hosp). En este caso, interpretamos las estimaciones de los parámetros como el aumento del logaritmo esperado del riesgo relativo por cada aumento de una unidad en el predictor, manteniendo los demás predictores constantes. Primero verificamos el supuesto de riesgos proporcionales.La verificación gráfica de esta suposición puede realizarse con la función ggcoxzph() del paquete survminer.Los resultados del modelo indican que existe una asociación negativa entre la duración del inicio del ingreso y la mortalidad por todas las causas. El riesgo esperado es 0,9 veces menor en una persona que ingresa un día más tarde que otra, manteniendo el género constante. O, en una explicación más directa, un aumento de una unidad en la duración del inicio al ingreso se asocia con una disminución del 10,7% (coef *100) en el riesgo de muerte.Los resultados muestran también una asociación positiva entre la fuente de infección y la mortalidad por todas las causas. Es decir, hay un mayor riesgo de muerte (1,21 veces) para los pacientes que tuvieron una fuente de infección distinta de los funerales.Podemos comprobar esta relación con una tabla:Habría que considerar e investigar por qué existe esta asociación en los datos. Una posible explicación podría ser que los pacientes que viven lo suficiente como para ser ingresados más tarde tenían una enfermedad menos grave para empezar. Otra explicación, quizá más probable, es que, dado que utilizamos unos datos falsos simulados, este patrón refleja la realidad.","code":"\n#fitting the cox model\nlinelistsurv_cox_sexage <-  survival::coxph(\n              Surv(futime, event) ~ gender + age_cat_small, \n              data = linelist_surv\n              )\n\n\n#printing the model fitted\nlinelistsurv_cox_sexage## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##                       coef exp(coef) se(coef)      z     p\n## genderm           -0.03149   0.96900  0.04767 -0.661 0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456 0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724 0.469\n## \n## Likelihood ratio test=2.8  on 3 df, p=0.4243\n## n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n#summary of the model\nsummary(linelistsurv_cox_sexage)## Call:\n## survival::coxph(formula = Surv(futime, event) ~ gender + age_cat_small, \n##     data = linelist_surv)\n## \n##   n= 4321, number of events= 1853 \n##    (218 observations deleted due to missingness)\n## \n##                       coef exp(coef) se(coef)      z Pr(>|z|)\n## genderm           -0.03149   0.96900  0.04767 -0.661    0.509\n## age_cat_small5-19  0.09400   1.09856  0.06454  1.456    0.145\n## age_cat_small20+   0.05032   1.05161  0.06953  0.724    0.469\n## \n##                   exp(coef) exp(-coef) lower .95 upper .95\n## genderm               0.969     1.0320    0.8826     1.064\n## age_cat_small5-19     1.099     0.9103    0.9680     1.247\n## age_cat_small20+      1.052     0.9509    0.9176     1.205\n## \n## Concordance= 0.514  (se = 0.007 )\n## Likelihood ratio test= 2.8  on 3 df,   p=0.4\n## Wald test            = 2.78  on 3 df,   p=0.4\n## Score (logrank) test = 2.78  on 3 df,   p=0.4\ntest_ph_sexage <- survival::cox.zph(linelistsurv_cox_sexage)\ntest_ph_sexage##               chisq df    p\n## gender        0.454  1 0.50\n## age_cat_small 0.838  2 0.66\n## GLOBAL        1.399  3 0.71\n#fit the model\nlinelistsurv_cox <-  coxph(\n                        Surv(futime, event) ~ gender + age_years+ source + days_onset_hosp,\n                        data = linelist_surv\n                        )\n\n\n#test the proportional hazard model\nlinelistsurv_ph_test <- cox.zph(linelistsurv_cox)\nlinelistsurv_ph_test##                    chisq df       p\n## gender           0.45062  1    0.50\n## age_years        0.00199  1    0.96\n## source           1.79622  1    0.18\n## days_onset_hosp 31.66167  1 1.8e-08\n## GLOBAL          34.08502  4 7.2e-07\nsurvminer::ggcoxzph(linelistsurv_ph_test)\n#print the summary of the model\nsummary(linelistsurv_cox)## Call:\n## coxph(formula = Surv(futime, event) ~ gender + age_years + source + \n##     days_onset_hosp, data = linelist_surv)\n## \n##   n= 2772, number of events= 1180 \n##    (1767 observations deleted due to missingness)\n## \n##                      coef exp(coef)  se(coef)      z Pr(>|z|)    \n## genderm          0.004710  1.004721  0.060827  0.077   0.9383    \n## age_years       -0.002249  0.997753  0.002421 -0.929   0.3528    \n## sourceother      0.178393  1.195295  0.084291  2.116   0.0343 *  \n## days_onset_hosp -0.104063  0.901169  0.014245 -7.305 2.77e-13 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n##                 exp(coef) exp(-coef) lower .95 upper .95\n## genderm            1.0047     0.9953    0.8918    1.1319\n## age_years          0.9978     1.0023    0.9930    1.0025\n## sourceother        1.1953     0.8366    1.0133    1.4100\n## days_onset_hosp    0.9012     1.1097    0.8764    0.9267\n## \n## Concordance= 0.566  (se = 0.009 )\n## Likelihood ratio test= 71.31  on 4 df,   p=1e-14\n## Wald test            = 59.22  on 4 df,   p=4e-12\n## Score (logrank) test = 59.54  on 4 df,   p=4e-12\nlinelist_case_data %>% \n  tabyl(days_onset_hosp, outcome) %>% \n  adorn_percentages() %>%  \n  adorn_pct_formatting()##  days_onset_hosp Death Recover   NA_\n##                0 44.3%   31.4% 24.3%\n##                1 46.6%   32.2% 21.2%\n##                2 43.0%   32.8% 24.2%\n##                3 45.0%   32.3% 22.7%\n##                4 41.5%   38.3% 20.2%\n##                5 40.0%   36.2% 23.8%\n##                6 32.2%   48.7% 19.1%\n##                7 31.8%   38.6% 29.5%\n##                8 29.8%   38.6% 31.6%\n##                9 30.3%   51.5% 18.2%\n##               10 16.7%   58.3% 25.0%\n##               11 36.4%   45.5% 18.2%\n##               12 18.8%   62.5% 18.8%\n##               13 10.0%   60.0% 30.0%\n##               14 10.0%   50.0% 40.0%\n##               15 28.6%   42.9% 28.6%\n##               16 20.0%   80.0%  0.0%\n##               17  0.0%  100.0%  0.0%\n##               18  0.0%  100.0%  0.0%\n##               22  0.0%  100.0%  0.0%\n##               NA 52.7%   31.2% 16.0%"},{"path":"survival-analysis.html","id":"forest-plots","chapter":"27 Análisis de supervivencia","heading":"Forest plots","text":"continuación, podemos visualizar los resultados del modelo cox utilizando los prácticos gráficos de bosque con la función ggforest() del paquete survminer.","code":"\nggforest(linelistsurv_cox, data = linelist_surv)"},{"path":"survival-analysis.html","id":"time-dependent-covariates-in-survival-models","chapter":"27 Análisis de supervivencia","heading":"27.6 Covariables tiempo-dependientes en modelos de supervivencia","text":"Algunas de las siguientes secciones han sido adaptadas con permiso de la excelente introducción al análisis de supervivencia en R por la Dra. Emily ZaborEn la última sección hemos tratado el uso de la regresión de Cox para examinar las asociaciones entre las covariables de interés y los resultados de supervivencia, pero estos análisis dependen de que la covariable se mida en la línea de base, es decir, antes de que comience el tiempo de seguimiento del evento.¿Qué ocurre si tienes interés en una covariable que se mide después del tiempo de seguimiento? O, ¿qué pasa si tienes una covariable que puede cambiar con el tiempo?Por ejemplo, tal vez estés trabajando con datos clínicos en los que se repiten medidas de valores de laboratorio del hospital que pueden cambiar con el tiempo. Este es un ejemplo de una covariable dependiente del tiempo. Para abordar esto se necesita una configuración especial, pero afortunadamente el modelo de Cox es muy flexible y este tipo de datos también puede ser modelado con herramientas del paquete survival.","code":""},{"path":"survival-analysis.html","id":"configuración-de-covariables-dependientes-del-tiempo","chapter":"27 Análisis de supervivencia","heading":"Configuración de covariables dependientes del tiempo","text":"El análisis de covariables dependientes del tiempo en R requiere la configuración de unos datos especial. Si tienes interés, mira el documento del autor del paquete survival Using Time Dependent Covariates Time Dependent Coefficients Cox Model.Para ello, utilizaremos un nuevo conjunto de datos del paquete SemiCompRisks denominado BMT, que incluye datos de 137 pacientes de trasplante de médula ósea. Las variables en las que nos centraremos son:T1 - tiempo (en días) hasta la muerte o el último seguimientodelta1 - indicador de muerte; 1-Muerto, 0-VivoTA - tiempo (en días) hasta la enfermedad aguda de injerto contra huéspeddeltaA - indicador de la enfermedad aguda de injerto contra huésped;\n1 - Desarrolló la enfermedad aguda de injerto contra huésped\n0 - Nunca desarrolló la enfermedad aguda de injerto contra huésped\n1 - Desarrolló la enfermedad aguda de injerto contra huésped0 - Nunca desarrolló la enfermedad aguda de injerto contra huéspedCargaremos este conjunto de datos del paquete survival utilizando el comando DE R base data(), que puede utilizarse para cargar datos que ya están incluidos en un paquete de R que se ha cargado. El dataframe BMT aparecerá en tu entorno de R.","code":"\ndata(BMT, package = \"SemiCompRisks\")"},{"path":"survival-analysis.html","id":"añadir-un-identificador-único-de-paciente","chapter":"27 Análisis de supervivencia","heading":"Añadir un identificador único de paciente","text":"hay una columna de identificación única en los datos de BMT, que es necesaria para crear el tipo de conjunto de datos que queremos. Así que utilizamos la función rowid_to_column() del paquete tibble de tidyverse para crear una nueva columna de identificación llamada my_id (añade una columna al principio del dataframe con identificadores de fila secuenciales, empezando por el 1). Llamamos al dataframe bmt.El conjunto de datos tiene ahora este aspecto:","code":"\nbmt <- rowid_to_column(BMT, \"my_id\")"},{"path":"survival-analysis.html","id":"ampliar-las-filas-de-pacientes","chapter":"27 Análisis de supervivencia","heading":"Ampliar las filas de pacientes","text":"continuación, utilizaremos la función tmerge() con las funciones de ayuda event() y tdc() para crear el conjunto de datos reestructurado. Nuestro objetivo es reestructurar el conjunto de datos para crear una fila separada para cada paciente por cada intervalo de tiempo en el que tengan un valor diferente de deltaA. En este caso, cada paciente puede tener como máximo dos filas dependiendo de si desarrollaron la enfermedad aguda de injerto contra huésped durante el periodo de recogida de datos. Llamaremos nuestro nuevo indicador para el desarrollo de la enfermedad aguda de injerto contra huésped agvhd.tmerge() crea unos datos largos con múltiples intervalos de tiempo para los diferentes valores de las covariables de cada pacienteevent() crea el nuevo indicador de eventos para que vaya con los intervalos de tiempo recién creadostdc() crea la columna de covarianza dependiente del tiempo, agvhd, para que vaya con los intervalos de tiempo recién creadosPara ver qué hace esto, veamos los datos de los 5 primeros pacientes individuales.Las variables de interés en los datos originales tenían este aspecto:El nuevo conjunto de datos para estos mismos pacientes tiene el siguiente aspecto:Ahora algunos de nuestros pacientes tienen dos filas en el conjunto de datos correspondientes intervalos en los que tienen un valor diferente de nuestra nueva variable, agvhd. Por ejemplo, el paciente 1 tiene ahora dos filas con un valor de agvhd de cero desde el tiempo 0 hasta el tiempo 67, y un valor de 1 desde el tiempo 67 hasta el tiempo 2081.","code":"\ntd_dat <- \n  tmerge(\n    data1 = bmt %>% select(my_id, T1, delta1), \n    data2 = bmt %>% select(my_id, T1, delta1, TA, deltaA), \n    id = my_id, \n    death = event(T1, delta1),\n    agvhd = tdc(TA)\n    )\nbmt %>% \n  select(my_id, T1, delta1, TA, deltaA) %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1   TA deltaA\n## 1     1 2081      0   67      1\n## 2     2 1602      0 1602      0\n## 3     3 1496      0 1496      0\n## 4     4 1462      0   70      1\n## 5     5 1433      0 1433      0\ntd_dat %>% \n  filter(my_id %in% seq(1, 5))##   my_id   T1 delta1 tstart tstop death agvhd\n## 1     1 2081      0      0    67     0     0\n## 2     1 2081      0     67  2081     0     1\n## 3     2 1602      0      0  1602     0     0\n## 4     3 1496      0      0  1496     0     0\n## 5     4 1462      0      0    70     0     0\n## 6     4 1462      0     70  1462     0     1\n## 7     5 1433      0      0  1433     0     0"},{"path":"survival-analysis.html","id":"regresión-de-cox-con-covariables-dependientes-del-tiempo","chapter":"27 Análisis de supervivencia","heading":"Regresión de Cox con covariables dependientes del tiempo","text":"Ahora que hemos remodelado nuestros datos y añadido la nueva variable aghvd dependiente del tiempo, vamos ajustar un modelo de regresión cox simple de una sola variable. Podemos utilizar la misma función coxph() que antes, sólo tenemos que cambiar nuestra función Surv() para especificar tanto el tiempo de inicio como el de finalización de cada intervalo utilizando los argumentos time1 = y time2 =.De nuevo, visualizaremos los resultados de nuestro modelo de Cox utilizando la función ggforest() del paquete urvminer.:Como se puede ver en el gráfico de forest, el intervalo de confianza y el valor-p, parece haber una fuerte asociación entre la muerte y la enfermedad aguda de injerto contra huésped en el contexto de nuestro modelo simple.","code":"\nbmt_td_model = coxph(\n  Surv(time = tstart, time2 = tstop, event = death) ~ agvhd, \n  data = td_dat\n  )\n\nsummary(bmt_td_model)## Call:\n## coxph(formula = Surv(time = tstart, time2 = tstop, event = death) ~ \n##     agvhd, data = td_dat)\n## \n##   n= 163, number of events= 80 \n## \n##         coef exp(coef) se(coef)    z Pr(>|z|)\n## agvhd 0.3351    1.3980   0.2815 1.19    0.234\n## \n##       exp(coef) exp(-coef) lower .95 upper .95\n## agvhd     1.398     0.7153    0.8052     2.427\n## \n## Concordance= 0.535  (se = 0.024 )\n## Likelihood ratio test= 1.33  on 1 df,   p=0.2\n## Wald test            = 1.42  on 1 df,   p=0.2\n## Score (logrank) test = 1.43  on 1 df,   p=0.2\nggforest(bmt_td_model, data = td_dat)"},{"path":"survival-analysis.html","id":"resources-20","chapter":"27 Análisis de supervivencia","heading":"27.7 Recursos","text":"Análisis de supervivencia Parte : Conceptos básicos y primeros análisisAnálisis de supervivencia en RAnálisis de supervivencia en la investigación de enfermedades infecciosas: Descripción de eventos en el tiempoCapítulo sobre modelos de supervivencia avanzados PrincetonUso de covariables y coeficientes dependientes del tiempo en el modelo de CoxHoja de trucos de análisis de supervivencia con RHoja de trucos de SurvminerDocumento sobre diferentes medidas de supervivencia para datos de registros de cáncer con Rcode proporcionado como material suplementario","code":""},{"path":"gis-basics.html","id":"gis-basics","chapter":"28 Conceptos básicos de los SIG","heading":"28 Conceptos básicos de los SIG","text":"","code":""},{"path":"gis-basics.html","id":"overview-6","chapter":"28 Conceptos básicos de los SIG","heading":"28.1 Resumen","text":"Los aspectos espaciales de tus datos pueden proporcionar mucha información sobre la situación del brote, y responder preguntas como:¿Dónde están los focos actuales de la enfermedad?¿Cómo han cambiado los puntos conflictivos con el tiempo?¿Cómo es el acceso las instalaciones sanitarias? ¿Se necesitan mejoras?El enfoque actual de esta página de los SIG (Sistemas de información geográfico; GIS, por sus siglas en inglés) es abordar las necesidades de la epidemiología aplicada en su respuesta los brotes. Exploraremos los métodos básicos de visualización de datos espaciales utilizando los paquetes tmap y ggplot2. También recorreremos algunos de los métodos básicos de gestión y consulta de datos espaciales con el paquete sf. Por último, abordaremos brevemente conceptos de estadística espacial como las relaciones espaciales, la autocorrelación espacial y la regresión espacial utilizando el paquete spdep.","code":""},{"path":"gis-basics.html","id":"key-terms-1","chapter":"28 Conceptos básicos de los SIG","heading":"28.2 Términos clave","text":"continuación presentamos algunos términos clave. Para una introducción completa los SIG y al análisis espacial, te sugerimos que revises uno de los tutoriales o cursos más largos que aparecen en la sección de Recursos.Sistemas de Información Geográfica (SIG) - Un SIG es un marco o entorno de trabajo para recopilar, gestionar, analizar y visualizar datos espaciales.","code":""},{"path":"gis-basics.html","id":"software-sig","chapter":"28 Conceptos básicos de los SIG","heading":"Software SIG","text":"Algunos de los programas de SIG más conocidos permiten la interacción “señalar y clicar” para el desarrollo de mapas y el análisis espacial. Estas herramientas tienen ventajas como tener que aprender código y la facilidad de seleccionar y colocar manualmente los iconos y características en un mapa. aquí dos de los más populares:ArcGIS - Un software comercial de SIG desarrollado por la empresa ESRI, que es muy popular pero bastante caro.QGIS - Un software de SIG gratuito de código abierto que puede hacer casi todo lo que ArcGIS puede hacer. Puedes descargar QGIS aquíEl uso de R como SIG puede parecer más intimidante al principio porque, en lugar de “señalar y clicar”, tiene una “interfaz de línea de comandos” (hay que codificar para adquirir el resultado deseado). Sin embargo, esto es una gran ventaja si se necesita producir mapas repetidamente o crear un análisis que sea reproducible.","code":""},{"path":"gis-basics.html","id":"datos-espaciales","chapter":"28 Conceptos básicos de los SIG","heading":"Datos espaciales","text":"Las dos formas principales de datos espaciales utilizadas en los SIG son los datos vectoriales y los ráster:Datos vectoriales - Es el formato más común de datos espaciales utilizado en los SIG. Los datos vectoriales se componen de características geométricas de vértices y trayectorias. Los datos espaciales vectoriales pueden dividirse su vez en tres tipos ampliamente utilizados:Puntos - Un punto consiste en un par de coordenadas (x,y) que representan una ubicación específica en un sistema de coordenadas. Los puntos son la forma más básica de datos espaciales, y pueden utilizarse para denotar un caso (por ejemplo, el domicilio de un paciente) o una ubicación (por ejemplo, un hospital) en un mapa.Puntos - Un punto consiste en un par de coordenadas (x,y) que representan una ubicación específica en un sistema de coordenadas. Los puntos son la forma más básica de datos espaciales, y pueden utilizarse para denotar un caso (por ejemplo, el domicilio de un paciente) o una ubicación (por ejemplo, un hospital) en un mapa.Líneas - Una línea está compuesta por dos puntos conectados. Las líneas tienen una longitud y pueden utilizarse para indicar cosas como carreteras o ríos.Líneas - Una línea está compuesta por dos puntos conectados. Las líneas tienen una longitud y pueden utilizarse para indicar cosas como carreteras o ríos.Polígonos - Un polígono está compuesto por al menos tres líneas conectadas por puntos. Los polígonos tiene una longitud (es decir, el perímetro del área) así como una medida de área. Los polígonos pueden utilizarse para señalar una zona (por ejemplo, un pueblo) o una estructura (por ejemplo, la superficie real de un hospital).Polígonos - Un polígono está compuesto por al menos tres líneas conectadas por puntos. Los polígonos tiene una longitud (es decir, el perímetro del área) así como una medida de área. Los polígonos pueden utilizarse para señalar una zona (por ejemplo, un pueblo) o una estructura (por ejemplo, la superficie real de un hospital).Datos ráster - Es un formato alternativo para los datos espaciales. Los datos ráster son una matriz de celdas (por ejemplo, píxeles) en la que cada celda contiene información como la altura, la temperatura, la pendiente, la cubierta forestal, etc. Suelen ser fotografías aéreas, imágenes de satélite, etc. Las imágenes ráster también pueden utilizarse como “mapas base” debajo de los datos vectoriales.","code":""},{"path":"gis-basics.html","id":"visualización-de-datos-espaciales","chapter":"28 Conceptos básicos de los SIG","heading":"Visualización de datos espaciales","text":"Para representar visualmente los datos espaciales en un mapa, el software SIG requiere que se proporcione suficiente información sobre dónde deben estar las diferentes características y la relación de unas con otras. Si se utilizan datos vectoriales, como ocurre en la mayoría de los casos, esta información suele almacenarse en un archivo shapefile:Shapefiles - Un shapefile es un formato de datos común para almacenar datos espaciales “vectoriales” consistentes en líneas, puntos o polígonos. Un shapefile es en realidad un grupo de al menos tres archivos - .shp, .shx y .dbf. Estos archivos deben estar en un determinado directorio (una misma carpeta) para que el shapefile se pueda leer. Estos archivos asociados pueden comprimirse en un archivo ZIP para enviarlos por correo electrónico o descargarlos de un sitio web.El shapefile contendrá información sobre las características con las que estemos tratando, así como su ubicación en la superficie de la Tierra. Esto es importante porque, aunque la Tierra es un globo terráqueo, los mapas suelen ser bidimensionales; las decisiones sobre cómo “aplanar” los datos espaciales pueden tener un gran impacto en el aspecto y la interpretación del mapa resultante.Sistemas de referencia de coordenadas (CRS-SRC) - Un SRC es un sistema basado en coordenadas que se utiliza para localizar accidentes geográficos en la superficie de la Tierra. Tiene unos cuantos componentes clave:Sistema de coordenadas - Hay muchos sistemas de coordenadas diferentes, así que asegúrate de saber en qué sistema están tus coordenadas. Los grados de latitud/longitud son muy comunes, pero también puede que tu información esté guardada como coordenadas UTM.Sistema de coordenadas - Hay muchos sistemas de coordenadas diferentes, así que asegúrate de saber en qué sistema están tus coordenadas. Los grados de latitud/longitud son muy comunes, pero también puede que tu información esté guardada como coordenadas UTM.Units - Asegúrate de saber cuáles son las unidades del sistema de coordenadas (por ejemplo, grados decimales, metros).Units - Asegúrate de saber cuáles son las unidades del sistema de coordenadas (por ejemplo, grados decimales, metros).Datum - Es una versión particular modelada de la Tierra. Los datum ya estan establecidos y han sido revisados lo largo de los años, así que asegúrate de que las capas de tu mapa utilizan el mismo datum.Datum - Es una versión particular modelada de la Tierra. Los datum ya estan establecidos y han sido revisados lo largo de los años, así que asegúrate de que las capas de tu mapa utilizan el mismo datum.Proyección - Es la referencia la ecuación matemática que se utilizó para proyectar la tierra (realmente redonda) sobre una superficie plana (mapa).Proyección - Es la referencia la ecuación matemática que se utilizó para proyectar la tierra (realmente redonda) sobre una superficie plana (mapa).Recuerda que puedes resumir los datos espaciales sin utilizar las herramientas cartográficas que se muestran continuación. veces basta con una simple tabla por zonas geográficas (por ejemplo, distrito, país, etc.).","code":""},{"path":"gis-basics.html","id":"getting-started-with-gis","chapter":"28 Conceptos básicos de los SIG","heading":"28.3 Introducción a los SIG","text":"Hay un par de elementos clave que deberás tener y en los que deberás pensar para hacer un mapa. Entre ellos están:Datos: pueden estar con un formato de datos espaciales (como los shapefiles, como se ha indicado anteriormente) o pueden estar en un formato espacial (por ejemplo, sólo como un csv).Datos: pueden estar con un formato de datos espaciales (como los shapefiles, como se ha indicado anteriormente) o pueden estar en un formato espacial (por ejemplo, sólo como un csv).Si tus datos están en formato espacial, también necesitarás unos datos de referencia. Los datos de referencia consisten en la representación espacial de los datos y sus atributos relacionados, que incluirían el material que contiene la información de ubicación y dirección de características específicas.Si tus datos están en formato espacial, también necesitarás unos datos de referencia. Los datos de referencia consisten en la representación espacial de los datos y sus atributos relacionados, que incluirían el material que contiene la información de ubicación y dirección de características específicas.Si estás trabajando con límites geográficos predefinidos (por ejemplo, regiones administrativas), probablemente puedas encontrar shapefiles de referencia que te puedes descargar de forma gratuita desde una agencia gubernamental u organización de intercambio de datos. En caso de duda, un buen punto de partida es buscar en Google “[regions] shapefile”Si estás trabajando con límites geográficos predefinidos (por ejemplo, regiones administrativas), probablemente puedas encontrar shapefiles de referencia que te puedes descargar de forma gratuita desde una agencia gubernamental u organización de intercambio de datos. En caso de duda, un buen punto de partida es buscar en Google “[regions] shapefile”Si tus datos están guardados como direcciones, en vez de como latitud/longitud, puede que tengas que utilizar un motor de geocodificación que te permita hacer la “traducción” de una dirección específica datos en formato espacial.Si tus datos están guardados como direcciones, en vez de como latitud/longitud, puede que tengas que utilizar un motor de geocodificación que te permita hacer la “traducción” de una dirección específica datos en formato espacial.Piensa cómo quieres presentar la información de los datos tu audiencia. Hay muchos tipos diferentes de mapas, y es importante pensar qué tipo de mapa se ajusta mejor tus necesidades.Piensa cómo quieres presentar la información de los datos tu audiencia. Hay muchos tipos diferentes de mapas, y es importante pensar qué tipo de mapa se ajusta mejor tus necesidades.","code":""},{"path":"gis-basics.html","id":"tipos-de-mapas-para-visualizar-tus-datos","chapter":"28 Conceptos básicos de los SIG","heading":"Tipos de mapas para visualizar tus datos","text":"Mapa de coropletas: Es un tipo de mapa temático en el que se utiliza colores, sombreados o patrones para representar regiones geográficas en relación con el valor de un atributo. Por ejemplo, un valor mayor podría indicarse con un color más oscuro que un valor menor. Este tipo de mapa es particularmente útil cuando se visualiza una variable y cómo cambia través de regiones o áreas geopolíticas definidas.Mapa de densidad de calor de casos: Es un tipo de mapa temático en el que se utiliza colores para representar la intensidad de un valor, pero que utiliza regiones definidas ni límites geopolíticos para agrupar los datos. Este tipo de mapa se suele utilizar para mostrar “puntos conflictivos” o zonas con una alta densidad o concentración de puntos.Mapa de densidad de puntos: Es un tipo de mapa temático que utiliza puntos para representar los valores de los datos. Este tipo de mapa es el más adecuado para visualizar cómo están dispersos los datos en el mapa y buscar clústers visualmente.Mapa de símbolos proporcionales (mapa de símbolos graduados): es un mapa temático similar un mapa de coropletas, pero en lugar de utilizar el color para indicar el valor de un atributo, utiliza un símbolo (normalmente un círculo) cuyo tamaño esta en relación con el valor. Por ejemplo, un valor mayor podría indicarse con un símbolo de tamaño mayor que un valor menor. Este tipo de mapa se utiliza mejor cuando se quiere visualizar el tamaño o la cantidad de los datos en distintas regiones geográficas.También puedes combinar varios tipos de visualizaciones diferentes para mostrar patrones geográficos complejos. Por ejemplo, los casos (puntos) del siguiente mapa están coloreados según su centro sanitario más cercano (véase la leyenda). Los círculos grandes de color negro muestran las zonas de captación de los centros sanitarios de un determinado radio, y los puntos/círculos rojos brillantes son los que tienen ninguna zona de captación de centros sanitarios dentro de ese radio determinado:Nota: El enfoque principal de esta página del SIG se centra en el contexto de respuesta brotes en el terreno. Por lo tanto, el contenido de esta página cubrirá la manipulación, visualización y análisis básicos de datos espaciales.","code":""},{"path":"gis-basics.html","id":"preparation-19","chapter":"28 Conceptos básicos de los SIG","heading":"28.4 Preparación","text":"","code":""},{"path":"gis-basics.html","id":"cargar-paquetes-17","chapter":"28 Conceptos básicos de los SIG","heading":"Cargar paquetes","text":"Este trozo de código muestra cómo puedes cargar de los paquetes necesarios para el análisis espacial que vamos realizar. En este manual destacamos la función p_load() del paquete pacman: esta instala el paquete (si aún está instalado) y lo carga para su uso. También puedes cargar los paquetes uno por uno con la funcion library() de R base., si ya los tienes instalados. Consulta la página sobre los Fundamentos de R para obtener más información sobre los paquetes de R.En este enlace de CRAN “Spatial Task View” puedes ver un resumen de todos los paquetes de R que pueden trabajar con datos espaciales.","code":"\npacman::p_load(\n  rio,           # to import data\n  here,          # to locate files\n  tidyverse,     # to clean, handle, and plot the data (includes ggplot2 package)\n  sf,            # to manage spatial data using a Simple Feature format\n  tmap,          # to produce simple maps, works for both interactive and static maps\n  janitor,       # to clean column names\n  OpenStreetMap, # to add OSM basemap in ggplot map\n  spdep          # spatial statistics\n  ) "},{"path":"gis-basics.html","id":"ejemplos-con-una-base-de-datos","chapter":"28 Conceptos básicos de los SIG","heading":"Ejemplos con una base de datos","text":"muestra de ejemplo, trabajaremos con una muestra aleatoria de 1000 casos del brote de ébola simulado en el dataframe linelist (computacionalmente, una base de datos pequeña hace que sea más fácil trabajar con este ejemplo). Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds).Los resultados que tengas al correr el código de este ejercicio puede que sean un poco diferentes de los que se aquí mostramos. Esto es porque vamos estar trabajando con una muestra aleatoria de los casos.Importa los datos con la función import() del paquete rio (este paquete puede manejar muchos tipos de archivos, como .xlsx, .csv, .rds - véase la página de importación y exportación para más detalles).Para seleccionar la muestra aleatoria de 1000 filas utiliza sample() de R base.Ahora queremos convertir este linelist, que es de tipo “dataframe”, en un objeto de tipo “sf” (spatial features, por sus siglas en inglés). Dado que linelist tiene dos columnas “lon” y “lat” que representan la longitud y latitud de la residencia de cada caso, esto será fácil.Utilizamos la función st_as_sf() del paquete sf (spatial features) para crear el nuevo objeto que llamamos linelist_sf. Este nuevo objeto tiene el mismo aspecto que la linelist, pero las columnas lon y lat han sido designadas como columnas de coordenadas, y se ha asignado un sistema de referencia de coordenadas (CRS) para poder visualizar los puntos. Este CRS es el númermo 4326 que corresponde coordenadas especificas basadas en el Sistema Geodésico Mundial 1984 (WGS84) - que es el estándar para las coordenadas GPS.Este es el aspecto del dataframe original linelist. En esta demostración, sólo utilizaremos la columna date_onset y geometry (que se construyó partir de los campos de longitud y latitud anteriores y es la última columna del dataframe).","code":"\n# import clean case linelist\nlinelist <- import(\"linelist_cleaned.rds\")  \n# generate 1000 random row numbers, from the number of rows in linelist\nsample_rows <- sample(nrow(linelist), 1000)\n\n# subset linelist to keep only the sample rows, and all columns\nlinelist <- linelist[sample_rows,]\n# Create sf object\nlinelist_sf <- linelist %>%\n     sf::st_as_sf(coords = c(\"lon\", \"lat\"), crs = 4326)\nDT::datatable(head(linelist_sf, 10), rownames = FALSE, options = list(pageLength = 5, scrollX=T), class = 'white-space: nowrap' )"},{"path":"gis-basics.html","id":"archivos-shapefiles-de-límites-administrativos","chapter":"28 Conceptos básicos de los SIG","heading":"Archivos shapefiles de límites administrativos","text":"Sierra Leona: Archivos shapefiles de los límites administrativosPrimero, descárgate todos los límites administrativos de Sierra Leona del sitio web de Humanitarian Data Exchange (HDX). Como alternativa, también te puedes descargar estos archivos y todos los demás datos de ejemplo que usamos para este manual través de nuestro paquete R, como se explica en la página descargando el manual y los datos.Ahora vamos hacer lo siguiente para guardar el shapefile del nivel administrativo 3 en R:Importar el shapefileLimpiar los nombres de las columnasFiltrar las filas para mantener sólo las áreas de interésPara importar un shapefile utilizamos la función read_sf() del paquete sf, y usamos la función () para que R encuentre el archivo. En nuestro caso, el archivo se encuentra dentro de nuestro proyecto R en las subcarpetas “data”, “gis” y “shp”, con nombre de archivo “sle_adm3.shp” (para más información ver las páginas sobre Importación y exportación y Proyectos en R). En tu caso, tendrás que indicar la localización específica donde tienes tus archivos en tu ordenador.continuación utilizamos clean_names() del paquete janitor para estandarizar los nombres de las columnas del shapefile. También utilizamos filter() para mantener sólo las filas con admin2name de “Western Area Urban” o “Western Area Rural”.continuación puedes ver el aspecto del shapefile después de la importación y limpieza. Desplázate la derecha para ver cómo hay columnas con el nivel de administración 0 (país), el nivel de administración 1, el nivel de administración 2 y, finalmente, el nivel de administración 3. Cada nivel tiene un nombre y un identificador único “pcode”. El pcode se expande con cada nivel de administración creciente, por ejemplo, SL (Sierra Leona) -> SL04 (Occidental) -> SL0410 (Zona Occidental Rural) -> SL040101 (Koya Rural).","code":"\n# ADM3 level clean\nsle_adm3 <- sle_adm3_raw %>%\n  janitor::clean_names() %>% # standardize column names \n  filter(admin2name %in% c(\"Western Area Urban\", \"Western Area Rural\")) # filter to keep certain areas"},{"path":"gis-basics.html","id":"datos-de-población","chapter":"28 Conceptos básicos de los SIG","heading":"Datos de población","text":"Sierra Leona: Población por ADM3Al igual que hemos hecho antes, te puedes descargar estos datos\nde HDX) o través de nuestro paquete R epirhandbook como se explica en esta página. Utilizamos import() para cargar el archivo .csv. Al igual que antes, pasamos el archivo importado clean_names() para estandarizar la sintaxis de los nombres de las columnas.Este es el aspecto del archivo de población. Desplázate la derecha para ver cómo cada jurisdicción tiene columnas con la población male, female, y la población total y el desglose de la población en columnas por grupos de edad.","code":"\n# Population by ADM3\nsle_adm3_pop <- import(here(\"data\", \"gis\", \"population\", \"sle_admpop_adm3_2020.csv\")) %>%\n  clean_names() "},{"path":"gis-basics.html","id":"instalaciones-sanitarias","chapter":"28 Conceptos básicos de los SIG","heading":"Instalaciones sanitarias","text":"Sierra Leone: Health facility data OpenStreetMapUna vez más, hemos descargado la localización de los centros sanitarios desde el HDX aquí o mediante las instrucciones de la página descarga de manuales y datos.Importamos el shapefile de puntos de las instalaciones con read_sf(), limpiamos de nuevo los nombres de las columnas y filtramos para mantener sólo los puntos etiquetados como “hospital”, “clinic” o “doctors”.Aquí está el dataframe resultante – desplázate la derecha para ver el nombre de la instalación y las coordenadas geométricas (geometry).","code":"\n# OSM health facility shapefile\nsle_hf <- sf::read_sf(here(\"data\", \"gis\", \"shp\", \"sle_hf.shp\")) %>% \n  clean_names() %>% \n  filter(amenity %in% c(\"hospital\", \"clinic\", \"doctors\"))"},{"path":"gis-basics.html","id":"plotting-coordinates","chapter":"28 Conceptos básicos de los SIG","heading":"28.5 Trazado de coordenadas","text":"La forma más sencilla de representar las coordenadas X-Y (longitud/latitud, puntos) de los casos es dibujarlas como puntos directamente desde el objeto linelist_sf que ya creamos en la sección de preparación.El paquete tmap nos permite visualizar este tipo de informacion tanto de modo estático (modo “plot”) como de modo interactivo (modo “view”) con sólo unas pocas líneas de código. La sintaxis de tmap es similar la de ggplot2, de forma que los comandos se añaden unos otros con +. Lee más detalles en esta viñeta.Lo primero es establecer qué modo tmap queremos. En este caso utilizaremos el modo “plot”, que produce salidas estáticas.Abajo puedes ver que, por ahora, sólo estamos trazando los puntos. Utilizamos el tm_shape() con el objeto linelist_sf. continuación, añadimos la informacion de los puntos mediante tm_dots(), especificando el tamaño y el color deseados. Recuerda que el linelist_sf es un objeto sf, con lo que ya tenemos designadas las dos columnas que contienen las coordenadas lat/long y el sistema de referencia de coordenadas (CRS):Por sí solos, los puntos nos dicen mucho. Así que también tenemos que dibujar los límites administrativos:Para esto, vamos usar tm_shape() (documentación), pero en vez de proporcionar el shapefile de los puntos de los casos, proporcionamos el shapefile de los límites administrativos (polígonos).Con el argumento bbox =(bbox significa “bounding box”) podemos especificar los límites de las coordenadas, lo cual nos ayuda hacer zoom una zona específica de interés. Primero mostramos la visualización del mapa sin bbox, y luego con él.Con esto ya podemos trazar los puntos y los polígonos juntos:Para leer una buena comparación de las opciones de mapeo en R, consulta esta entrada del blog.","code":"\ntmap_mode(\"plot\") # choose either \"view\" or \"plot\"\n# Just the cases (points)\ntm_shape(linelist_sf) + tm_dots(size=0.08, col='blue')\n# Just the administrative boundaries (polygons)\ntm_shape(sle_adm3) +               # admin boundaries shapefile\n  tm_polygons(col = \"#F7F7F7\")+    # show polygons in light grey\n  tm_borders(col = \"#000000\",      # show borders with color and line weight\n             lwd = 2) +\n  tm_text(\"admin3name\")            # column text to display for each polygon\n\n\n# Same as above, but with zoom from bounding box\ntm_shape(sle_adm3,\n         bbox = c(-13.3, 8.43,    # corner\n                  -13.2, 8.5)) +  # corner\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")\n# All together\ntm_shape(sle_adm3, bbox = c(-13.3, 8.43, -13.2, 8.5)) +     #\n  tm_polygons(col = \"#F7F7F7\") +\n  tm_borders(col = \"#000000\", lwd = 2) +\n  tm_text(\"admin3name\")+\ntm_shape(linelist_sf) +\n  tm_dots(size=0.08, col='blue', alpha = 0.5) +\n  tm_layout(title = \"Distribution of Ebola cases\")   # give title to map"},{"path":"gis-basics.html","id":"spatial-joins","chapter":"28 Conceptos básicos de los SIG","heading":"28.6 Uniones espaciales","text":"Es posible que estés familiarizado/con la unión de datos entre bases de datos. En la página unión de datos de este manual se trata varios métodos para unir bases de datos. Una unión espacial tiene un propósito similar, pero aprovecha las relaciones espaciales entre bases de datos. En lugar de confiar en los valores comunes de las columnas para hacer coincidir correctamente las observaciones, puede utilizar distintos tipos de relaciones espaciales, como por ejemplo que una característica esté contenida dentro de otra, que sea el “vecino más cercano” de otra característica, o que esté dentro de un buffer de determinado radio de otra.El paquete sf ofrece varios métodos para las uniones espaciales. Puedes explorar la documentación del método st_join() y otros tipos de uniones espaciales en esta referencia.","code":""},{"path":"gis-basics.html","id":"puntos-en-el-polígono","chapter":"28 Conceptos básicos de los SIG","heading":"Puntos en el polígono","text":"Asignación espacial de unidades administrativas los casosAquí se plantea un dilema interesante: la lista de casos contiene ninguna información sobre las unidades administrativas de los mismos. Aunque lo ideal es recoger dicha información durante la fase inicial de recogida de datos, también podemos asignar unidades administrativas los casos individuales basándonos en sus relaciones espaciales (es decir, el punto se cruza con un polígono).continuación, haremos una intersección espacial de las ubicaciones de nuestros casos (puntos) con los límites de la ADM3 (polígonos):Comenzamos con la linelist (casos/puntos)Continuamos con la unión espacial los límites administrativos, estableciendo el tipo de unión en “st_intersects”Utilizamos select() para mantener sólo algunas de las nuevas columnas de los límites administrativos (este paso lo realizamos un poco más abajo)¡Todas las columnas de sle_adms se han añadido linelist! Cada caso tiene ahora columnas que detallan los niveles administrativos los que pertenece. En este ejemplo, sólo queremos mantener dos de las nuevas columnas (las de nivel administrativo 3), así que haremos select() de los nombres de las columnas antiguas de la linelist, y sólo las dos adicionales de interés:Aquí os mostramos los diez primeros casos para que veais que se ha añadido la información correspondiente de sus jurisdicciones nivel de administración 3 (ADM3), basándose en la región del polígono donde se cruza el punto.Ahora podemos describir nuestros casos por unidad administrativa, algo que podíamos hacer antes de la unión espacial.También podemos crear un gráfico de barras con el número de casos por unidad administrativa.En este ejemplo, utilizamos ggplot() con linelist_adm para poder aplicar funciones que manejan factores, como fct_infreq() que ordena las barras por frecuencia (véase la página sobre Factores para ver algunos consejos).","code":"\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects)\nlinelist_adm <- linelist_sf %>%\n  \n  # join the administrative boundary file to the linelist, based on spatial intersection\n  sf::st_join(sle_adm3, join = st_intersects) %>% \n  \n  # Keep the old column names and two new admin ones of interest\n  select(names(linelist_sf), admin3name, admin3pcod)\n# Now you will see the ADM3 names attached to each case\nlinelist_adm %>% select(case_id, admin3name, admin3pcod)## Simple feature collection with 1000 features and 3 fields\n## Geometry type: POINT\n## Dimension:     XY\n## Bounding box:  xmin: -13.27276 ymin: 8.448383 xmax: -13.20545 ymax: 8.490648\n## Geodetic CRS:  WGS 84\n## First 10 features:\n##      case_id     admin3name admin3pcod                   geometry\n## 3894  ffae72        West II   SL040207 POINT (-13.23586 8.469718)\n## 793   dacbc6        East II   SL040204 POINT (-13.21413 8.481517)\n## 3536  22ba3a        West II   SL040207 POINT (-13.23397 8.467928)\n## 304   e8a7e7 Mountain Rural   SL040102 POINT (-13.21455 8.471473)\n## 1394  88eff2 Mountain Rural   SL040102 POINT (-13.21956 8.462108)\n## 4196  f4651a Mountain Rural   SL040102 POINT (-13.21066 8.459345)\n## 2511  41f5c5       West III   SL040208 POINT (-13.25315 8.459406)\n## 47    38cc4a       West III   SL040208 POINT (-13.25737 8.453257)\n## 3637  b97c05        West II   SL040207 POINT (-13.24598 8.464553)\n## 122   f0251f        West II   SL040207 POINT (-13.24911 8.469541)\n# Make new dataframe containing counts of cases by administrative unit\ncase_adm3 <- linelist_adm %>%          # begin with linelist with new admin cols\n  as_tibble() %>%                      # convert to tibble for better display\n  group_by(admin3pcod, admin3name) %>% # group by admin unit, both by name and pcode \n  summarise(cases = n()) %>%           # summarize and count rows\n  arrange(desc(cases))                     # arrange in descending order\n\ncase_adm3## # A tibble: 10 × 3\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases\n##    <chr>      <chr>          <int>\n##  1 SL040102   Mountain Rural   267\n##  2 SL040208   West III         212\n##  3 SL040207   West II          180\n##  4 SL040204   East II          114\n##  5 SL040203   East I            68\n##  6 SL040201   Central I         62\n##  7 SL040206   West I            43\n##  8 SL040202   Central II        32\n##  9 SL040205   East III          17\n## 10 <NA>       <NA>               5\nggplot(\n    data = linelist_adm,                       # begin with linelist containing admin unit info\n    mapping = aes(\n      x = fct_rev(fct_infreq(admin3name))))+ # x-axis is admin units, ordered by frequency (reversed)\n  geom_bar()+                                # create bars, height is number of rows\n  coord_flip()+                              # flip X and Y axes for easier reading of adm units\n  theme_classic()+                           # simplify background\n  labs(                                      # titles and labels\n    x = \"Admin level 3\",\n    y = \"Number of cases\",\n    title = \"Number of cases, by adminstative unit\",\n    caption = \"As determined by a spatial join, from 1000 randomly sampled cases from linelist\"\n  )"},{"path":"gis-basics.html","id":"vecino-más-cercano","chapter":"28 Conceptos básicos de los SIG","heading":"Vecino más cercano","text":"Encontrar el centro sanitario más cercanoPodría ser útil saber dónde se encuentran los centros sanitarios (clínicas/hospitales) en relación con los focos de la enfermedad.Podemos utilizar el método de unión st_nearest_feature de la función st_join() (paquete sf) para visualizar el centro sanitario más cercano cada uno de los casos.Comenzamos con el shapefile linelist linelist_sfUnimos espacialmente con sle_hf, que es la ubicación de los centros sanitarios y las clínicas (puntos), estableciendo el tipo de unión en “st_nearest_feature”Podemos ver continuación (primeras 50 filas) que cada caso tiene ahora datos sobre la clínica/hospital más cercanoPodemos ver que “Den Clinic” es el centro sanitario más cercano para aproximadamente el 30% de los casos.Para visualizar los resultados, podemos utilizar tmap - esta vez en modo interactivo para facilitar la visualización","code":"\n# Closest health facility to each case\nlinelist_sf_hf <- linelist_sf %>%                  # begin with linelist shapefile  \n  st_join(sle_hf, join = st_nearest_feature) %>%   # data from nearest clinic joined to case data \n  select(case_id, osm_id, name, amenity) %>%       # keep columns of interest, including id, name, type, and geometry of healthcare facility\n  rename(\"nearest_clinic\" = \"name\")                # re-name for clarity\n# Count cases by health facility\nhf_catchment <- linelist_sf_hf %>%   # begin with linelist including nearest clinic data\n  as.data.frame() %>%                # convert from shapefile to dataframe\n  count(nearest_clinic,              # count rows by \"name\" (of clinic)\n        name = \"case_n\") %>%         # assign new counts column as \"case_n\"\n  arrange(desc(case_n))              # arrange in descending order\n\nhf_catchment                         # print to console##                          nearest_clinic case_n\n## 1                            Den Clinic    366\n## 2       Shriners Hospitals for Children    313\n## 3         GINER HALL COMMUNITY HOSPITAL    183\n## 4 Princess Christian Maternity Hospital     50\n## 5                             panasonic     46\n## 6                     ARAB EGYPT CLINIC     15\n## 7                                  <NA>     14\n## 8                  MABELL HEALTH CENTER     13\ntmap_mode(\"view\")   # set tmap mode to interactive  \n\n# plot the cases and clinic points \ntm_shape(linelist_sf_hf) +            # plot cases\n  tm_dots(size=0.08,                  # cases colored by nearest clinic\n          col='nearest_clinic') +    \ntm_shape(sle_hf) +                    # plot clinic facilities in large black dots\n  tm_dots(size=0.3, col='black', alpha = 0.4) +      \n  tm_text(\"name\") +                   # overlay with name of facility\ntm_view(set.view = c(-13.2284, 8.4699, 13), # adjust zoom (center coords, zoom)\n        set.zoom.limits = c(13,14))+\ntm_layout(title = \"Cases, colored by nearest clinic\")"},{"path":"gis-basics.html","id":"buffers","chapter":"28 Conceptos básicos de los SIG","heading":"Buffers","text":"También podemos explorar cuántos casos se encuentran menos de 2,5 km (~30 minutos) de distancia pie del centro sanitario más cercano. Esto se conoce como buffer o zona o ámbito de influencia.Nota: Para un cálculo más preciso de la distancia, es mejor reproyectar el objeto sf al respectivo sistema de proyección cartográfica local, como UTM (Tierra proyectada sobre una superficie plana). En este ejemplo, para simplificar, nos ceñiremos al sistema de coordenadas geográficas del Sistema Geodésico Mundial (WGS84) (la Tierra representada en una superficie esférica/redonda, por lo que las unidades están en grados decimales). Utilizaremos una conversión general de: 1 grado decimal = ~111km.Puedes ver más información sobre proyecciones cartográficas y sistemas de coordenadas en este artículo de esri. Este blog habla de los diferentes tipos de proyecciones cartográficas y de cómo se puede elegir una proyección adecuada en función del área de interés y del contexto de su mapa/análisis.En primer lugar, se crea un buffer circular con un radio de ~2,5km alrededor de cada centro sanitario. Esto se hace con la función st_buffer() de tmap. Como la unidad del mapa está en grados decimales lat/long, tenemos que proporcionar el valor de dist en grados decimales, es decir, tenemos que proporcionar un valor de “0,02” (2,5/111 = 0.02 grados decimales, correspondiente ~2,5km). Si el sistema de coordenadas del mapa está en metros, el número debe proporcionarse en metros.continuación, trazamos las zonas de influencia propiamente dichas, con ese buffer:En segundo lugar, intersectamos estos buffers con los casos (puntos) utilizando st_join() y el tipo de unión st_intersects. Es decir, ponemos juntos los datos de los buffers y los de los puntos con los que se cruzan.Ahora podemos contabilizar cuántos de nuestros casos estan dentro de ningun buffer (sus puntos se cruzan con ningún buffer): nrow(linelist_sf_hf_2k[.na(linelist_sf_hf_2k$osm_id.y),]). Con este código vemos que falta información para este valor (estamos buscando NA), y por tanto, inferimos que estos casos viven más de 30 minutos pie del centro sanitario más cercano.Podemos visualizar los resultados de forma que los casos que se cruzan con ningún buffer aparezcan en rojo.","code":"\nsle_hf_2k <- sle_hf %>%\n  st_buffer(dist=0.02)       # decimal degrees translating to approximately 2.5km \ntmap_mode(\"plot\")\n# Create circular buffers\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2)+\ntm_shape(sle_hf) +                    # plot clinic facilities in large red dots\n  tm_dots(size=0.3, col='black')      \n# Intersect the cases with the buffers\nlinelist_sf_hf_2k <- linelist_sf_hf %>%\n  st_join(sle_hf_2k, join = st_intersects, left = TRUE) %>%\n  filter(osm_id.x==osm_id.y | is.na(osm_id.y)) %>%\n  select(case_id, osm_id.x, nearest_clinic, amenity.x, osm_id.y)\n# Cases which did not get intersected with any of the health facility buffers\nlinelist_sf_hf_2k %>% \n  filter(is.na(osm_id.y)) %>%\n  nrow()## [1] 1000\ntmap_mode(\"view\")\n\n# First display the cases in points\ntm_shape(linelist_sf_hf) +\n  tm_dots(size=0.08, col='nearest_clinic') +\n\n# plot clinic facilities in large black dots\ntm_shape(sle_hf) +                    \n  tm_dots(size=0.3, col='black')+   \n\n# Then overlay the health facility buffers in polylines\ntm_shape(sle_hf_2k) +\n  tm_borders(col = \"black\", lwd = 2) +\n\n# Highlight cases that are not part of any health facility buffers\n# in red dots  \ntm_shape(linelist_sf_hf_2k %>%  filter(is.na(osm_id.y))) +\n  tm_dots(size=0.1, col='red') +\ntm_view(set.view = c(-13.2284,8.4699, 13), set.zoom.limits = c(13,14))+\n\n# add title  \ntm_layout(title = \"Cases by clinic catchment area\")"},{"path":"gis-basics.html","id":"otras-uniones-espaciales","chapter":"28 Conceptos básicos de los SIG","heading":"Otras uniones espaciales","text":"Los siguientes son valores alternativos para el argunmento join (puedes encontrar más información en documentation)st_contains_properlyst_containsst_covered_byst_coversst_crossesst_disjointst_equals_exactst_equalsst_is_within_distancest_nearest_featurest_overlapsst_touchesst_within","code":""},{"path":"gis-basics.html","id":"choropleth-maps","chapter":"28 Conceptos básicos de los SIG","heading":"28.7 Mapas de coropletas","text":"Los mapas de coropletas pueden ser útiles para visualizar los datos por áreas predefinidas, como por ejemplo unidades administrativas o áreas de salud. Cuando se responde un brote esto puede ser muy útil para dirigir los recursos zonas específicas con altas tasas de incidencia, por ejemplo.Ahora que tenemos los nombres de las unidades administrativas asignados todos los casos (véase la sección sobre uniones espaciales, más arriba), podemos empezar mapear el número de casos por zonas (mapa de coropletas).Como también tenemos datos de población por ADM3, podemos añadir esta información la tabla case_adm3 creada anteriormente.Comenzamos con el dataframe creado en el paso anterior case_adm3, que es una tabla resumen de cada unidad administrativa y su número de casos.Los datos de la población sle_adm3_pop se unen utilizando un left_join() de dplyr utilizando la columna admin3pcod del dataframe case_adm3, y la columna adm_pcode en el dataframe sle_adm3_pop, que tienen la misma información. Véase la página sobre la unión de datos.select() se aplica al nuevo dataframe, para mantener sólo las columnas que nos interesan - total es la población total.Los casos por cada 10.000 habitantes se calculan como una nueva columna con mutate().Para poder mapear estos datos, tenemos que unir esta tabla con el shapefile de polígonos ADM3:Para mapear los resultados en un mapa estático:También podemos mapear las tasas de incidencia:","code":"\n# Add population data and calculate cases per 10K population\ncase_adm3 <- case_adm3 %>% \n     left_join(sle_adm3_pop,                             # add columns from pop dataset\n               by = c(\"admin3pcod\" = \"adm3_pcode\")) %>%  # join based on common values across these two columns\n     select(names(case_adm3), total) %>%                 # keep only important columns, including total population\n     mutate(case_10kpop = round(cases/total * 10000, 3)) # make new column with case rate per 10000, rounded to 3 decimals\n\ncase_adm3                                                # print to console for viewing## # A tibble: 10 × 5\n## # Groups:   admin3pcod [10]\n##    admin3pcod admin3name     cases  total case_10kpop\n##    <chr>      <chr>          <int>  <int>       <dbl>\n##  1 SL040102   Mountain Rural   267  33993       78.5 \n##  2 SL040208   West III         212 210252       10.1 \n##  3 SL040207   West II          180 145109       12.4 \n##  4 SL040204   East II          114  99821       11.4 \n##  5 SL040203   East I            68  68284        9.96\n##  6 SL040201   Central I         62  69683        8.90\n##  7 SL040206   West I            43  60186        7.14\n##  8 SL040202   Central II        32  23874       13.4 \n##  9 SL040205   East III          17 500134        0.34\n## 10 <NA>       <NA>               5     NA       NA\ncase_adm3_sf <- case_adm3 %>%                 # begin with cases & rate by admin unit\n  left_join(sle_adm3, by=\"admin3pcod\") %>%    # join to shapefile data by common column\n  select(objectid, admin3pcod,                # keep only certain columns of interest\n         admin3name = admin3name.x,           # clean name of one column\n         admin2name, admin1name,\n         cases, total, case_10kpop,\n         geometry) %>%                        # keep geometry so polygons can be plotted\n  drop_na(objectid)%>%                        # drop any empty rows\n  st_as_sf()                                  # convert to shapefile\n# tmap mode\ntmap_mode(\"plot\")               # view static map\n\n# plot polygons\ntm_shape(case_adm3_sf) + \n        tm_polygons(\"cases\") +  # color by number of cases column\n        tm_text(\"admin3name\")   # name display\n# Cases per 10K population\ntmap_mode(\"plot\")             # static viewing mode\n\n# plot\ntm_shape(case_adm3_sf) +                # plot polygons\n  tm_polygons(\"case_10kpop\",            # color by column containing case rate\n              breaks=c(0, 10, 50, 100), # define break points for colors\n              palette = \"Purples\"       # use a purple color palette\n              ) +\n  tm_text(\"admin3name\")                 # display text"},{"path":"gis-basics.html","id":"mapping-with-ggplot2","chapter":"28 Conceptos básicos de los SIG","heading":"28.8 Mapeo con ggplot2","text":"Si ya conoces el uso de ggplot2, puedes utilizar ese paquete para crear mapas estáticos de tus datos. La función geom_sf() dibujará diferentes objetos en función de las características de los datos. Por ejemplo, puedes utilizar geom_sf() en un ggplot() utilizando datos sf con geometría de polígonos para crear un mapa de coropletas.Para ilustrar cómo funciona esto, podemos empezar con el archivo shape de polígonos ADM3 que hemos utilizado antes. Recordemos que se trata de regiones de nivel administrativo 3 en Sierra Leona:Podemos utilizar la función left_join() de dplyr para añadir al objeto shapefile los datos que queremos mapear. En este caso, vamos utilizar el dataframe case_adm3 que creamos anteriormente para resumir los recuentos de casos por región administrativa. También podemos utilizar este mismo enfoque para mapear cualquier dato almacenado en un dataframe.Para hacer un gráfico de columnas de los recuentos de casos por región utilizando ggplot2, podemos llamar geom_col() de la siguiente manera:Si queremos utilizar ggplot2 para hacer un mapa de coropletas de los recuentos de casos, podemos utilizar una sintaxis similar para llamar la función geom_sf():continuación, podemos personalizar la apariencia de nuestro mapa utilizando una sintaxis que sea consistente en ggplot2, por ejemplo:Para las personas que se sientan cómodas trabajando con ggplot2, geom_sf() ofrece una implementación simple y directa que es adecuada para las visualizaciones básicas de mapas. Para saber más, mira la viñeta de geom_sf() o el libro de ggplot2.","code":"\nsle_adm3## Simple feature collection with 12 features and 19 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.094272 xmax: -12.91333 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 12 × 20\n##    objec…¹ admin…² admin…³ admin…⁴ admin…⁵ admin…⁶ admin…⁷ admin…⁸ admin…⁹ admin…˟ date       valid_on  \n##  *   <dbl> <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <chr>   <date>     <date>    \n##  1     155 Koya R… SL0401… Koya R… Wester… SL0401  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  2     156 Mounta… SL0401… Mounta… Wester… SL0401  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  3     157 Waterl… SL0401… Waterl… Wester… SL0401  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  4     158 York R… SL0401… York R… Wester… SL0401  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  5     159 Centra… SL0402… Centra… Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  6     160 East I  SL0402… East I  Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  7     161 East II SL0402… East II Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  8     162 Centra… SL0402… Centra… Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n##  9     163 West I… SL0402… West I… Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n## 10     164 West I  SL0402… West I  Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n## 11     165 West II SL0402… West II Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n## 12     167 East I… SL0402… East I… Wester… SL0402  Western SL04    Sierra… SL      2016-08-01 2016-10-17\n## # … with 8 more variables: valid_to <date>, shape_leng <dbl>, shape_area <dbl>, rowcacode0 <chr>,\n## #   rowcacode1 <chr>, rowcacode2 <chr>, rowcacode3 <chr>, geometry <MULTIPOLYGON [°]>, and abbreviated\n## #   variable names ¹​objectid, ²​admin3name, ³​admin3pcod, ⁴​admin3ref_n, ⁵​admin2name, ⁶​admin2pcod,\n## #   ⁷​admin1name, ⁸​admin1pcod, ⁹​admin0name, ˟​admin0pcod\nsle_adm3_dat <- sle_adm3 %>% \n  inner_join(case_adm3, by = \"admin3pcod\") # inner join = retain only if in both data objects\n\nselect(sle_adm3_dat, admin3name.x, cases) # print selected variables to console## Simple feature collection with 9 features and 2 fields\n## Geometry type: MULTIPOLYGON\n## Dimension:     XY\n## Bounding box:  xmin: -13.29894 ymin: 8.384533 xmax: -13.12612 ymax: 8.499809\n## Geodetic CRS:  WGS 84\n## # A tibble: 9 × 3\n##   admin3name.x   cases                                                                          geometry\n##   <chr>          <int>                                                                <MULTIPOLYGON [°]>\n## 1 Mountain Rural   267 (((-13.21496 8.474341, -13.21479 8.474289, -13.21465 8.474296, -13.21455 8.47429…\n## 2 Central I         62 (((-13.22646 8.489716, -13.22648 8.48955, -13.22644 8.489513, -13.22663 8.489229…\n## 3 East I            68 (((-13.2129 8.494033, -13.21076 8.494026, -13.21013 8.494041, -13.2096 8.494025,…\n## 4 East II          114 (((-13.22653 8.491883, -13.22647 8.491853, -13.22642 8.49186, -13.22633 8.491814…\n## 5 Central II        32 (((-13.23154 8.491768, -13.23141 8.491566, -13.23144 8.49146, -13.23131 8.491294…\n## 6 West III         212 (((-13.28529 8.497354, -13.28456 8.496497, -13.28403 8.49621, -13.28338 8.496086…\n## 7 West I            43 (((-13.24677 8.493453, -13.24669 8.493285, -13.2464 8.493132, -13.24627 8.493131…\n## 8 West II          180 (((-13.25698 8.485518, -13.25685 8.485501, -13.25668 8.485505, -13.25657 8.48550…\n## 9 East III          17 (((-13.20465 8.485758, -13.20461 8.485698, -13.20449 8.485757, -13.20431 8.48557…\nggplot(data=sle_adm3_dat) +\n  geom_col(aes(x=fct_reorder(admin3name.x, cases, .desc=T),   # reorder x axis by descending 'cases'\n               y=cases)) +                                  # y axis is number of cases by region\n  theme_bw() +\n  labs(                                                     # set figure text\n    title=\"Number of cases, by administrative unit\",\n    x=\"Admin level 3\",\n    y=\"Number of cases\"\n  ) + \n  guides(x=guide_axis(angle=45))                            # angle x-axis labels 45 degrees to fit better\nggplot(data=sle_adm3_dat) + \n  geom_sf(aes(fill=cases))    # set fill to vary by case count variable\nggplot(data=sle_adm3_dat) +                           \n  geom_sf(aes(fill=cases)) +                        \n  scale_fill_continuous(high=\"#54278f\", low=\"#f2f0f7\") +    # change color gradient\n  theme_bw() +\n  labs(title = \"Number of cases, by administrative unit\",   # set figure text\n       subtitle = \"Admin level 3\"\n  )"},{"path":"gis-basics.html","id":"basemaps","chapter":"28 Conceptos básicos de los SIG","heading":"28.9 Mapas base","text":"","code":""},{"path":"gis-basics.html","id":"openstreetmap","chapter":"28 Conceptos básicos de los SIG","heading":"OpenStreetMap","text":"continuación describimos cómo conseguir un mapa base para realizar un mapa con ggplot2 utilizando las características de OpenStreetMap. Existen métodos alternativos que incluyen el uso de ggmap que requiere el registro gratuito con Google (detalles).OpenStreetMap es un proyecto de colaboración para crear un mapa editable y gratuito del mundo. Los datos de geolocalización subyacentes (por ejemplo, ubicaciones de ciudades, carreteras, características naturales, aeropuertos, escuelas, hospitales, caminos, etc.) se consideran el resultado principal del proyecto.Primero cargamos el paquete OpenStreetMap, del que obtendremos nuestro mapa base.continuación, creamos el objeto map, que definimos mediante la función openmap() del paquete OpenStreetMap (documentación). Proporcionamos lo siguiente:upperLeft y lowerRight: Estas son dos pares de coordenadas que especifican los límites del marco del mapa base.\nEn este caso hemos puesto los máximos y mínimos de las filas del listado, para que el mapa responda dinámicamente los datos\nupperLeft y lowerRight: Estas son dos pares de coordenadas que especifican los límites del marco del mapa base.En este caso hemos puesto los máximos y mínimos de las filas del listado, para que el mapa responda dinámicamente los datoszoom = (si es nulo se determina automáticamente)zoom = (si es nulo se determina automáticamente)type = qué tipo de mapa base - aquí hemos enumerado varias posibilidades y el código utiliza actualmente la primera ([1]) “osm”type = qué tipo de mapa base - aquí hemos enumerado varias posibilidades y el código utiliza actualmente la primera ([1]) “osm”mergeTiles = elegimos TRUE para que las capas se fusionen en uno solomergeTiles = elegimos TRUE para que las capas se fusionen en uno soloSi trazamos este mapa ahora mismo, usando autoplot.OpenStreetMap() del paquete OpenStreetMap, verás que las unidades en los ejes son coordenadas de latitud/longitud. Se está utilizando un sistema de coordenadas diferente. Para mostrar correctamente las residencias de los casos (que se almacenan en lat/long), se debe cambiar esto.Vamos convertir el mapa latitud/longitud con la función openproj() del paquete OpenStreetMap. Proporcionamos el mapa base map y también el Sistema de Referencia de Coordenadas (CRS) que queremos. Lo hacemos proporcionando la cadena de caracteres “proj.4” para la proyección WGS 1984, pero también se puede proporcionar el CRS de otras maneras. (ver esta página para entender mejor qué es una cadena proj.4)Ahora cuando creamos el gráfico vemos que lo largo de los ejes están las coordenadas de latitud y longitud. El sistema de coordenadas ha sido convertido. Ahora nuestros casos se trazarán correctamente si se superponen:Consulta estos dos tutoriales aquí y aquí para obtener más información sobre este tema.","code":"\n# load package\npacman::p_load(OpenStreetMap)\n\n# Fit basemap by range of lat/long coordinates. Choose tile type\nmap <- openmap(\n  upperLeft = c(max(linelist$lat, na.rm=T), max(linelist$lon, na.rm=T)),   # limits of basemap tile\n  lowerRight = c(min(linelist$lat, na.rm=T), min(linelist$lon, na.rm=T)),\n  zoom = NULL,\n  type = c(\"osm\", \"stamen-toner\", \"stamen-terrain\", \"stamen-watercolor\", \"esri\",\"esri-topo\")[1])\nautoplot.OpenStreetMap(map)\n# Projection WGS84\nmap_latlon <- openproj(map, projection = \"+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs\")\n# Plot map. Must use \"autoplot\" in order to work with ggplot\nautoplot.OpenStreetMap(map_latlon)"},{"path":"gis-basics.html","id":"contoured-density-heatmaps","chapter":"28 Conceptos básicos de los SIG","heading":"28.10 Mapas de calor de densidad contorneada","text":"continuación describimos cómo conseguir un mapa de calor de densidad contorneada de casos, sobre un mapa base, comenzando con un listado (una fila por caso).Crear un mapa base partir de OpenStreetMap, como se ha descrito anteriormente.Trazar los casos de linelist utilizando las columnas de latitud y longitud.Convertir los puntos en un mapa de calor de densidad con stat_density_2d() de ggplot2,Cuando tenemos un mapa base con coordenadas de latitud y longitud, podemos trazar nuestros casos encima utilizando las coordenadas de latitud y longitud de su residencia.Partiendo de la función autoplot.OpenStreetMap() para crear el mapa base, se pueden añadir las funciones de ggplot2, como se muestra con geom_point() continuación:El mapa anterior puede ser difícil de interpretar, especialmente con los puntos superpuestos. Para mejorar esto, vamos trazar un mapa de densidad en 2d utilizando la función ggplot2 stat_density_2d(). Sguemos utilizando las coordenadas lat/lon del listado, pero ahora estamos realizando una estimación de la densidad del núcleo en 2D y los resultados se muestran con líneas de contorno - como un mapa topográfico. Puedes leer esta documentación completa para saber más.","code":"\n# Plot map. Must be autoplotted to work with ggplot\nautoplot.OpenStreetMap(map_latlon)+                 # begin with the basemap\n  geom_point(                                       # add xy points from linelist lon and lat columns \n    data = linelist,                                \n    aes(x = lon, y = lat),\n    size = 1, \n    alpha = 0.5,\n    show.legend = FALSE) +                          # drop legend entirely\n  labs(x = \"Longitude\",                             # titles & labels\n       y = \"Latitude\",\n       title = \"Cumulative cases\")\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases\")"},{"path":"gis-basics.html","id":"mapa-de-calor-de-series-temporales","chapter":"28 Conceptos básicos de los SIG","heading":"Mapa de calor de series temporales","text":"El mapa de calor de densidad anterior muestra los casos acumulados. Podemos examinar el brote lo largo del tiempo y del espacio haciendo un facetado del mapa de calor basado en el mes de inicio de los síntomas, si tenemos esta información en el linelist.Comenzamos con linelist, creando una nueva columna con el Año y el Mes de inicio. La función format() de R base cambia la forma en que se muestra una fecha. En este caso queremos “AAAA-MM”.Ahora, simplemente introducimos el facetado través de ggplot2 en el mapa de calor de densidad. Se aplica facet_wrap(), utilizando la nueva columna como filas. Fijamos el número de columnas de facetas en 4 paraque se vea mejor.","code":"\n# Extract month of onset\nlinelist <- linelist %>% \n  mutate(date_onset_ym = format(date_onset, \"%Y-%m\"))\n\n# Examine the values \ntable(linelist$date_onset_ym, useNA = \"always\")## \n## 2014-04 2014-05 2014-06 2014-07 2014-08 2014-09 2014-10 2014-11 2014-12 2015-01 2015-02 2015-03 2015-04 \n##       1       9      17      32      92     190     192     130     110      65      44      46      26 \n##    <NA> \n##      46\n# packages\npacman::p_load(OpenStreetMap, tidyverse)\n\n# begin with the basemap\nautoplot.OpenStreetMap(map_latlon)+\n  \n  # add the density plot\n  ggplot2::stat_density_2d(\n        data = linelist,\n        aes(\n          x = lon,\n          y = lat,\n          fill = ..level..,\n          alpha = ..level..),\n        bins = 10,\n        geom = \"polygon\",\n        contour_var = \"count\",\n        show.legend = F) +                          \n  \n  # specify color scale\n  scale_fill_gradient(low = \"black\", high = \"red\")+\n  \n  # labels \n  labs(x = \"Longitude\",\n       y = \"Latitude\",\n       title = \"Distribution of cumulative cases over time\")+\n  \n  # facet the plot by month-year of onset\n  facet_wrap(~ date_onset_ym, ncol = 4)               "},{"path":"gis-basics.html","id":"spatial-statistics","chapter":"28 Conceptos básicos de los SIG","heading":"28.11 Estadísticas espaciales","text":"La mayor parte de nuestra discusión hasta ahora se ha centrado en la visualización de datos espaciales. En algunos casos, también puede interesarte utilizar estadísticas espaciales para cuantificar las relaciones espaciales de los atributos de tus datos. En esta sección se ofrece una breve visión general de algunos conceptos claves de la estadística espacial y se sugiere algunos recursos que te resultarán útiles si deseas realizar análisis espaciales más exhaustivos.","code":""},{"path":"gis-basics.html","id":"relaciones-espaciales","chapter":"28 Conceptos básicos de los SIG","heading":"Relaciones espaciales","text":"Antes de poder calcular cualquier estadística espacial, tenemos que especificar las relaciones entre las características de nuestros datos. Hay muchas formas de conceptualizar las relaciones espaciales, pero un modelo sencillo y comúnmente aplicable es el de la adyacencia, es decir, que esperamos una relación geográfica entre las zonas que comparten una frontera o son “vecinas” unas de otras.Podemos cuantificar las relaciones de adyacencia entre los polígonos de las regiones administrativas en los datos sle_adm3 que hemos estado utilizando con el paquete spdep. Especificaremos la contigüidad queen, que significa que las regiones serán vecinas si comparten al menos un punto lo largo de sus fronteras. La alternativa sería la contigüidad rook, que requiere que las regiones compartan un borde - en nuestro caso, con polígonos irregulares, la distinción es trivial, pero en algunos casos la elección entre queen y rook puede ser influyente.La matriz de arriba muestra las relaciones entre las 9 regiones de nuestros datos sle_adm3. Una puntuación de 0 indica que dos regiones son vecinas, mientras que cualquier valor distinto de 0 indica una relación de vecindad. Los valores de la matriz se han escalado para que cada región tenga un peso total de 1 en la fila.La mejor manera de visualizar estas relaciones de vecindad es dibujarlas:Hemos utilizado un enfoque de adyacencia para identificar los polígonos vecinos; los vecinos que identificamos también se denominan veces vecinos por contigüidad. Pero ésta es sólo una forma de elegir qué regiones se espera que tengan una relación geográfica. Los enfoques alternativos más comunes para identificar las relaciones geográficas generan vecinos basados en la distancia; brevemente, estos son:K-vecinos más cercanos - Basándose en la distancia entre los centroides (el centro ponderado geográficamente de cada región poligonal), selecciona las n regiones más cercanas como vecinas. También se puede especificar un umbral de proximidad de distancia máxima. En spdep, puedes utilizar knearneigh() (documentación).K-vecinos más cercanos - Basándose en la distancia entre los centroides (el centro ponderado geográficamente de cada región poligonal), selecciona las n regiones más cercanas como vecinas. También se puede especificar un umbral de proximidad de distancia máxima. En spdep, puedes utilizar knearneigh() (documentación).Vecinos de umbral de distancia - Selecciona todos los vecinos dentro de un umbral de distancia. En spdep, estas relaciones de vecindad pueden ser identificadas usando dnearneigh() (documentación).Vecinos de umbral de distancia - Selecciona todos los vecinos dentro de un umbral de distancia. En spdep, estas relaciones de vecindad pueden ser identificadas usando dnearneigh() (documentación).","code":"\nsle_nb <- spdep::poly2nb(sle_adm3_dat, queen=T) # create neighbors \nsle_adjmat <- spdep::nb2mat(sle_nb)    # create matrix summarizing neighbor relationships\nsle_listw <- spdep::nb2listw(sle_nb)   # create listw (list of weights) object -- we will need this later\n\nsle_nb## Neighbour list object:\n## Number of regions: 9 \n## Number of nonzero links: 30 \n## Percentage nonzero weights: 37.03704 \n## Average number of links: 3.333333\nround(sle_adjmat, digits = 2)##   [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]\n## 1 0.00 0.20 0.00 0.20 0.00  0.2 0.00 0.20 0.20\n## 2 0.25 0.00 0.00 0.25 0.25  0.0 0.00 0.25 0.00\n## 3 0.00 0.00 0.00 0.50 0.00  0.0 0.00 0.00 0.50\n## 4 0.25 0.25 0.25 0.00 0.00  0.0 0.00 0.00 0.25\n## 5 0.00 0.33 0.00 0.00 0.00  0.0 0.33 0.33 0.00\n## 6 0.50 0.00 0.00 0.00 0.00  0.0 0.00 0.50 0.00\n## 7 0.00 0.00 0.00 0.00 0.50  0.0 0.00 0.50 0.00\n## 8 0.20 0.20 0.00 0.00 0.20  0.2 0.20 0.00 0.00\n## 9 0.33 0.00 0.33 0.33 0.00  0.0 0.00 0.00 0.00\n## attr(,\"call\")\n## spdep::nb2mat(neighbours = sle_nb)\nplot(sle_adm3_dat$geometry) +                                           # plot region boundaries\n  spdep::plot.nb(sle_nb,as(sle_adm3_dat, 'Spatial'), col='grey', add=T) # add neighbor relationships"},{"path":"gis-basics.html","id":"autocorrelación-espacial","chapter":"28 Conceptos básicos de los SIG","heading":"Autocorrelación espacial","text":"La tan citada primera ley de la geografía de Tobler afirma que “todo está relacionado con todo lo demás, pero las cosas cercanas están más relacionadas que las lejanas”. En epidemiología, esto suele significar que el riesgo de un determinado resultado sanitario en una región determinada es más similar al de sus regiones vecinas que al de las lejanas. Este concepto se ha formalizado como autocorrelación espacial: la propiedad estadística de que las características geográficas con valores similares se agrupan en el espacio. Las medidas estadísticas de autocorrelación espacial pueden utilizarse para cuantificar el alcance de la agrupación espacial de tus datos, localizar dónde se produce la agrupación e identificar patrones compartidos de autocorrelación espacial entre distintas variables de los datos. Esta sección ofrece una visión general de algunas medidas comunes de autocorrelación espacial y cómo calcularlas en R.de Moran - Se trata de una estadística de resumen global de la correlación entre el valor de una variable en una región y los valores de la misma variable en las regiones vecinas. La estadística de Moran suele oscilar entre -1 y 1. Un valor de 0 indica que hay ningún patrón de correlación espacial, mientras que los valores más cercanos 1 o -1 indican una mayor autocorrelación espacial (valores similares cercanos) o dispersión espacial (valores disímiles cercanos), respectivamente.Como ejemplo, calcularemos la estadística de Moran para cuantificar la autocorrelación espacial en los casos de Ébola que hemos mapeado antes (recordemos que se trata de un subconjunto de casos de la epidemia simulada del dataframe linelist). El paquete spdep tiene una función, moran.test, que puede hacer este cálculo por nosotros:El resultado de la función moran.test() nos muestra una estadística de Moran de round(moran_i$estimate[1],2). Esto indica la presencia de autocorrelación espacial en nuestros datos; en concreto, sugiere que es probable que las regiones con un número similar de casos de Ébola estén próximas entre sí. El valor p proporcionado por moran.test() se genera mediante la comparación con la expectativa bajo la hipótesis nula de ausencia de autocorrelación espacial, y puede utilizarse si se necesita informar de los resultados de una prueba de hipótesis formal.de Moran local - Podemos descomponer la estadística de Moran (global) calculada anteriormente para identificar la autocorrelación espacial localizada; es decir, para identificar grupos específicos en nuestros datos. Esta estadística, que veces se denomina indicador local de asociación espacial (LISA), resume el grado de autocorrelación espacial alrededor de cada región individual. Puede ser útil para encontrar puntos “calientes” y “fríos” en el mapa.Para mostrar un ejemplo, podemos calcular y mapear la de Moran local para los recuentos de casos de Ébola utilizados anteriormente, con la función local_moran() de spdep:Getis-Ord Gi\n* - Esta es otra estadística que se utiliza comúnmente para el análisis de puntos calientes; en gran parte, la popularidad de esta estadística se relaciona con su uso en la herramienta de análisis de puntos calientes en ArcGIS. Se basa en la suposición de que, normalmente, la diferencia del valor de una variable entre regiones vecinas debería seguir una distribución normal. Utiliza un enfoque de puntuación z para identificar las regiones que tienen valores significativamente más altos (punto caliente) o significativamente más bajos (punto frío) de una variable específica, en comparación con sus vecinos.Podemos calcular y asignar la estadística Gi* utilizando la función localG() de spdep:Como puedes ver, el mapa de Getis-Ord Gi* tiene un aspecto ligeramente diferente del mapa de Moran local elaborado anteriormente. Esto refleja que el método utilizado para calcular estas dos estadísticas es ligeramente diferente. Cuál de ellas debes utilizar depende de tu caso de uso específico y de la pregunta de investigación de interés.Prueba L de Lee - Es una prueba estadística de correlación espacial bivariada. Permite comprobar si el patrón espacial de una determinada variable x es similar al patrón espacial de otra variable, y, que se supone que está relacionada espacialmente con x.Para dar un ejemplo, vamos probar si el patrón espacial de los casos de Ébola de la epidemia simulada está correlacionado con el patrón espacial de la población. Para empezar, necesitamos tener una variable population en nuestros datos sle_adm3. Podemos utilizar la variable total del dataframe sle_adm3_pop que hemos cargado anteriormente.Podemos visualizar rápidamente los patrones espaciales de las dos variables una al lado de la otra, para ver si se parecen:Visualmente, los patrones parecen parecen muy similares. Podemos utilizar la función lee.test() de spdep para comprobar estadísticamente si el patrón de autocorrelación espacial de las dos variables está relacionado. La estadística L será cercana 0 si hay correlación entre los patrones, cercana 1 si hay una fuerte correlación positiva (es decir, los patrones son similares), y cercana -1 si hay una fuerte correlación negativa (es decir, los patrones son inversos).El resultado anterior muestra que la estadística L de Lee para nuestras dos variables fue round(lee_test$estimate[1],2), lo que indica una débil correlación negativa. Esto confirma nuestra evaluación visual de que el patrón de los casos y la población están relacionados entre sí, y proporciona pruebas de que el patrón espacial de los casos es estrictamente un resultado de la densidad de población en las zonas de alto riesgo.La estadística L de Lee puede ser útil para hacer este tipo de inferencias sobre la relación entre variables distribuidas espacialmente; sin embargo, para describir la naturaleza de la relación entre dos variables con más detalle, o ajustar por confusión, tenemos que aplicar técnicas de regresión espacial. Describeremos brevemente algunas de estas en la siguiente sección.","code":"\nmoran_i <-spdep::moran.test(sle_adm3_dat$cases,    # numeric vector with variable of interest\n                            listw=sle_listw)       # listw object summarizing neighbor relationships\n\nmoran_i                                            # print results of Moran's I test## \n##  Moran I test under randomisation\n## \n## data:  sle_adm3_dat$cases  \n## weights: sle_listw    \n## \n## Moran I statistic standard deviate = 1.4451, p-value = 0.07422\n## alternative hypothesis: greater\n## sample estimates:\n## Moran I statistic       Expectation          Variance \n##        0.17828008       -0.12500000        0.04404663\n# calculate local Moran's I\nlocal_moran <- spdep::localmoran(                  \n  sle_adm3_dat$cases,                              # variable of interest\n  listw=sle_listw                                  # listw object with neighbor weights\n)\n\n# join results to sf data\nsle_adm3_dat<- cbind(sle_adm3_dat, local_moran)    \n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=Ii)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Local Moran's I\") +\n  labs(title=\"Local Moran's I statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\n# Perform local G analysis\ngetis_ord <- spdep::localG(\n  sle_adm3_dat$cases,\n  sle_listw\n)\n\n# join results to sf data\nsle_adm3_dat$getis_ord <- getis_ord\n\n# plot map\nggplot(data=sle_adm3_dat) +\n  geom_sf(aes(fill=getis_ord)) +\n  theme_bw() +\n  scale_fill_gradient2(low=\"#2c7bb6\", mid=\"#ffffbf\", high=\"#d7191c\",\n                       name=\"Gi*\") +\n  labs(title=\"Getis-Ord Gi* statistic for Ebola cases\",\n       subtitle=\"Admin level 3 regions, Sierra Leone\")\nsle_adm3_dat <- sle_adm3_dat %>% \n  rename(population = total)                          # rename 'total' to 'population'\ntmap_mode(\"plot\")\n\ncases_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"cases\") + tm_layout(main.title=\"Cases\")\npop_map <- tm_shape(sle_adm3_dat) + tm_polygons(\"population\") + tm_layout(main.title=\"Population\")\n\ntmap_arrange(cases_map, pop_map, ncol=2)   # arrange into 2x1 facets\nlee_test <- spdep::lee.test(\n  x=sle_adm3_dat$cases,          # variable 1 to compare\n  y=sle_adm3_dat$population,     # variable 2 to compare\n  listw=sle_listw                # listw object with neighbor weights\n)\n\nlee_test## \n##  Lee's L statistic randomisation\n## \n## data:  sle_adm3_dat$cases ,  sle_adm3_dat$population \n## weights: sle_listw  \n## \n## Lee's L statistic standard deviate = -0.96035, p-value = 0.8316\n## alternative hypothesis: greater\n## sample estimates:\n## Lee's L statistic       Expectation          Variance \n##       -0.16028629       -0.05356836        0.01234855"},{"path":"gis-basics.html","id":"regresión-espacial","chapter":"28 Conceptos básicos de los SIG","heading":"Regresión espacial","text":"Es posible que quieras hacer inferencias estadísticas sobre las relaciones entre las variables de tus datos espaciales. En estos casos, es útil considerar las técnicas de regresión espacial, es decir, los enfoques de regresión que consideran explícitamente la organización espacial de las unidades en los datos. Algunas de las razones por las que puedes necesitar considerar modelos de regresión espacial, en lugar de modelos de regresión estándar como los GLM, incluyen:Los modelos de regresión estándar asumen que los residuos son independientes entre sí. En presencia de una autocorrelación espacial fuerte, es probable que los residuos de un modelo de regresión estándar también estén autocorrelacionados espacialmente, violando así este supuesto. Esto puede dar lugar problemas de interpretación de los resultados del modelo, en cuyo caso sería preferible un modelo espacial.Los modelos de regresión estándar asumen que los residuos son independientes entre sí. En presencia de una autocorrelación espacial fuerte, es probable que los residuos de un modelo de regresión estándar también estén autocorrelacionados espacialmente, violando así este supuesto. Esto puede dar lugar problemas de interpretación de los resultados del modelo, en cuyo caso sería preferible un modelo espacial.Los modelos de regresión también suelen suponer que el efecto de una variable x es constante en todas las observaciones. En el caso de la heterogeneidad espacial, los efectos que deseamos estimar pueden variar lo largo del espacio, y podemos estar interesados en cuantificar esas diferencias. En este caso, los modelos de regresión espacial ofrecen más flexibilidad para estimar e interpretar los efectos.Los modelos de regresión también suelen suponer que el efecto de una variable x es constante en todas las observaciones. En el caso de la heterogeneidad espacial, los efectos que deseamos estimar pueden variar lo largo del espacio, y podemos estar interesados en cuantificar esas diferencias. En este caso, los modelos de regresión espacial ofrecen más flexibilidad para estimar e interpretar los efectos.Los detalles de los enfoques de regresión espacial están fuera del alcance de este manual. En su lugar, esta sección ofrece una visión general de los modelos de regresión espacial más comunes y sus usos, y te remite referencias que pueden ser útiles por si se deseas profundizar en este ámbito.Modelos de error espacial - Estos modelos suponen que los términos de error entre unidades espaciales están correlacionados, en cuyo caso los datos violarían los supuestos de un modelo OLS estándar. Los modelos de error espacial también se denominan veces modelos autorregresivos simultáneos (SAR). Pueden ajustarse utilizando la función errorsarlm() del paquete spatialreg (funciones de regresión espacial que solían formar parte de spdep).Modelos de desfase espacial - Estos modelos suponen que la variable dependiente de una región está influida sólo por el valor de las variables independientes en , sino también por los valores de esas variables en las regiones vecinas . Al igual que los modelos de error espacial, los modelos de desfase espacial también se describen veces como modelos autorregresivos simultáneos (SAR). Pueden ajustarse utilizando la función lagsarlm() del paquete spatialreg.El paquete spdep contiene varias pruebas de diagnóstico útiles para decidir entre los modelos OLS estándar, de desfase espacial y de error espacial. Estas pruebas, denominadas diagnósticos del multiplicador de Lagrange, pueden utilizarse para identificar el tipo de dependencia espacial en sus datos y elegir el modelo más apropiado. La función lm.LMtests() puede utilizarse para calcular todos los diagnósticos del multiplicador de Lagrange. Anselin (1988) también proporciona una útil herramienta de diagrama de flujo para decidir qué modelo de regresión espacial utilizar basándose en los resultados de las pruebas del multiplicador de Lagrange:Modelos jerárquicos bayesianos: Los enfoques bayesianos se utilizan habitualmente para algunas aplicaciones del análisis espacial, sobre todo para el mapeo de enfermedades. Se prefieren en los casos en los que los datos de los casos están escasamente distribuidos (por ejemplo, en el caso de un resultado raro) o son estadísticamente “ruidosos”, ya que pueden utilizarse para generar estimaciones “suavizadas” del riesgo de enfermedad al tener en cuenta el proceso espacial latente subyacente. Esto puede mejorar la calidad de las estimaciones. También permiten que el investigador especifique previamente (mediante la elección de “priors” (valores pre-establecidos)) los patrones complejos de correlación espacial que pueden existir en los datos, los cuales pueden tomar en cuenta la variación espacialmente dependiente e independiente en las variables independientes y dependientes. En R, los modelos jerárquicos bayesianos pueden ajustarse utilizando el paquete CARbayes (véase la viñeta) o R-INLA (véase este sitio web y el libro de texto). través de R también puedes usar software externo que realice estimaciones bayesianas, como JAGS o WinBUGS.","code":""},{"path":"gis-basics.html","id":"resources-21","chapter":"28 Conceptos básicos de los SIG","heading":"28.12 Recursos","text":"Funciones simples de R y viñeta del paquete sfFunciones simples de R y viñeta del paquete sfViñeta del paquete tmapViñeta del paquete tmapggmap: Visualización espacial con ggplot2ggmap: Visualización espacial con ggplot2Introducción la elaboración de mapas con R, visión general de los diferentes paquetesIntroducción la elaboración de mapas con R, visión general de los diferentes paquetesDatos espaciales en R (curso EarthLab)Datos espaciales en R (curso EarthLab)Libro de texto Applied Spatial Data Analysis RLibro de texto Applied Spatial Data Analysis RSpatialEpiApp - una aplicación Shiny que se puede descargar como un paquete de R, lo que le permite proporcionar sus propios datos y llevar cabo la cartografía, el análisis de conglomerados y las estadísticas espaciales.SpatialEpiApp - una aplicación Shiny que se puede descargar como un paquete de R, lo que le permite proporcionar sus propios datos y llevar cabo la cartografía, el análisis de conglomerados y las estadísticas espaciales.Taller de introducción la econometría espacial en RTaller de introducción la econometría espacial en R","code":""},{"path":"tables-for-presentation.html","id":"tables-for-presentation","chapter":"29 Tablas para presentaciones","heading":"29 Tablas para presentaciones","text":"HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Esta página muestra cómo convertir dataframes con datos agrupados en tablas preparadas para su presentación con el paquete flextable. Estas tablas pueden insertarse en diapositivas de PowerPoint, páginas HTML, documentos PDF o Word, etc.Comprende que antes de utilizar flextable, debes crear la tabla resumen como un dataframe. Utiliza los métodos de las páginas Tablas descriptivas y Pivotar de datos, como tabulaciones, tabulaciones cruzadas, pivoteo y cálculo de estadísticas descriptivas. El dataframe resultante puede pasarse flextable para ponerle el formato.Hay muchos otros paquetes de R que se pueden utilizar para elaborar tablas para su presentación - hemos elegido destacar flextable en esta página. Un ejemplo que utiliza el paquete knitr y su función kable() se puede encontrar en la página rastreo de contactos. Asimismo, el paquete DT se destaca en la página Dashboards con Shiny. Otros como GT y huxtable se mencionan en la página de Paquetes recomendados.","code":""},{"path":"tables-for-presentation.html","id":"preparation-20","chapter":"29 Tablas para presentaciones","heading":"29.1 Preparación","text":"","code":""},{"path":"tables-for-presentation.html","id":"cargar-paquetes-18","chapter":"29 Tablas para presentaciones","heading":"Cargar paquetes","text":"Instala y carga flextable. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar paquetes con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization"},{"path":"tables-for-presentation.html","id":"importar-datos-14","chapter":"29 Tablas para presentaciones","heading":"Importar datos","text":"Para empezar, importamos los datos limpios de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio”(como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - Mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas de linelist.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"tables-for-presentation.html","id":"preparar-la-tabla","chapter":"29 Tablas para presentaciones","heading":"Preparar la tabla","text":"Antes de empezar utilizar flextable tendrás que crear tu tabla como un dataframe. Consulta la página sobre Tablas descriptivas y Pivotar datos para aprender crear un dataframe utilizando paquetes como janitor y dplyr. Debes organizar el contenido en filas y columnas tal y como quieres que se muestre. Luego, el dataframe se pasará flextable para mostrarlo con colores, encabezados, fuentes, etc.continuación se muestra un ejemplo de la página de tablas descriptivas para convertir la lista de casos en un dataframe que resume los resultados de los pacientes y los valores de TC por hospital, con una fila de totales en la parte inferior. El resultado se guarda como table.","code":"\ntable <- linelist %>% \n  \n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Agrupar datos\n  summarise(                                           # Creaar columnas nuevas con indicadores de interés\n    N = n(),                                            # Número de filas por grupos de hospital-resultado     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # Valor de la mediana CT por grupo\n  \n  # add totals\n  ############\n  bind_rows(                                           # Une la tabla anterior con esta mini-tabla de totales\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Agrupados sólo por resultado, no por hospital    \n      summarise(\n        N = n(),                                       # Número de filas del conjunto de datos     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Mediana CT del conjunto de datos \n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivotar de largo a ancho\n    values_from = c(ct_value, N),                       # Los nuevos valores están desde la columna ct a la count\n    names_from = outcome) %>%                           # los nombres nuevos de columna son para el resultado \n  mutate(                                              # Añadir columnas nuevas\n    N_Known = N_Death + N_Recover,                               # número con resultado conocidos\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # porcentaje de casos que fallecieron (con 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # porcentaje que se recuperaron (con 1 decimal)\n  select(                                              # Re-ordenar columnas\n    hospital, N_Known,                                   # Intro columnas\n    N_Recover, Pct_Recover, ct_value_Recover,            # Columnas para recuerados\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Columnas para fallecidos\n  arrange(N_Known)                                    # Ordenar las filas de menor a mayor (fila total al final)\n\ntable  # print## # A tibble: 7 × 8\n## # Groups:   hospital [7]\n##   hospital                             N_Known N_Recover Pct_Recover ct_value_…¹ N_Death Pct_D…² ct_va…³\n##   <chr>                                  <int>     <int> <chr>             <dbl>   <int> <chr>     <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH)     325       126 38.8%                22     199 61.2%        22\n## 2 Central Hospital                         358       165 46.1%                22     193 53.9%        22\n## 3 Other                                    685       290 42.3%                21     395 57.7%        22\n## 4 Military Hospital                        708       309 43.6%                22     399 56.4%        21\n## 5 Missing                                 1125       514 45.7%                21     611 54.3%        21\n## 6 Port Hospital                           1364       579 42.4%                21     785 57.6%        22\n## 7 Total                                   3440      1469 42.7%                22    1971 57.3%        22\n## # … with abbreviated variable names ¹​ct_value_Recover, ²​Pct_Death, ³​ct_value_Death"},{"path":"tables-for-presentation.html","id":"basic-flextable","chapter":"29 Tablas para presentaciones","heading":"29.2 Flextable básica","text":"","code":""},{"path":"tables-for-presentation.html","id":"crear-una-flextble","chapter":"29 Tablas para presentaciones","heading":"Crear una flextble","text":"Para crear y gestionar los objetos de flextable, primero pasamos el dataframe por la función flextable(). Guardamos el resultado como my_table.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Después de hacer esto, podemos enlazar con pipe progresivamente el objeto my_table través de más funciones de formato de flextable.En esta página, para mayor claridad, guardaremos la tabla en pasos intermedios como my_table, añadiendo las funciones de flextable bit bit. Si quieres ver todo el código de principio fin escrito en un solo trozo, visita la sección Todo el código junto más abajo.La sintaxis general de cada línea de código de flextable es la siguiente:function(table, = X, j = X, part = \"X\"), donde:\nLa “función” puede ser una de muchas funciones diferentes, como width() para determinar el ancho de las columnas, bg() para establecer los colores de fondo, align() para establecer si el texto está alineado al centro/derecha/izquierda, etc.\ntable = es el nombre del dataframe, aunque es necesario indicarlo si el dataframe se introduce en la función.\npart = se refiere la parte de la tabla la que se aplica la función. Por ejemplo, “header”, “body” o “”.\n= especifica la fila la que se aplicará la función, donde ‘X’ es el número de fila. Si se trata de varias filas, por ejemplo de la primera la tercera, se puede especificar:= c(1:3). Ten en cuenta que si se selecciona “body”, la primera fila empieza por debajo de la sección de cabecera.\nj = especifica la columna la que se aplicará la función, donde ‘x’ es el número o nombre de la columna. Si hay varias columnas, por ejemplo la quinta y la sexta, se puede especificar: j = c(5,6).\nLa “función” puede ser una de muchas funciones diferentes, como width() para determinar el ancho de las columnas, bg() para establecer los colores de fondo, align() para establecer si el texto está alineado al centro/derecha/izquierda, etc.table = es el nombre del dataframe, aunque es necesario indicarlo si el dataframe se introduce en la función.part = se refiere la parte de la tabla la que se aplica la función. Por ejemplo, “header”, “body” o “”.= especifica la fila la que se aplicará la función, donde ‘X’ es el número de fila. Si se trata de varias filas, por ejemplo de la primera la tercera, se puede especificar:= c(1:3). Ten en cuenta que si se selecciona “body”, la primera fila empieza por debajo de la sección de cabecera.j = especifica la columna la que se aplicará la función, donde ‘x’ es el número o nombre de la columna. Si hay varias columnas, por ejemplo la quinta y la sexta, se puede especificar: j = c(5,6).Puedes encontrar la lista completa de funciones de formato de flextable aquí o revisar la documentación escribiendo ?flextable.","code":"\nmy_table <- flextable(table) \nmy_table"},{"path":"tables-for-presentation.html","id":"ancho-de-columna","chapter":"29 Tablas para presentaciones","heading":"Ancho de columna","text":"Podemos utilizar la función autofit(), que estira la tabla de forma que cada celda sólo tiene una fila de texto. La función qflextable() es una abreviatura conveniente para flextable() y autofit().hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Sin embargo, esto podría ser siempre apropiado, especialmente si hay valores muy largos dentro de las celdas, lo que significa que la tabla podría caber en la página.En cambio, podemos especificar el ancho con la función width(). Puede ser necesario jugar un poco para saber qué valor de anchura poner. En el ejemplo siguiente, especificamos diferentes anchos para la columna 1, la columna 2 y las columnas 4 8.hospitalN_KnownN_RecoverPct_Recoverct_value_RecoverN_DeathPct_Deathct_value_DeathSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% autofit()\nmy_table <- my_table %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1)\n\nmy_table"},{"path":"tables-for-presentation.html","id":"encabezados-de-columna","chapter":"29 Tablas para presentaciones","heading":"Encabezados de columna","text":"Queremos encabezados más claros para facilitar la interpretación del contenido de la tabla.Para esta tabla, querremos añadir una segunda capa de cabecera para que las columnas que cubren los mismos subgrupos puedan agruparse. Lo hacemos con la función add_header_row() con top = TRUE. Proporcionamos el nuevo nombre de cada columna values = , dejando los valores vacíos \"\" para las columnas que sabemos que vamos fusionar más tarde.También renombramos los nombres de las cabeceras en la ahora segunda cabecera en un comando separado set_header_labels().Por último, para “combinar” ciertas cabeceras de columna en la cabecera superior utilizamos merge_at() para fusionar las cabeceras de columna en la fila de la cabecera superior.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  \n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    \n  set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\")     # Horizontally merge columns 6 to 8 in new header row\n\nmy_table  # print"},{"path":"tables-for-presentation.html","id":"bordes-y-fondos","chapter":"29 Tablas para presentaciones","heading":"Bordes y fondos","text":"Puedes ajustar los bordes, las líneas internas, etc. con varias funciones de flextable. menudo es más fácil empezar eliminando todos los bordes existentes con border_remove().continuación, puedes aplicar los temas de borde por defecto pasando la tabla theme_box(), theme_booktabs() o theme_alafoli().Puedes añadir líneas verticales y horizontales con una variedad de funciones. hline() y vline() añaden líneas una fila o columna especificada, respectivamente. Dentro de cada una, debes especificar la part = como “”, “body”, o “header”. Para las líneas verticales, especifica la columna j =, y para las líneas horizontales la fila =. Otras funciones como vline_right(), vline_left(), hline_top(), y hline_bottom() añaden líneas sólo los lados.En todas estas funciones, el propio estilo de línea debe especificarse border = y debe ser la salida de un comando separado utilizando la función fp_border() del paquete officer. Esta función te ayuda definir el ancho y el color de la línea. Puedes definirlo sobre los comandos de la tabla, como se muestra continuación.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\n# define style for border line\nborder_style = officer::fp_border(color=\"black\", width=1)\n\n# add border lines to table\nmy_table <- my_table %>% \n\n  # Remove all existing borders\n  border_remove() %>%  \n  \n  # add horizontal lines via a pre-determined theme setting\n  theme_booktabs() %>% \n  \n  # add vertical lines to separate Recovered and Died sections\n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style)       # at column 5\n\nmy_table"},{"path":"tables-for-presentation.html","id":"fuente-y-alineación","chapter":"29 Tablas para presentaciones","heading":"Fuente y alineación","text":"Alineamos en el centro todas las columnas, excepto la más la izquierda, con los nombres de los hospitales, utilizando la función align() de flextable.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Además, podemos aumentar el tamaño de la fuente de la cabecera y cambiarla negrita. También podemos cambiar la fila total negrita.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22Podemos asegurar que las columnas de proporción muestren sólo un decimal utilizando la función colformat_num(). Ten en cuenta que esto también podría haberse hecho en la fase de gestión de datos con la función round().HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n   flextable::align(align = \"center\", j = c(2:8), part = \"all\") \nmy_table\nmy_table <-  my_table %>%  \n  fontsize(i = 1, size = 12, part = \"header\") %>%   # adjust font size of header\n  bold(i = 1, bold = TRUE, part = \"header\") %>%     # adjust bold face of header\n  bold(i = 7, bold = TRUE, part = \"body\")           # adjust bold face of total row (row 7 of body)\n\nmy_table\nmy_table <- colformat_num(my_table, j = c(4,7), digits = 1)\nmy_table"},{"path":"tables-for-presentation.html","id":"fusionar-celdas","chapter":"29 Tablas para presentaciones","heading":"Fusionar celdas","text":"Al igual que fusionamos celdas horizontalmente en la fila de la cabecera, también podemos fusionar celdas verticalmente utilizando merge_at() y especificando las filas () y la columna (j). Aquí fusionamos los valores “Hospital” y “Total cases known outcome” verticalmente para darles más espacio.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\")\n\nmy_table"},{"path":"tables-for-presentation.html","id":"color-de-fondo","chapter":"29 Tablas para presentaciones","heading":"Color de fondo","text":"Para distinguir el contenido de la tabla de las cabeceras, es posible que queramos añadir un formato adicional, por ejemplo, cambiando el color de fondo. En este ejemplo cambiamos el cuerpo de la tabla gris.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table <- my_table %>% \n    bg(part = \"body\", bg = \"gray95\")  \n\nmy_table "},{"path":"tables-for-presentation.html","id":"conditional-formatting","chapter":"29 Tablas para presentaciones","heading":"29.3 Formato condicional","text":"Podemos resaltar todos los valores de una columna que cumplan una determinada regla, por ejemplo, que más del 55% de los casos hayan muerto. Basta con poner el criterio en el argumento = o j =, precedido de una tilde ~. Escribe la referencia la columna en el dataframe, los valores del encabezamiento de la pantalla.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22O bien, podemos resaltar toda la fila que cumpla un determinado criterio, como un hospital de interés. Para ello, basta con eliminar la especificación de la columna (j) para que los criterios se apliquen todas las columnas.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nmy_table %>% \n  bg(j = 7, i = ~ Pct_Death >= 55, part = \"body\", bg = \"red\") \nmy_table %>% \n  bg(., i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") "},{"path":"tables-for-presentation.html","id":"tbl_pres_all","chapter":"29 Tablas para presentaciones","heading":"29.4 Todo el código junto","text":"continuación mostramos todo el código de las secciones anteriores juntas.HospitalTotal cases known outcomeRecoveredDiedTotal% casesMedian CT valuesTotal% casesMedian CT valuesSt. Mark's Maternity Hospital (SMMH)32512638.8%2219961.2%22Central Hospital35816546.1%2219353.9%22Other68529042.3%2139557.7%22Military Hospital70830943.6%2239956.4%21Missing1,12551445.7%2161154.3%21Port Hospital1,36457942.4%2178557.6%22Total3,4401,46942.7%221,97157.3%22","code":"\nborder_style = officer::fp_border(color=\"black\", width=1)\n\npacman::p_load(\n  rio,            # import/export\n  here,           # file pathways\n  flextable,      # make HTML tables \n  officer,        # helper functions for tables\n  tidyverse)      # data management, summary, and visualization\n\ntable <- linelist %>% \n\n  # Get summary values per hospital-outcome group\n  ###############################################\n  group_by(hospital, outcome) %>%                      # Group data\n  summarise(                                           # Create new summary columns of indicators of interest\n    N = n(),                                            # Number of rows per hospital-outcome group     \n    ct_value = median(ct_blood, na.rm=T)) %>%           # median CT value per group\n  \n  # add totals\n  ############\n  bind_rows(                                           # Bind the previous table with this mini-table of totals\n    linelist %>% \n      filter(!is.na(outcome) & hospital != \"Missing\") %>%\n      group_by(outcome) %>%                            # Grouped only by outcome, not by hospital    \n      summarise(\n        N = n(),                                       # Number of rows for whole dataset     \n        ct_value = median(ct_blood, na.rm=T))) %>%     # Median CT for whole dataset\n  \n  # Pivot wider and format\n  ########################\n  mutate(hospital = replace_na(hospital, \"Total\")) %>% \n  pivot_wider(                                         # Pivot from long to wide\n    values_from = c(ct_value, N),                       # new values are from ct and count columns\n    names_from = outcome) %>%                           # new column names are from outcomes\n  mutate(                                              # Add new columns\n    N_Known = N_Death + N_Recover,                               # number with known outcome\n    Pct_Death = scales::percent(N_Death / N_Known, 0.1),         # percent cases who died (to 1 decimal)\n    Pct_Recover = scales::percent(N_Recover / N_Known, 0.1)) %>% # percent who recovered (to 1 decimal)\n  select(                                              # Re-order columns\n    hospital, N_Known,                                   # Intro columns\n    N_Recover, Pct_Recover, ct_value_Recover,            # Recovered columns\n    N_Death, Pct_Death, ct_value_Death)  %>%             # Death columns\n  arrange(N_Known) %>%                                 # Arrange rows from lowest to highest (Total row at bottom)\n\n  # formatting\n  ############\n  flextable() %>%              # table is piped in from above\n  add_header_row(\n    top = TRUE,                # New header goes on top of existing header row\n    values = c(\"Hospital\",     # Header values for each column below\n               \"Total cases with known outcome\", \n               \"Recovered\",    # This will be the top-level header for this and two next columns\n               \"\",\n               \"\",\n               \"Died\",         # This will be the top-level header for this and two next columns\n               \"\",             # Leave blank, as it will be merged with \"Died\"\n               \"\")) %>% \n    set_header_labels(         # Rename the columns in original header row\n      hospital = \"\", \n      N_Known = \"\",                  \n      N_Recover = \"Total\",\n      Pct_Recover = \"% of cases\",\n      ct_value_Recover = \"Median CT values\",\n      N_Death = \"Total\",\n      Pct_Death = \"% of cases\",\n      ct_value_Death = \"Median CT values\")  %>% \n  merge_at(i = 1, j = 3:5, part = \"header\") %>% # Horizontally merge columns 3 to 5 in new header row\n  merge_at(i = 1, j = 6:8, part = \"header\") %>%  \n  border_remove() %>%  \n  theme_booktabs() %>% \n  vline(part = \"all\", j = 2, border = border_style) %>%   # at column 2 \n  vline(part = \"all\", j = 5, border = border_style) %>%   # at column 5\n  merge_at(i = 1:2, j = 1, part = \"header\") %>% \n  merge_at(i = 1:2, j = 2, part = \"header\") %>% \n  width(j=1, width = 2.7) %>% \n  width(j=2, width = 1.5) %>% \n  width(j=c(4,5,7,8), width = 1) %>% \n  flextable::align(., align = \"center\", j = c(2:8), part = \"all\") %>% \n  bg(., part = \"body\", bg = \"gray95\")  %>% \n  bg(., j=c(1:8), i= ~ hospital == \"Military Hospital\", part = \"body\", bg = \"#91c293\") %>% \n  colformat_num(., j = c(4,7), digits = 1) %>%\n  bold(i = 1, bold = TRUE, part = \"header\") %>% \n  bold(i = 7, bold = TRUE, part = \"body\")## `summarise()` has grouped output by 'hospital'. You can override using the `.groups` argument.\ntable"},{"path":"tables-for-presentation.html","id":"saving-your-table","chapter":"29 Tablas para presentaciones","heading":"29.5 Guardar tu tabla","text":"Hay diferentes maneras de integrar la tabla en tu salida.","code":""},{"path":"tables-for-presentation.html","id":"guardar-una-tabla","chapter":"29 Tablas para presentaciones","heading":"Guardar una tabla","text":"Puedes exportar las tablas Word, PowerPoint o HTML o como archivos de imagen (PNG). Para ello, utiliza una de las siguientes funciones:save_as_docx()save_as_pptx()save_as_image()save_as_html()Por ejemplo, continuación guardamos nuestra tabla como un documento de Word. Ten en cuenta la sintaxis del primer argumento - puedes proporcionar simplemente el nombre de tu objeto flextable, por ejemplo, my_table, o puedes darle un “nombre” como se muestra continuación (el nombre es “my_table”). Si se especifica un nombre, éste aparecerá como el título de la tabla en Word. También mostramos el código para guardar como imagen PNG.Ten en cuenta que los paquetes webshot o webshot2 son necesarios para guardar una flextable como imagen. Las imágenes pueden salir con fondos transparentes.Si deseas ver una versión “en vivo” de la salida de flextable en el formato de documento previsto, utiliza print() y especifica uno de los siguientes para preview =. El documento se “abrirá” en tu ordenador en el programa de software especificado, pero se guardará. Esto puede ser útil para comprobar si la tabla cabe en una página/diapositiva o para poder copiarla rápidamente en otro documento, puedes utilizar el método de impresión con el argumento vista previa establecido en “pptx” o “docx”.","code":"\n# Edit the 'my table' as needed for the title of table.  \nsave_as_docx(\"my table\" = my_table, path = \"file.docx\")\n\nsave_as_image(my_table, path = \"file.png\")\nprint(my_table, preview = \"docx\") # Word document example\nprint(my_table, preview = \"pptx\") # Powerpoint example"},{"path":"tables-for-presentation.html","id":"imprimir-tabla-en-r-markdown","chapter":"29 Tablas para presentaciones","heading":"Imprimir tabla en R markdown","text":"Esta tabla puede integrarse en un documento automatizado, una salida de R markdown, si el objeto tabla se llama dentro del chunk de R markdown. Esto significa que la tabla puede actualizarse como parte de un informe en el que los datos podrían cambiar, por lo que los números pueden actualizarse.Mira los detalles en la página de Informes con R Markdown de este manual.","code":""},{"path":"tables-for-presentation.html","id":"resources-22","chapter":"29 Tablas para presentaciones","heading":"29.6 Recursos","text":"El libro completo de flextable está en: https://ardata-fr.github.io/flextable-book/ El sitio Github está aquí\nUn manual de todas las funciones de flextable puede encontrarse aquíPuedes acceder una galería de bonitos ejemplos de flextables con código aquí","code":""},{"path":"ggplot-basics.html","id":"ggplot-basics","chapter":"30 Conceptos básicos de ggplot","heading":"30 Conceptos básicos de ggplot","text":"ggplot2 es el paquete de R más popular para la visualización de datos. Su función ggplot() es el núcleo de este paquete, y todo este enfoque se conoce coloquialmente como “ggplot”, con las figuras resultantes veces llamadas afectuosamente “ggplots”. El “gg” en estos nombres se refiere la “gramática de los gráficos” utilizada para construir las figuras. ggplot2 se beneficia de una amplia variedad de paquetes de R complementarios que mejoran aún más su funcionalidad.La sintaxis es significativamente diferente de los dibujos de R base, y tiene una curva de aprendizaje asociada. El uso de ggplot2 generalmente requiere que el usuario formatee sus datos de una manera que sea altamente compatible con tidyverse, lo que en última instancia hace que el uso conjunto de estos paquetes sea muy eficaz.En esta página cubriremos los fundamentos de la creación de gráficos con ggplot2. Consulta la página Consejos de ggplot para sugerencias y técnicas avanzadas para lograr que sus gráficos se vean realmente bien.Hay varios tutoriales extensos de ggplot2 enlazados en la sección de recursos. También puede descargar esta hoja de trucos de visualización de datos con ggplot desde el sitio web de RStudio. Si quieres inspirarte en formas de visualizar tus datos de forma creativa, te sugerimos que revises sitios web como la galería de gráficos de R y Data--viz.","code":""},{"path":"ggplot-basics.html","id":"preparation-21","chapter":"30 Conceptos básicos de ggplot","heading":"30.1 Preparación","text":"","code":""},{"path":"ggplot-basics.html","id":"cargar-paquetes-19","chapter":"30 Conceptos básicos de ggplot","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También podes cargar los paquetes instalados con library() de R base. Consulta la página sobre los fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  tidyverse,      # incluye ggplot2 y otras herramientas de gestión de datos\n  rio,            # importación/exportación\n  here,           # rutas d elos archivos\n  stringr         # trabajar con caracteres    \n)"},{"path":"ggplot-basics.html","id":"importar-datos-15","chapter":"30 Conceptos básicos de ggplot","heading":"Importar datos","text":"Importamos el conjunto de datos de casos de una epidemia de Ebola simulada. Si quieres seguir el proceso, cliquea para descargar linelist “limpia” (como archivo .rds). Para importar sus datos utilizando la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - consulta la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado. Nos centraremos en las variables continuas age, wt_kg (peso en kilos), ct_blood (valores de CT, cycle threshold, umbral de ciclo del test de PCR) y days_onset_hosp (diferencia entre la fecha de inicio de síntomas y la hospitalización).","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-basics.html","id":"limpieza-general","chapter":"30 Conceptos básicos de ggplot","heading":"Limpieza general","text":"Cuando se preparan los datos para trazarlos (graficarlos), lo mejor es hacer que los datos se adhieran los estándares de datos “ordenados” tanto como sea posible. En las páginas de este manual, sobre Limpieza de datos y funciones básicas, se explica cómo conseguirlo.Algunas formas sencillas de preparar nuestros datos para que sea mas fáciles trazarlos pueden incluir la mejora del contenido de los datos para su visualización, lo que equivale necesariamente una manipulación de los datos mas sencilla. Por ejemplo:Sustituye los valores NA de una columna de caracteres por la cadena de caracteres “Unknown” (Desconocido)Considera la posibilidad de convertir la columna en de tipo factor para que sus valores tengan niveles ordinales prescritosLimpia los valores de algunas columnas para cambiar texto “amigable con los datos” con barra baja, etc. texto normal o mayúsculas y minúsculas (ver Caracteres y cadenas)aquí algunos ejemplos de esto en acción:","code":"\n# hace la versión de visualización de las columnas con nombres más amigables\nlinelist <- linelist %>%\n  mutate(\n    gender_disp = case_when(gender == \"m\" ~ \"Male\",        # m a Masculino \n                            gender == \"f\" ~ \"Female\",      # f a Femenino,\n                            is.na(gender) ~ \"Unknown\"),    # NA a Desconocido\n    \n    outcome_disp = replace_na(outcome, \"Unknown\")          # sustituye el resultado NA por \"unknown\"\n  )"},{"path":"ggplot-basics.html","id":"pivotar-a-lo-largo","chapter":"30 Conceptos básicos de ggplot","heading":"Pivotar a lo largo","text":"Como una cuestión de estructura de datos, para ggplot2 menudo queremos pivotar nuestros datos en formatos largos. Lee más sobre esto en la página de Pivoteo de datos.Por ejemplo, digamos que queremos trazar datos que están en un formato “lo ancho”, como por ejemplo para cada caso en linelist y sus síntomas. continuación creamos una minilista llamada symptoms_data que contiene sólo las columnas case_id y symptoms.Así es como se ven las primeras 50 filas de esta minilista - ¿ves cómo están formateadas “lo ancho” con cada síntoma como una columna?Si quisiéramos trazar el número de casos con síntomas específicos, estamos limitados por el hecho de que cada síntoma es una columna específica. Sin embargo, podemos hacer pivotar las columnas de síntomas un formato más largo como este:Aquí están las primeras 50 filas. Observa que cada caso tiene 5 filas - una para cada síntoma posible. Las nuevas columnas symptom_name y symptom_is_present son el resultado del pivote. Ten en cuenta que este formato puede ser muy útil para otras operaciones, pero es útil para trazar.","code":"\nsymptoms_data <- linelist %>% \n  select(c(case_id, fever, chills, cough, aches, vomit))\nsymptoms_data_long <- symptoms_data %>%    # comienza con una \"mini\" lista de líneas llamada symptoms_data\n  \n  pivot_longer(\n    cols = -case_id,                       # pivotea todas las columnas excepto case_id (todas las de síntomas)\n    names_to = \"symptom_name\",             # se asigna un nombre a la nueva columna que contiene los síntomas\n    values_to = \"symptom_is_present\") %>%  # se asigna un nombre a la nueva columna que contiene los valores (yes/no)\n  \n  mutate(symptom_is_present = replace_na(symptom_is_present, \"unknown\")) # convierte NA en \"unknown\""},{"path":"ggplot-basics.html","id":"basics-of-ggplot","chapter":"30 Conceptos básicos de ggplot","heading":"30.2 Fundamentos de ggplot","text":"“Gramática de los gráficos” - ggplot2El trazado con ggplot2 se basa en “añadir” capas de trazado y elementos de diseño unos sobre otros, añadiendo cada comando los anteriores con un símbolo de suma (+). El resultado es un objeto de trazado multicapa que se puede guardar, modificar, imprimir, exportar, etc.Los objetos ggplot pueden ser muy complejos, pero el orden básico de las capas suele ser el siguiente:Comienza con el comando ggplot() como punto de partida - esto “abre” el ggplot y permite agregar las funciones subsecuentes con +. Normalmente, el conjunto de datos también se especifica en este comandoAñadí capas “geom” - estas funciones visualizan los datos como geometrías (formas), por ejemplo, como un gráfico de barras, un gráfico de líneas, un gráfico de dispersión, un histograma (¡o una combinación!). Todas estas funciones comienzan con geom_ como prefijo.Añadí elementos de diseño al gráfico, como etiquetas de ejes, título, fuentes, tamaños, esquemas de color, leyendas o rotación de ejes.Un ejemplo sencillo del esqueleto del código es el siguiente. Explicaremos cada componente en las secciones siguientes.","code":"\n# Traza los datos de las columnas de my_data como puntos rojos\nggplot(data = my_data)+                   # Usa el conjunto de datos my_data\"\n  geom_point(                             # añade una capa de puntos\n    mapping = aes(x = col1, y = col2),    # \"asigna\" la columna de datos a los ejes\n    color = \"red\")+                       # otras especificaciones para el geom\n  labs()+                                 # aquí se añaden los títulos, las etiquetas de los ejes, etc.\n  theme()                                 # aquí se ajusta el color, la fuente, el tamaño, etc. de los elementos de trazado no relacionados con los datos (ejes, título, etc.) "},{"path":"ggplot-basics.html","id":"ggplot","chapter":"30 Conceptos básicos de ggplot","heading":"30.3 ggplot()","text":"El comando de apertura de cualquier gráfico ggplot2 es ggplot(). Este comando simplemente crea un lienzo en blanco sobre el que añadir capas. Se “abre” el camino para añadir más capas con un símbolo +.Normalmente, el comando ggplot() incluye el argumento data = para el gráfico. Esto establece el conjunto de datos que se utilizará de manera predeterminada para las capas posteriores del gráfico.Este comando terminará con un + después de su paréntesis de cierre. Esto deja el comando “abierto”. El ggplot sólo se ejecutará/aparecerá cuando el comando completo incluya una capa final sin un + al final.","code":"\n# Esto creará un lienzo en blanco\nggplot(data = linelist)"},{"path":"ggplot-basics.html","id":"geoms","chapter":"30 Conceptos básicos de ggplot","heading":"30.4 Geoms","text":"Un lienzo en blanco es suficiente: necesitamos crear geometrías (formas o tipos de gráfico) partir de nuestros datos (por ejemplo, gráficos de barras, histogramas, gráficos de dispersión, gráficos de caja).Esto se hace añadiendo capas “geoms” al comando inicial ggplot(). Hay muchas funciones de ggplot2 que crean “geoms”. Cada una de estas funciones comienza con “geom_”, por lo que nos referiremos ellas genéricamente como geom_XXXX(). Hay más de 40 geoms disponibles en ggplot2 y muchos otros creados por fans. Míralos en la galería de ggplot2. Algunos geoms de uso común se enumeran continuación:Histogramas - geom_histogram()Gráficos de barras - geom_bar() o geom_col() (véase la sección “Gráfico de barras”)Gráficos de caja - geom_boxplot()Puntos (por ejemplo, gráficos de dispersión) - geom_point()Gráficos de líneas - geom_line() o geom_path()Líneas de tendencia - geom_smooth()En un gráfico se pueden exponer uno o varios geoms. Cada uno se añade los comandos anteriores de ggplot2 con un +, y se agregan secuencialmente de manera que los geoms posteriores se trazan encima de los anteriores.","code":""},{"path":"ggplot-basics.html","id":"ggplot_basics_mapping","chapter":"30 Conceptos básicos de ggplot","heading":"30.5 Asignación de datos al gráfico","text":"la mayoría de las funciones geom hay que darle instrucciones sobre qué elementos utilizar para crear sus formas, por lo que hay que indicarles cómo se deben asignar las columnas de los datos los distintos componentes del gráfico, como los ejes, los colores de las formas, los tamaños de las formas, etc. Para la mayoría de las funciones geom, los componentes esenciales que deben asignarse las columnas de los datos son el eje-x y (si es necesario) el eje-y.Este “mapeo” (o asignación) se produce con el argumento mapping =. Los mapeos que proporciones mapping deben estar envueltos en la función aes(), por lo que hay que escribir algo como mapping = aes(x = col1, y = col2), como se muestra continuación.continuación, en el comando ggplot() los datos se identifican utilizando el termino linelist . En el argumento mapping = aes() la columna age se asigna al eje-x, y la columna wt_kg se asigna al eje-y.Después de agregar un +, los comandos de trazado pueden continuar. Se crea una forma o tipo de gráfico con la función de “geom” denominada geom_point(). Este geom hereda los mapeos del comando ggplot() anterior - conoce las asignaciones eje-columna y procede visualizar esas relaciones como puntos en el lienzo.Otro ejemplo que presentamos continuación demuestra el uso de los mismos datos pero con un mapeo ligeramente diferente y utilizando un geom diferente. Ahora utilizamos la función geom_histogram() que sólo requiere una columna mapeada en el eje-x, ya que el eje-y de conteo de casos (‘count’) se genera automáticamente.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+\n  geom_point()\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()"},{"path":"ggplot-basics.html","id":"estética-del-gráfico","chapter":"30 Conceptos básicos de ggplot","heading":"Estética del gráfico","text":"En la terminología de ggplot, la “estética” de un gráfico tiene un significado específico. Se refiere una propiedad visual de los datos trazados. Ten en cuenta que “estética” aquí se refiere los datos que se trazan en geoms / formas - lo que aparece en la periferia, tales como títulos, etiquetas de los ejes, el color de fondo, como podría comúnmente asociarse con la palabra “estética”. En ggplot esos detalles se llaman “temas” y se ajustan dentro de un comando denominado theme() (ver esta sección).Por lo tanto, la estética de los objetos de ploteo puede ser colores, tamaños, transparencias, colocación, etc. de los datos ploteados. todos los geoms tendrán las mismas opciones estéticas, pero muchas pueden ser utilizadas por la mayoría de los geoms. aquí algunos ejemplos:shape = Representar un punto con geom_point() con forma de punto, estrella, triángulo o cuadrado…fill = El color interior (por ejemplo, de una barra o boxplot)color = El color de la línea exterior o borde de una barra, boxplot, etc., o el color del perimetro del punto si se utiliza geom_point()size = El tamaño (por ejemplo, grosor de línea, tamaño de punto)alpha = Transparencia (1 = opaco, 0 = invisible)binwidth = Ancho de los bins (o cubos) del histogramawidth = Ancho de las columnas del “diagrama de barras”linetype = Tipo de línea (por ejemplo, sólida, discontinua, punteada)esta estética de los objetos del gráfico se le pueden asignar valores de dos maneras:Se asigna un valor estático (por ejemplo, color = \"blue\") que se aplica todas las observaciones trazadasSe asigna un valor estático (por ejemplo, color = \"blue\") que se aplica todas las observaciones trazadasSe asigna una columna de los datos (por ejemplo, color = hospital) de manera que la visualización de cada observación depende de su valor en esa columnaSe asigna una columna de los datos (por ejemplo, color = hospital) de manera que la visualización de cada observación depende de su valor en esa columna","code":""},{"path":"ggplot-basics.html","id":"asignar-un-valor-estático","chapter":"30 Conceptos básicos de ggplot","heading":"Asignar un valor estático","text":"Si se desea que la estética del objeto de trazado sea estática, es decir, que sea la misma para cada observación de los datos, se escribe su asignación dentro del geom pero fuera del comando mapping = aes(). Estas asignaciones podrían escribirse como size = 1 o color = \"blue\". Aquí hay dos ejemplos:En el primer ejemplo, el mapping = aes() está en el comando ggplot() y los ejes se asignan las columnas de edad (age) y peso (wt_kg) en los datos. La estética del gráfico color =, size =, y alpha = (transparencia) se asignan valores estáticos. Aclaramos que la asignación de valores estéticos de naturaleza estática se hace en la función geom_point(), ya que se pueden añadir otros geoms después que tomarían valores estéticos diferentesEn el primer ejemplo, el mapping = aes() está en el comando ggplot() y los ejes se asignan las columnas de edad (age) y peso (wt_kg) en los datos. La estética del gráfico color =, size =, y alpha = (transparencia) se asignan valores estáticos. Aclaramos que la asignación de valores estéticos de naturaleza estática se hace en la función geom_point(), ya que se pueden añadir otros geoms después que tomarían valores estéticos diferentesEn el segundo ejemplo, el histograma requiere sólo el eje-x mapeado una columna. El binwidth = (el ancho de los cubos), el color = (el color del borde de los cubos), el fill = (color interno o color de relleno de los cubos), y el alpha = (la transparencia del color de los cubos) se establecen dentro del geom como valores estáticos.En el segundo ejemplo, el histograma requiere sólo el eje-x mapeado una columna. El binwidth = (el ancho de los cubos), el color = (el color del borde de los cubos), el fill = (color interno o color de relleno de los cubos), y el alpha = (la transparencia del color de los cubos) se establecen dentro del geom como valores estáticos.","code":"\n# scatterplot\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  # establecer datos y ejes de mapeo\n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)         # establecer la estética de los puntos estáticos\n\n# histogram\nggplot(data = linelist, mapping = aes(x = age))+       # establecer datos y ejes\n  geom_histogram(              # mostrar histograma\n    binwidth = 7,                # anchura de los bins (cuadrados)\n    color = \"red\",               # color de la línea del bin\n    fill = \"blue\",               # color del interior del bin\n    alpha = 0.1)                 # transparencia del bin"},{"path":"ggplot-basics.html","id":"escalado-a-los-valores-de-la-columna","chapter":"30 Conceptos básicos de ggplot","heading":"Escalado a los valores de la columna","text":"Como alternativa al uso de estéticas de naturaleza estática, se pueden graficar objetos con tamaños proporcionales sus valores como aparecen en su respectiva columna. Con este enfoque, la visualización de esta estética dependerá del valor de esa observación en la columna de datos correspondiente. Si los valores de la columna son continuos, la escala de visualización (en la leyenda) para esa estética será continua. Si los valores de la columna son discretos, la leyenda mostrará cada valor y los datos trazados aparecerán claramente “agrupados” (lea más en la sección de agrupación de esta página).Para conseguir esto, se asigna esa estética de gráfico un nombre de columna o variable (sin utilizar comillas). Esto debe hacerse dentro del comando mapping = aes()(nota: hay varios lugares en el código donde puedes hacer estas asignaciones de mapeo, como se discute continuación).Presentamos dos ejemplos continuación.En el primer ejemplo, la estética d color = (de cada punto) está mapeada la columna age - ¡y ha aparecido una escala en una leyenda! Por ahora sólo hay que tener en cuenta que la escala existe - mostraremos cómo modificarla en secciones posteriores.En el segundo ejemplo, dos nuevas estéticas de trazado se asignan columnas (color = y size =), mientras que las estéticas de trazado shape = y alpha = se asignan valores estáticos fuera de cualquier función de mapping = aes().Nota: Los ejes siempre se asignan las columnas de los datos o variables (los valores estáticos), y esto se hace siempre dentro de mapping = aes().Es importante mantener un seguimiento de las capas y las estéticas se hacen gráficos más complejos, por ejemplo, gráficos con múltiples geom. En el ejemplo siguiente, la estetica size = se asigna dos veces - una para geom_point() y otra para geom_smooth() - ambas veces como un valor estático.","code":"\n# scatterplot\nggplot(data = linelist,   # establecer los datos\n       mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad             \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age)     # asignar el color a la edad\n       )+     \n  geom_point()         # mostrar los datos como puntos \n\n# scatterplot\nggplot(data = linelist,   # establecer los datos\n       mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad            \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age,       # asignar el color a la edad\n         size = age))+      # asignar el tamaño a la edad\n  geom_point(             # mostrar los datos como puntos\n    shape = \"diamond\",      # los puntos se muestran como diamantes\n    alpha = 0.3)            # transparencia de los puntos al 30%\nggplot(data = linelist,\n       mapping = aes(           # asignar la estética a las columnas\n         x = age,\n         y = wt_kg,\n         color = age_years)\n       ) + \n  geom_point(                   # añadir puntos para cada fila de datos\n    size = 1,\n    alpha = 0.5) +  \n  geom_smooth(                  # añadir una línea de tendencia  \n    method = \"lm\",             # con método lineal\n    size = 2)                   # tamaño (ancho de la línea) de 2"},{"path":"ggplot-basics.html","id":"ggplot_basics_map_loc","chapter":"30 Conceptos básicos de ggplot","heading":"Dónde hacer las asignaciones","text":"La asignación de estéticas dentro de mapping = aes() puede hacerse en varios lugares en sus comandos e incluso puede escribirse más de una vez. Esto puede ser escrito en el comando ggplot() inicial, y/o en cada geom individual debajo. Los matices incluyen:Las asignaciones de estéticas realizadas en el comando ggplot() inicial se heredarán por defecto en cualquier geom continuación, al igual que se heredan x = e y =Las asignaciones de estéticas realizadas en el comando ggplot() inicial se heredarán por defecto en cualquier geom continuación, al igual que se heredan x = e y =Las asignaciones realizadas dentro de un geom se aplican sólo ese geomLas asignaciones realizadas dentro de un geom se aplican sólo ese geomDel mismo modo, el comando data = especificado en el ggplot() inicial se aplicará por defecto cualquier geom que se agregue continuación, pero también se podrían especificar datos para cada geom (pero esto es más difícil).Así, cada uno de los siguientes comandos creará el mismo gráfico:","code":"\n# Estos comandos producirán exactamente el mismo gráfico\nggplot(data = linelist, mapping = aes(x = age))+\n  geom_histogram()\n\nggplot(data = linelist)+\n  geom_histogram(mapping = aes(x = age))\n\nggplot()+\n  geom_histogram(data = linelist, mapping = aes(x = age))"},{"path":"ggplot-basics.html","id":"ggplotgroups","chapter":"30 Conceptos básicos de ggplot","heading":"Grupos","text":"Puedes agrupar fácilmente los datos y “graficar por grupo”. De hecho, ¡ya lo hecho!Asigna la columna que quieres agrupar la estética adecuada, dentro del comando mapping = aes(). Más arriba hemos mostrado esto usando valores continuos cuando asignamos el tamaño del punto usando size = la columna age. Sin embargo, esto funciona de la misma manera con columnas o variables discretas/categóricas.Por ejemplo, si quieres agrupar los puntos por género asignándole un color distinto cada genero, deberás establecer mapping = aes(color = gender). Automáticamente aparecerá una leyenda. Esta asignación puede hacerse dentro de mapping = aes() en el comando ggplot() inicial (y ser heredado por el geom), o podría asignarse dentro de mapping = aes() escrito dentro del comando de geom. Ambos enfoques se muestran continuación:Tené en cuenta que dependiendo del tipo de geom, tendrás que utilizar diferentes argumentos para agrupar los datos. Para geom_point() lo más probable es que tengas que utilizar color =, shape = o size =. Mientras que para geom_bar() es más probable que utilices fill =. Esto dependerá del tipo de geom y de la estética del gráfico que deses usar para reflejar las agrupaciones.Para tu información - la forma más básica de agrupar los datos es utilizando sólo el argumento group = dentro de mapping = aes(). Sin embargo, esto por sí mismo cambiará los colores, el relleno o las formas. Tampoco creará una leyenda. Sin embargo, los datos están agrupados, por lo que las visualizaciones estadísticas pueden verse afectadas.Para ajustar el orden de los grupos en un gráfico, consulta la página de Consejos de ggplot o la página sobre Factores. Hay muchos ejemplos de gráficos agrupados en las secciones siguientes sobre el trazado de datos continuos y categóricos.","code":"\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg, color = gender))+\n  geom_point(alpha = 0.5)\n# Este código alternativo produce el mísmo gráfico\nggplot(data = linelist,\n       mapping = aes(x = age, y = wt_kg))+\n  geom_point(\n    mapping = aes(color = gender),\n    alpha = 0.5)"},{"path":"ggplot-basics.html","id":"ggplot_basics_facet","chapter":"30 Conceptos básicos de ggplot","heading":"30.6 Facetas / Múltiplos pequeños","text":"Las facetas, o “pequeños gráficos múltiples”, se utilizan para dividir un gráfico en una figura de varios paneles, con un panel (“faceta”) representando un grupo de datos. El mismo tipo de gráfico se crea varias veces, cada vez utilizando un subgrupo del mismo conjunto de datos.El facetado es una funcionalidad que viene con ggplot2, por lo que las leyendas y los ejes de los paneles facetados se alinean automáticamente. Hay otros paquetes que abordamos en la página de Consejos de ggplot que se utilizan para combinar gráficos representando conjuntos de datos completamente diferentes (cowplot y patchwork) en una figura.El facetado se realiza con una de las siguientes funciones de ggplot2:facet_wrap() Para mostrar un panel diferente para cada nivel de una unica variable. Un ejemplo de esto podría ser mostrar una curva de epidemia diferente para cada hospital de una región. Las facetas se ordenan alfabéticamente, menos que la variable sea un factor con otro orden definido.Puedes invocar ciertas opciones para determinar la disposición de las facetas, por ejemplo, nrow = 1 o ncol = 1 para controlar el número de filas o columnas en las que se organizan los gráficos con facetas.facet_grid() Se utiliza cuando se quiere introducir una segunda variable en la disposición de las facetas. Aquí cada panel de una cuadrícula muestra la intersección entre los valores de dos columnas. Por ejemplo, las curvas epidémicas para cada combinación hospital-grupo de edad con los hospitales en la parte superior (columnas) y los grupos de edad en los lados (filas).nrow y ncol son relevantes, ya que los subgrupos se presentan en una cuadrículaCada una de estas funciones acepta una sintaxis de fórmula para especificar la(s) columna(s) para el facetado. Ambas aceptan hasta dos columnas, una cada lado de la tilde ~.Para facet_wrap() lo más frecuente es escribir una sola columna precedida de una tilde ~ como facet_wrap(~hospital). Sin embargo, puedes escribir dos columnas facet_wrap(outcome~hospital) - cada combinación única se mostrará en un panel separado, pero se organizarán en una cuadrícula. Los encabezados mostrarán los términos combinados y éstos tendrán una lógica específica para las columnas frente las filas. Si quieres proporcionar una sóla variable de facetado, debes utilizar un punto . como marcador de posición en el otro lado de la fórmula - mira los ejemplos de código.Para facet_wrap() lo más frecuente es escribir una sola columna precedida de una tilde ~ como facet_wrap(~hospital). Sin embargo, puedes escribir dos columnas facet_wrap(outcome~hospital) - cada combinación única se mostrará en un panel separado, pero se organizarán en una cuadrícula. Los encabezados mostrarán los términos combinados y éstos tendrán una lógica específica para las columnas frente las filas. Si quieres proporcionar una sóla variable de facetado, debes utilizar un punto . como marcador de posición en el otro lado de la fórmula - mira los ejemplos de código.Para facet_grid() también puedes especificar una o dos columnas en la fórmula (rows ~ columns). Si sólo quieres especificar una, puedes colocar un punto . al otro lado de la tilde como facet_grid(. ~ hospital) o facet_grid(hospital ~ .).Para facet_grid() también puedes especificar una o dos columnas en la fórmula (rows ~ columns). Si sólo quieres especificar una, puedes colocar un punto . al otro lado de la tilde como facet_grid(. ~ hospital) o facet_grid(hospital ~ .).Las facetas pueden contener rápidamente una cantidad abrumadora de información, por lo que conviene asegurarse de tener demasiados niveles de cada variable por la que se elija hacer la faceta. aquí algunos ejemplos rápidos con el conjunto de datos sobre la malaria (véase Descargar el manual y los datos), que consiste en el recuento diario de casos de malaria en los centros, por grupos de edad.continuación importamos y hacemos algunas modificaciones rápidas para simplificar la tarea:continuación se muestran las primeras 50 filas de los datos sobre la malaria. Observa que hay una columna malaria_tot, pero también columnas para los recuentos por grupo de edad (que se utilizarán en el segundo ejemplo de facet_grid()).","code":"\n# Estos datos son recuentos diarios de casos de paludismo, por centro-día\nmalaria_data <- import(here(\"data\", \"malaria_facility_count_data.rds\")) %>%  # importa\n  select(-submitted_date, -Province, -newid)                                 # elimina columnas innecesarias"},{"path":"ggplot-basics.html","id":"facet_wrap","chapter":"30 Conceptos básicos de ggplot","heading":"facet_wrap()","text":"Por el momento, vamos centrarnos en las columnas malaria_tot y District. Ignoremos por ahora las columnas de recuento por edad. Trazaremos las curvas epidémicas con geom_col(), que produce una columna para cada día la altura del eje-y especificada en la columna malaria_tot (los datos ya son recuentos diarios, por lo que utilizamos geom_col() - véase más adelante la sección “Diagrama de barras”).Cuando añadimos el comando facet_wrap(), especificamos una tilde y continuación la columna sobre la que hacer la faceta (District en este caso). Podés colocar otra columna la izquierda de la tilde, - esto creará una faceta para cada combinación - pero te recomendamos que lo hagas con facet_grid() en su lugar. En este caso, se crea una faceta para cada valor único de District.","code":"\n# Un gráfico con facetas por distrito\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # graficar los datos de recuento en forma de columnas\n  theme_minimal()+                              # simplificar los paneles de fondo\n  labs(                                         # añadir al gráfico etiquetas, título, etc.\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district\") +\n  facet_wrap(~District)                       # se crean las facetas"},{"path":"ggplot-basics.html","id":"facet_grid","chapter":"30 Conceptos básicos de ggplot","heading":"facet_grid()","text":"Podemos utilizar un enfoque de facet_grid() para cruzar dos variables. Digamos que queremos cruzar District y edad. Bien, necesitamos hacer algunas transformaciones de datos en las columnas de edad para poner estos datos en el formato “largo” preferido por ggplot. Los grupos de edad tienen sus propias columnas - los queremos en una sola columna llamada age_group y otra llamada num_cases. Consulta la página sobre Pivoteo de datos para obtener más información sobre este proceso.Ahora las primeras 50 filas de datos tienen este aspecto:Cuando se asignan las dos variables facet_grid(), lo más fácil es utilizar la notación de fórmula (por ejemplo, x ~  y) donde x son filas e y son columnas. Aquí está el gráfico, utilizando facet_grid() que muestra los gráficos para cada combinación de las columnas age_group y District.","code":"\nmalaria_age <- malaria_data %>%\n  select(-malaria_tot) %>% \n  pivot_longer(\n    cols = c(starts_with(\"malaria_rdt_\")),  # elegir columnas para pivotar más largo\n    names_to = \"age_group\",      # los nombres de las columnas se convierten en grupos de edad\n    values_to = \"num_cases\"      # valores a una sola columna (num_cases)\n  ) %>%\n  mutate(\n    age_group = str_replace(age_group, \"malaria_rdt_\", \"\"),\n    age_group = forcats::fct_relevel(age_group, \"5-14\", after = 1))\nggplot(malaria_age, aes(x = data_date, y = num_cases)) +\n  geom_col(fill = \"darkred\", width = 1) +\n  theme_minimal()+\n  labs(\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Casos de malaria por distrito y grupo de edad\"\n  ) +\n  facet_grid(District ~ age_group)"},{"path":"ggplot-basics.html","id":"ejes-libres-o-fijos","chapter":"30 Conceptos básicos de ggplot","heading":"Ejes libres o fijos","text":"Las escalas de los ejes que se muestran en gráficos facetados son, por defecto, las mismas (fijas) en todas las facetas. Esto es útil para las comparaciones cruzadas, pero siempre es apropiado.Al utilizar facet_wrap() o facet_grid(), podemos añadir scales = \"free_y\" para “liberar” los ejes-y de los paneles para que se ajuste la escala adecuadamente en relación su subconjunto de datos. Esto es particularmente útil si los recuentos reales son pequeños para una de las subcategorías y las tendencias son difíciles de ver. En lugar de “free_y” también podemos escribir “free_x” para hacer lo mismo con el eje-x (por ejemplo, para las fechas) o “free” para liberar ambos ejes. Ten en cuenta que en facet_grid, las escalas de y serán las mismas para las facetas en la misma fila, y las escalas de x serán las mismas para las facetas en la misma columna.Cuando se utiliza facet_grid solamente, podemos añadir space = \"free_y\" o space = \"free_x\" para que la altura o el ancho de la faceta sea ponderada en relación los valores de la figura en su interior. Esto sólo funciona si ya se ha asignado scale = \"free\" (y o x).","code":"\n# Free y-axis\nggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1, fill = \"darkred\") +       # graficar los datos de recuento en forma de columnas\n  theme_minimal()+                              # simplificar los paneles de fondo\n  labs(                                         # añadir al gráfico etiquetas, título, etc..\n    x = \"Date of report\",\n    y = \"Malaria cases\",\n    title = \"Malaria cases by district - 'free' x and y axes\") +\n  facet_wrap(~District, scales = \"free\")        # se crean las facetas"},{"path":"ggplot-basics.html","id":"orden-del-nivel-de-los-factores-en-las-facetas","chapter":"30 Conceptos básicos de ggplot","heading":"Orden del nivel de los factores en las facetas","text":"Consulta esta entrada sobre cómo reordenar los niveles de los factores dentro de las facetas.","code":""},{"path":"ggplot-basics.html","id":"storing-plots","chapter":"30 Conceptos básicos de ggplot","heading":"30.7 Almacenamiento de gráficos","text":"","code":""},{"path":"ggplot-basics.html","id":"guardar-los-gráficos","chapter":"30 Conceptos básicos de ggplot","heading":"Guardar los gráficos","text":"Cuando se ejecuta un comando ggplot(), el gráfico se mostrará en el panel de Plots RStudio de manera predeterminada. Sin embargo, también podés guardar el gráfico como un objeto utilizando el operador de asignación <- y asignandole un nombre. Entonces el gráfico se mostrará menos que se ejecute el nombre del objeto mismo. También podés mostrarlo envolviendo el nombre del gráfico con print(), pero esto sólo es necesario en ciertas circunstancias, como cuando el gráfico se crea dentro de un loop o bucle utilizado para imprimir múltiples gráficos la vez (véase la página Iteración, bucles y listas ).","code":"\n# define plot\nage_by_wt <- ggplot(data = linelist, mapping = aes(x = age_years, y = wt_kg, color = age_years))+\n  geom_point(alpha = 0.1)\n\n# print\nage_by_wt    "},{"path":"ggplot-basics.html","id":"modificación-de-gráficos-guardados","chapter":"30 Conceptos básicos de ggplot","heading":"Modificación de gráficos guardados","text":"Una gran ventaja de ggplot2 es que podés definir un gráfico (como se ve arriba), y luego añadirle capas empezando por su nombre sin necesidad de repetir todos los comandos que crearon el gráfico original.Por ejemplo, si se desea modificar el gráfico age_by_wt que se definió anteriormente, para incluir una línea vertical la edad de 50 años, sólo tendríamos que añadir un + y empezar añadir capas adicionales al gráfico.","code":"\nage_by_wt+\n  geom_vline(xintercept = 50)"},{"path":"ggplot-basics.html","id":"exportación-de-gráficos","chapter":"30 Conceptos básicos de ggplot","heading":"Exportación de gráficos","text":"La exportación de ggplots es fácil con la función ggsave() de ggplot2. Puede funcionar de dos maneras, ya sea:Especifica el nombre del objeto del gráfico, continuación, la ruta del archivo y el nombre del archivo incluyendo la extensión\nPor ejemplo: ggsave(my_plot, (\"plots\", \"my_plot.png\"))\nPor ejemplo: ggsave(my_plot, (\"plots\", \"my_plot.png\"))Ejecuta el comando con sólo una ruta de archivo, para guardar el último gráfico que se imprimió en pantalla\nPor ejemplo: ggsave((\"plots\", \"my_plot.png\"))\nPor ejemplo: ggsave((\"plots\", \"my_plot.png\"))Puedes exportar como png, pdf, jpeg, tiff, bmp, svg, o varios otros tipos de archivos, especificando la extensión del archivo en la ruta del mismo.También puedes especificar los argumentos width =, height = y units = (ya sea “”, “cm” o “mm”). Asimismo podés especificar dpi = asignando un número para la resolución del trazado (por ejemplo, 300). Consulta los detalles de la función ejecutando ?ggsave o leyendo la documentación en línea.Recuerda que podés utilizar la sintaxis () para proporcionar la ruta de archivo deseada. Consulta la página de importación y exportación para obtener más información.","code":""},{"path":"ggplot-basics.html","id":"labels","chapter":"30 Conceptos básicos de ggplot","heading":"30.8 Etiquetas","text":"Seguramente querrás añadir o ajustar las etiquetas del gráfico. Esto se hace más fácilmente dentro de la función labs() que se añade al gráfico con + al igual que los geoms.Dentro de labs() podes proporcionar cadenas de caracteres estos argumentos:x = e y = El título del eje-x y del eje-y (etiquetas)title = El título del gráfico principalsubtitle = El subtítulo del gráfico, en texto más pequeño debajo del títulocaption = El pie del gráfico, que aparecerá en la parte inferior derecha de manera predeterminadaAquí está el mismo gráfico que hicimos antes, pero con etiquetas más bonitas:Observa cómo en la asignación del pie del gráfico hemos utilizado str_glue() del paquete stringr para integrar código R dinámico dentro del texto de la cadena. El pie del gráfico mostrará la fecha “Datos partir de:” que refleja la fecha máxima de hospitalización en el listado de datos. Puedes leer más sobre esto en la página sobre Caracteres y cadenas.Una nota sobre la especificación del título de la leyenda: hay un argumento “título de la leyenda”, ya que podrías tener múltiples escalas en tu leyenda. Dentro de labs(), podes escribir el argumento de la estética del gráfico utilizado para crear la leyenda, y proporcionar el título de esta manera. Por ejemplo, arriba asignamos color = age para crear la leyenda. Por lo tanto, proporcionamos color = labs() y asignamos el título de la leyenda deseado (“Age” con mayúscula). Si se crea la leyenda con aes(fill = COLUMN), entonces en labs() se escribiría fill = para ajustar el título de esa leyenda. La sección sobre escalas de color en la página Consejos de ggplot proporciona más detalles sobre la edición de leyendas, y un enfoque alternativo utilizando las funciones scales_().","code":"\nage_by_wt <- ggplot(\n  data = linelist,   # establecer los datos\n  mapping = aes(     # asignar la estética a los valores de la columna\n         x = age,           # asigna el eje-x a la edad             \n         y = wt_kg,         # asignar el eje-y al peso\n         color = age))+     # asignar el color a la edad\n  geom_point()+           # mostrar los datos como puntos \n  labs(\n    title = \"Age and weight distribution\",\n    subtitle = \"Fictional Ebola outbreak, 2014\",\n    x = \"Age in years\",\n    y = \"Weight in kilos\",\n    color = \"Age\",\n    caption = stringr::str_glue(\"Data as of {max(linelist$date_hospitalisation, na.rm=T)}\"))\n\nage_by_wt"},{"path":"ggplot-basics.html","id":"ggplot_basics_themes","chapter":"30 Conceptos básicos de ggplot","heading":"30.9 Temas","text":"Una de las mejores partes de ggplot2 es el nivel de control que tienes sobre el gráfico - ¡puedes definir lo que quieras! Como se mencionó anteriormente, los aspectos de diseño del gráfico que están relacionados con las formas/geometrías de los datos se ajustan dentro de la función theme(). Por ejemplo, el color de fondo del gráfico, la presencia/ausencia de líneas de cuadrícula, y la fuente/tamaño/color/alineación del texto (títulos, subtítulos, pie de gráfico, texto de los ejes…). Estos ajustes pueden realizarse de dos maneras:Añadiendo una función theme_() completa para realizar ajustes de barrido – estas funciones de tema completo incluyen theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() entre otrasAñadiendo una función theme_() completa para realizar ajustes de barrido – estas funciones de tema completo incluyen theme_classic(), theme_minimal(), theme_dark(), theme_light() theme_grey(), theme_bw() entre otrasAjustando cada pequeño aspecto del gráfico individualmente dentro de theme()Ajustando cada pequeño aspecto del gráfico individualmente dentro de theme()","code":""},{"path":"ggplot-basics.html","id":"temas-completos","chapter":"30 Conceptos básicos de ggplot","heading":"Temas completos","text":"Como son bastante sencillas, demostraremos las funciones del tema completo continuación y las describiremos más aquí. Ten en cuenta que cualquier microajuste con theme() debe hacerse después de utilizar un tema completo.Escribílos con paréntesis vacíos.","code":"\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme classic\")+\n  theme_classic()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme bw\")+\n  theme_bw()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme minimal\")+\n  theme_minimal()\n\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+  \n  geom_point(color = \"darkgreen\", size = 0.5, alpha = 0.2)+\n  labs(title = \"Theme gray\")+\n  theme_gray()"},{"path":"ggplot-basics.html","id":"modificar-el-tema","chapter":"30 Conceptos básicos de ggplot","heading":"Modificar el tema","text":"La función theme() puede tomar un gran número de argumentos, cada uno de los cuales edita un aspecto específico del gráfico. hay manera de que podamos cubrir todos los argumentos, pero describiremos el patrón general para ellos y te mostraremos cómo encontrar el nombre del argumento que necesitas. La sintaxis básica es esta:Dentro de theme() escribe el nombre del argumento del elemento del gráfico que queres editar, como plot.title =Proporciona una función element_() al argumento\nLo más habitual es utilizar element_text(), pero también element_rect() para los colores de fondo del lienzo, o element_blank() para eliminar los elementos del gráfico\nLo más habitual es utilizar element_text(), pero también element_rect() para los colores de fondo del lienzo, o element_blank() para eliminar los elementos del gráficoDentro de la función element_(), escribí las asignaciones de argumentos para realizar los ajustes finos que deseesEsa descripción es bastante abstracta, así que aquí hay algunos ejemplos.El siguiente gráfico parece tonto, pero sirve para mostrarte una variedad de formas en las que podés ajustar su gráfico.Comenzamos con el gráfico age_by_wt definido anteriormente y añadimos theme_classic()Para realizar ajustes más finos, añadimos theme() e incluimos un argumento por cada elemento del gráfico que queremos ajustarPuede ser util organizar los argumentos en secciones lógicas. continuación se describen algunos argumentos utilizados:legend.position = es el único argumento que acepta valores simples como “bottom”, “top”, “left”, y “right” (abajo, arriba, izquierda y derecha). Por lo general, los argumentos relacionados con el texto requieren que se coloquen los detalles dentro de element_text().Tamaño del título se ajusta con element_text(size = 30)La alineación horizontal del pie del gráfico se logra con el argumento element_text(hjust = 0) (de derecha izquierda)El subtítulo aparece en cursiva gracias al argumento element_text(face = \"italic\")Aquí hay algunos argumentos de theme() especialmente comunes. Reconocerás algunos patrones, como añadir .x o .y para aplicar el cambio sólo un eje.Pero ¡hay tantos argumentos de tema! ¿Cómo podría recordarlos todos? te preocupes, es imposible recordarlos todos. Por suerte, hay algunas herramientas que te ayudarán:La documentación de tidyverse sobre la modificación del tema, tiene una lista completa.CONSEJO: Ejecuta theme_get() de ggplot2 para imprimir en pantalla una lista de los más de 90 argumentos de theme() en la consola.CONSEJO: Si alguna vez quieres eliminar un elemento de un gráfico, también puedes hacerlo través de theme(). Basta con pasar element_blank() un argumento para que desaparezca por completo. Para eliminar leyendas, puedes asignar legend.position = \"none\".","code":"\nage_by_wt + \n  theme_classic()+                                 # ajustes temáticos predefinidos\n  theme(\n    legend.position = \"bottom\",                    # mover la leyenda a la parte inferior\n    \n    plot.title = element_text(size = 30),          # tamaño del título a 30\n    plot.caption = element_text(hjust = 0),        # alinear el título a la izquierda\n    plot.subtitle = element_text(face = \"italic\"), # poner en cursiva el subtítulo\n    \n    axis.text.x = element_text(color = \"red\", size = 15, angle = 90), # ajustar sólo el texto del eje-x\n    axis.text.y = element_text(size = 15),         # ajustar sólo el texto del eje-y\n    \n    axis.title = element_text(size = 20)           # ajusta los títulos de ambos ejes\n    )     "},{"path":"ggplot-basics.html","id":"colors","chapter":"30 Conceptos básicos de ggplot","heading":"30.10 Colores","text":"Consulta esta sección sobre las escalas de color de la página de consejos de ggplot.","code":""},{"path":"ggplot-basics.html","id":"piping-into-ggplot2","chapter":"30 Conceptos básicos de ggplot","heading":"30.11 Pipes en ggplot2","text":"Cuando se utilizan pipes para limpiar y transformar los datos, es fácil pasar los datos transformados ggplot().Las pipes que pasan el conjunto de datos de función función se convertiran + una vez que se invoque la función ggplot(). Ten en cuenta que, en este caso, es necesario especificar el argumento data =, ya que éste se define automáticamente como el conjunto de datos canalizado.Así es como podría verse:","code":"\nlinelist %>%                                                     # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )"},{"path":"ggplot-basics.html","id":"plot-continuous-data","chapter":"30 Conceptos básicos de ggplot","heading":"30.12 Trazado de datos continuos","text":"lo largo de esta página, ya visto muchos ejemplos de trazado de datos continuos. Aquí los consolidamos brevemente y presentamos algunas variaciones. Las visualizaciones que aquí se cubren incluyen:Gráficos para una variable continua:\nHistogram, un gráfico clásico para presentar la distribución de una variable continua.\nGráfico de caja (también llamado de caja y bigotes), para mostrar los percentiles 25, 50 y 75, los extremos de la cola de la distribución y los valores atípicos (limitaciones importantes).\nGráfico de fluctuación, para mostrar todos los valores como puntos que se “fluctúan” para que se puedan ver (casi) todos, incluso cuando dos tienen el mismo valor.\nGráfico del violín, muestra la distribución de una variable continua en función del ancho simétrico del “violín”.\nLos gráficos de Sina, son una combinación de los gráficos de jitter y de violín, donde se muestran los puntos individuales pero con la forma simétrica de la distribución (través del paquete ggforce).\nGráfico de dispersión para dos variables continuas.\nGráficos de calor para tres variables continuas (enlazado la página de gráficos de calor)\nHistogram, un gráfico clásico para presentar la distribución de una variable continua.Gráfico de caja (también llamado de caja y bigotes), para mostrar los percentiles 25, 50 y 75, los extremos de la cola de la distribución y los valores atípicos (limitaciones importantes).Gráfico de fluctuación, para mostrar todos los valores como puntos que se “fluctúan” para que se puedan ver (casi) todos, incluso cuando dos tienen el mismo valor.Gráfico del violín, muestra la distribución de una variable continua en función del ancho simétrico del “violín”.Los gráficos de Sina, son una combinación de los gráficos de jitter y de violín, donde se muestran los puntos individuales pero con la forma simétrica de la distribución (través del paquete ggforce).Gráfico de dispersión para dos variables continuas.Gráficos de calor para tres variables continuas (enlazado la página de gráficos de calor)","code":""},{"path":"ggplot-basics.html","id":"histogramas","chapter":"30 Conceptos básicos de ggplot","heading":"Histogramas","text":"Los histogramas pueden parecerse los gráficos de barras, pero son distintos porque miden la distribución de una variable continua. hay espacios entre las “barras”, y sólo se proporciona una columna geom_histogram().continuación se muestra el código para generar histogramas, que agrupan datos continuos en rangos y se muestran en barras adyacentes de altura variable. Esto se hace utilizando geom_histogram(). Consulta la sección “Gráfico de barras” de la página de fundamentos de ggplot para entender la diferencia entre geom_histogram(), geom_bar() y geom_col().Vamos mostrar la distribución de las edades de los casos. Dentro de mapping = aes() especifique la columna de la que quiere ver la distribución. Puedes asignar esta columna al eje-x o al eje-y.Las filas serán asignadas “bins” basados en su edad numérica, y estos bins serán representados gráficamente por barras. Si se especifica un número de bins con la estética de gráfico bins =, los puntos de ruptura se espacian uniformemente entre los valores mínimos y máximos del histograma. Si se especifica bins =, se adivinará un número apropiado de bins y aparecera este mensaje después del gráfico:Si quieres especificar un número de bins bins =, puedes especificar alternativamente binwidth = en las unidades del eje. Damos algunos ejemplos que muestran diferentes bins y anchos de bins:Para obtener proporciones suavizadas, puede utilizar geom_density():get “stacked” histogram (continuous column data), can one following:Use geom_histogram() fill = argument within aes() assigned grouping column, orUse geom_freqpoly(), likely easier read (can still set binwidth =)see proportions values, set y = after_stat(density) (use syntax exactly - changed data). Note: proportions show per group.Cada uno se muestra continuación (*nótese el uso de color = versus fill = en cada uno):Si quieres divertirte un poco, prueba con geom_density_ridges del paquete ggridges vignette aquí.Lee más en detalle sobre los histogramas en la página de tidyverse sobre geom_histogram()","code":"## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n# A) Regular histogram\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram()+\n  labs(title = \"A) Default histogram (30 bins)\")\n\n# B) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 50)+\n  labs(title = \"B) Set to 50 bins\")\n\n# C) Fewer bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(bins = 5)+\n  labs(title = \"C) Set to 5 bins\")\n\n\n# D) More bins\nggplot(data = linelist, aes(x = age))+  # provide x variable\n  geom_histogram(binwidth = 1)+\n  labs(title = \"D) binwidth of 1\")\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional density\")\n\n# Stacked frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_density(size = 2, alpha = 0.2, position = \"stack\")+\n  labs(title = \"'Stacked' proportional densities\")\n# \"Stacked\" histogram\nggplot(data = linelist, mapping = aes(x = age, fill = gender)) +\n  geom_histogram(binwidth = 2)+\n  labs(title = \"'Stacked' histogram\")\n\n# Frequency \nggplot(data = linelist, mapping = aes(x = age, color = gender)) +\n  geom_freqpoly(binwidth = 2, size = 2)+\n  labs(title = \"Freqpoly\")\n\n# Frequency with proportion axis\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), color = gender)) +\n  geom_freqpoly(binwidth = 5, size = 2)+\n  labs(title = \"Proportional freqpoly\")\n\n# Frequency with proportion axis, smoothed\nggplot(data = linelist, mapping = aes(x = age, y = after_stat(density), fill = gender)) +\n  geom_density(size = 2, alpha = 0.2)+\n  labs(title = \"Proportional, smoothed with geom_density()\")"},{"path":"ggplot-basics.html","id":"gráficos-de-caja","chapter":"30 Conceptos básicos de ggplot","heading":"Gráficos de caja","text":"Los gráficos de caja (Boxplot) son habituales, pero tienen limitaciones importantes. Pueden ocultar la distribución real - por ejemplo, una distribución bimodal. Consulta esta galería de gráficos de R y este artículo sobre la visualización de datos para obtener más detalles. Sin embargo, muestran muy bien el rango intercuartil y los valores atípicos, por lo que pueden superponerse otros tipos de gráficos que muestran la distribución con más detalle.continuación te recordamos los distintos componentes de un boxplot:Cuando se utiliza geom_boxplot() para crear un gráfico de caja, generalmente se asigna sólo un eje (x o y) dentro de aes(). El eje especificado determina si los gráficos son horizontales o verticales.En la mayoría de los geoms, se crea un gráfico por grupo asignando una estética como color = o fill = una columna dentro de aes(). Sin embargo, en el caso de los gráficos de caja, esto se consigue asignando la columna de agrupación al eje asignado (x o y). continuación se muestra el código para un diagrama de caja de todos los valores de edad en el conjunto de datos, y un segundo trozo de código para mostrar un diagrama de caja para cada género (ausente) en el conjunto de datos. Ten en cuenta que los valores NA (valores faltantes) aparecerán como un gráfico de caja separado menos que se eliminen. En este ejemplo, también hemos asignado el fill de la columna outcome para que cada gráfico tenga un color diferente, pero esto es necesario.Para ver el código para añadir un gráfico de caja los bordes de un gráfico de dispersión (gráficos “marginales”), consulta la página Consejos de ggplot.","code":"\n# A) Overall boxplot\nggplot(data = linelist)+  \n  geom_boxplot(mapping = aes(y = age))+   # only y axis mapped (not x)\n  labs(title = \"A) Overall boxplot\")\n\n# B) Box plot by group\nggplot(data = linelist, mapping = aes(y = age, x = gender, fill = gender)) + \n  geom_boxplot()+                     \n  theme(legend.position = \"none\")+   # remove legend (redundant)\n  labs(title = \"B) Boxplot by gender\")      "},{"path":"ggplot-basics.html","id":"gráficos-de-violín-fluctuación-y-sina","chapter":"30 Conceptos básicos de ggplot","heading":"Gráficos de violín, fluctuación y sina","text":"continuación se muestra el código para crear gráficos de violín (geom_violin) y gráficos de fluctuación (geom_jitter) para mostrar distribuciones. Se puede especificar que el relleno o el color también estén determinados por los datos, insertando estas opciones dentro de aes().Puedes combinar los dos tipos de gráfico usando la función geom_sina() del paquete ggforce. La sina traza los puntos de jitter en la forma del gráfico de violín. Cuando se superpone al gráfico de violín (ajustando las transparencias) puede ser más fácil de interpretar visualmente.","code":"\n# A) Jitter plot by group\nggplot(data = linelist %>% drop_na(outcome),      # remove missing values\n       mapping = aes(y = age,                     # Continuous variable\n           x = outcome,                           # Grouping variable\n           color = outcome))+                     # Color variable\n  geom_jitter()+                                  # Create the violin plot\n  labs(title = \"A) jitter plot by gender\")     \n\n\n\n# B) Violin plot by group\nggplot(data = linelist %>% drop_na(outcome),       # remove missing values\n       mapping = aes(y = age,                      # Continuous variable\n           x = outcome,                            # Grouping variable\n           fill = outcome))+                       # fill variable (color)\n  geom_violin()+                                   # create the violin plot\n  labs(title = \"B) violin plot by gender\")    \n# A) Sina plot by group\nggplot(\n  data = linelist %>% drop_na(outcome), \n  aes(y = age,           # numeric variable\n      x = outcome)) +    # group variable\n  geom_violin(\n    aes(fill = outcome), # fill (color of violin background)\n    color = \"white\",     # white outline\n    alpha = 0.2)+        # transparency\n### jcfernandezm\n#    geom_sina(\n#    size=1,                # Change the size of the jitter\n#    aes(color = outcome))+ # color (color of dots)\n  scale_fill_manual(       # Define fill for violin background by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  scale_color_manual(      # Define colours for points by death/recover\n    values = c(\"Death\" = \"#bf5300\", \n              \"Recover\" = \"#11118c\")) + \n  theme_minimal() +                                # Remove the gray background\n  theme(legend.position = \"none\") +                # Remove unnecessary legend\n  labs(title = \"B) violin and sina plot by gender, with extra formatting\")      "},{"path":"ggplot-basics.html","id":"dos-variables-continuas","chapter":"30 Conceptos básicos de ggplot","heading":"Dos variables continuas","text":"Siguiendo una sintaxis similar, geom_point() te permitirá trazar dos variables continuas en un gráfico de dispersión. Esto es útil para mostrar los valores reales en lugar de sus distribuciones. En () se muestra un gráfico de dispersión simple de la edad frente al peso. En (B) volvemos utilizar facet_grid() para mostrar la relación entre dos variables continuas.","code":"\n# Basic scatter plot of weight and age\nggplot(data = linelist, \n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"A) Scatter plot of weight and age\")\n\n# Scatter plot of weight and age by gender and Ebola outcome\nggplot(data = linelist %>% drop_na(gender, outcome), # filter retains non-missing gender/outcome\n       mapping = aes(y = wt_kg, x = age))+\n  geom_point() +\n  labs(title = \"B) Scatter plot of weight and age faceted by gender and outcome\")+\n  facet_grid(gender ~ outcome) "},{"path":"ggplot-basics.html","id":"tres-variables-continuas","chapter":"30 Conceptos básicos de ggplot","heading":"Tres variables continuas","text":"Puedes mostrar tres variables continuas utilizando el argumento fill = para crear un gráfico de calor. El color de cada “celda” reflejará el valor de la tercera columna continua de datos. Consulta la página Consejos de ggplot y la página de gráficos de calor para obtener más detalles y varios ejemplos.Hay formas de hacer gráficos en 3D en R, pero para la epidemiología aplicada suelen ser difíciles de interpretar y, por tanto, menos útiles para la toma de decisiones.","code":""},{"path":"ggplot-basics.html","id":"trazar-datos-categóricos","chapter":"30 Conceptos básicos de ggplot","heading":"Trazar datos categóricos","text":"Los datos categóricos pueden ser valores de carácter, pueden ser lógicos (TRUE/FALSE), o factores (ver la página de Factores).","code":""},{"path":"ggplot-basics.html","id":"preparación","chapter":"30 Conceptos básicos de ggplot","heading":"Preparación","text":"","code":""},{"path":"ggplot-basics.html","id":"estructura-de-datos","chapter":"30 Conceptos básicos de ggplot","heading":"Estructura de datos","text":"Lo primero que hay que entender sobre tus datos categóricos es si existen como observaciones en bruto, como una lista de casos, o como un dataframe de resumen o agregado que contiene recuentos o proporciones. El estado de sus datos afectará la función de trazado que utilice:Si tus datos son observaciones en bruto con una fila por observación, es probable que utilices geom_bar()Si sus datos ya están agregados en recuentos o proporciones, es probable que utilices geom_col()","code":""},{"path":"ggplot-basics.html","id":"tipo-de-columna-y-ordenación-de-valores","chapter":"30 Conceptos básicos de ggplot","heading":"Tipo de columna y ordenación de valores","text":"continuación, examina el tipo o clase de las columnas (variables) que desea trazar. Veamos hospital, primero usando class() de R base, y luego con tabyl() de janitor.Podemos ver que los valores de la variable hospital son caracteres, ya que son nombres de hospitales, y por defecto están ordenados alfabéticamente. Hay valores otros y `faltantes”, que preferiríamos que fueran las últimas subcategorías al presentar los desgloses. Así que convertimos esta columna clase factor y la reordenamos. Esto se trata con más detalle en la página de Factores.","code":"\n# View class of hospital column - we can see it is a character\nclass(linelist$hospital)## [1] \"character\"\n# Look at values and proportions within hospital column\n###jcfernandezm\n#linelist %>% \n#  tabyl(hospital)\n# Convert to factor and define level order so \"Other\" and \"Missing\" are last\nlinelist <- linelist %>% \n  mutate(\n    hospital = fct_relevel(hospital, \n      \"St. Mark's Maternity Hospital (SMMH)\",\n      \"Port Hospital\", \n      \"Central Hospital\",\n      \"Military Hospital\",\n      \"Other\",\n      \"Missing\"))\nlevels(linelist$hospital)## [1] \"St. Mark's Maternity Hospital (SMMH)\" \"Port Hospital\"                       \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Other\"                                \"Missing\""},{"path":"ggplot-basics.html","id":"ggplot_basics_bars","chapter":"30 Conceptos básicos de ggplot","heading":"Gráfico de barras","text":"Utiliza geom_bar() si deseas que la altura de las barras (o la altura de los componentes de las barras apiladas) refleje el número de filas relevantes de los datos. Estas barras tendrán huecos entre ellas, menos que se ajuste la estética de width =.Proporciona sólo una asignación de columna de eje (normalmente el eje-x). Si proporcionas x e y, obtendrás un Error: stat_count() can x y aesthetic.Puedes crear barras apiladas añadiendo una asignación de Columba usando fill = dentro de mapping = aes()El eje opuesto se llamará por defecto “count” (recuento), ya que representa el número de filasA continuación, hemos asignado el resultado (outcome) al eje-y, pero podría estar fácilmente asignarse al eje-x. Si tienes valores de caracteres más largos, veces el gráfico se ve mejor si las barras se grafican de manera horizontal en vez de vertical ,poniendo la leyenda en la parte inferior del gráfico. Esto puede afectar el orden en el que aparecen los factores - en este caso los invertimos con fct_rev() para poner la categoría de “faltantes” y “otros” en la parte inferior.","code":"\n# A) Outcomes in all cases\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital)), width = 0.7) +\n  theme_minimal()+\n  labs(title = \"A) Number of cases by hospital\",\n       y = \"Hospital\")\n\n\n# B) Outcomes in all cases by hosptial\nggplot(linelist %>% drop_na(outcome)) + \n  geom_bar(aes(y = fct_rev(hospital), fill = outcome), width = 0.7) +\n  theme_minimal()+\n  theme(legend.position = \"bottom\") +\n  labs(title = \"B) Number of recovered and dead Ebola cases, by hospital\",\n       y = \"Hospital\")"},{"path":"ggplot-basics.html","id":"geom_col","chapter":"30 Conceptos básicos de ggplot","heading":"geom_col()","text":"Utiliza geom_col() si deseas que la altura de las barras (o la altura de los componentes de las barras apiladas) refleje valores precalculados que existen en los datos. menudo, se trata de recuentos sumarios o “agregados”, o de proporciones.Proporciona las asignaciones de columna para ambos ejes geom_col(). Normalmente la columna del eje-x es discreta y la del eje-y es numérica.Digamos que tenemos los un conjunto de datos denominado outcomes:continuación se muestra un código que utiliza geom_col() para crear gráficos de barras sencillos que muestren la distribución de los resultados de los pacientes con Ebola. Con geom_col, es necesario especificar tanto x como y. Aquí x es la variable categórica lo largo del eje-x, e y es la columna de proporciones precalculada denominada proportion.Para mostrar los desgloses por hospital, necesitaríamos que nuestra tabla contuviera más información, y que estuviera en formato “largo”. Creamos esta tabla con las frecuencias de las categorías combinadas outcome y hospital (véase la página de Agrupar datos para obtener consejos de agrupación).continuación, creamos el ggplot añadiendo algunas asignaciones de formato:Cambio de posición del eje: Intercambiamos los ejes con coord_flip() para poder leer los nombres de los hospitales.Columnas de lado lado: Se ha añadido un argumento de position = \"dodge\" para que las barras de muerte (Death) y recuperación (Recover) se presenten una al lado de la otra en lugar de apiladas. Ten en cuenta que las barras apiladas aparecen de manera predeterminada.Ancho de columna: Se especifica el “ancho”, para graficar las columnas la mitad del ancho posible.Orden de las columnas: Se ha invertido el orden de las categorías en el eje-y para que “Otros” y “Faltantes” aparezcan últimos, con scale_x_discrete(limits=rev). Ten en cuenta que usamos eso en lugar de scale_y_discrete porque la variable hospital se asigno al eje-x en el en el argumento de aes(), aunque visualmente se vea en el eje-y. Hacemos esto porque ggplot parece presentar las categorías al revés menos que le digamos que lo haga.Otros detalles: Añadimos etiquetas/títulos y colores dentro de las funciones de labs y scale_fill_color respectivamente.Ten en cuenta que las proporciones son binarias, por lo que podemos preferir omitir recuperar y mostrar sólo la proporción que murió. Esto es sólo título ilustrativo.Si se utiliza geom_col() con datos de fechas (por ejemplo, una epicurva partir de datos agregados) - querrá ajustar el argumento width = para eliminar los “huecos” entre las barras. Si se utilizan datos diarios (en días), ajuste width= 1. Si se trata de datos semanales, la anchura seria width = 7. Los meses son posibles de representar porque cada mes tiene un número diferente de días.","code":"## # A tibble: 2 × 3\n##   outcome     n proportion\n##   <chr>   <int>      <dbl>\n## 1 Death    1022       56.2\n## 2 Recover   796       43.8\n# Outcomes in all cases\nggplot(outcomes) + \n  geom_col(aes(x=outcome, y = proportion)) +\n  labs(subtitle = \"Number of recovered and dead Ebola cases\")\noutcomes2 <- linelist %>% \n  drop_na(outcome) %>% \n  count(hospital, outcome) %>%  # get counts by hospital and outcome\n  group_by(hospital) %>%        # Group so proportions are out of hospital total\n  mutate(proportion = n/sum(n)*100) # calculate proportions of hospital total\n\nhead(outcomes2) # Preview data## # A tibble: 6 × 4\n## # Groups:   hospital [3]\n##   hospital                             outcome     n proportion\n##   <fct>                                <chr>   <int>      <dbl>\n## 1 St. Mark's Maternity Hospital (SMMH) Death     199       61.2\n## 2 St. Mark's Maternity Hospital (SMMH) Recover   126       38.8\n## 3 Port Hospital                        Death     785       57.6\n## 4 Port Hospital                        Recover   579       42.4\n## 5 Central Hospital                     Death     193       53.9\n## 6 Central Hospital                     Recover   165       46.1\n# Outcomes in all cases by hospital\nggplot(outcomes2) +  \n  geom_col(\n    mapping = aes(\n      x = proportion,                 # show pre-calculated proportion values\n      y = fct_rev(hospital),          # reverse level order so missing/other at bottom\n      fill = outcome),                # stacked by outcome\n    width = 0.5)+                    # thinner bars (out of 1)\n  theme_minimal() +                  # Minimal theme \n  theme(legend.position = \"bottom\")+\n  labs(subtitle = \"Number of recovered and dead Ebola cases, by hospital\",\n       fill = \"Outcome\",             # legend title\n       y = \"Count\",                  # y axis title\n       x = \"Hospital of admission\")+ # x axis title\n  scale_fill_manual(                 # adding colors manually\n    values = c(\"Death\"= \"#3B1c8C\",\n               \"Recover\" = \"#21908D\" )) "},{"path":"ggplot-basics.html","id":"geom_histogram","chapter":"30 Conceptos básicos de ggplot","heading":"geom_histogram()","text":"Los histogramas pueden parecerse los gráficos de barras, pero son distintos porque miden la distribución de una variable continua. hay huecos o espacios entre las “barras” y sólo se asigna una columna geom_histogram(). Hay argumentos específicos para los histogramas como bin_width = y breaks = para especificar cómo se deben dividir los datos. La sección anterior sobre datos continuos y la página sobre curvas epidémicas proporcionan detalles adicionales.","code":""},{"path":"ggplot-basics.html","id":"resources-23","chapter":"30 Conceptos básicos de ggplot","heading":"30.13 Recursos","text":"Hay una gran cantidad de ayuda en línea, especialmente sobre ggplot. Consulta las siguietnes páginas con maerial en inglés:hoja de trucos de ggplot2otra hoja de trucospágina de fundamentos de tidyverse ggplottrazado de variables continuaspáginas de R Data Science en español sobre visualización de datosgráficos para la comunicación","code":""},{"path":"ggplot-tips.html","id":"ggplot-tips","chapter":"31 Consejos de ggplot","heading":"31 Consejos de ggplot","text":"En esta página cubriremos consejos y trucos para hacer que tus ggplots sean nítidos y elegantes. Consulta la página sobre Conceptos básicos de ggplot para conocer los fundamentos.Hay varios tutoriales extensos de ggplot2 enlazados en la sección de Recursos. También puedes descargar esta hoja de trucos de visualización de datos con ggplot desde el sitio web de RStudio. Recomendamos encarecidamente que busques inspiración en la galería de gráficos de R y en Data--viz.","code":""},{"path":"ggplot-tips.html","id":"preparation-23","chapter":"31 Consejos de ggplot","heading":"31.1 Preparación","text":"","code":""},{"path":"ggplot-tips.html","id":"cargar-paquetes-20","chapter":"31 Consejos de ggplot","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  tidyverse,      # includes ggplot2 and other\n  rio,            # import/export\n  here,           # file locator\n  stringr,        # working with characters   \n  scales,         # transform numbers\n  ggrepel,        # smartly-placed labels\n  gghighlight,    # highlight one part of plot\n  RColorBrewer    # color scales\n)"},{"path":"ggplot-tips.html","id":"importar-datos-16","chapter":"31 Consejos de ggplot","heading":"Importar datos","text":"Para esta página, importamos el conjunto de datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - ver la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas de linelist.","code":"\nlinelist <- rio::import(\"linelist_cleaned.rds\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_colors","chapter":"31 Consejos de ggplot","heading":"31.2 Escalas para el color, relleno, ejes, etc.","text":"En ggplot2, cuando la estética de los datos trazados (por ejemplo, el tamaño, el color, la forma, el relleno, el eje de trazado) se asigna las columnas de los datos, la visualización exacta se puede ajustar con el correspondiente comando “scale”. En esta sección explicamos algunos ajustes de escala comunes.","code":""},{"path":"ggplot-tips.html","id":"esquemas-de-color","chapter":"31 Consejos de ggplot","heading":"Esquemas de color","text":"Una cosa que puede ser inicialmente difícil de entender con ggplot2 es el control de los esquemas de color. Ten en cuenta que esta sección discute el color de los objetos representar (geoms/shapes) como puntos, barras, líneas, mosaicos, etc. Para ajustar el color del texto accesorio, los títulos o el color de fondo, consulta la sección Temas de la página Conceptos básicos de ggplot.Para controlar el “color” de los objetos de la gráfica se ajustará la estética del color = (el color exterior) o la estética del relleno, fill = (el color interior). Una excepción este patrón es geom_point(), donde realmente sólo se llega controlar color =, que controla el color del punto (interior y exterior).Al establecer el color o el relleno puedes utilizar nombres de colores reconocidos por R como \"red\" (ver lista completa o introducir ?colors), o un color hexadecimal específico como \"#ff0505\".Como se explica en la sección asignación de datos al gráfico de Conceptos básicos de ggplot sobre la estética como fill = y color = puede definirse fuera de una sentencia mapping = aes() o dentro de ella. Si está fuera de aes(), el valor asignado debe ser estático (por ejemplo, color = \"blue\") y se aplicará todos los datos trazados por geom. Si está dentro, la estética debe asignarse una columna, como color = hospital, y la expresión variará según el valor de esa fila en los datos. Algunos ejemplos:","code":"\n# histogram - \nggplot(data = linelist, mapping = aes(x = age))+       # set data and axes\n  geom_histogram(              # display histogram\n    binwidth = 7,                # width of bins\n    color = \"red\",               # bin line color\n    fill = \"lightblue\")          # bin interior color (fill) \n# Static color for points and for line\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(color = \"purple\")+\n  geom_vline(xintercept = 50, color = \"orange\")+\n  labs(title = \"Static color for points and line\")\n\n# Color mapped to continuous column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = temp))+         \n  labs(title = \"Color mapped to continuous column\")\n\n# Color mapped to discrete column\nggplot(data = linelist, mapping = aes(x = age, y = wt_kg))+     \n  geom_point(mapping = aes(color = gender))+         \n  labs(title = \"Color mapped to discrete column\")\n\n# bar plot, fill to discrete column, color to static value\nggplot(data = linelist, mapping = aes(x = hospital))+     \n  geom_bar(mapping = aes(fill = gender), color = \"yellow\")+         \n  labs(title = \"Fill mapped to discrete column, static color\")"},{"path":"ggplot-tips.html","id":"ggplot_tips_scales","chapter":"31 Consejos de ggplot","heading":"Escalas","text":"Una vez que se asigna una columna una estética de la gráfica (por ejemplo, x =, y =, fill =, color =…), tu gráfica ganará una escala / leyenda. Mira arriba cómo la escala puede ser continua, discreta, de fecha, etc. dependiendo del tipo de la columna asignada. Si tienes múltiples estéticas asignadas las columnas, tu gráfico tendrá múltiples escalas.Puedes controlar las escalas con la función scales_() apropiada. Las funciones de escala de ggplot() tienen 3 partes que se escriben así: scale_AESTHETIC_METHOD().La primera parte, scale_(), es fija.La segunda parte, la ESTÉTICA, debe ser la estética para la que deseas ajustar la escala (_fill_, _shape_, _color_, _size_, _alpha_…) - las opciones aquí también incluyen _x_ e _y_.La tercera parte, el MÉTODO, será _discrete(), continuous(), _date(), _gradient(), o _manual() dependiendo del tipo de la columna y de cómo se quiera controlar. Hay otros, pero estos son los más utilizados.Asegúrate de utilizar la función correcta para la escala. De lo contrario, tu comando de escala parecerá cambiar nada. Si tienes varias escalas, puedes utilizar varias funciones de escala para ajustarlas. Por ejemplo:","code":""},{"path":"ggplot-tips.html","id":"argumentos-de-la-escala","chapter":"31 Consejos de ggplot","heading":"Argumentos de la escala","text":"Cada tipo de escala tiene sus propios argumentos, aunque hay cierto solapamiento. Consulta la función escribiendo ?scale_color_discrete en la consola de R para ver la documentación de los argumentos de la función.Para escalas continuas, utiliza breaks = para proporcionar una secuencia de valores con seq() (=, =, y = como se muestra en el ejemplo siguiente. Fija expand = c(0,0) para eliminar el espacio de relleno alrededor de los ejes (esto se puede utilizar en cualquier escala _x_ o _y_.En el caso de las escalas discretas, puedes ajustar el orden de aparición de los niveles con los breaks =, y cómo se muestran los valores con el argumento labels =. Proporciona un vector de caracteres cada uno de ellos (véase el ejemplo siguiente). También puedes dejar de lado NA fácilmente estableciendo na.translate = FALSE.Los matices de las escalas de fechas se tratan más ampliamente en la página de curvas epidémicas.","code":""},{"path":"ggplot-tips.html","id":"ajustes-manuales","chapter":"31 Consejos de ggplot","heading":"Ajustes manuales","text":"Uno de los trucos más útiles es utilizar las funciones de escalado “manual” para asignar explícitamente los colores que se deseen. Son funciones con la sintaxis scale_xxx_manual() (por ejemplo, scale_colour_manual() o scale_fill_manual()). Cada uno de los argumentos siguientes se demuestra en el ejemplo de código que sigue.Asignar colores los valores de los datos con el argumento values =Especificar un color para NA con na.value =Cambiar cómo se escriben los valores en la leyenda con el argumento labels =Cambiar el título de la leyenda con name =continuación, creamos un gráfico de barras y mostramos cómo aparece por defecto, y luego con tres escalas ajustadas - la escala continua del eje-y, la escala discreta del eje-x, y el ajuste manual del relleno (color interior de la barra).","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n# SCALES ADJUSTED\nggplot(data = linelist)+\n  \n  geom_bar(mapping = aes(x = outcome, fill = gender), color = \"black\")+\n  \n  theme_minimal()+                   # simplify background\n  \n  scale_y_continuous(                # continuous scale for y-axis (counts)\n    expand = c(0,0),                 # no padding\n    breaks = seq(from = 0,\n                 to = 3000,\n                 by = 500))+\n  \n  scale_x_discrete(                   # discrete scale for x-axis (gender)\n    expand = c(0,0),                  # no padding\n    drop = FALSE,                     # show all factor levels (even if not in data)\n    na.translate = FALSE,             # remove NA outcomes from plot\n    labels = c(\"Died\", \"Recovered\"))+ # Change display of values\n    \n  \n  scale_fill_manual(                  # Manually specify fill (bar interior color)\n    values = c(\"m\" = \"violetred\",     # reference values in data to assign colors\n               \"f\" = \"aquamarine\"),\n    labels = c(\"m\" = \"Male\",          # re-label the legend (use \"=\" assignment to avoid mistakes)\n              \"f\" = \"Female\",\n              \"Missing\"),\n    name = \"Gender\",                  # title of legend\n    na.value = \"grey\"                 # assign a color for missing values\n  )+\n  labs(title = \"Adjustment of scales\") # Adjust the title of the fill legend"},{"path":"ggplot-tips.html","id":"escalas-de-ejes-continuos","chapter":"31 Consejos de ggplot","heading":"Escalas de ejes continuos","text":"Cuando los datos se mapean los ejes del gráfico, éstos también pueden ajustarse con comandos de escalas. Un ejemplo común es el ajuste de la visualización de un eje (por ejemplo, el eje-y) que se asigna una columna con datos continuos.Es posible que queramos ajustar los descansos o la visualización de los valores en ggplot utilizando scale_y_continuous(). Como se indicó anteriormente, utiliza el argumento breaks = para proporcionar una secuencia de valores que servirán como “saltos” lo largo de la escala. Estos son los valores en los que se mostrarán los números. este argumento, puedes proporcionar un vector c() que contenga los valores de ruptura deseados, o puedes proporcionar una secuencia regular de números utilizando la función seq() de R base. Esta función seq() acepta =, =, y =.","code":"\n# BASELINE - no scale adjustment\nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  labs(title = \"Baseline - no scale adjustments\")\n\n# \nggplot(data = linelist)+\n  geom_bar(mapping = aes(x = outcome, fill = gender))+\n  scale_y_continuous(\n    breaks = seq(\n      from = 0,\n      to = 3000,\n      by = 100)\n  )+\n  labs(title = \"Adjusted y-axis breaks\")"},{"path":"ggplot-tips.html","id":"mostrar-porcentajes","chapter":"31 Consejos de ggplot","heading":"Mostrar porcentajes","text":"Si los valores de datos originales son proporciones, puedes mostrarlos fácilmente como porcentajes con “%” proporcionando labels = scales::percent en el comando de escalas, como se muestra continuación.Aunque una alternativa sería convertir los valores en caracteres y añadir un carácter “%” al final, este enfoque causará complicaciones porque tus datos ya serán valores numéricos continuos.","code":"\n# Original y-axis proportions\n#############################\nlinelist %>%                                   # start with linelist\n  group_by(hospital) %>%                       # group data by hospital\n  summarise(                                   # create summary columns\n    n = n(),                                     # total number of rows in group\n    deaths = sum(outcome == \"Death\", na.rm=T),   # number of deaths in group\n    prop_death = deaths/n) %>%                   # proportion deaths in group\n  ggplot(                                      # begin plotting\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+ \n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis original proportions\")\n\n\n\n# Display y-axis proportions as percents\n########################################\nlinelist %>%         \n  group_by(hospital) %>% \n  summarise(\n    n = n(),\n    deaths = sum(outcome == \"Death\", na.rm=T),\n    prop_death = deaths/n) %>% \n  ggplot(\n    mapping = aes(\n      x = hospital,\n      y = prop_death))+\n  geom_col()+\n  theme_minimal()+\n  labs(title = \"Display y-axis as percents (%)\")+\n  scale_y_continuous(\n    labels = scales::percent                    # display proportions as percents\n  )"},{"path":"ggplot-tips.html","id":"escala-logarítmica","chapter":"31 Consejos de ggplot","heading":"Escala logarítmica","text":"Para transformar un eje continuo escala logarítmica, añade trans = \"log2\" al comando de escala. modo de ejemplo, creamos un dataframe de regiones con sus respectivos valores de preparedness_index y casos acumulados.Los casos acumulados de la región “” son mucho mayores que los de las demás regiones. En circunstancias como ésta, puedes optar por mostrar el eje-y utilizando una escala logarítmica para que el lector pueda ver las diferencias entre las regiones con menos casos acumulados.","code":"\nplot_data <- data.frame(\n  region = c(\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\"),\n  preparedness_index = c(8.8, 7.5, 3.4, 3.6, 2.1, 7.9, 7.0, 5.6, 1.0),\n  cases_cumulative = c(15, 45, 80, 20, 21, 7, 51, 30, 1442)\n)\n\nplot_data##   region preparedness_index cases_cumulative\n## 1      A                8.8               15\n## 2      B                7.5               45\n## 3      C                3.4               80\n## 4      D                3.6               20\n## 5      E                2.1               21\n## 6      F                7.9                7\n## 7      G                7.0               51\n## 8      H                5.6               30\n## 9      I                1.0             1442\n# Original y-axis\npreparedness_plot <- ggplot(data = plot_data,  \n       mapping = aes(\n         x = preparedness_index,\n         y = cases_cumulative))+\n  geom_point(size = 2)+            # points for each region \n  geom_text(\n    mapping = aes(label = region),\n    vjust = 1.5)+                  # add text labels\n  theme_minimal()\n\npreparedness_plot                  # print original plot\n\n\n# print with y-axis transformed\npreparedness_plot+                   # begin with plot saved above\n  scale_y_continuous(trans = \"log2\") # add transformation for y-axis"},{"path":"ggplot-tips.html","id":"escalas-de-gradiente","chapter":"31 Consejos de ggplot","heading":"Escalas de gradiente","text":"Las escalas de degradado de relleno pueden implicar matices adicionales. Los valores predeterminados suelen ser bastante agradables, pero es posible que desees ajustar los valores, los cortes, etc.Para demostrar cómo ajustar una escala de colores continua, utilizaremos unos datos de la página de Rastreo de contactos que contiene las edades de los casos y de sus casos de origen.continuación, producimos un gráfico de densidad de mapa de calor “rasterizado”. vamos desarrollar cómo (ver el enlace en el párrafo anterior), pero nos centraremos en cómo podemos ajustar la escala de colores. Lee más sobre la función stat_density2d() de ggplot2 aquí. Observa cómo la escala de relleno es continua.Ahora mostramos algunas variaciones en la escala de relleno:Ahora mostramos algunos ejemplos de cómo ajustar realmente los puntos de ruptura de la escala:scale_fill_gradient() acepta dos colores (high/low)scale_fill_gradientn() acepta un vector de cualquier longitud de colores values = (los valores intermedios serán interpolados)Usa scales::rescale() para ajustar la posición de los colores lo largo del gradiente; reescala tu vector de posiciones para que esté entre 0 y 1.","code":"\ncase_source_relationships <- rio::import(here::here(\"data\", \"godata\", \"relationships_clean.rds\")) %>% \n  select(source_age, target_age) \ntrans_matrix <- ggplot(\n    data = case_source_relationships,\n    mapping = aes(x = source_age, y = target_age))+\n  stat_density2d(\n    geom = \"raster\",\n    mapping = aes(fill = after_stat(density)),\n    contour = FALSE)+\n  theme_minimal()\ntrans_matrix\ntrans_matrix + scale_fill_viridis_c(option = \"plasma\")\ntrans_matrix + \n  scale_fill_gradient(     # 2-sided gradient scale\n    low = \"aquamarine\",    # low value\n    high = \"purple\",       # high value\n    na.value = \"grey\",     # value for NA\n    name = \"Density\")+     # Legend title\n  labs(title = \"Manually specify high/low colors\")\n\n# 3+ colors to scale\ntrans_matrix + \n  scale_fill_gradientn(    # 3-color scale (low/mid/high)\n    colors = c(\"blue\", \"yellow\",\"red\") # provide colors in vector\n  )+\n  labs(title = \"3-color scale\")\n\n# Use of rescale() to adjust placement of colors along scale\ntrans_matrix + \n  scale_fill_gradientn(    # provide any number of colors\n    colors = c(\"blue\", \"yellow\",\"red\", \"black\"),\n    values = scales::rescale(c(0, 0.05, 0.07, 0.10, 0.15, 0.20, 0.3, 0.5)) # positions for colors are rescaled between 0 and 1\n    )+\n  labs(title = \"Colors not evenly positioned\")\n\n# use of limits to cut-off values that get fill color\ntrans_matrix + \n  scale_fill_gradientn(    \n    colors = c(\"blue\", \"yellow\",\"red\"),\n    limits = c(0, 0.0002))+\n  labs(title = \"Restrict value limits, resulting in grey space\")"},{"path":"ggplot-tips.html","id":"paletas","chapter":"31 Consejos de ggplot","heading":"Paletas","text":"","code":""},{"path":"ggplot-tips.html","id":"colorbrewer-y-viridis","chapter":"31 Consejos de ggplot","heading":"Colorbrewer y Viridis","text":"En general, si deseas paletas predefinidas, puedes utilizar las funciones scale_xxx_brewer o scale_xxx_viridis_y.Las funciones ‘brewer’ pueden dibujar desde las paletas de colorbrewer.org.Las funciones ‘viridis’ se basan en las paletas viridis (¡difíciles para los daltónicos!), que “proporcionan mapas de color que son perceptivamente uniformes tanto en color como en blanco y negro. También están diseñadas para ser percibidas por espectadores con formas comunes de daltonismo”. (lee más aquí y aquí). Define si la paleta es discreta, continua o con intervalos especificando esto al final de la función (por ejemplo, discreta es scale_xxx_viridis_d).Se aconseja que pruebes tu esquema en este simulador de daltonismo. Si tienes un esquema de color rojo/verde, prueba en su lugar un esquema “caliente-frío” (rojo-azul) como se describe aquíAquí hay un ejemplo de la página de Conceptos básicos de ggplot, utilizando varios esquemas de color.","code":"\nsymp_plot <- linelist %>%                                         # begin with linelist\n  select(c(case_id, fever, chills, cough, aches, vomit)) %>%     # select columns\n  pivot_longer(                                                  # pivot longer\n    cols = -case_id,                                  \n    names_to = \"symptom_name\",\n    values_to = \"symptom_is_present\") %>%\n  mutate(                                                        # replace missing values\n    symptom_is_present = replace_na(symptom_is_present, \"unknown\")) %>% \n  ggplot(                                                        # begin ggplot!\n    mapping = aes(x = symptom_name, fill = symptom_is_present))+\n  geom_bar(position = \"fill\", col = \"black\") +                    \n  theme_classic() +\n  theme(legend.position = \"bottom\")+\n  labs(\n    x = \"Symptom\",\n    y = \"Symptom status (proportion)\"\n  )\n\nsymp_plot  # print with default colors\n\n#################################\n# print with manually-specified colors\nsymp_plot +\n  scale_fill_manual(\n    values = c(\"yes\" = \"black\",         # explicitly define colours\n               \"no\" = \"white\",\n               \"unknown\" = \"grey\"),\n    breaks = c(\"yes\", \"no\", \"unknown\"), # order the factors correctly\n    name = \"\"                           # set legend to no title\n\n  ) \n\n#################################\n# print with viridis discrete colors\nsymp_plot +\n  scale_fill_viridis_d(\n    breaks = c(\"yes\", \"no\", \"unknown\"),\n    name = \"\"\n  )"},{"path":"ggplot-tips.html","id":"change-order-of-discrete-variables","chapter":"31 Consejos de ggplot","heading":"31.3 Cambiar el orden de las variables discretas","text":"Cambiar el orden en que aparecen las variables discretas es menudo difícil de entender para las personas que son nuevas en los gráficos de ggplot2. Sin embargo, es fácil de entender cómo hacer esto una vez que se entiende cómo ggplot2 maneja las variables discretas por debajo. En general, si se utiliza una variable discreta, se convierte automáticamente en un tipo de factor - que ordena los factores por orden alfabético por defecto. Para manejar esto, simplemente tienes que reordenar los niveles de los factores para reflejar el orden en que te gustaría que aparecieran en el gráfico. Para obtener información más detallada sobre cómo reordenar los objetos de factor, consulta la página Factores.Podemos ver un ejemplo común utilizando los grupos de edad - por defecto el grupo de 5 9 años se colocará en medio de los grupos de edad (dado el orden alfanumérico), pero podemos moverlo detrás del grupo de 0 4 años del gráfico renivelando los factores.","code":"\nggplot(\n  data = linelist %>% drop_na(age_cat5),                         # remove rows where age_cat5 is missing\n  mapping = aes(x = fct_relevel(age_cat5, \"5-9\", after = 1))) +  # relevel factor\n\n  geom_bar() +\n  \n  labs(x = \"Age group\", y = \"Number of hospitalisations\",\n       title = \"Total hospitalisations by age group\") +\n  \n  theme_minimal()"},{"path":"ggplot-tips.html","id":"ggthemr","chapter":"31 Consejos de ggplot","heading":"31.3.0.1 ggthemr","text":"También considera utilizar el paquete ggthemr. Puedes descargar este paquete desde Github usando estas instrucciones. Ofrece paletas que son muy agradables estéticamente, pero ten en cuenta que estas suelen tener un número máximo de valores que puede ser limitante si quieres más de 7 u 8 colores.","code":""},{"path":"ggplot-tips.html","id":"contour-lines","chapter":"31 Consejos de ggplot","heading":"31.4 Líneas de contorno","text":"Los gráficos de contorno son útiles cuando se tienen muchos puntos que pueden cubrirse unos otros (“sobretrazado”). Los datos de la fuente de casos utilizados anteriormente se trazan de nuevo, pero de forma más sencilla utilizando stat_density2d() y stat_density2d_filled() para producir niveles de contorno discretos - como un mapa topográfico. Lee más sobre las estadísticas aquí.","code":"\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d()+\n  geom_point()+\n  theme_minimal()+\n  labs(title = \"stat_density2d() + geom_point()\")\n\n\ncase_source_relationships %>% \n  ggplot(aes(x = source_age, y = target_age))+\n  stat_density2d_filled()+\n  theme_minimal()+\n  labs(title = \"stat_density2d_filled()\")"},{"path":"ggplot-tips.html","id":"marginal-distributions","chapter":"31 Consejos de ggplot","heading":"31.5 Distribuciones marginales","text":"Para mostrar las distribuciones en los bordes de un gráfico de dispersión geom_point(), puedes utilizar el paquete ggExtra y su función ggMarginal(). Guarda tu ggplot original como un objeto, y pásalo ggMarginal() como se muestra continuación. Estos son los argumentos clave:Debe especificar el type = como “histogram”, “density” “boxplot”, “violin”, o “densigram”Por defecto, los gráficos marginales aparecerán para ambos ejes. Puedes establecer margins = “x” o “y” si sólo quieres uno.Otros argumentos opcionales son fill = (color de la barra), color = (color de la línea), size = (tamaño del gráfico en relación con el tamaño del margen, por lo que un número mayor hace que el gráfico marginal sea más pequeño).Puedes proporcionar otros argumentos específicos del eje xparams = e yparams =. Por ejemplo, para tener diferentes tamaños de cubos de histograma, como se muestra continuación.Puedes hacer que los gráficos marginales reflejen grupos (columnas las que se les ha asignado un color = en su estética mapeada de ggplot()). Si este es el caso, establece el argumento ggMarginal() groupColour = o groupFill = TRUE, como se muestra continuación.Lee más en esta viñeta, en la galería de gráficos de R o en la documentación de la función R ?ggMarginal.Para añadir histogramas marginales utiliza type = \"histogram\". Opcionalmente puedes establecer groupFill = TRUE para obtener histogramas apilados.Gráfico de densidad marginal con valores agrupados/coloreados:Establece el argumento size = para ajustar el tamaño relativo del gráfico marginal. Un número más pequeño hace un gráfico marginal más grande. También se establece el color =. continuación se muestra un boxplot marginal, con la demostración del argumento margins = por lo que aparece en un solo eje:","code":"\n# Install/load ggExtra\npacman::p_load(ggExtra)\n\n# Basic scatter plot of weight and age\nscatter_plot <- ggplot(data = linelist)+\n  geom_point(mapping = aes(y = wt_kg, x = age)) +\n  labs(title = \"Scatter plot of weight and age\")\n# with histograms\nggMarginal(\n  scatter_plot,                     # add marginal histograms\n  type = \"histogram\",               # specify histograms\n  fill = \"lightblue\",               # bar fill\n  xparams = list(binwidth = 10),    # other parameters for x-axis marginal\n  yparams = list(binwidth = 5))     # other parameters for y-axis marginal\n# Scatter plot, colored by outcome\n# Outcome column is assigned as color in ggplot. groupFill in ggMarginal set to TRUE\nscatter_plot_color <- ggplot(data = linelist %>% drop_na(gender))+\n  geom_point(mapping = aes(y = wt_kg, x = age, color = gender)) +\n  labs(title = \"Scatter plot of weight and age\")+\n  theme(legend.position = \"bottom\")\n\nggMarginal(scatter_plot_color, type = \"density\", groupFill = TRUE)\n# with boxplot \nggMarginal(\n  scatter_plot,\n  margins = \"x\",      # only show x-axis marginal plot\n  type = \"boxplot\")   "},{"path":"ggplot-tips.html","id":"smart-labeling","chapter":"31 Consejos de ggplot","heading":"31.6 Etiquetado inteligente","text":"En ggplot2, también es posible añadir texto los gráficos. Sin embargo, esto viene con la notable limitación de que las etiquetas de texto menudo chocan con los puntos de datos en un gráfico, haciendo que se vean desordenados o difíciles de leer. hay una manera ideal de lidiar con esto en el paquete base, pero hay un complemento de ggplot2, conocido como ggrepel que hace que esto sea muy simple.El paquete ggrepel proporciona dos nuevas funciones, geom_label_repel() y geom_text_repel(), que sustituyen geom_label() y geom_text(). Basta con utilizar estas funciones en lugar de las funciones base para producir etiquetas ordenadas. Dentro de la función, mapea la estética aes() como siempre, pero incluye el argumento label = al que le proporciona un nombre de columna que contenga los valores que deseas mostrar (por ejemplo, id de paciente, o nombre, etc.). Puedes hacer etiquetas más complejas combinando columnas y nuevas líneas (\\n) dentro de str_glue() como se muestra continuación.Algunos consejos:Utiliza min.segment.length = 0 para dibujar siempre segmentos de línea, o min.segment.length = Inf para dibujarlos nuncaUtiliza size = fuera de aes() para establecer el tamaño del textoUtiliza force = para cambiar el grado de repulsión entre las etiquetas y sus respectivos puntos (por defecto es 1)Incluye fill = dentro de aes() para tener la etiqueta coloreada por el valor\nPuede aparecer una letra “” en la leyenda - añade guides(fill = guide_legend(override.aes = aes(color = NA)))+ para eliminarla\nPuede aparecer una letra “” en la leyenda - añade guides(fill = guide_legend(override.aes = aes(color = NA)))+ para eliminarlaPara verlo con mayor profundidad, consulta este tutorialPuedes etiquetar sólo un subconjunto de los puntos de datos - utilizando la sintaxis estándar de ggplot() para proporcionar diferentes data = para cada geom del gráfico. continuación, se trazan todos los casos, pero sólo se etiquetan algunos.","code":"\npacman::p_load(ggrepel)\n\nlinelist %>%                                               # start with linelist\n  group_by(hospital) %>%                                   # group by hospital\n  summarise(                                               # create new dataset with summary values per hospital\n    n_cases = n(),                                           # number of cases per hospital\n    delay_mean = round(mean(days_onset_hosp, na.rm=T),1),    # mean delay per hospital\n  ) %>% \n  ggplot(mapping = aes(x = n_cases, y = delay_mean))+      # send data frame to ggplot\n  geom_point(size = 2)+                                    # add points\n  geom_label_repel(                                        # add point labels\n    mapping = aes(\n      label = stringr::str_glue(\n        \"{hospital}\\n{n_cases} cases, {delay_mean} days\")  # how label displays\n      ), \n    size = 3,                                              # text size in labels\n    min.segment.length = 0)+                               # show all line segments                \n  labs(                                                    # add axes labels\n    title = \"Mean delay to admission, by hospital\",\n    x = \"Number of cases\",\n    y = \"Mean delay (days)\")\nggplot()+\n  # All points in grey\n  geom_point(\n    data = linelist,                                   # all data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    color = \"grey\",\n    alpha = 0.5)+                                              # grey and semi-transparent\n  \n  # Few points in black\n  geom_point(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filtered data provided to this layer\n    mapping = aes(x = ht_cm, y = wt_kg),\n    alpha = 1)+                                                # default black and not transparent\n  \n  # point labels for few points\n  geom_label_repel(\n    data = linelist %>% filter(days_onset_hosp > 15),  # filter the data for the labels\n    mapping = aes(\n      x = ht_cm,\n      y = wt_kg,\n      fill = outcome,                                          # label color by outcome\n      label = stringr::str_glue(\"Delay: {days_onset_hosp}d\")), # label created with str_glue()\n    min.segment.length = 0) +                                  # show line segments for all\n  \n  # remove letter \"a\" from inside legend boxes\n  guides(fill = guide_legend(override.aes = aes(color = NA)))+\n  \n  # axis labels\n  labs(\n    title = \"Cases with long delay to admission\",\n    y = \"weight (kg)\",\n    x = \"height(cm)\")"},{"path":"ggplot-tips.html","id":"time-axes","chapter":"31 Consejos de ggplot","heading":"31.7 Ejes temporales","text":"Trabajar con ejes de tiempo en ggplot puede parecer desalentador, pero se hace muy fácil con unas pocas funciones clave. Recuerda que cuando trabajes con el tiempo o la fecha debes asegurarte que las variables correctas están formateadas como tipo date o datetime - mira la página Trabajar con fechas para más información sobre esto, o la página Curvas epidémicas (sección ggplot) para ver ejemplos.El conjunto de funciones más útil para trabajar con fechas en ggplot2 son las funciones de escala (scale_x_date(), scale_x_datetime(), y sus funciones afines del eje-y). Estas funciones permiten definir la frecuencia de las etiquetas de los ejes, y cómo formatear las etiquetas de los ejes. Para saber cómo dar formato las fechas, vuelve ver la sección de trabajar con fechas. Puedes utilizar los argumentos date_breaks y date_labels para especificar el aspecto de las fechas:date_breaks permite especificar la frecuencia con la que se producen las rupturas de los ejes - se puede pasar aquí una cadena (por ejemplo, \"3 months\", “2 days\")date_breaks permite especificar la frecuencia con la que se producen las rupturas de los ejes - se puede pasar aquí una cadena (por ejemplo, \"3 months\", “2 days\")date_labels permite definir el formato en el que se muestran las fechas. Puedes pasar una cadena de formato de fecha estos argumentos (por ejemplo, \"%b-%d-%Y\"):date_labels permite definir el formato en el que se muestran las fechas. Puedes pasar una cadena de formato de fecha estos argumentos (por ejemplo, \"%b-%d-%Y\"):","code":"\n# make epi curve by date of onset when available\nggplot(linelist, aes(x = date_onset)) +\n  geom_histogram(binwidth = 7) +\n  scale_x_date(\n    # 1 break every 1 month\n    date_breaks = \"1 months\",\n    # labels should show month then date\n    date_labels = \"%b %d\"\n  ) +\n  theme_classic()"},{"path":"ggplot-tips.html","id":"highlighting","chapter":"31 Consejos de ggplot","heading":"31.8 Resaltando","text":"Resaltar elementos específicos en un gráfico es una forma útil de llamar la atención sobre una instancia específica de una variable, la vez que se proporciona información sobre la dispersión de los datos. Aunque esto es fácil de hacer en ggplot2 base, hay un paquete externo que puede ayudar hacer esto conocido como gghighlight. Es fácil de usar dentro de la sintaxis de ggplot.El paquete gghighlight utiliza la función gghighlight() para lograr este efecto. Para usar esta función, suministra una declaración lógica la función - esto puede tener resultados bastante flexibles, pero aquí mostraremos un ejemplo de la distribución de edad de los casos en nuestro listado, resaltándolos por resultado.Esto también funciona bien con las funciones de facetas - ¡permite al usuario producir gráficos de facetas con los datos de fondo resaltados que se aplican la faceta! continuación, contamos los casos por semana y trazamos las curvas de epidemia por hospital (color = y facet_wrap() ajustado la columna hospital).","code":"\n# load gghighlight\nlibrary(gghighlight)\n\n# replace NA values with unknown in the outcome variable\nlinelist <- linelist %>%\n  mutate(outcome = replace_na(outcome, \"Unknown\"))\n\n# produce a histogram of all cases by age\nggplot(\n  data = linelist,\n  mapping = aes(x = age_years, fill = outcome)) +\n  geom_histogram() + \n  gghighlight::gghighlight(outcome == \"Death\")     # highlight instances where the patient has died.\n# produce a histogram of all cases by age\nlinelist %>% \n  count(week = lubridate::floor_date(date_hospitalisation, \"week\"),\n        hospital) %>% \n  ggplot()+\n  geom_line(aes(x = week, y = n, color = hospital))+\n  theme_minimal()+\n  gghighlight::gghighlight() +                      # highlight instances where the patient has died\n  facet_wrap(~hospital)                              # make facets by outcome"},{"path":"ggplot-tips.html","id":"plotting-multiple-datasets","chapter":"31 Consejos de ggplot","heading":"31.9 Representar múltiples conjuntos de datos","text":"Ten en cuenta que alinear correctamente los ejes para trazar múltiples conjuntos de datos en el mismo gráfico puede ser difícil. Considera una de las siguientes estrategias:Fusionar los datos antes de trazarlos y convertirlos al formato “long” con una columna que refleje el conjunto de datosUtilizar Cowplot o un paquete similar para combinar dos gráficos (véase más abajo)","code":""},{"path":"ggplot-tips.html","id":"combine-plots","chapter":"31 Consejos de ggplot","heading":"31.10 Combinar gráficos","text":"Dos paquetes que son muy útiles para combinar gráficos son cowplot y patchwork. En esta página nos centraremos principalmente en cowplot, con el uso ocasional de patchwork.Aquí está la introducción en línea cowplot. Puedes leer la documentación más extensa de cada función en línea aquí. continuación cubriremos algunos de los casos de uso y funciones más comunes.El paquete cowplot funciona en tándem con ggplot2 - esencialmente, se utiliza para organizar y combinar ggplots y sus leyendas en figuras compuestas. También puede aceptar gráficos de R base.Mientras que las facetas (descritas en la página de Conceptos básicos de ggplot) son un enfoque conveniente para el trazado, veces es posible obtener los resultados que deseas de su enfoque relativamente restrictivo. En este caso, se puede optar por combinar los gráficos pegándolos en un gráfico más grande. Hay tres paquetes bien conocidos que son excelentes para esto - cowplot, gridExtra, y patchwork. Sin embargo, estos paquetes hacen en gran medida las mismas cosas, por lo que nos centraremos en cowplot para esta sección.","code":"\npacman::p_load(\n  tidyverse,      # data manipulation and visualisation\n  cowplot,        # combine plots\n  patchwork       # combine plots\n)"},{"path":"ggplot-tips.html","id":"plot_grid","chapter":"31 Consejos de ggplot","heading":"plot_grid()","text":"El paquete cowplot tiene una gama bastante amplia de funciones, pero el uso más fácil de él se puede lograr mediante el uso de plot_grid(). Se trata de una forma de organizar los gráficos predefinidos en una cuadrícula. Podemos trabajar través de otro ejemplo con el conjunto de datos de la malaria - aquí podemos trazar el total de casos por distrito, y también mostrar la curva epidémica en el tiempo.","code":"\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) \n\n# bar chart of total cases by district\np1 <- ggplot(malaria_data, aes(x = District, y = malaria_tot)) +\n  geom_bar(stat = \"identity\") +\n  labs(\n    x = \"District\",\n    y = \"Total number of cases\",\n    title = \"Total malaria cases by district\"\n  ) +\n  theme_minimal()\n\n# epidemic curve over time\np2 <- ggplot(malaria_data, aes(x = data_date, y = malaria_tot)) +\n  geom_col(width = 1) +\n  labs(\n    x = \"Date of data submission\",\n    y =  \"number of cases\"\n  ) +\n  theme_minimal()\n\ncowplot::plot_grid(p1, p2,\n                  # 1 column and two rows - stacked on top of each other\n                   ncol = 1,\n                   nrow = 2,\n                   # top plot is 2/3 as tall as second\n                   rel_heights = c(2, 3))"},{"path":"ggplot-tips.html","id":"combinar-leyendas","chapter":"31 Consejos de ggplot","heading":"Combinar leyendas","text":"Si tus gráficos tienen la misma leyenda, combinarlos es relativamente sencillo. Simplemente utiliza el método de cowplot anterior para combinar los gráficos, pero elimina la leyenda de uno de ellos (de-duplica).Si tus gráficos tienen leyendas diferentes, debes utilizar un enfoque alternativo:Crea y guarda tus gráficos sin leyendas utilizando theme(legend.position = \"none\")Extrae las leyendas de cada gráfica utilizando get_legend() como se muestra continuación - pero extrae las leyendas de los gráficos modificados para mostrar realmente la leyendaCombina las leyendas en un panel de leyendasCombina el panel de gráficos y leyendasPara comprobarlo, mostramos las dos gráficos por separado, y luego dispuestas en una cuadrícula con sus propias leyendas mostrando (uso feo e ineficiente del espacio):Así es como se ven los dos gráficos cuando se combinan usando plot_grid() sin combinar sus leyendas:Y ahora mostramos cómo combinar las leyendas. Esencialmente lo que hacemos es definir cada gráfica sin su leyenda (theme(legend.position = \"none\"), y luego definimos la leyenda de cada gráfica por separado, utilizando la función get_legend() de cowplot. Cuando extraemos la leyenda del gráfico guardado, tenemos que añadir + la leyenda de nuevo, incluyendo la especificación de la colocación (“derecha”) y pequeños ajustes para la alineación de las leyendas y sus títulos. continuación, combinamos las leyendas verticalmente, y luego combinamos los dos gráficos con las leyendas recién combinadas. Voila!Esta solución fue aprendida de este post con un arreglo menor para alinear las leyendas de este post.CONSEJO: Nota divertida: la “vaca” en cowplot viene del nombre del creador: Claus O. Wilke.","code":"\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  labs(title = \"Cases by outcome\")\n\n\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(axis.text.y = element_blank())+\n  labs(title = \"Cases by age\")\ncowplot::plot_grid(p1, p2, rel_widths = c(0.3))\n# Define plot 1 without legend\np1 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n  scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(legend.position = \"none\")+\n  labs(title = \"Cases by outcome\")\n\n\n# Define plot 2 without legend\np2 <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, age_cat) %>% \n  ggplot()+\n  geom_col(mapping = aes(x = hospital, y = n, fill = age_cat))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+\n  coord_flip()+\n  theme_minimal()+\n  theme(\n    legend.position = \"none\",\n    axis.text.y = element_blank(),\n    axis.title.y = element_blank()\n  )+\n  labs(title = \"Cases by age\")\n\n\n# extract legend from p1 (from p1 + legend)\nleg_p1 <- cowplot::get_legend(p1 +\n                                theme(legend.position = \"right\",        # extract vertical legend\n                                      legend.justification = c(0,0.5))+ # so legends  align\n                                labs(fill = \"Outcome\"))                 # title of legend\n# extract legend from p2 (from p2 + legend)\nleg_p2 <- cowplot::get_legend(p2 + \n                                theme(legend.position = \"right\",         # extract vertical legend   \n                                      legend.justification = c(0,0.5))+  # so legends align\n                                labs(fill = \"Age Category\"))             # title of legend\n\n# create a blank plot for legend alignment\n#blank_p <- patchwork::plot_spacer() + theme_void()\n\n# create legends panel, can be one on top of the other (or use spacer commented above)\nlegends <- cowplot::plot_grid(leg_p1, leg_p2, nrow = 2, rel_heights = c(.3, .7))\n\n# combine two plots and the combined legends panel\ncombined <- cowplot::plot_grid(p1, p2, legends, ncol = 3, rel_widths = c(.4, .4, .2))\n\ncombined  # print"},{"path":"ggplot-tips.html","id":"gráficos-insertados","chapter":"31 Consejos de ggplot","heading":"Gráficos insertados","text":"Puedes insertar una gráfica en otra utilizando cowplot. Aquí hay cosas que hay que tener en cuenta:Define el gráfico principal con theme_half_open() de cowplot; puede ser mejor tener la leyenda arriba o abajoDefine el gráfico de inserción. Lo mejor es tener un gráfico en el que se necesite una leyenda. Puedes eliminar los elementos del tema del gráfico con element_blank() como se muestra continuación.Combínalos aplicando ggdraw() al gráfico principal, y luego añadiendo draw_plot() en el gráfico de inserción y especificando las coordenadas (x e y de la esquina inferior izquierda), la altura y la anchura como proporción de todo el gráfico principal.Esta técnica se explica mejor en estas dos viñetas:Laboratorio Wilkedocumentación de draw_plot()","code":"\n# Define main plot\nmain_plot <- ggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset, fill = hospital))+\n  scale_fill_brewer(type = \"qual\", palette = 1, na.value = \"grey\")+ \n  theme_half_open()+\n  theme(legend.position = \"bottom\")+\n  labs(title = \"Epidemic curve and outcomes by hospital\")\n\n\n# Define inset plot\ninset_plot <- linelist %>% \n  mutate(hospital = recode(hospital, \"St. Mark's Maternity Hospital (SMMH)\" = \"St. Marks\")) %>% \n  count(hospital, outcome) %>% \n  ggplot()+\n    geom_col(mapping = aes(x = hospital, y = n, fill = outcome))+\n    scale_fill_brewer(type = \"qual\", palette = 4, na.value = \"grey\")+\n    coord_flip()+\n    theme_minimal()+\n    theme(legend.position = \"none\",\n          axis.title.y = element_blank())+\n    labs(title = \"Cases by outcome\") \n\n\n# Combine main with inset\ncowplot::ggdraw(main_plot)+\n     draw_plot(inset_plot,\n               x = .6, y = .55,    #x = .07, y = .65,\n               width = .4, height = .4)"},{"path":"ggplot-tips.html","id":"dual-axes","chapter":"31 Consejos de ggplot","heading":"31.11 Ejes dobles","text":"Un eje-y secundario es menudo una adición solicitada un gráfico ggplot2. Aunque existe un fuerte debate sobre la validez de estos gráficos en la comunidad de visualización de datos, y menudo se recomiendan, es posible que tu jefe los quiera. continuación, presentamos un método para conseguirlos: usa el paquete cowplot para combinar dos gráficos separados.Este enfoque implica la creación de dos gráficos separados - uno con un eje-y la izquierda, y el otro con un eje-y la derecha. Ambos utilizarán un tema específico de theme_cowplot() y deben tener el mismo eje-x. Luego, en un tercer comando, los dos gráficos se alinean y se superponen. Las funcionalidades de cowplot, de las que ésta es sólo una, se describen en profundidad en este sitio.Para demostrar esta técnica, superpondremos la curva epidémica con una línea del porcentaje semanal de pacientes fallecidos. Utilizamos este ejemplo porque la alineación de las fechas en el eje-x es más compleja que, por ejemplo, alinear un gráfico de barras con otro gráfico. Hay que tener en cuenta algunas cosas:Para la curva epidémica y la línea se agrupan en semanas antes de trazarlas y los date_breaks y date_labels son idénticos - lo hacemos para que los ejes-x de los dos gráficos sean los mismos cuando se superponen.El eje-y se mueve la derecha para el gráfico 2 con el argumento position = de scale_y_continuous().Ambos gráficos hacen uso de theme_cowplot()Observa que hay otro ejemplo de esta técnica en la página de curvas epidémicas: la superposición de la incidencia acumulada sobre la curva epidemica.Hacer el gráfico 1\nEsto es esencialmente la curva epidémica. Usamos geom_area() sólo para mostrar su uso (área bajo una línea, por defecto)Hacer el gráfico 2\nCrea el segundo gráfico mostrando una línea del porcentaje semanal de casos que murieron.Ahora alineamos el gráfico utilizando la función align_plots(), especificando la alineación horizontal y vertical (“hv”, también podría ser “h”, “v”, “none”). También especificamos la alineación de todos los ejes (top, bottom, left, y right) con “tblr”. La salida es de tipo list (2 elementos).Luego dibujamos los dos gráficos juntos usando ggdraw() (de cowplot) y referenciando las dos partes del objeto aligned_plots.","code":"\npacman::p_load(cowplot)            # load/install cowplot\n\np1 <- linelist %>%                 # save plot as object\n     count(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     ggplot()+\n          geom_area(aes(x = epiweek, y = n), fill = \"grey\")+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n     theme_cowplot()+\n     labs(\n       y = \"Weekly cases\"\n     )\n\np1                                      # view plot \np2 <- linelist %>%         # save plot as object\n     group_by(\n       epiweek = lubridate::floor_date(date_onset, \"week\")) %>% \n     summarise(\n       n = n(),\n       pct_death = 100*sum(outcome == \"Death\", na.rm=T) / n) %>% \n     ggplot(aes(x = epiweek, y = pct_death))+\n          geom_line()+\n          scale_x_date(\n               date_breaks = \"month\",\n               date_labels = \"%b\")+\n          scale_y_continuous(\n               position = \"right\")+\n          theme_cowplot()+\n          labs(\n            x = \"Epiweek of symptom onset\",\n            y = \"Weekly percent of deaths\",\n            title = \"Weekly case incidence and percent deaths\"\n          )\n\np2     # view plot\naligned_plots <- cowplot::align_plots(p1, p2, align=\"hv\", axis=\"tblr\")         # align the two plots and save them as list\naligned_plotted <- ggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])  # overlay them and save the visual plot\naligned_plotted                                                                # print the overlayed plots"},{"path":"ggplot-tips.html","id":"packages-to-help-you","chapter":"31 Consejos de ggplot","heading":"31.12 Paquetes para ayudarte","text":"Hay algunos paquetes de R muy buenos diseñados específicamente para ayudarte navegar por ggplot2:","code":""},{"path":"ggplot-tips.html","id":"apuntar-y-clicar-en-ggplot2-con-equisse","chapter":"31 Consejos de ggplot","heading":"Apuntar y clicar en ggplot2 con equisse","text":"“Este complemento te permite explorar interactivamente tus datos visualizándolos con el paquete ggplot2. Te permite dibujar gráficos de barras, curvas, gráficos de dispersión, histogramas, boxplot y objetos sf, y luego exportar el gráfico o recuperar el código para reproducir el gráfico.”Instala y luego lanza el complemento con el menú de RStudio o con esquisse::esquisser().Ver la página de Github de esquisseDocumentación adicional","code":""},{"path":"ggplot-tips.html","id":"miscellaneous","chapter":"31 Consejos de ggplot","heading":"31.13 Miscelánea","text":"","code":""},{"path":"ggplot-tips.html","id":"pantalla-numérica","chapter":"31 Consejos de ggplot","heading":"Pantalla numérica","text":"Puedes desactivar la notación científica ejecutando este comando antes de representar gráficamente.O aplicar number_format() del paquete scales un valor o columna específicos, como se muestra continuación.Utiliza las funciones del paquete scales para ajustar fácilmente la forma en que se muestran los números. Pueden aplicarse las columnas del dataframe, pero se muestran en los números individuales modo de ejemplo.","code":"\noptions(scipen=999)\nscales::number(6.2e5)## [1] \"620 000\"\nscales::number(1506800.62,  accuracy = 0.1,)## [1] \"1 506 800.6\"\nscales::comma(1506800.62, accuracy = 0.01)## [1] \"1,506,800.62\"\nscales::comma(1506800.62, accuracy = 0.01,  big.mark = \".\" , decimal.mark = \",\")## [1] \"1.506.800,62\"\nscales::percent(0.1)## [1] \"10%\"\nscales::dollar(56)## [1] \"$56\"\nscales::scientific(100000)## [1] \"1e+05\""},{"path":"ggplot-tips.html","id":"resources-24","chapter":"31 Consejos de ggplot","heading":"31.14 Recursos","text":"Inspiración galería de gráficos de ggplotDirectrices para la presentación de los datos de vigilancia del Centro Europeo para la Prevención y el Control de las Enfermedades (ecdc)Utilización de etiquetadoras para tiras de facetas y Etiquetadoras]Ajuste del orden con factoresfct_reorderfct_inorderCómo reordenar un boxplotReordenar una variable en ggplot2R Data Science en español - FactoresLeyendasAjustar el orden de las leyendasPies de fotoAlineación de las leyendasEtiquetasggrepelCheetsheetsTrazado bonito con ggplot2","code":""},{"path":"epidemic-curves.html","id":"epidemic-curves","chapter":"32 Curvas epidémicas","heading":"32 Curvas epidémicas","text":"Una curva epidémica (también conocida como “curva epi”) es un gráfico epidemiológico básico que se suele utilizar para visualizar el patrón temporal de aparición de la enfermedad entre un grupo o epidemia de casos.El análisis de la curva epidémica puede revelar tendencias temporales, valores atípicos, la magnitud del brote, el periodo de exposición más probable, los intervalos de tiempo entre las generaciones de casos, e incluso puede ayudar identificar el modo de transmisión de una enfermedad identificada (por ejemplo, fuente puntual, fuente común continua, propagación de persona persona). En el sitio web de los CDC de EE.UU. se puede encontrar una lección en línea sobre la interpretación de las curvas epidémicas.En esta página mostramos dos enfoques para producir curva epidémicas en R:El paquete incidence2, que puede producir una curva epi con simples comandosEl paquete ggplot2, que permite una personalización avanzada mediante comandos más complejosTambién se abordan casos de uso específicos como:Grágicos de datos de recuento agregadosFacetado o producción de múltiplos gráficos pequeñosAplicación de medias móvilesMostrar qué datos son “provisionales” o están sujetos retrasos en la presentación de informesSuperposición de la incidencia de casos acumulados mediante un segundo eje","code":""},{"path":"epidemic-curves.html","id":"preparation-24","chapter":"32 Curvas epidémicas","heading":"32.1 Preparación","text":"","code":""},{"path":"epidemic-curves.html","id":"paquetes-3","chapter":"32 Curvas epidémicas","heading":"Paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,          # file import/export\n  here,         # relative filepaths \n  lubridate,    # working with dates/epiweeks\n  aweek,        # alternative package for working with dates/epiweeks\n  incidence2,   # epicurves of linelist data\n  i2extras,     # supplement to incidence2\n  stringr,      # search and manipulate character strings\n  forcats,      # working with factors\n  RColorBrewer, # Color palettes from colorbrewer2.org\n  tidyverse     # data management + ggplot2 graphics\n) "},{"path":"epidemic-curves.html","id":"importar-datos-17","chapter":"32 Curvas epidémicas","heading":"Importar datos","text":"En esta sección se utilizan dos conjuntos de datos de ejemplo:Linelist con casos individuales de una epidemia simuladaRecuentos agregados por hospital de la misma epidemia simuladaLos datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.Linelist con casosImportamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso paso, consulta las instrucciones en la página Descargando el manual y los datos. Asumimos que el archivo está en el directorio de trabajo, por lo que se especifican subcarpetas en esta ruta de archivo.continuación se muestran las primeras 50 filas.Recuentos de casos agregados por hospitalA efectos del manual, los datos de recuentos semanales agregados por hospital se crean partir de linelist con el siguiente código.continuación se muestran las primeras 50 filas:","code":"\nlinelist <- import(\"linelist_cleaned.rds\")\n# import the counts data into R\ncount_data <- linelist %>% \n  group_by(hospital, date_hospitalisation) %>% \n  summarize(n_cases = dplyr::n()) %>% \n  filter(date_hospitalisation > as.Date(\"2013-06-01\")) %>% \n  ungroup()"},{"path":"epidemic-curves.html","id":"establecer-parámetros","chapter":"32 Curvas epidémicas","heading":"Establecer parámetros","text":"Para la producción de un informe, es posible que desees establecer parámetros editables como la fecha para la que los datos sean actuales (la “data_date”). continuación, puedes hacer referencia al objeto data_date en tu código cuando apliques filtros o en subtítulos dinámicos.","code":"\n## set the report date for the report\n## note: can be set to Sys.Date() for the current date\ndata_date <- as.Date(\"2015-05-15\")"},{"path":"epidemic-curves.html","id":"verificar-las-fechas","chapter":"32 Curvas epidémicas","heading":"Verificar las fechas","text":"Verifica que cada columna de fecha relevante es de tipo Date y tiene un rango de valores apropiado. Puedes hacerlo simplemente utilizando hist() para histogramas, o range() con na.rm=TRUE, o con ggplot() como se indica continuación.","code":"\n# check range of onset dates\nggplot(data = linelist)+\n  geom_histogram(aes(x = date_onset))"},{"path":"epidemic-curves.html","id":"epicurves-with-incidence2-package","chapter":"32 Curvas epidémicas","heading":"32.2 Epicurves con el paquete incidence2","text":"continuación mostramos cómo hacer curvas epidémicas utilizando el paquete incidence2. Los autores de este paquete han intentado que el usuario pueda crear y modificar curvas epidémicas sin necesidad de conocer la sintaxis de ggplot2. Gran parte de esta página está adaptada de las viñetas del paquete, que se pueden encontrar en la página de github de incidence2.","code":""},{"path":"epidemic-curves.html","id":"ejemplo-sencillo","chapter":"32 Curvas epidémicas","heading":"Ejemplo sencillo","text":"Se requieren 2 pasos para trazar una curva epidémica con el paquete incidence2:Crear un objeto de incidencia (utilizando la función incidence())\nProporcionar los datos\nEspecificar la columna de fecha date_index =\nEspecificar el interval = en el que deben agregarse los casos (diario, semanal, mensual..)\nEspecificar cualquier columna de agrupación (por ejemplo, sexo, hospital, resultado)\nProporcionar los datosEspecificar la columna de fecha date_index =Especificar el interval = en el que deben agregarse los casos (diario, semanal, mensual..)Especificar cualquier columna de agrupación (por ejemplo, sexo, hospital, resultado)Representarr el objeto de incidencia\nEspecificar etiquetas, colores, títulos, etc.\nEspecificar etiquetas, colores, títulos, etc.continuación, cargamos el paquete incidence2, creamos el objeto de incidencia partir de linelist en la columna date_onset y agregamos los casos por día. continuación, imprimimos un resumen del objeto de incidencia.El objeto epi_day2 tiene el aspecto de un tibble (como una trama de datos) y puede imprimirse o manipularse como un dataframe.Este es el aspecto que tiene cuando se imprime. Tiene una columna date_index y una columna count.También puedes imprimir un resumen del objeto:Para trazar el objeto de incidencia, utiliza plot() en el nombre del objeto de incidencia. En segundo plano, se llama la función plot.incidence2(), por lo que para leer la documentación específica de incidence2** se ejecutaría ?plot.incidence2.Si notas muchas líneas blancas verticales diminutas, intenta ajustar el tamaño de la imagen. Por ejemplo, si exportas el gráfico con ggsave(), puede proporcionar números width = y height =. Si amplías el gráfico esas líneas pueden desaparecer.","code":"\n# load incidence2 package\npacman::p_load(incidence2)\n\n# create the incidence object, aggregating cases by day\nepi_day <- incidence(       # create incidence object\n  x = linelist,             # dataset\n  date_index = date_onset,  # date column\n  interval = \"day\"          # date grouping interval\n  )\nclass(epi_day)## [1] \"incidence2\"   \"incidence_df\" \"tbl_df\"       \"tbl\"          \"data.frame\"\nepi_day## An incidence object: 367 x 2\n## date range: [2014-04-07] to [2015-04-30]\n## cases: 5632\n## interval: 1 day\n## cumulative: FALSE\n## \n##    date_index count\n##    <date>     <int>\n##  1 2014-04-07     1\n##  2 2014-04-15     1\n##  3 2014-04-21     2\n##  4 2014-04-25     1\n##  5 2014-04-26     1\n##  6 2014-04-27     1\n##  7 2014-05-01     2\n##  8 2014-05-03     1\n##  9 2014-05-04     1\n## 10 2014-05-05     1\n## # … with 357 more rows\n# print summary of the incidence object\nsummary(epi_day)## date range: [2014-04-07] to [2015-04-30]\n## cases: 5632\n## interval: 1 day\n## cumulative: FALSE\n## timespan: 389 days\n# plot the incidence object\nplot(epi_day)"},{"path":"epidemic-curves.html","id":"cambiar-el-intervalo-de-tiempo-de-la-agregación-de-casos","chapter":"32 Curvas epidémicas","heading":"Cambiar el intervalo de tiempo de la agregación de casos","text":"El argumento interval = de incidence() define cómo se agrupan las observaciones en barras verticales.Especificar el intervaloincidence2 proporciona flexibilidad y una sintaxis comprensible para especificar cómo quieres agregar tus casos en una curva epidémica de barras Proporcione un valor como los siguientes al argumento interval =. Puedes escribir cualquiera de los siguientes en plural (por ejemplo, “weeks”), y puedes añadir números antes (por ejemplo, “3 months”).continuación se muestran ejemplos de cómo se ven los diferentes intervalos cuando se aplican linelist. Observa cómo el formato por defecto y la frecuencia de las etiquetas de fecha en el eje-x cambian medida que cambia el intervalo de fecha.Primera fechaPuedes especificar opcionalmente un valor de tipo Date (por ejemplo, .Date(\"2016-05-01\")) firstdate = en el comando incidence(). Si se da, los datos se recortarán este rango y los intervalos comenzarán en esta fecha.","code":"\n# Create the incidence objects (with different intervals)\n##############################\n# Weekly (Monday week by default)\nepi_wk      <- incidence(linelist, date_onset, interval = \"Monday week\")\n\n# Sunday week\nepi_Sun_wk  <- incidence(linelist, date_onset, interval = \"Sunday week\")\n\n# Three weeks (Monday weeks by default)\nepi_2wk     <- incidence(linelist, date_onset, interval = \"2 weeks\")\n\n# Monthly\nepi_month   <- incidence(linelist, date_onset, interval = \"month\")\n\n# Quarterly\nepi_quarter   <- incidence(linelist, date_onset, interval = \"quarter\")\n\n# Years\nepi_year   <- incidence(linelist, date_onset, interval = \"year\")\n\n\n# Plot the incidence objects (+ titles for clarity)\n############################\nplot(epi_wk)+      labs(title = \"Monday weeks\")\nplot(epi_Sun_wk)+  labs(title = \"Sunday weeks\")\nplot(epi_2wk)+     labs(title = \"2 (Monday) weeks\")\nplot(epi_month)+   labs(title = \"Months\")\nplot(epi_quarter)+ labs(title = \"Quarters\")\nplot(epi_year)+    labs(title = \"Years\")"},{"path":"epidemic-curves.html","id":"grupos","chapter":"32 Curvas epidémicas","heading":"Grupos","text":"Los grupos se especifican en el comando incidence(), y pueden utilizarse para colorear las barras o para facetar los datos. Para especificar los grupos en tus datos, escribe el nombre de la(s) columna(s) en el argumento groups = del comando incidence() (sin comillas alrededor del nombre de la columna). Si especificas varias columnas, pon sus nombres dentro de c().Puedes especificar que los casos con valores faltantes en las columnas de agrupación sean listados como un grupo NA distinto estableciendo na_as_group = TRUE. De lo contrario, se excluirán del gráfico.Para colorear las barras por una columna de agrupación, debes proporcionar de nuevo el nombre de la columna en fill = del comando plot().Para colorear las barras por una columna de agrupación, debes proporcionar de nuevo el nombre de la columna en fill = del comando plot().Para crear una faceta basada en una columna de agrupación, consulta la sección siguiente sobre facetas con incidence2.Para crear una faceta basada en una columna de agrupación, consulta la sección siguiente sobre facetas con incidence2.En el ejemplo siguiente, los casos de todo el brote se agrupan por su categoría de edad. Los valores faltantes se incluyen como grupo. El intervalo de la curva epidémica es de semanas.CONSEJO: Cambia el título de la leyenda añadiendo + el comando de ggplot2 labs(fill = \"su título\")También puedes hacer que las barras agrupadas se muestren una al lado de la otra estableciendo stack = FALSE en plot(), como se muestra continuación:Puedes establecer el argumento na_as_group = FALSE en el comando incidence() para eliminar las filas con valores faltantes del gráfico.","code":"\n# Create incidence object, with data grouped by age category\nage_outbreak <- incidence(\n  linelist,                # dataset\n  date_index = date_onset, # date column\n  interval = \"week\",       # Monday weekly aggregation of cases\n  groups = age_cat,        # age_cat is set as a group\n  na_as_group = TRUE)      # missing values assigned their own group\n\n# plot the grouped incidence object\nplot(\n  age_outbreak,             # incidence object with age_cat as group\n  fill = age_cat)+          # age_cat is used for bar fill color (must have been set as a groups column above)\nlabs(fill = \"Age Category\") # change legend title from default \"age_cat\" (this is a ggplot2 modification)\n# Make incidence object of monthly counts. \nmonthly_gender <- incidence(\n linelist,\n date_index = date_onset,\n interval = \"month\",\n groups = gender            # set gender as grouping column\n)\n\nplot(\n  monthly_gender,   # incidence object\n  fill = gender,    # display bars colored by gender\n  stack = FALSE)    # side-by-side (not stacked)"},{"path":"epidemic-curves.html","id":"datos-filtrados","chapter":"32 Curvas epidémicas","heading":"Datos filtrados","text":"Para trazar la curva epidémica de un subconjunto de datos:Filtrar los datos del listadoProporcionar los datos filtrados al comando incidence()Trazar el objeto de incidenciaEl ejemplo siguiente utiliza datos filtrados para mostrar sólo los casos del Central Hospital.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(central_data, date_index = date_onset, interval = \"week\")\n\n# plot the incidence object\nplot(central_outbreak, title = \"Weekly case incidence at Central Hospital\")"},{"path":"epidemic-curves.html","id":"recuentos-agregados","chapter":"32 Curvas epidémicas","heading":"Recuentos agregados","text":"Si los datos originales son agregados (recuentos), cuando crees el objeto de incidencia con incidence() proporciona el nombre de la columna que contiene los recuentos de casos al argumento count =.Por ejemplo, este dataframe count_data son casos de linelist agregados en recuentos diarios por hospital. Las primeras 50 filas tienen este aspecto:Si comienzas tu análisis con datos de recuento diario como el conjunto de datos anterior, tu comando incidence() para convertirlo en una curva epidémica semanal por hospital tendría el siguiente aspecto:","code":"\nepi_counts <- incidence(              # create weekly incidence object\n  count_data,                         # dataset with counts aggregated by day\n  date_index = date_hospitalisation,  # column with dates\n  count = n_cases,                    # column with counts\n  interval = \"week\",                  # aggregate daily counts up to weeks\n  groups = hospital                   # group by hospital\n  )\n\n# plot the weekly incidence epi curve, with stacked bars by hospital\nplot(epi_counts,                      # incidence object\n     fill = hospital)                 # color the bars by hospital"},{"path":"epidemic-curves.html","id":"facetaspequeños-múltiplos","chapter":"32 Curvas epidémicas","heading":"Facetas/pequeños múltiplos","text":"Facetar los datos por grupos (es decir, producir “pequeños múltiples”):Especificar la columna facetar en groups =Especificar la columna facetar en groups =Utilizar el comando facet_plot() en lugar de plot()Utilizar el comando facet_plot() en lugar de plot()Especificar qué columnas de agrupación utilizar como fill = y cuáles utilizar como facets =Especificar qué columnas de agrupación utilizar como fill = y cuáles utilizar como facets =continuación, establecemos las columnas hospital y outcome como columnas de agrupación en el comando incidence(). continuación, en facet_plot() trazamos la curva epidémica, especificando que queremos una curva epidémica diferente para cada hospital y que dentro de cada curva epidémica las barras deben estar apiladas y coloreadas por outcome.Ten en cuenta que el paquete ggtree (utilizado para mostrar árboles filogenéticos) también tiene una función facet_plot() - por eso especificamos incidence2::facet_plot() arriba.","code":"\nepi_wks_hosp_out <- incidence(\n  linelist,                      # dataset\n  date_index = date_onset,       # date column\n  interval = \"month\",            # monthly bars  \n  groups = c(outcome, hospital)  # both outcome and hospital are given as grouping columns\n  )\n\n# plot\nincidence2::facet_plot(\n  epi_wks_hosp_out,      # incidence object\n  facets = hospital,     # facet column\n  fill = outcome)        # fill column"},{"path":"epidemic-curves.html","id":"modificaciones-con-plot","chapter":"32 Curvas epidémicas","heading":"Modificaciones con plot()","text":"Una curva epidémica producida por incidence2 puede ser modificada través de estos argumentos dentro de la función plot().Aquí están los argumentos de plot() que modifican la apariencia de las barras:Aquí están los argumentos de plot() que modifican el eje de la fecha:Ten en cuenta que el argumento date_breaks = sólo funciona si centre_dates = FALSE. Proporciona un valor de carácter entre comillas utilizando la sintaxis strptime que se indica continuación, como se detalla en la página Trabajar con fechas. Puedes utilizar \\n para una “nueva línea”.%d = Número de día del mes (5, 17, 28, etc.)%j = Número de día del año (día juliano 001-366)%= Día de la semana abreviado (Mon, Tue, Wed, etc.)%= Día de la semana completo (Monday, Tuesday, etc.))%w = Número del día de la semana (0-6, el domingo es 0)%u = Número del día de la semana (1-7, el lunes es 1)%W = Número de la semana (00-53, el lunes es el comienzo de la semana)%U = Número de la semana (01-53, el domingo es el comienzo de la semana)%m = Número del mes (ej. 01, 02, 03, 04)%b = Mes abreviado (Jan, Feb, etc. )%B = Mes completo (January, February, etc.)%y = Año de 2 dígitos (por ejemplo, 89)%Y = Año de 4 dígitos (por ejemplo, 1989)%h = horas (reloj de 24 horas)%m = minutos%s = segundos%z = desviación de GMT%Z = Zona horaria (carácter)Estos son los argumentos de plot() que modifican las etiquetas de los gráficos:Un ejemplo que utiliza muchos de los argumentos anteriores:Para ajustar aún más la apariencia del gráfico, consulta la sección siguiente sobre modificaciones con ggplot().","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = outcome)\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  angle = 30,                           # angle of date labels\n  centre_dates = FALSE,                 # date labels at edge of bar\n  date_format = \"%a %d %b %Y\\n(Week %W)\" # adjust how dates are displayed\n  )"},{"path":"epidemic-curves.html","id":"modificaciones-con-ggplot2","chapter":"32 Curvas epidémicas","heading":"Modificaciones con ggplot2","text":"Puedes modificar aún más un gráfico de incidence2 añadiendo modificaciones de ggplot2 con un + después del cierre de la función plot() de incidence, como se demuestra continuación.continuación, el gráfico de incidence2 termina y luego se utilizan los comandos de ggplot2 para modificar los ejes, añadir una leyenda y ajustar la fuente en negrita y el tamaño del texto.Ten en cuenta que si añades scale_x_date(), la mayor parte del formato de fecha de plot() se sobrescribirá. Consulta la sección de curvas epidémicas de ggplot() y la página del Manual Consejos de ggplot para más opciones.","code":"\n# filter the linelist\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")\n\n# create incidence object using filtered data\ncentral_outbreak <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = c(outcome))\n\n# plot incidence object\nplot(\n  central_outbreak,\n  fill = outcome,                       # box/bar color\n  legend = \"top\",                       # legend on top\n  title = \"Cases at Central Hospital\",  # title\n  xlab = \"Week of onset\",               # x-axis label\n  ylab = \"Week of onset\",               # y-axis label\n  show_cases = TRUE,                    # show each case as an individual box\n  alpha = 0.7,                          # transparency \n  border = \"grey\",                      # box border\n  centre_dates = FALSE,                   \n  date_format = \"%a %d %b\\n%Y (Week %W)\", \n  angle = 30                           # angle of date labels\n  )+\n  \n  scale_y_continuous(\n    breaks = seq(from = 0, to = 30, by = 5),  # specify y-axis increments by 5\n    expand = c(0,0))+                         # remove excess space below 0 on y-axis\n  \n  # add dynamic caption\n  labs(\n    fill = \"Patient outcome\",                               # Legend title\n    caption = stringr::str_glue(                            # dynamic caption - see page on characters and strings for details\n      \"n = {central_cases} from Central Hospital\n      Case onsets range from {earliest_date} to {latest_date}. {missing_onset} cases are missing date of onset and not shown\",\n      central_cases = nrow(central_data),\n      earliest_date = format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),\n      latest_date = format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y'),      \n      missing_onset = nrow(central_data %>% filter(is.na(date_onset)))))+\n  \n  # adjust bold face, and caption position\n  theme(\n    axis.title = element_text(size = 12, face = \"bold\"),    # axis titles larger and bold\n    axis.text = element_text(size = 10, face = \"bold\"),     # axis text size and bold\n    plot.caption = element_text(hjust = 0, face = \"italic\") # move caption to left\n  )"},{"path":"epidemic-curves.html","id":"cambiar-los-colores","chapter":"32 Curvas epidémicas","heading":"Cambiar los colores","text":"","code":""},{"path":"epidemic-curves.html","id":"especificar-una-paleta","chapter":"32 Curvas epidémicas","heading":"Especificar una paleta","text":"Proporciona el nombre de una paleta predefinida al argumento col_pal = en plot(). El paquete incidence2 viene con 2 paletas predefinidas: “vibrant” y “muted”. En “vibrant” los primeros 6 colores son distintos y en “muted” los primeros 9 colores son distintos. Después de estos números, los colores son interpolaciones/intermediarios de otros colores. Estas paletas predefinidas se pueden encontrar en este sitio web. Las paletas excluyen el gris, que está reservado para los datos que faltan (utiliza na_color = para cambiar este valor por defecto).También puedes utilizar una de las paletas de R base (pon el nombre de la paleta sin comillas).También puedes añadir una paleta de colores del paquete viridis o del paquete RColorBrewer. Primero hay que cargar esos paquetes, y luego añadir sus respectivas funciones scale_fill_*() con un +, como se muestra continuación.","code":"\n# Create incidence object, with data grouped by age category  \nage_outbreak <- incidence(\n  linelist,\n  date_index = date_onset,   # date of onset for x-axis\n  interval = \"week\",         # weekly aggregation of cases\n  groups = age_cat)\n\n# plot the epicurve with default palette\nplot(age_outbreak, fill = age_cat, title = \"'vibrant' default incidence2 palette\")\n\n# plot with different color palette\n#plot(age_outbreak, fill = age_cat, col_pal = muted, title = \"'muted' incidence2 palette\")\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = heat.colors, title = \"base R heat.colors palette\")\n\n# plot with base R palette\nplot(age_outbreak, fill = age_cat, col_pal = rainbow, title = \"base R rainbow palette\")\npacman::p_load(RColorBrewer, viridis)\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"Viridis palette\")+\n  scale_fill_viridis_d(\n    option = \"inferno\",     # color scheme, try also \"plasma\" or the default\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values\n\n# plot with color palette\nplot(age_outbreak, fill = age_cat, title = \"RColorBrewer palette\")+\n  scale_fill_brewer(\n    palette = \"Dark2\",      # color palette, try also Accent, Dark2, Paired, Pastel1, Pastel2, Set1, Set2, Set3\n    name = \"Age Category\",  # legend name\n    na.value = \"grey\")      # for missing values"},{"path":"epidemic-curves.html","id":"especificar-manualmente","chapter":"32 Curvas epidémicas","heading":"Especificar manualmente","text":"Para especificar los colores manualmente, añade la función scale_fill_manual() de ggplot2 la función plot() con un + y proporciona el vector de nombres de colores o códigos HEX al argumento values =. El número de colores listados debe ser igual al número de grupos. Ten en cuenta que si los valores faltantes son un grupo - pueden ser convertidos un valor de carácter como “Missing” durante la preparación de los datos con la función fct_explicit_na() como se explica en la página sobre Factores.Como se menciona en la página Consejos de ggplot, puedes crear tus propias paletas utilizando colorRampPalette() sobre un vector de colores y especificando el número de colores que deseas. Esta es una buena manera de obtener muchos colores en una rampa especificando unos pocos.","code":"\n# manual colors\nplot(age_outbreak, fill = age_cat, title = \"Manually-specified colors\")+\n  scale_fill_manual(\n    values = c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\", \"red\", \"lightblue\"),  # colors\n    name = \"Age Category\")      # Name for legend\nmy_cols <- c(\"darkgreen\", \"darkblue\", \"purple\", \"grey\", \"yellow\", \"orange\")\nmy_palette <- colorRampPalette(my_cols)(12)  # expand the 6 colors above to 12 colors\nmy_palette##  [1] \"#006400\" \"#00363F\" \"#00097E\" \"#3A0BAF\" \"#821ADD\" \"#A84BE2\" \"#B592CB\" \"#C9C99B\" \"#E7E745\" \"#FFF600\"\n## [11] \"#FFCD00\" \"#FFA500\""},{"path":"epidemic-curves.html","id":"ajustar-el-orden-de-los-niveles","chapter":"32 Curvas epidémicas","heading":"Ajustar el orden de los niveles","text":"Para ajustar el orden de aparición de los grupos (en el gráfico y en la leyenda), la columna de agrupación debe ser de tipo Factor. Consulta la página sobre Factores para obtener más información.En primer lugar, veamos una curva epidémica semanal por hospital con la ordenación por defecto:Ahora, para ajustar el orden de manera que los “Missing” y “Otros” estén en la parte superior de la curva epidémica podemos hacer lo siguiente:Cargar el paquete forcats, para trabajar con factoresAjustar los datos - en este caso vamos definir un nuevo dataset (plot_data) en el que:\nla columna gender se define como un factor el orden de los niveles se establecen con fct_relevel() de manera que “” y “Missing” son los primeros, por lo que aparecen en la parte superior de las barras\nla columna gender se define como un factor el orden de los niveles se establecen con fct_relevel() de manera que “” y “Missing” son los primeros, por lo que aparecen en la parte superior de las barrasEl objeto de incidencia se crea y se traza como antesAñadimos modificaciones de ggplot2 \nscale_fill_manual() para asignar manualmente los colores para que “Missing” sea gris y “” sea beige\nscale_fill_manual() para asignar manualmente los colores para que “Missing” sea gris y “” sea beigeCONSEJO: Si deseas invertir el orden de la leyenda solamente, añade este comando guides(fill = guide_legend(reverse = TRUE))de ggplot2.","code":"\n# ORIGINAL - hospital NOT as factor\n###################################\n\n# create weekly incidence object, rows grouped by hospital and week\nhospital_outbreak <- incidence(\n  linelist,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak, fill = hospital, title = \"ORIGINAL - hospital not a factor\")\n# MODIFIED - hospital as factor\n###############################\n\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Convert hospital column to factor and adjust levels\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Set \"Missing\" and \"Other\" as top levels\n\n\n# Create weekly incidence object, grouped by hospital and week\nhospital_outbreak_mod <- incidence(\n  plot_data,\n  date_index = date_onset, \n  interval = \"week\", \n  groups = hospital)\n\n# plot incidence object\nplot(hospital_outbreak_mod, fill = hospital)+\n  \n  # manual specify colors\n  scale_fill_manual(values = c(\"grey\", \"beige\", \"darkgreen\", \"green2\", \"orange\", \"red\", \"pink\"))+                      \n\n  # labels added via ggplot\n  labs(\n      title = \"MODIFIED - hospital as factor\",   # plot title\n      subtitle = \"Other & Missing at top of epicurve\",\n      y = \"Weekly case incidence\",               # y axis title  \n      x = \"Week of symptom onset\",               # x axis title\n      fill = \"Hospital\")                         # title of legend     "},{"path":"epidemic-curves.html","id":"líneas-de-cuadrícula-verticales","chapter":"32 Curvas epidémicas","heading":"Líneas de cuadrícula verticales","text":"Si utilizas la configuración predeterminada de incidence2, puedes observar que las líneas de cuadrícula verticales aparecen en cada etiqueta de fecha y una vez entre cada etiqueta de semana. Esto puede dar lugar que las líneas de cuadrícula se crucen con la parte superior de algunas barras.Puedes eliminar todas las líneas de la cuadrícula añadiendo el comando theme_classic() de ggplot2.Ten en cuenta, sin embargo, que si utiliza semanas, los argumentos date_breaks y date_minor_breaks sólo funcionan para las semanas del lunes. Si tus semanas emepiezan por otro día de la semana tendrás que proporcionar manualmente un vector de fechas los argumentos breaks = y minor_breaks =. Consulta la sección de ggplot2 para ver ejemplos de esto utilizando seq.Date().","code":"\n# make incidence object\na <- incidence(\n  central_data,\n  date_index = date_onset,\n  interval = \"Monday weeks\"\n)\n\n# Default gridlines\nplot(a, title = \"Default lines\")\n\n# Specified gridline intervals\n# NOT WORKING WITH INCIDENCE2 1.0.0\n# plot(a, title = \"Weekly lines\")+\n#   scale_x_date(\n#     date_breaks = \"4 weeks\",      # major vertical lines align on weeks\n#     date_minor_breaks = \"weeks\",  # minor vertical lines every week\n#     date_labels = \"%a\\n%d\\n%b\")   # format of date labels\n\n# No gridlines\nplot(a, title = \"No lines\")+\n  theme_classic()                 # remove all gridlines"},{"path":"epidemic-curves.html","id":"incidencia-acumulada","chapter":"32 Curvas epidémicas","heading":"Incidencia acumulada","text":"En versiones anteriores de incidence2 se podía usar la función cumulate(). Esto se ha eliminado en la versión más reciente del paquete.Ver la sección más abajo en esta página para el método alternativo para trazar la incidencia acumulativa con ggplot2 - por ejemplo para superponer una línea de incidencia acumulativa sobre una curva epidémica.","code":""},{"path":"epidemic-curves.html","id":"media-móvil","chapter":"32 Curvas epidémicas","heading":"Media móvil","text":"Puedes añadir una media móvil un gráfico de incidence2 fácilmente con add_rolling_average() del paquete i2extras. Pasa tu objeto incidence2 esta función, y luego plot(). Establece en = el número de días anteriores que deseas incluir en la media móvil (por defecto es 2). Si tus datos están agrupados, la media móvil se calculará por grupo.Para aprender aplicar las medias móviles de forma más general sobre los datos, consulta la página del Manual sobre medias móviles.","code":"\nrolling_avg <- incidence(                    # make incidence object\n  linelist,\n  date_index = date_onset,\n  interval = \"week\",\n  groups = gender) %>% \n  \n  i2extras::add_rolling_average(before = 6)  # add rolling averages (in this case, by gender)\n\n# plot\nplot(rolling_avg) # faceted automatically because rolling average on groups"},{"path":"epidemic-curves.html","id":"epicurves-with-ggplot2","chapter":"32 Curvas epidémicas","heading":"32.3 Curvas epidémicas con ggplot2","text":"El uso de ggplot() para construir tu curva epidémica permite más flexibilidad y personalización, pero requiere más esfuerzo y comprensión de cómo funciona ggplot().diferencia de lo que ocurre con el paquete incidence2, hay que controlar manualmente la agregación de los casos por tiempo (en semanas, meses, etc.) y los intervalos de las etiquetas en el eje de fechas. Esto debe gestionarse cuidadosamente.Estos ejemplos utilizan un subconjunto de los datos de linelist: sólo los casos del Hospital Central.Para producir una curva epidémica con ggplot() hay tres elementos principales:Un histograma, con los casos de la lista de líneas agregados en “bins” distinguidos por puntos específicos de “ruptura”.Escalas para los ejes y sus etiquetasTemas para la apariencia del gráfico, incluyendo títulos, etiquetas, subtítulos, etc.","code":"\ncentral_data <- linelist %>% \n  filter(hospital == \"Central Hospital\")"},{"path":"epidemic-curves.html","id":"especificaciones-de-las-barras","chapter":"32 Curvas epidémicas","heading":"Especificaciones de las barras","text":"Aquí mostramos cómo especificar cómo se agregarán los casos en los intervalos del histograma (“barras”). Es importante reconocer que la agregación de los casos en los intervalos del histograma son necesariamente los mismos intervalos que las fechas que aparecerán en el eje-x.continuación se muestra el código más sencillo para producir curvas epidémicas diarias y semanales.En el comando general ggplot() se proporciona el conjunto de datos en data =. Sobre esta base, se añade la geometría de un histograma con un +. Dentro de geom_histogram(), mapeamos la estética de tal manera que la columna date_onset se mapea al eje-x. También dentro de geom_histogram() pero dentro de aes() establecemos la anchura de las barras del histograma con binwidth =, en días. Si esta sintaxis de ggplot2 es confusa, revisa la página sobre Conceptos básicos de ggplot.PRECAUCIÓN: El trazado de casos semanales mediante el uso de binwidth = 7 inicia la primera barra de 7 días en el primer caso, ¡que podría ser cualquier día de la semana! Para crear semanas específicas, véase la sección siguiente.Observamos que el primer caso de este conjunto de datos del Hospital Central tuvo un inicio de síntomas el:Para especificar manualmente las pausas del histograma, utilices el argumento binwidth =, y en su lugar suministra un vector de fechas breaks =.Crea el vector de fechas con la función seq.Date() de R base. Esta función espera argumentos =, =, y =. Por ejemplo, el comando siguiente devuelve fechas mensuales que comienzan en el 15 de enero y terminan en el 28 de junio.Este vector puede proporcionarse geom_histogram() como breaks =:Una secuencia simple de fechas semanales puede ser devuelta estableciendo = \"week\". Por ejemplo:Una alternativa la provisión de fechas específicas de inicio y fin es escribir un código dinámico para que los intervalos semanales comiencen el lunes anterior al primer caso. Utilizaremos estos vectores de fechas lo largo de los ejemplos siguientes.Descompongamos el código anterior, que es bastante desalentador:El valor “” (fecha más temprana) se crea de la siguiente manera: el valor mínimo de fecha (min() con na.rm=TRUE) en la columna date_onset se introduce en floor_date() del paquete lubridate. floor_date() ajustado “week” devuelve la fecha de inicio de la “semana” de esos casos, dado que el día de inicio de cada semana es un lunes (week_start = 1).Asimismo, el valor “” (fecha final) se crea utilizando la función inversa ceiling_date() para devolver el lunes posterior al último caso.El argumento “” de seq.Date() puede establecerse en cualquier número de días, semanas o meses.Utiliza week_start = 7 para las semanas de domingoComo vamos utilizar estos vectores de fechas lo largo de esta página, también definimos uno para todo el brote (el anterior es sólo para el Hospital Central).Estas salidas de seq.Date() pueden utilizarse para crear los saltos de las casillas del histograma, pero también los saltos de las etiquetas de fecha, que pueden ser independientes de las casillas. Lea más sobre las etiquetas de fecha en secciones posteriores.CONSEJO: Para un comando ggplot() más sencillo, guarda los saltos de cubo y los saltos de etiqueta de fecha como vectores con nombre por adelantado, y simplemente proporciona sus nombres breaks =..","code":"\n# daily \nggplot(data = central_data) +          # set data\n  geom_histogram(                      # add histogram\n    mapping = aes(x = date_onset),     # map date column to x-axis\n    binwidth = 1)+                     # cases binned by 1 day \n  labs(title = \"Central Hospital - Daily\")                # title\n\n# weekly\nggplot(data = central_data) +          # set data \n  geom_histogram(                      # add histogram\n      mapping = aes(x = date_onset),   # map date column to x-axis\n      binwidth = 7)+                   # cases binned every 7 days, starting from first case (!) \n  labs(title = \"Central Hospital - 7-day bins, starting at first case\") # title\nformat(min(central_data$date_onset, na.rm=T), \"%A %d %b, %Y\")## [1] \"Thursday 01 May, 2014\"\nmonthly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                           to = as.Date(\"2015-07-15\"),\n                           by = \"months\")\n\nmonthly_breaks   # print##  [1] \"2014-02-01\" \"2014-03-01\" \"2014-04-01\" \"2014-05-01\" \"2014-06-01\" \"2014-07-01\" \"2014-08-01\"\n##  [8] \"2014-09-01\" \"2014-10-01\" \"2014-11-01\" \"2014-12-01\" \"2015-01-01\" \"2015-02-01\" \"2015-03-01\"\n## [15] \"2015-04-01\" \"2015-05-01\" \"2015-06-01\" \"2015-07-01\"\n# monthly \nggplot(data = central_data) +  \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    breaks = monthly_breaks)+         # provide the pre-defined vector of breaks                    \n  labs(title = \"Monthly case bins\")   # title\nweekly_breaks <- seq.Date(from = as.Date(\"2014-02-01\"),\n                          to = as.Date(\"2015-07-15\"),\n                          by = \"week\")\n# Sequence of weekly Monday dates for CENTRAL HOSPITAL\nweekly_breaks_central <- seq.Date(\n  from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")\n# Sequence for the entire outbreak\nweekly_breaks_all <- seq.Date(\n  from = floor_date(min(linelist$date_onset, na.rm=T),   \"week\", week_start = 1), # monday before first case\n  to   = ceiling_date(max(linelist$date_onset, na.rm=T), \"week\", week_start = 1), # monday after last case\n  by   = \"week\")"},{"path":"epidemic-curves.html","id":"ejemplo-de-curva-epidémica-semanal","chapter":"32 Curvas epidémicas","heading":"Ejemplo de curva epidémica semanal","text":"continuación se muestra un código de ejemplo detallado para producir curvas epidémicas semanales para las semanas del lunes, con barras alineadas, etiquetas de fecha y líneas de cuadrícula verticales. Esta sección es para el usuario que necesita el código rápidamente. Para entender cada aspecto (temas, etiquetas de fecha, etc.) en profundidad, continúa con las secciones siguientes. Es importante tener en cuenta:Las pausas del histograma se definen con seq.Date(), como se ha explicado anteriormente, para comenzar el lunes anterior al caso más antiguo y terminar el lunes posterior al último casoEl intervalo de las etiquetas de fecha se especifica mediante date_breaks = dentro de scale_x_date()El intervalo de líneas verticales menores entre etiquetas de fecha se especifica en date_minor_breaks =expand = c(0,0) en los ejes x e y elimina el exceso de espacio cada lado de los ejes, lo que también asegura que las etiquetas de fecha comiencen desde la primera barra.","code":"\n# TOTAL MONDAY WEEK ALIGNMENT\n#############################\n# Define sequence of weekly breaks\nweekly_breaks_central <- seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 1), # Monday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 1), # Monday after last case\n      by   = \"week\")    # bins are 7-days \n\n\nggplot(data = central_data) + \n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    \n    # mapping aesthetics\n    mapping = aes(x = date_onset),  # date column mapped to x-axis\n    \n    # histogram bin breaks\n    breaks = weekly_breaks_central, # histogram bin breaks defined previously\n    \n    # bars\n    color = \"darkblue\",     # color of lines around bars\n    fill = \"lightblue\"      # color of fill within bars\n  )+ \n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),           # remove excess x-axis space before and after case bars\n    date_breaks       = \"4 weeks\",        # date labels and major vertical gridlines appear every 3 Monday weeks\n    date_minor_breaks = \"week\",           # minor vertical lines appear every Monday week\n    date_labels       = \"%a\\n%d %b\\n%Y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+             # remove excess y-axis space below 0 (align histogram flush with x-axis)\n  \n  # aesthetic themes\n  theme_minimal()+                # simplify plot background\n  \n  theme(\n    plot.caption = element_text(hjust = 0,        # caption on left side\n                                face = \"italic\"), # caption in italics\n    axis.title = element_text(face = \"bold\"))+    # axis titles in bold\n  \n  # labels including dynamic caption\n  labs(\n    title    = \"Weekly incidence of cases (Monday weeks)\",\n    subtitle = \"Note alignment of bars, vertical gridlines, and axis labels on Monday weeks\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"semanas-dominicales","chapter":"32 Curvas epidémicas","heading":"Semanas dominicales","text":"Para conseguir el gráfico anterior para las semanas desde los domingos son necesarias algunas modificaciones, ya que los date_breaks = \"weeks\" sólo funcionan para las semanas de los lunes.Los puntos de ruptura de las franjas del histograma deben fijarse en los domingos (week_start = 7)Dentro de scale_x_date(), los saltos de fecha similares deben proporcionarse breaks = y minor_breaks = para asegurar que las etiquetas de fecha y las líneas verticales de la cuadrícula se alineen los domingos.Por ejemplo, el comando scale_x_date() para las semanas del domingo podría tener este aspecto:","code":"scale_x_date(\n    expand = c(0,0),\n    \n    # specify interval of date labels and major vertical gridlines\n    breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"4 weeks\"),\n    \n    # specify interval of minor vertical gridline \n    minor_breaks = seq.Date(\n      from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7), # Sunday before first case\n      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7), # Sunday after last case\n      by   = \"week\"),\n   \n    # date label format\n    date_labels = \"%a\\n%d %b\\n%Y\")+         # day, above month abbrev., above 2-digit year"},{"path":"epidemic-curves.html","id":"agruparcolorear-por-valor","chapter":"32 Curvas epidémicas","heading":"Agrupar/colorear por valor","text":"Las barras del histograma pueden colorearse por grupos y “apilarse”. Para designar la columna de agrupación, haz los siguientes cambios. Consulta la página de Conceptos básicos de ggplot para más detalles.Dentro del mapeo estético del histograma aes(), asigna el nombre de la columna los argumentos group = y fill =Elimina cualquier argumento fill = fuera de aes(), ya que anulará el de dentroLos argumentos dentro de aes() se aplicarán por grupo, mientras que los de fuera se aplicarán todas las barras (por ejemplo, es posible que quieras color = fuera, para que cada barra tenga el mismo borde)Este es el aspecto que tendría el comando aes() para agrupar y colorear las barras por gender:Aquí se aplica:","code":"\naes(x = date_onset, group = gender, fill = gender)\nggplot(data = linelist) +     # begin with linelist (many hospitals)\n  \n  # make histogram: specify bin break points: starts the Monday before first case, end Monday after last case\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = hospital,       # set data to be grouped by hospital\n      fill = hospital),       # bar fill (inside color) by hospital\n    \n    # bin breaks are Monday weeks\n    breaks = weekly_breaks_all,   # sequence of weekly Monday bin breaks for whole outbreak, defined in previous code       \n    \n    # Color around bars\n    color = \"black\")"},{"path":"epidemic-curves.html","id":"ajustar-los-colores","chapter":"32 Curvas epidémicas","heading":"Ajustar los colores","text":"Para establecer manualmente el relleno de cada grupo, utiliza scale_fill_manual() (nota: scale_color_manual() es diferente).\nUtiliza el argumento values = para aplicar un vector de colores.\nUtiliza na.value = para especificar un color para los valores NA.\nUtiliza el argumento labels = para cambiar el texto de los elementos de la leyenda. Para estar seguro, proporciónalo como un vector, como c(\"old\" = \"new\", \"old\" = \"new\") o ajusta los valores en los propios datos.\nUtiliza name = para dar un título adecuado la leyenda\nUtiliza el argumento values = para aplicar un vector de colores.Utiliza na.value = para especificar un color para los valores NA.Utiliza el argumento labels = para cambiar el texto de los elementos de la leyenda. Para estar seguro, proporciónalo como un vector, como c(\"old\" = \"new\", \"old\" = \"new\") o ajusta los valores en los propios datos.Utiliza name = para dar un título adecuado la leyendaConsulta la página sobre Conceptos básicos de ggplot para obtener más información sobre escalas y paletas de colores.","code":"\nggplot(data = linelist)+           # begin with linelist (many hospitals)\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,          # cases grouped by hospital\n        fill = hospital),          # bar fill by hospital\n    \n    # bin breaks\n    breaks = weekly_breaks_all,        # sequence of weekly Monday bin breaks, defined in previous code\n    \n    # Color around bars\n    color = \"black\")+              # border color of each bar\n  \n  # manual specification of colors\n  scale_fill_manual(\n    values = c(\"black\", \"orange\", \"grey\", \"beige\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\") # specify fill colors (\"values\") - attention to order!"},{"path":"epidemic-curves.html","id":"ajustar-el-orden-de-los-niveles-1","chapter":"32 Curvas epidémicas","heading":"Ajustar el orden de los niveles","text":"El orden en que se apilan las barras agrupadas se ajusta mejor clasificando la columna de agrupación como tipo Factor. continuación, puedes designar el orden de los niveles de los factores (y sus etiquetas de visualización). Consulta la página sobre Factores o consejos de ggplot para obtener más detalles.Antes de realizar el gráfico, utiliza la función fct_relevel() del paquete forcats para convertir la columna de agrupación en de tipo factor y ajustar manualmente el orden de los niveles, como se detalla en la página sobre Factores.En el siguiente gráfico, las únicas diferencias con respecto al anterior es que la columna hospital se ha consolidado como en el caso anterior, y utilizamos guides() para invertir el orden de la leyenda, de modo que “Missing” se encuentra en la parte inferior de la leyenda.CONSEJO: Para invertir solamente el orden de la leyenda, añade este comando ggplot2: guides(fill = guide_legend(reverse = TRUE)).","code":"\n# load forcats package for working with factors\npacman::p_load(forcats)\n\n# Define new dataset with hospital as factor\nplot_data <- linelist %>% \n  mutate(hospital = fct_relevel(hospital, c(\"Missing\", \"Other\"))) # Convert to factor and set \"Missing\" and \"Other\" as top levels to appear on epicurve top\n\nlevels(plot_data$hospital) # print levels in order## [1] \"Missing\"                              \"Other\"                               \n## [3] \"Central Hospital\"                     \"Military Hospital\"                   \n## [5] \"Port Hospital\"                        \"St. Mark's Maternity Hospital (SMMH)\"\nggplot(plot_data) +                     # Use NEW dataset with hospital as re-ordered factor\n  \n  # make histogram\n  geom_histogram(\n    mapping = aes(x = date_onset,\n        group = hospital,               # cases grouped by hospital\n        fill = hospital),               # bar fill (color) by hospital\n    \n    breaks = weekly_breaks_all,         # sequence of weekly Monday bin breaks for whole outbreak, defined at top of ggplot section\n    \n    color = \"black\")+                   # border color around each bar\n    \n  # x-axis labels\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space before and after case bars\n    date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n    date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n    date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(\n    expand = c(0,0))+                   # remove excess y-axis space below 0\n  \n  # manual specification of colors, ! attention to order\n  scale_fill_manual(\n    values = c(\"grey\", \"beige\", \"black\", \"orange\", \"blue\", \"brown\"),\n    labels = c(\"St. Mark's Maternity Hospital (SMMH)\" = \"St. Mark's\"),\n    name = \"Hospital\")+ \n  \n  # aesthetic themes\n  theme_minimal()+                      # simplify plot background\n  \n  theme(\n    plot.caption = element_text(face = \"italic\", # caption on left side in italics\n                                hjust = 0), \n    axis.title = element_text(face = \"bold\"))+   # axis titles in bold\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases by hospital\",\n    subtitle = \"Hospital as re-ordered factor\",\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly cases\")"},{"path":"epidemic-curves.html","id":"ajustar-la-leyenda","chapter":"32 Curvas epidémicas","heading":"Ajustar la leyenda","text":"Lee más sobre las leyendas y las escalas en la página Consejos de ggplot. Aquí hay algunos puntos destacados:Edita el título de la leyenda, ya sea en la función de escala o con labs(fill = \"Título de la leyenda\") (si estás usando color = estético, entonces usa labs(color = \"\"))theme(legend.title = element_blank()) para tener título de leyendatheme(legend.position = \"top\") (“bottom”, “left”, “right”, o “none” para eliminar la leyenda)theme(legend.direction = \"horizontal\") leyenda horizontalguides(fill = guide_legend(reverse = TRUE)) para invertir el orden de la leyenda","code":""},{"path":"epidemic-curves.html","id":"barras-de-lado-a-lado","chapter":"32 Curvas epidémicas","heading":"Barras de lado a lado","text":"La visualización lado lado de las barras de grupo (en lugar de apiladas) se especifica dentro de geom_histogram() con position = \"dodge\" colocado fuera de aes().Si hay más de dos grupos de valores, éstos pueden resultar difíciles de leer. Considera la posibilidad de utilizar un gráfico facetado (múltiples pequeños). Para mejorar la legibilidad en este ejemplo, se han eliminado los valores de género que faltan.","code":"\nggplot(central_data %>% drop_na(gender))+   # begin with Central Hospital cases dropping missing gender\n    geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = gender,         # cases grouped by gender\n          fill = gender),         # bars filled by gender\n        \n        # histogram bin breaks\n        breaks = weekly_breaks_central,   # sequence of weekly dates for Central outbreak - defined at top of ggplot section\n        \n        color = \"black\",          # bar edge color\n        \n        position = \"dodge\")+      # SIDE-BY-SIDE bars\n                      \n  \n  # The labels on the x-axis\n  scale_x_date(expand            = c(0,0),         # remove excess x-axis space below and after case bars\n               date_breaks       = \"3 weeks\",      # labels appear every 3 Monday weeks\n               date_minor_breaks = \"week\",         # vertical lines appear every Monday week\n               date_labels       = \"%d\\n%b\\n'%y\")+ # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+             # removes excess y-axis space between bottom of bars and the labels\n  \n  #scale of colors and legend labels\n  scale_fill_manual(values = c(\"brown\", \"orange\"),  # specify fill colors (\"values\") - attention to order!\n                    na.value = \"grey\" )+     \n\n  # aesthetic themes\n  theme_minimal()+                                               # a set of themes to simplify plot\n  theme(plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n        axis.title = element_text(face = \"bold\"))+               # axis titles in bold\n  \n  # labels\n  labs(title    = \"Weekly incidence of cases, by gender\",\n       subtitle = \"Subtitle\",\n       fill     = \"Gender\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\")"},{"path":"epidemic-curves.html","id":"límites-del-eje","chapter":"32 Curvas epidémicas","heading":"Límites del eje","text":"Hay dos maneras de limitar la extensión de los valores del eje.Por lo general, la forma preferida es utilizar el comando coord_cartesian(), que acepta xlim = c(min, max) y ylim = c(min, max) (donde proporcionas los valores mínimos y máximos). Esto actúa como un “zoom” sin eliminar realmente ningún dato, lo que es importante para las estadísticas y las medidas de resumen.Alternativamente, puedes establecer valores de fecha máximos y mínimos utilizando limits = c() dentro de scale_x_date(). Por ejemplo:Asimismo, si deseas que el eje-x se extienda hasta una fecha concreta (por ejemplo, la fecha actual), aunque se hayan notificado nuevos casos, puedes utilizarPELIGRO: Ten cuidado al establecer los cortes o límites de la escala del eje-y (por ejemplo, de 0 30 por 5: seq(0, 30, 5)). Tales números estáticos pueden cortar tu gráfica demasiado si los datos cambian para superar el límite!","code":"\nscale_x_date(limits = c(as.Date(\"2014-04-01\"), NA)) # sets a minimum date but leaves the maximum open.  scale_x_date(limits = c(NA, Sys.Date()) # ensures date axis will extend until current date  "},{"path":"epidemic-curves.html","id":"ejes-de-fecha-etiquetascuadrículas","chapter":"32 Curvas epidémicas","heading":"Ejes de fecha etiquetas/cuadrículas","text":"CONSEJO: Recuerda que las etiquetas de los ejes de fecha son independientes de la agregación de los datos en barras, pero visualmente puede ser importante alinear las franjas, las etiquetas de fecha y las líneas verticales de la cuadrícula.Para modificar las etiquetas de fecha y las líneas de la cuadrícula, utiliza scale_x_date() de una de estas maneras:Si los intervalos de tu histograma son días, semanas de lunes, meses o años:\nUtiliza date_breaks = para especificar el intervalo de las etiquetas y las líneas principales de la cuadrícula (por ejemplo, “day”, “week”, “3 weeks”, “month”, o “year”)\nUtiliza date_minor_breaks = para especificar el intervalo de las líneas verticales menores (entre las etiquetas de fecha)\nAñade expand = c(0,0) para comenzar las etiquetas en la primera barra\nUsa date_labels = para especificar el formato de las etiquetas de fecha - mira la página de trabajar con fechas para consejos (usa \\n para una nueva línea)\nUtiliza date_breaks = para especificar el intervalo de las etiquetas y las líneas principales de la cuadrícula (por ejemplo, “day”, “week”, “3 weeks”, “month”, o “year”)Utiliza date_minor_breaks = para especificar el intervalo de las líneas verticales menores (entre las etiquetas de fecha)Añade expand = c(0,0) para comenzar las etiquetas en la primera barraUsa date_labels = para especificar el formato de las etiquetas de fecha - mira la página de trabajar con fechas para consejos (usa \\n para una nueva línea)Si las franjas de tu histograma son semanas de domingo:\nUsa breaks = y minor_breaks = proporcionando una secuencia de saltos de fecha para cada una\nPuedes seguir utilizando date_labels = y expand = para formatear, como se ha descrito anteriormente\nUsa breaks = y minor_breaks = proporcionando una secuencia de saltos de fecha para cada unaPuedes seguir utilizando date_labels = y expand = para formatear, como se ha descrito anteriormenteAlgunas notas:Consulta la sección de apertura de ggplot para obtener instrucciones sobre cómo crear una secuencia de fechas utilizando seq.Date().Consulta esta página o la página Trabajar con fechas para obtener consejos sobre la creación de etiquetas con fechas.","code":""},{"path":"epidemic-curves.html","id":"demostraciones","chapter":"32 Curvas epidémicas","heading":"Demostraciones","text":"continuación se hace una demostración de gráficos en los que los intervalos y las etiquetas de los gráficos/líneas de la cuadrícula están alineados y alineados:","code":"\n# 7-day bins + Monday labels\n#############################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,                 # 7-day bins with start at first case\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),               # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",       # Monday every 3 weeks\n    date_minor_breaks = \"week\",    # Monday weeks\n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+              # remove excess space under x-axis, make flush\n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays at first case\\nDate labels and gridlines on Mondays\\nNote how ticks don't align with bars\")\n\n\n\n# 7-day bins + Months\n#####################\nggplot(central_data) +\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    binwidth = 7,\n    color = \"darkblue\",\n    fill = \"lightblue\") +\n  \n  scale_x_date(\n    expand = c(0,0),                  # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",           # 1st of month\n    date_minor_breaks = \"week\",       # Monday weeks\n    date_labels = \"%a\\n%d %b\\n%Y\")+    # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"MISALIGNED\",\n    subtitle = \"! CAUTION: 7-day bars start Thursdays with first case\\nMajor gridlines and date labels at 1st of each month\\nMinor gridlines weekly on Mondays\\nNote uneven spacing of some gridlines and ticks unaligned with bars\")\n\n\n# TOTAL MONDAY ALIGNMENT: specify manual bin breaks to be mondays\n#################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,    # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"4 weeks\",           # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%a\\n%d %b\\n%Y\")+      # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(\n    title = \"ALIGNED Mondays\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels and gridlines on Mondays as well\")\n\n\n# TOTAL MONDAY ALIGNMENT WITH MONTHS LABELS:\n############################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Monday before first case\n    breaks = weekly_breaks_central,            # defined earlier in this page\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"months\",            # Monday every 4 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%b\\n%Y\")+          # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  theme(panel.grid.major = element_blank())+  # Remove major gridlines (fall on 1st of month)\n          \n  labs(\n    title = \"ALIGNED Mondays with MONTHLY labels\",\n    subtitle = \"7-day bins manually set to begin Monday before first case (28 Apr)\\nDate labels on 1st of Month\\nMonthly major gridlines removed\")\n\n\n# TOTAL SUNDAY ALIGNMENT: specify manual bin breaks AND labels to be Sundays\n############################################################################\nggplot(central_data) + \n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    # histogram breaks set to 7 days beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"7 days\"),\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") + \n  \n  scale_x_date(\n    expand = c(0,0),\n    # date label breaks and major gridlines set to every 3 weeks beginning Sunday before first case\n    breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                      to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                      by   = \"3 weeks\"),\n    \n    # minor gridlines set to weekly beginning Sunday before first case\n    minor_breaks = seq.Date(from = floor_date(min(central_data$date_onset, na.rm=T),   \"week\", week_start = 7),\n                            to   = ceiling_date(max(central_data$date_onset, na.rm=T), \"week\", week_start = 7),\n                            by   = \"7 days\"),\n    \n    date_labels = \"%a\\n%d\\n%b\\n'%y\")+  # label format\n  \n  scale_y_continuous(\n    expand = c(0,0))+                # remove excess space under x-axis, make flush \n  \n  labs(title = \"ALIGNED Sundays\",\n       subtitle = \"7-day bins manually set to begin Sunday before first case (27 Apr)\\nDate labels and gridlines manually set to Sundays as well\")"},{"path":"epidemic-curves.html","id":"datos-agregados","chapter":"32 Curvas epidémicas","heading":"Datos agregados","text":"menudo, en lugar de un listado, se comienza con recuentos agregados de instalaciones, distritos, etc. Se puede hacer una curva epidémica con ggplot() pero el código será ligeramente diferente. Esta sección utilizará los datos de count_data que fue importado anteriormente, en la sección de preparación de datos. Este conjunto de datos es linelist agregado los recuentos de día-hospital. continuación se muestran las primeras 50 filas.","code":""},{"path":"epidemic-curves.html","id":"representar-recuentos-diarios","chapter":"32 Curvas epidémicas","heading":"Representar recuentos diarios","text":"Podemos trazar una curva epidémica diaria partir de estos recuentos diarios. Aquí están las diferencias con el código:Dentro del mapeo estético aes(), especifica y = como columna de recuento (en este caso, el nombre de la columna es n_cases)Añadir el argumento stat = \"identity\" dentro de geom_histogram(), que especifica que la altura de la barra debe ser el valor y = y el número de filas, como es el valor por defectoAñade el argumento width = para evitar las líneas blancas verticales entre las barras. Para los datos diarios, establece el valor 1. Para los datos semanales, escribe 7. Para los datos de recuento mensual, las líneas blancas son un problema (cada mes tiene un número diferente de días) - considera la posibilidad de transformar el eje x en un factor categórico ordenado (meses) y utilizar geom_col().","code":"\nggplot(data = count_data)+\n  geom_histogram(\n   mapping = aes(x = date_hospitalisation, y = n_cases),\n   stat = \"identity\",\n   width = 1)+                # for daily counts, set width = 1 to avoid white space between bars\n  labs(\n    x = \"Date of report\", \n    y = \"Number of cases\",\n    title = \"Daily case incidence, from daily count data\")"},{"path":"epidemic-curves.html","id":"representar-recuentos-semanales","chapter":"32 Curvas epidémicas","heading":"representar recuentos semanales","text":"Si tus datos ya son recuentos de casos por semana, podrían parecerse este conjunto de datos (llamado count_data_weekly):continuación se muestran las primeras 50 filas de count_data_weekly. Puedes ver que los recuentos se han agregado en semanas. Cada semana se muestra por el primer día de la semana (lunes por defecto).Ahora trace de manera que x =la columna epiweek. Recuerda añadir y = la columna de recuentos al mapeo estético, y añadir stat = \"identity\" como se ha explicado anteriormente.","code":"\nggplot(data = count_data_weekly)+\n  \n  geom_histogram(\n    mapping = aes(\n      x = epiweek,           # x-axis is epiweek (as class Date)\n      y = n_cases_weekly,    # y-axis height in the weekly case counts\n      group = hospital,      # we are grouping the bars and coloring by hospital\n      fill = hospital),\n    stat = \"identity\")+      # this is also required when plotting count data\n     \n  # labels for x-axis\n  scale_x_date(\n    date_breaks = \"2 months\",      # labels every 2 months \n    date_minor_breaks = \"1 month\", # gridlines every month\n    date_labels = '%b\\n%Y')+       #labeled by month with year below\n     \n  # Choose color palette (uses RColorBrewer package)\n  scale_fill_brewer(palette = \"Pastel2\")+ \n  \n  theme_minimal()+\n  \n  labs(\n    x = \"Week of onset\", \n    y = \"Weekly case incidence\",\n    fill = \"Hospital\",\n    title = \"Weekly case incidence, from aggregated count data by hospital\")"},{"path":"epidemic-curves.html","id":"medias-móviles","chapter":"32 Curvas epidémicas","heading":"Medias móviles","text":"Consulta la página sobre medias móviles para obtener una descripción detallada y varias opciones. continuación se muestra una opción para calcular medias móviles con el paquete slider. En este enfoque, la media móvil se calcula antes de representarla:Agrega los datos en recuentos según sea necesario (diario, semanal, etc.) (véase la página de Agrupar datos)Crea una nueva columna para contener la media móvil, creada con slide_index() del paquete sliderDibuja la media móvil como una geom_line() encima (después) del histograma de la curva epidémicaEs muy útil la viñeta en línea del paquete slider","code":"\n# load package\npacman::p_load(slider)  # slider used to calculate rolling averages\n\n# make dataset of daily counts and 7-day moving average\n#######################################################\nll_counts_7day <- linelist %>%    # begin with linelist\n  \n  ## count cases by date\n  count(date_onset, name = \"new_cases\") %>%   # name new column with counts as \"new_cases\"\n  drop_na(date_onset) %>%                     # remove cases with missing date_onset\n  \n  ## calculate the average number of cases in 7-day window\n  mutate(\n    avg_7day = slider::slide_index(    # create new column\n      new_cases,                       # calculate based on value in new_cases column\n      .i = date_onset,                 # index is date_onset col, so non-present dates are included in window \n      .f = ~mean(.x, na.rm = TRUE),    # function is mean() with missing values removed\n      .before = 6,                     # window is the day and 6-days before\n      .complete = FALSE),              # must be FALSE for unlist() to work in next step\n    avg_7day = unlist(avg_7day))       # convert class list to class numeric\n\n\n# plot\n######\nggplot(data = ll_counts_7day) +  # begin with new dataset defined above \n    geom_histogram(              # create epicurve histogram\n      mapping = aes(\n        x = date_onset,          # date column as x-axis\n        y = new_cases),          # height is number of daily new cases\n        stat = \"identity\",       # height is y value\n        fill=\"#92a8d1\",          # cool color for bars\n        colour = \"#92a8d1\",      # same color for bar border\n        )+ \n    geom_line(                   # make line for rolling average\n      mapping = aes(\n        x = date_onset,          # date column for x-axis\n        y = avg_7day,            # y-value set to rolling average column\n        lty = \"7-day \\nrolling avg\"), # name of line in legend\n      color=\"red\",               # color of line\n      size = 1) +                # width of line\n    scale_x_date(                # date scale\n      date_breaks = \"1 month\",\n      date_labels = '%d/%m',\n      expand = c(0,0)) +\n    scale_y_continuous(          # y-axis scale\n      expand = c(0,0),\n      limits = c(0, NA)) +       \n    labs(\n      x=\"\",\n      y =\"Number of confirmed cases\",\n      fill = \"Legend\")+ \n    theme_minimal()+\n    theme(legend.title = element_blank())  # removes title of legend"},{"path":"epidemic-curves.html","id":"facetaspequeñas-múltiples","chapter":"32 Curvas epidémicas","heading":"Facetas/pequeñas múltiples","text":"Al igual que con otros ggplots, puedes crear gráficos facetados (“pequeños múltiples”). Como se explica en la página Consejos de ggplot de este manual, puedes utilizar facet_wrap() o facet_grid(). Aquí lo mostramos con facet_wrap(). Para las curvas epidémicas, facet_wrap() es típicamente más fácil, ya que es probable que sólo necesites facetar una columna.La sintaxis general es facet_wrap(rows ~ cols), donde la izquierda de la tilde (~) está el nombre de una columna que se extiende través de las “filas” del gráfico facetado, y la derecha de la tilde está el nombre de una columna que se extiende través de las “columnas” del gráfico facetado. Lo más sencillo es utilizar un nombre de columna, la derecha de la tilde: facet_wrap(~age_cat).Ejes libres\nTendrás que decidir si las escalas de los ejes para cada faceta son “fijas” (por defecto), o “libres” (lo que significa que cambiarán en función de los datos dentro de la faceta). Haz esto con el argumento scales = dentro de facet_wrap() especificando “free_x” o “free_y”, o “free”.Número de columnas y filas de las facetas\nSe puede especificar con ncol = y nrow = dentro de facet_wrap().Orden de los paneles\nPara cambiar el orden de aparición, cambia el orden de los niveles de la columna de factores utilizada para crear las facetas.Estética\nEl tamaño y tipo de la fuente, el color de la franja, etc, se pueden modificar mediante theme() con argumentos como:strip.text = element_text() (size, colour, face, angle..(tamaño, color, cara, ángulo)strip.background = element_rect() (e.g. element_rect(fill=“grey”))strip.position = (posición “bottom”, “top”, “left”, o “right” (Abajo, arriba, izquierda o derecha))Etiquetas de banda\nLas etiquetas de los gráficos de facetas pueden modificarse través de las “etiquetas” de la columna como factor, o mediante el uso de un “etiquetador”.Haz un etiquetador como este, usando la función as_labeller() de ggplot2. continuación, proporciona el argumento labeller = en facet_wrap() como se muestra continuación.Un ejemplo de gráfico facetado - facetado por la columna age_cat.Consulta este enlace para obtener más información sobre las etiquetadoras.","code":"\nmy_labels <- as_labeller(c(\n     \"0-4\"   = \"Ages 0-4\",\n     \"5-9\"   = \"Ages 5-9\",\n     \"10-14\" = \"Ages 10-14\",\n     \"15-19\" = \"Ages 15-19\",\n     \"20-29\" = \"Ages 20-29\",\n     \"30-49\" = \"Ages 30-49\",\n     \"50-69\" = \"Ages 50-69\",\n     \"70+\"   = \"Over age 70\"))\n# make plot\n###########\nggplot(central_data) + \n  \n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),    # arguments inside aes() apply by group\n      \n    color = \"black\",      # arguments outside aes() apply to all data\n        \n    # histogram breaks\n    breaks = weekly_breaks_central)+  # pre-defined date vector (see earlier in this page)\n                      \n  # The labels on the x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+                       # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"grey\"))+         # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,\n    ncol = 4,\n    strip.position = \"top\",\n    labeller = my_labels)+             \n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"conjunto-de-la-epidemia-como-fondo-de-la-faceta","chapter":"32 Curvas epidémicas","heading":"Conjunto de la Epidemia como fondo de la faceta","text":"Para mostrar el conjunto de la epidemia como fondo de cada faceta, añade la función gghighlight() con paréntesis vacíos al ggplot. Esto es del paquete gghighlight. Observa que el máximo del eje Y en todas las facetas se basa ahora en el pico de toda la epidemia. Hay más ejemplos de este paquete en la página Consejos de ggplot.","code":"\nggplot(central_data) + \n  \n  # epicurves by group\n  geom_histogram(\n    mapping = aes(\n      x = date_onset,\n      group = age_cat,\n      fill = age_cat),  # arguments inside aes() apply by group\n    \n    color = \"black\",    # arguments outside aes() apply to all data\n    \n    # histogram breaks\n    breaks = weekly_breaks_central)+     # pre-defined date vector (see top of ggplot section)                \n  \n  # add grey epidemic in background to each facet\n  gghighlight::gghighlight()+\n  \n  # labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space below 0\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\",\n    strip.text = element_text(face = \"bold\", size = 10),\n    strip.background = element_rect(fill = \"white\"))+        # axis titles in bold\n  \n  # create facets\n  facet_wrap(\n    ~age_cat,                          # each plot is one value of age_cat\n    ncol = 4,                          # number of columns\n    strip.position = \"top\",            # position of the facet title/strip\n    labeller = my_labels)+             # labeller defines above\n  \n  # labels\n  labs(\n    title    = \"Weekly incidence of cases, by age category\",\n    subtitle = \"Subtitle\",\n    fill     = \"Age category\",                                      # provide new title for legend\n    x        = \"Week of symptom onset\",\n    y        = \"Weekly incident cases reported\",\n    caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"una-faceta-con-datos","chapter":"32 Curvas epidémicas","heading":"Una faceta con datos","text":"Si quieres tener una caja de facetas que contenga todos los datos, duplica todo el conjunto de datos y trata los duplicados como un solo valor de facetas. Una función de “ayuda” CreateAllFacet() continuación puede ayudar con esto (gracias esta entrada del blog). Cuando se ejecuta, el número de filas se duplica y habrá una nueva columna llamada facet en la que las filas duplicadas tendrán el valor “”, y las filas originales tienen el valor original de la columna facet. Ahora sólo tienes que hacer la faceta con la columna facet.Aquí está la función de ayuda. Ejecútala para que esté disponible para ti.Ahora aplica la función de ayuda los datos, en la columna age_cat:Los cambios más importantes en el comando ggplot() son:Los datos utilizados son ahora central_data2 (el doble de filas, con la nueva columna “facet”)La etiquetadora tendrá que ser actualizada, si se utilizaOpcional: para conseguir facetas apiladas verticalmente: la columna de la faceta se mueve al lado de las filas de la ecuación y la derecha se sustituye por “.” (facet_wrap(facet\\~.)), y ncol = 1. También puede ser necesario ajustar la anchura y la altura de la imagen png guardada (ver ggsave() en Conceptos básicos de ggplot).","code":"\n# Define helper function\nCreateAllFacet <- function(df, col){\n     df$facet <- df[[col]]\n     temp <- df\n     temp$facet <- \"all\"\n     merged <-rbind(temp, df)\n     \n     # ensure the facet value is a factor\n     merged[[col]] <- as.factor(merged[[col]])\n     \n     return(merged)\n}\n# Create dataset that is duplicated and with new column \"facet\" to show \"all\" age categories as another facet level\ncentral_data2 <- CreateAllFacet(central_data, col = \"age_cat\") %>%\n  \n  # set factor levels\n  mutate(facet = fct_relevel(facet, \"all\", \"0-4\", \"5-9\",\n                             \"10-14\", \"15-19\", \"20-29\",\n                             \"30-49\", \"50-69\", \"70+\"))## Warning: 1 unknown level in `f`: 70+\n# check levels\ntable(central_data2$facet, useNA = \"always\")## \n##   all   0-4   5-9 10-14 15-19 20-29 30-49 50-69  <NA> \n##   454    84    84    82    58    73    57     7     9\nggplot(central_data2) + \n  \n  # actual epicurves by group\n  geom_histogram(\n        mapping = aes(\n          x = date_onset,\n          group = age_cat,\n          fill = age_cat),  # arguments inside aes() apply by group\n        color = \"black\",    # arguments outside aes() apply to all data\n        \n        # histogram breaks\n        breaks = weekly_breaks_central)+    # pre-defined date vector (see top of ggplot section)\n                     \n  # Labels on x-axis\n  scale_x_date(\n    expand            = c(0,0),         # remove excess x-axis space below and after case bars\n    date_breaks       = \"2 months\",     # labels appear every 2 months\n    date_minor_breaks = \"1 month\",      # vertical lines appear every 1 month \n    date_labels       = \"%b\\n'%y\")+     # date labels format\n  \n  # y-axis\n  scale_y_continuous(expand = c(0,0))+  # removes excess y-axis space between bottom of bars and the labels\n  \n  # aesthetic themes\n  theme_minimal()+                                           # a set of themes to simplify plot\n  theme(\n    plot.caption = element_text(face = \"italic\", hjust = 0), # caption on left side in italics\n    axis.title = element_text(face = \"bold\"),\n    legend.position = \"bottom\")+               \n  \n  # create facets\n  facet_wrap(facet~. ,                            # each plot is one value of facet\n             ncol = 1)+            \n\n  # labels\n  labs(title    = \"Weekly incidence of cases, by age category\",\n       subtitle = \"Subtitle\",\n       fill     = \"Age category\",                                      # provide new title for legend\n       x        = \"Week of symptom onset\",\n       y        = \"Weekly incident cases reported\",\n       caption  = stringr::str_glue(\"n = {nrow(central_data)} from Central Hospital; Case onsets range from {format(min(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')} to {format(max(central_data$date_onset, na.rm=T), format = '%a %d %b %Y')}\\n{nrow(central_data %>% filter(is.na(date_onset)))} cases missing date of onset and not shown\"))"},{"path":"epidemic-curves.html","id":"tentative-data","chapter":"32 Curvas epidémicas","heading":"32.4 Datos provisionales","text":"Los datos más recientes que se muestran en las curvas epidémicas deben marcarse menudo como provisionales, o sujetos retrasos en los informes. Esto puede hacerse añadiendo una línea vertical y/o un rectángulo sobre un número determinado de días. Aquí hay dos opciones:Utiliza annotate():\nPara una línea utiliza annotate(geom = \"segment\"). Proporciona x, xend, y, e yend. Ajusta el tamaño, el tipo de línea (lty) y el color.\nPara un rectángulo utiliza annotate(geom = \"rect\"). Proporciona xmin/xmax/ymin/ymax. Ajusta el color y el alpha.\nPara una línea utiliza annotate(geom = \"segment\"). Proporciona x, xend, y, e yend. Ajusta el tamaño, el tipo de línea (lty) y el color.Para un rectángulo utiliza annotate(geom = \"rect\"). Proporciona xmin/xmax/ymin/ymax. Ajusta el color y el alpha.Agrupar los datos por estado tentativo y colorear esas barras de forma diferentePRECAUCIÓN: Puedes intentar geom_rect() para dibujar un rectángulo, pero el ajuste de la transparencia funciona en un contexto de listado. Esta función superpone un rectángulo para cada observación/fila!. Utiliza un alfa muy bajo (por ejemplo, 0,01), u otro enfoque. ","code":""},{"path":"epidemic-curves.html","id":"uso-de-annotate","chapter":"32 Curvas epidémicas","heading":"Uso de annotate()","text":"Dentro de annotate(geom = \"rect\"), los argumentos xmin y xmax deben tener entradas del tipo Date.Ten en cuenta que, como estos datos se agregan en barras semanales, y la última barra se extiende hasta el lunes siguiente al último punto de datos, la región sombreada puede parecer que abarca 4 semanasEste es un ejemplo de annotate() en líneaLa misma línea vertical negra se puede conseguir con el código de abajo, pero usando geom_vline() se pierde la capacidad de controlar la altura:","code":"\nggplot(central_data) + \n  \n  # histogram\n  geom_histogram(\n    mapping = aes(x = date_onset),\n    \n    breaks = weekly_breaks_central,   # pre-defined date vector - see top of ggplot section\n    \n    color = \"darkblue\",\n    \n    fill = \"lightblue\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"1 month\",           # 1st of month\n    date_minor_breaks = \"1 month\",     # 1st of month\n    date_labels = \"%b\\n'%y\")+          # label format\n  \n  # labels and theme\n  labs(\n    title = \"Using annotate()\\nRectangle and line showing that data from last 21-days are tentative\",\n    x = \"Week of symptom onset\",\n    y = \"Weekly case indicence\")+ \n  theme_minimal()+\n  \n  # add semi-transparent red rectangle to tentative data\n  annotate(\n    \"rect\",\n    xmin  = as.Date(max(central_data$date_onset, na.rm = T) - 21), # note must be wrapped in as.Date()\n    xmax  = as.Date(Inf),                                          # note must be wrapped in as.Date()\n    ymin  = 0,\n    ymax  = Inf,\n    alpha = 0.2,          # alpha easy and intuitive to adjust using annotate()\n    fill  = \"red\")+\n  \n  # add black vertical line on top of other layers\n  annotate(\n    \"segment\",\n    x     = max(central_data$date_onset, na.rm = T) - 21, # 21 days before last data\n    xend  = max(central_data$date_onset, na.rm = T) - 21, \n    y     = 0,         # line begins at y = 0\n    yend  = Inf,       # line to top of plot\n    size  = 2,         # line size\n    color = \"black\",\n    lty   = \"solid\")+   # linetype e.g. \"solid\", \"dashed\"\n\n  # add text in rectangle\n  annotate(\n    \"text\",\n    x = max(central_data$date_onset, na.rm = T) - 15,\n    y = 15,\n    label = \"Subject to reporting delays\",\n    angle = 90)\ngeom_vline(xintercept = max(central_data$date_onset, na.rm = T) - 21,\n           size = 2,\n           color = \"black\")"},{"path":"epidemic-curves.html","id":"color-de-las-barras","chapter":"32 Curvas epidémicas","heading":"Color de las barras","text":"Un enfoque alternativo podría ser ajustar el color o la visualización de las propias barras de datos tentativos. Podrías crear una nueva columna en la etapa de preparación de los datos y utilizarla para agrupar los datos, de manera que el aes(fill = ) de los datos tentativos pueda tener un color o un alfa diferente al de las otras barras.","code":"\n# add column\n############\nplot_data <- central_data %>% \n  mutate(tentative = case_when(\n    date_onset >= max(date_onset, na.rm=T) - 7 ~ \"Tentative\", # tenative if in last 7 days\n    TRUE                                       ~ \"Reliable\")) # all else reliable\n\n# plot\n######\nggplot(plot_data, aes(x = date_onset, fill = tentative)) + \n  \n  # histogram\n  geom_histogram(\n    breaks = weekly_breaks_central,   # pre-defined data vector, see top of ggplot page\n    color = \"black\") +\n\n  # scales\n  scale_y_continuous(expand = c(0,0))+\n  scale_fill_manual(values = c(\"lightblue\", \"grey\"))+\n  scale_x_date(\n    expand = c(0,0),                   # remove excess x-axis space below and after case bars\n    date_breaks = \"3 weeks\",           # Monday every 3 weeks\n    date_minor_breaks = \"week\",        # Monday weeks \n    date_labels = \"%d\\n%b\\n'%y\")+      # label format\n  \n  # labels and theme\n  labs(title = \"Show days that are tentative reporting\",\n    subtitle = \"\")+ \n  theme_minimal()+\n  theme(legend.title = element_blank())                 # remove title of legend"},{"path":"epidemic-curves.html","id":"multi-level-date-labels","chapter":"32 Curvas epidémicas","heading":"32.5 Etiquetas de fecha de varios niveles","text":"Si deseas etiquetas de fecha de varios niveles (por ejemplo, mes y año) sin duplicar los niveles de etiquetas inferiores, considera uno de los enfoques siguientes:Recuerda - puedes utilizar herramientas como \\n dentro de los argumentos date_labels o labels para poner partes de cada etiqueta en una nueva línea inferior. Sin embargo, el código de abajo le ayuda usar años o meses (por ejemplo) en una línea inferior y sólo una vez. Algunas notas sobre el código de abajo:Los recuentos de casos se agregan en semanas por motivos estéticos. Véase la página de Epicurves (sección de datos agregados) para más detalles.Se utiliza una línea geom_area() en lugar de un histograma, ya que el enfoque de facetas que se presenta continuación funciona bien con los histogramas.Agregar los recuentos semanalesHacer gráficosLas técnicas anteriores fueron adaptadas de este y este post en stackoverflow.com.","code":"\n# Create dataset of case counts by week\n#######################################\ncentral_weekly <- linelist %>%\n  filter(hospital == \"Central Hospital\") %>%   # filter linelist\n  mutate(week = lubridate::floor_date(date_onset, unit = \"weeks\")) %>%  \n  count(week) %>%                              # summarize weekly case counts\n  drop_na(week) %>%                            # remove cases with missing onset_date\n  complete(                                    # fill-in all weeks with no cases reported\n    week = seq.Date(\n      from = min(week),   \n      to   = max(week),\n      by   = \"week\"),\n    fill = list(n = 0))                        # convert new NA values to 0 counts\n# plot with box border on year\n##############################\nggplot(central_weekly) +\n  geom_area(aes(x = week, y = n),    # make line, specify x and y\n            stat = \"identity\") +             # because line height is count number\n  scale_x_date(date_labels=\"%b\",             # date label format show month \n               date_breaks=\"month\",          # date labels on 1st of each month\n               expand=c(0,0)) +              # remove excess space on each end\n  scale_y_continuous(\n    expand  = c(0,0))+                       # remove excess space below x-axis\n  facet_grid(~lubridate::year(week), # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",                # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                   # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",         # facet labels placement\n        strip.background = element_rect(fill = NA, # facet labels no fill grey border\n                                        colour = \"grey50\"),\n        panel.spacing = unit(0, \"cm\"))+      # no space between facet panels\n  labs(title = \"Nested year labels, grey label border\")\n# plot with no box border on year\n#################################\nggplot(central_weekly,\n       aes(x = week, y = n)) +              # establish x and y for entire plot\n  geom_line(stat = \"identity\",              # make line, line height is count number\n            color = \"#69b3a2\") +            # line color\n  geom_point(size=1, color=\"#69b3a2\") +     # make points at the weekly data points\n  geom_area(fill = \"#69b3a2\",               # fill area below line\n            alpha = 0.4)+                   # fill transparency\n  scale_x_date(date_labels=\"%b\",            # date label format show month \n               date_breaks=\"month\",         # date labels on 1st of each month\n               expand=c(0,0)) +             # remove excess space\n  scale_y_continuous(\n    expand  = c(0,0))+                      # remove excess space below x-axis\n  facet_grid(~lubridate::year(week),        # facet on year (of Date class column)\n             space=\"free_x\",                \n             scales=\"free_x\",               # x-axes adapt to data range (not \"fixed\")\n             switch=\"x\") +                  # facet labels (year) on bottom\n  theme_bw() +\n  theme(strip.placement = \"outside\",                     # facet label placement\n          strip.background = element_blank(),            # no facet lable background\n          panel.grid.minor.x = element_blank(),          \n          panel.border = element_rect(colour=\"grey40\"),  # grey border to facet PANEL\n          panel.spacing=unit(0,\"cm\"))+                   # No space between facet panels\n  labs(title = \"Nested year labels - points, shaded, no label border\")"},{"path":"epidemic-curves.html","id":"dual-axis","chapter":"32 Curvas epidémicas","heading":"32.6 Doble eje","text":"Aunque hay fuertes discusiones sobre la validez de los ejes duales dentro de la comunidad de visualización de datos, muchos supervisores de epi todavía quieren ver una curva epidémica o un gráfico similar con un porcentaje superpuesto con un segundo eje. Esto se discute más ampliamente en la página Consejos de ggplot, pero continuación se muestra un ejemplo utilizando el método cowplot:Se hacen dos gráficos distintos y luego se combinan con el paquete cowplot.Los gráficos deben tener exactamente el mismo eje x (límites establecidos) o de lo contrario los datos y las etiquetas se alinearánCada uno de ellos utiliza theme_cowplot() y uno de ellos tiene el eje-y desplazado la derecha del gráficoAhora utiliza cowplot para superponer los dos gráficos. Se ha prestado atención la alineación del eje-x, al lado del eje-y y al uso de theme_cowplot().","code":"\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\n#######################################\nplot_cases <- linelist %>% \n  \n  # plot cases per week\n  ggplot()+\n  \n  # create histogram  \n  geom_histogram(\n    \n    mapping = aes(x = date_onset),\n    \n    # bin breaks every week beginning monday before first case, going to monday after last case\n    breaks = weekly_breaks_all)+  # pre-defined vector of weekly dates (see top of ggplot section)\n        \n  # specify beginning and end of date axis to align with other plot\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  # labels\n  labs(\n      y = \"Daily cases\",\n      x = \"Date of symptom onset\"\n    )+\n  theme_cowplot()\n\n\n# make second plot of percent died per week\n###########################################\nplot_deaths <- linelist %>%                        # begin with linelist\n  group_by(week = floor_date(date_onset, \"week\")) %>%  # create week column\n  \n  # summarise to get weekly percent of cases who died\n  summarise(n_cases = n(),\n            died = sum(outcome == \"Death\", na.rm=T),\n            pct_died = 100*died/n_cases) %>% \n  \n  # begin plot\n  ggplot()+\n  \n  # line of weekly percent who died\n  geom_line(                                # create line of percent died\n    mapping = aes(x = week, y = pct_died),  # specify y-height as pct_died column\n    stat = \"identity\",                      # set line height to the value in pct_death column, not the number of rows (which is default)\n    size = 2,\n    color = \"black\")+\n  \n  # Same date-axis limits as the other plot - perfect alignment\n  scale_x_date(\n    limits = c(min(weekly_breaks_all), max(weekly_breaks_all)))+  # min/max of the pre-defined weekly breaks of histogram\n  \n  \n  # y-axis adjustments\n  scale_y_continuous(                # adjust y-axis\n    breaks = seq(0,100, 10),         # set break intervals of percent axis\n    limits = c(0, 100),              # set extent of percent axis\n    position = \"right\")+             # move percent axis to the right\n  \n  # Y-axis label, no x-axis label\n  labs(x = \"\",\n       y = \"Percent deceased\")+      # percent axis label\n  \n  theme_cowplot()                   # add this to make the two plots merge together nicely\naligned_plots <- cowplot::align_plots(plot_cases, plot_deaths, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"cumulative-incidence-1","chapter":"32 Curvas epidémicas","heading":"32.7 Incidencia acumulada","text":"Nota: Si utilizas incidence2, consulta la sección sobre cómo puede producirse la incidencia acumulada con una función simple. Esta página abordará cómo calcular la incidencia acumulada y dibujarla con ggplot().Si se empieza con una lista de casos, crea una nueva columna que contenga el número acumulado de casos por día en un brote utilizando cumsum() de R base:continuación se muestran las 10 primeras filas:Esta columna acumulativa puede entonces ser dibujada contra date_onset, usando geom_line():También se puede superponer la curva epidémica, con doble eje utilizando el método cowplot descrito anteriormente y en la página Consejos de ggplot:Ahora utiliza cowplot para superponer los dos gráficos. Se ha prestado atención la alineación del eje-x, al lado del eje-y y al uso de theme_cowplot().","code":"\ncumulative_case_counts <- linelist %>% \n  count(date_onset) %>%                # count of rows per day (returned in column \"n\")   \n  mutate(                         \n    cumulative_cases = cumsum(n)       # new column of the cumulative number of rows at each date\n    )\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")\n\nplot_cumulative\n#load package\npacman::p_load(cowplot)\n\n# Make first plot of epicurve histogram\nplot_cases <- ggplot()+\n  geom_histogram(          \n    data = linelist,\n    aes(x = date_onset),\n    binwidth = 1)+\n  labs(\n    y = \"Daily cases\",\n    x = \"Date of symptom onset\"\n  )+\n  theme_cowplot()\n\n# make second plot of cumulative cases line\nplot_cumulative <- ggplot()+\n  geom_line(\n    data = cumulative_case_counts,\n    aes(x = date_onset, y = cumulative_cases),\n    size = 2,\n    color = \"blue\")+\n  scale_y_continuous(\n    position = \"right\")+\n  labs(x = \"\",\n       y = \"Cumulative cases\")+\n  theme_cowplot()+\n  theme(\n    axis.line.x = element_blank(),\n    axis.text.x = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks = element_blank())\naligned_plots <- cowplot::align_plots(plot_cases, plot_cumulative, align=\"hv\", axis=\"tblr\")\nggdraw(aligned_plots[[1]]) + draw_plot(aligned_plots[[2]])"},{"path":"epidemic-curves.html","id":"resources-25","chapter":"32 Curvas epidémicas","heading":"32.8 Recursos","text":"","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"demographic-pyramids-and-likert-scales","chapter":"33 Pirámides de población y escalas de Likert","heading":"33 Pirámides de población y escalas de Likert","text":"Las pirámides demográficas son útiles para mostrar distribuciones de edad y género. Se puede utilizar un código similar para visualizar los resultados de las preguntas de las encuestas tipo Likert (por ejemplo, “Muy de acuerdo”, “De acuerdo”, “Neutral”, “En desacuerdo”, “Muy en desacuerdo”). En esta página cubrimos lo siguiente:Pirámides rápidas y sencillas con el paquete apyramidMás pirámides personalizables con ggplot()Visualización de datos demográficos “de referencia” en el fondo de la pirámideUtilización de gráficos de tipo pirámide para mostrar otros tipos de datos (por ejemplo, respuestas preguntas de encuestas tipo Likert)","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"preparation-23","chapter":"33 Pirámides de población y escalas de Likert","heading":"33.1 Preparación","text":"","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"cargar-paquetes-21","chapter":"33 Pirámides de población y escalas de Likert","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de . Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(rio,       # to import data\n               here,      # to locate files\n               tidyverse, # to clean, handle, and plot the data (includes ggplot2 package)\n               apyramid,  # a package dedicated to creating age pyramids\n               janitor,   # tables and cleaning data\n               stringr)   # working with strings for titles, captions, etc."},{"path":"demographic-pyramids-and-likert-scales.html","id":"importar-datos-18","chapter":"33 Pirámides de población y escalas de Likert","heading":"Importar datos","text":"Para empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - vea la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import case linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"demographic-pyramids-and-likert-scales.html","id":"limpieza","chapter":"33 Pirámides de población y escalas de Likert","heading":"Limpieza","text":"Para hacer una pirámide demográfica tradicional de edad/género, primero hay que limpiar los datos de la siguiente manera:Debe limpiarse la columna gender.Dependiendo del método, la edad debe ser almacenada como un número o en una columna de categoría de edad.Si se utilizan categorías de edad, los valores de las columnas deben corregirse ordenados, ya sea por defecto alfanumérico o intencionadamente al convertirlo en de tipo factor.continuación utilizamos tabyl() de janitor para inspeccionar las columnas gender y age_cat5.También realizamos un histograma rápido de la columna age para asegurarnos de que está limpia y correctamente clasificada:","code":"\nlinelist %>% \n  tabyl(age_cat5, gender)##  age_cat5   f   m NA_\n##       0-4 640 416  39\n##       5-9 641 412  42\n##     10-14 518 383  40\n##     15-19 359 364  20\n##     20-24 305 316  17\n##     25-29 163 259  13\n##     30-34 104 213   9\n##     35-39  42 157   3\n##     40-44  25 107   1\n##     45-49   8  80   5\n##     50-54   2  37   1\n##     55-59   0  30   0\n##     60-64   0  12   0\n##     65-69   0  12   1\n##     70-74   0   4   0\n##     75-79   0   0   1\n##     80-84   0   1   0\n##       85+   0   0   0\n##      <NA>   0   0  86\nhist(linelist$age)"},{"path":"demographic-pyramids-and-likert-scales.html","id":"apyramid-package","chapter":"33 Pirámides de población y escalas de Likert","heading":"33.2 paquete apyramid","text":"El paquete apyramid es un producto del proyecto R4Epis. Puedes leer más sobre este paquete aquí. Te permite hacer rápidamente una pirámide de edad. Para situaciones más matizadas consulta, más abajo, la sección sobre el uso de ggplot(). Puedes leer más sobre el paquete apyramid en su página de ayuda introduciendo ?age_pyramid en la consola de R.","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"datos-individualizados","chapter":"33 Pirámides de población y escalas de Likert","heading":"Datos individualizados","text":"Utilizando el conjunto de datos de linelist limpio, podemos crear una pirámide de edad con un simple comando age_pyramid(). En este comando:En el argumento data = se establece el dataframe linelistEn el argumento age_group = (para el eje Y) se establece la columna age categórica (entre comillas)En el argumento split_by = (para el eje x) se establece la columna genderLa pirámide puede mostrarse con el porcentaje de todos los casos en el eje x, en lugar de los recuentos, incluyendo proportional = TRUE.Cuando se utiliza el paquete agepyramid, si la columna split_by es binaria (por ejemplo, male/female, o yes/), el resultado aparecerá como una pirámide. Sin embargo, si hay más de dos valores en la columna split_by (sin incluir NA), la pirámide aparecerá como un gráfico de barras facetadas con barras grises en el “fondo” que indican el rango de los datos facetados para ese grupo de edad. En este caso, los valores de split_by = aparecerán como etiquetas en la parte superior de cada panel de facetas. Por ejemplo, continuación se muestra lo que ocurre si split_by = se le asigna la columna hospital.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\")\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      proportional = TRUE)\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"hospital\")  "},{"path":"demographic-pyramids-and-likert-scales.html","id":"valores-faltantes-2","chapter":"33 Pirámides de población y escalas de Likert","heading":"Valores faltantes","text":"Las filas que tienen valores faltantes NA en las columnas split_by = o age_group =, si se codifican como NA, producirán el aspecto mostrado arriba. Por defecto, estas filas se mostrarán. Sin embargo, puede especificar que aparezcan, en un gráfico de barras adyacente y como un grupo de edad separado en la parte superior, especificando na.rm = FALSE.","code":"\napyramid::age_pyramid(data = linelist,\n                      age_group = \"age_cat5\",\n                      split_by = \"gender\",\n                      na.rm = FALSE)         # show patients missing age or gender"},{"path":"demographic-pyramids-and-likert-scales.html","id":"proporciones-colores-y-estética","chapter":"33 Pirámides de población y escalas de Likert","heading":"Proporciones, colores y estética","text":"Por defecto, las barras muestran los recuentos (el %), se muestra una línea media discontinua para cada grupo y los colores son verde/morado. Cada uno de estos parámetros puede ajustarse, como se muestra continuación:También puede añadir comandos adicionales de ggplot() al gráfico utilizando la sintaxis estándar de ggplot() “+”, como temas estéticos y ajustes de etiquetas:","code":"\napyramid::age_pyramid(\n  data = linelist,\n  age_group = \"age_cat5\",\n  split_by = \"gender\",\n  proportional = TRUE,              # show percents, not counts\n  show_midpoint = FALSE,            # remove bar mid-point line\n  #pal = c(\"orange\", \"purple\")      # can specify alt. colors here (but not labels)\n  )+                 \n  \n  # additional ggplot commands\n  theme_minimal()+                               # simplfy background\n  scale_fill_manual(                             # specify colors AND labels\n    values = c(\"orange\", \"purple\"),              \n    labels = c(\"m\" = \"Male\", \"f\" = \"Female\"))+\n  labs(y = \"Percent of all cases\",              # note x and y labs are switched\n       x = \"Age categories\",                          \n       fill = \"Gender\", \n       caption = \"My data source and caption here\",\n       title = \"Title of my plot\",\n       subtitle = \"Subtitle with \\n a second line...\")+\n  theme(\n    legend.position = \"bottom\",                          # legend to bottom\n    axis.text = element_text(size = 10, face = \"bold\"),  # fonts/sizes\n    axis.title = element_text(size = 12, face = \"bold\"))"},{"path":"demographic-pyramids-and-likert-scales.html","id":"datos-agregados-1","chapter":"33 Pirámides de población y escalas de Likert","heading":"Datos agregados","text":"Los ejemplos anteriores suponen que sus datos están en formato de listado, con una fila por observación. Si los datos ya están agregados en recuentos por categoría de edad, puedes seguir utilizando el paquete apyramid, como se muestra continuación.Para la demostración, agregamos los datos del listado en recuentos por categoría de edad y género, en un formato “ancho”. Esto simulará como si sus datos estuvieran agregados desde el principios. Aprende más sobre Agrupar datos y Pivotar datos en sus respectivas páginas.…lo que hace que el conjunto de datos tenga el siguiente aspecto: con columnas para la categoría age, y recuentos de male, de female y de missing.Para configurar estos datos para la pirámide de edad, pivotaremos los datos para que sean “largos” con la función pivot_longer() de dplyr. Esto se debe que ggplot() generalmente prefiere datos “largos”, y apyramid está utilizando ggplot().continuación, utiliza los argumentos split_by = y count = de age_pyramid() para especificar las respectivas columnas de los datos:Observa en lo anterior, que el orden de los factores “m” y “f” es diferente (pirámide invertida). Para ajustar el orden debes redefinir el género en los datos agregados como un Factor y ordenar los niveles como se desee. Consulta la página Factores.","code":"\ndemo_agg <- linelist %>% \n  count(age_cat5, gender, name = \"cases\") %>% \n  pivot_wider(\n    id_cols = age_cat5,\n    names_from = gender,\n    values_from = cases) %>% \n  rename(`missing_gender` = `NA`)\n# pivot the aggregated data into long format\ndemo_agg_long <- demo_agg %>% \n  pivot_longer(\n    col = c(f, m, missing_gender),            # cols to elongate\n    names_to = \"gender\",                # name for new col of categories\n    values_to = \"counts\") %>%           # name for new col of counts\n  mutate(\n    gender = na_if(gender, \"missing_gender\")) # convert \"missing_gender\" to NA\napyramid::age_pyramid(data = demo_agg_long,\n                      age_group = \"age_cat5\",# column name for age category\n                      split_by = \"gender\",   # column name for gender\n                      count = \"counts\")      # column name for case counts"},{"path":"demographic-pyramids-and-likert-scales.html","id":"demo_pyr_gg","chapter":"33 Pirámides de población y escalas de Likert","heading":"33.3 ggplot()","text":"El uso de ggplot() para construir tu pirámide de edad permite más flexibilidad, pero requiere más esfuerzo y comprensión de cómo funciona ggplot(). También es más fácil cometer errores accidentalmente.Para usar ggplot() para hacer pirámides demográficas, se crean dos gráficos de barras (uno para cada género), se convierten los valores de un gráfico en negativo y, finalmente, se invierten los ejes x e y para mostrar los gráficos de barras verticalmente, con sus bases encontrándose en el centro del gráfico.","code":""},{"path":"demographic-pyramids-and-likert-scales.html","id":"preparación-1","chapter":"33 Pirámides de población y escalas de Likert","heading":"Preparación","text":"Este enfoque utiliza la columna numérica age, la columna categórica de age_cat5. Así que comprobaremos que el tipo de esta columna es efectivamente numérica.Podrías utilizar la misma lógica que se indica continuación para construir una pirámide partir de datos categóricos utilizando geom_col() en lugar de geom_histogram().","code":"\nclass(linelist$age)## [1] \"numeric\""},{"path":"demographic-pyramids-and-likert-scales.html","id":"construcción-del-gráfico","chapter":"33 Pirámides de población y escalas de Likert","heading":"Construcción del gráfico","text":"En primer lugar, hay que entender que para hacer una pirámide de este tipo utilizando ggplot() el planteamiento es el siguiente:Dentro de ggplot(), crea dos histogramas utilizando la columna numérica de la edad. Crea uno para cada uno de los dos valores de agrupación (en este caso los géneros masculino y femenino). Para ello, los datos para cada histograma se especifican dentro de sus respectivos comandos geom_histogram(), con los respectivos filtros aplicados linelist.Dentro de ggplot(), crea dos histogramas utilizando la columna numérica de la edad. Crea uno para cada uno de los dos valores de agrupación (en este caso los géneros masculino y femenino). Para ello, los datos para cada histograma se especifican dentro de sus respectivos comandos geom_histogram(), con los respectivos filtros aplicados linelist.Un gráfico tendrá valores de recuento positivos, mientras que el otro tendrá sus recuentos convertidos valores negativos - esto crea la “pirámide” con el valor 0 en el centro del gráfico. Los valores negativos se crean utilizando un término especial de ggplot2 ..count.. y multiplicando por -1.Un gráfico tendrá valores de recuento positivos, mientras que el otro tendrá sus recuentos convertidos valores negativos - esto crea la “pirámide” con el valor 0 en el centro del gráfico. Los valores negativos se crean utilizando un término especial de ggplot2 ..count.. y multiplicando por -1.El comando coord_flip() cambia los ejes X e Y, lo que hace que los gráficos se vuelvan verticales y se cree la pirámide.El comando coord_flip() cambia los ejes X e Y, lo que hace que los gráficos se vuelvan verticales y se cree la pirámide.Por último, hay que modificar las etiquetas de los valores del eje de recuento para que aparezcan como recuentos “positivos” en ambos lados de la pirámide (pesar de que los valores subyacentes en un lado sean negativos).Por último, hay que modificar las etiquetas de los valores del eje de recuento para que aparezcan como recuentos “positivos” en ambos lados de la pirámide (pesar de que los valores subyacentes en un lado sean negativos).continuación se muestra una versión sencilla de esto, utilizando geom_histogram():PELIGRO: Si los límites de tu eje de recuentos son demasiado bajos, y una barra de recuentos los sobrepasa, la barra desaparecerá por completo o se acortará artificialmente. Ten cuidado con esto si analizas datos que se actualizan de forma rutinaria. Evítalo haciendo que los límites del eje de recuentos se ajusten automáticamente los datos, como se indica continuación.Hay muchas cosas que puedes cambiar/añadir esta sencilla versión, entre ellas:Ajustar automáticamente la escala del eje de recuentos sus datos (evita los errores que se comentan en la advertencia que aparece continuación)Especificar manualmente los colores y las etiquetas de las leyendasConvertir recuentos en porcentajesPara convertir los recuentos en porcentajes (del total), hazlo en los datos antes de representarlos. continuación, obtenemos los recuentos de age-gender, entonces desagrupamos con ungroup(), y luego mutamos con mutate() para crear nuevas columnas de porcentajes. Si quieres porcentajes por género, omite el paso de desagrupación.Es importante que guardemos los valores máximo y mínimo para saber cuáles deben ser los límites de la escala. Estos se utilizarán en el comando ggplot() continuación.Finalmente hacemos el ggplot() sobre los datos porcentuales. Especificamos scale_y_continuous() para extender las longitudes predefinidas en cada dirección (positiva y “negativa”). Usamos floor() y ceiling() para redondear los decimales en la dirección apropiada (abajo o arriba) para el lado del eje.","code":"\n  # begin ggplot\n  ggplot(mapping = aes(x = age, fill = gender)) +\n  \n  # female histogram\n  geom_histogram(data = linelist %>% filter(gender == \"f\"),\n                 breaks = seq(0,85,5),\n                 colour = \"white\") +\n  \n  # male histogram (values converted to negative)\n  geom_histogram(data = linelist %>% filter(gender == \"m\"),\n                 breaks = seq(0,85,5),\n                 mapping = aes(y = ..count..*(-1)),\n                 colour = \"white\") +\n  \n  # flip the X and Y axes\n  coord_flip() +\n  \n  # adjust counts-axis scale\n  scale_y_continuous(limits = c(-600, 900),\n                     breaks = seq(-600,900,100),\n                     labels = abs(seq(-600, 900, 100)))\n# create dataset with proportion of total\npyramid_data <- linelist %>%\n  count(age_cat5,\n        gender,\n        name = \"counts\") %>% \n  ungroup() %>%                 # ungroup so percents are not by group\n  mutate(percent = round(100*(counts / sum(counts, na.rm=T)), digits = 1), \n         percent = case_when(\n            gender == \"f\" ~ percent,\n            gender == \"m\" ~ -percent,     # convert male to negative\n            TRUE          ~ NA_real_))    # NA val must by numeric as well\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n\nmax_per## [1] 10.9\nmin_per## [1] -7.1\n# begin ggplot\n  ggplot()+  # default x-axis is age in years;\n\n  # case data graph\n  geom_col(data = pyramid_data,\n           mapping = aes(\n             x = age_cat5,\n             y = percent,\n             fill = gender),         \n           colour = \"white\")+       # white around each bar\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n\n  # adjust the axes scales\n  # scale_x_continuous(breaks = seq(0,100,5), labels = seq(0,100,5)) +\n  scale_y_continuous(\n    limits = c(min_per, max_per),\n    breaks = seq(from = floor(min_per),                # sequence of values, by 2s\n                 to = ceiling(max_per),\n                 by = 2),\n    labels = paste0(abs(seq(from = floor(min_per),     # sequence of absolute values, by 2s, with \"%\"\n                            to = ceiling(max_per),\n                            by = 2)),\n                    \"%\"))+  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",\n               \"m\" = \"darkgreen\"),\n    labels = c(\"Female\", \"Male\")) +\n  \n  # label values (remember X and Y flipped now)\n  labs(\n    title = \"Age and gender of cases\",\n    x = \"Age group\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Data are from linelist \\nn = {nrow(linelist)} (age or sex missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases) \\nData as of: {format(Sys.Date(), '%d %b %Y')}\")) +\n  \n  # display themes\n  theme(\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0.5), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\")\n    )"},{"path":"demographic-pyramids-and-likert-scales.html","id":"comparación-con-una-línea-basal","chapter":"33 Pirámides de población y escalas de Likert","heading":"Comparación con una línea basal","text":"Con la flexibilidad de ggplot(), se puede tener una segunda capa de barras en el fondo que represente la pirámide de población “verdadera” o “de referencia”. Esto puede proporcionar una buena visualización para comparar lo observado con una referencia.Importa y visualiza los datos de población (véase la página Descargando el manual y los datos):En primer lugar, algunos pasos de gestión de datos:Aquí registramos el orden de las categorías de edad que queremos que aparezcan. Debido algunas peculiaridades de la forma en que se implementa ggplot(), en este escenario específico es más fácil almacenar estos como un vector de caracteres y utilizarlos más tarde en la función de representación gráfica.Combina los datos de la población y de los casos mediante la función bind_rows() de dplyr:En primer lugar, asegúrate que los nombres de las columnas, los valores de las categorías de edad y los valores del género son exactamente los mismosHaz que tengan la misma estructura de datos: columnas de categoría de edad, sexo, recuentos y porcentaje del totalAgruparlas, una encima de la otra (bind_rows())Revisar el conjunto de datos de la población modificadaAhora implementa lo mismo para los casos de linelist Ligeramente diferente porque comienza con las filas de casos, con los recuentos.Revisa los datos de casos modificadosAhora los dos dataframes están combinados, uno encima del otro (tienen los mismos nombres de columna). Podemos “nombrar” cada uno de los dataframes, y utilizar el argumento .id = para crear una nueva columna “data_source” que indicará de qué dataframe se originó cada fila. Podemos utilizar esta columna para filtrar en ggplot().Almacena los valores porcentuales máximo y mínimo, utilizados en la función de trazado para definir la extensión del gráfico (¡y acortar ninguna barra!)Ahora el gráfico se hace con ggplot():Un gráfico de barras de los datos de población (barras más anchas y transparentes)Un gráfico de barras de los datos del caso (barras pequeñas y más sólidas)","code":"\n# import the population demographics data\npop <- rio::import(\"country_demographics.csv\")\n# record correct age cat levels\nage_levels <- c(\"0-4\",\"5-9\", \"10-14\", \"15-19\", \"20-24\",\n                \"25-29\",\"30-34\", \"35-39\", \"40-44\", \"45-49\",\n                \"50-54\", \"55-59\", \"60-64\", \"65-69\", \"70-74\",\n                \"75-79\", \"80-84\", \"85+\")\n# create/transform populaton data, with percent of total\n########################################################\npop_data <- pop %>% \n  pivot_longer(      # pivot gender columns longer\n    cols = c(m, f),\n    names_to = \"gender\",\n    values_to = \"counts\") %>% \n  \n  mutate(\n    percent  = round(100*(counts / sum(counts, na.rm=T)),1),  # % of total\n    percent  = case_when(                                                        \n     gender == \"f\" ~ percent,\n     gender == \"m\" ~ -percent,               # if male, convert % to negative\n     TRUE          ~ NA_real_))\n# create case data by age/gender, with percent of total\n#######################################################\ncase_data <- linelist %>%\n  count(age_cat5, gender, name = \"counts\") %>%  # counts by age-gender groups\n  ungroup() %>% \n  mutate(\n    percent = round(100*(counts / sum(counts, na.rm=T)),1),  # calculate % of total for age-gender groups\n    percent = case_when(                                     # convert % to negative if male\n      gender == \"f\" ~ percent,\n      gender == \"m\" ~ -percent,\n      TRUE          ~ NA_real_))\n# combine case and population data (same column names, age_cat values, and gender values)\npyramid_data <- bind_rows(\"cases\" = case_data, \"population\" = pop_data, .id = \"data_source\")\n# Define extent of percent axis, used for plot limits\nmax_per <- max(pyramid_data$percent, na.rm=T)\nmin_per <- min(pyramid_data$percent, na.rm=T)\n# begin ggplot\n##############\nggplot()+  # default x-axis is age in years;\n\n  # population data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"population\"),\n    mapping = aes(\n      x = age_cat5,\n      y = percent,\n      fill = gender),\n    colour = \"black\",                               # black color around bars\n    alpha = 0.2,                                    # more transparent\n    width = 1)+                                     # full width\n  \n  # case data graph\n  geom_col(\n    data = pyramid_data %>% filter(data_source == \"cases\"), \n    mapping = aes(\n      x = age_cat5,                               # age categories as original X axis\n      y = percent,                                # % as original Y-axis\n      fill = gender),                             # fill of bars by gender\n    colour = \"black\",                               # black color around bars\n    alpha = 1,                                      # not transparent \n    width = 0.3)+                                   # half width\n  \n  # flip the X and Y axes to make pyramid vertical\n  coord_flip()+\n  \n  # manually ensure that age-axis is ordered correctly\n  scale_x_discrete(limits = age_levels)+     # defined in chunk above\n  \n  # set percent-axis \n  scale_y_continuous(\n    limits = c(min_per, max_per),                                          # min and max defined above\n    breaks = seq(floor(min_per), ceiling(max_per), by = 2),                # from min% to max% by 2 \n    labels = paste0(                                                       # for the labels, paste together... \n              abs(seq(floor(min_per), ceiling(max_per), by = 2)), \"%\"))+                                                  \n\n  # designate colors and legend labels manually\n  scale_fill_manual(\n    values = c(\"f\" = \"orange\",         # assign colors to values in the data\n               \"m\" = \"darkgreen\"),\n    labels = c(\"f\" = \"Female\",\n               \"m\"= \"Male\"),      # change labels that appear in legend, note order\n  ) +\n\n  # plot labels, titles, caption    \n  labs(\n    title = \"Case age and gender distribution,\\nas compared to baseline population\",\n    subtitle = \"\",\n    x = \"Age category\",\n    y = \"Percent of total\",\n    fill = NULL,\n    caption = stringr::str_glue(\"Cases shown on top of country demographic baseline\\nCase data are from linelist, n = {nrow(linelist)}\\nAge or gender missing for {sum(is.na(linelist$gender) | is.na(linelist$age_years))} cases\\nCase data as of: {format(max(linelist$date_onset, na.rm=T), '%d %b %Y')}\")) +\n  \n  # optional aesthetic themes\n  theme(\n    legend.position = \"bottom\",                             # move legend to bottom\n    panel.grid.major = element_blank(),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    axis.line = element_line(colour = \"black\"),\n    plot.title = element_text(hjust = 0), \n    plot.caption = element_text(hjust=0, size=11, face = \"italic\"))"},{"path":"demographic-pyramids-and-likert-scales.html","id":"likert-scale","chapter":"33 Pirámides de población y escalas de Likert","heading":"33.4 Escalas de Likert","text":"Las técnicas utilizadas para hacer una pirámide de población con ggplot() también se pueden utilizar para hacer gráficos de datos de encuestas en escala Likert.Importa los datos (consulta la página Descargando el manual y los datos si lo deseas).Empieza con datos que tengan este aspecto, con una clasificación categórica de cada encuestado (status y sus respuestas 8 preguntas en una escala tipo Likert de 4 puntos (“Muy pobre”, “Pobre”, “Bueno”, “Muy bueno”).En primer lugar, algunos pasos de gestión de datos:Pivotar los datos lo largoCrear una nueva columna direction en función de si la respuesta fue generalmente “positiva” o “negativa”Establece el orden del nivel de factor para la columnas status y ResponseAlmacena el valor de recuento máximo para que los límites del gráfico sean los adecuadosAhora haz el gráfico. Como en las pirámides de edad anteriores, estamos creando dos gráficos de barras e invirtiendo los valores de uno de ellos negativo.Utilizamos geom_bar() porque nuestros datos son una fila por observación, recuentos agregados. Utilizamos el término especial de ggplot2 ..count.. en uno de los gráficos de barras para invertir los valores en negativo (*-1), y establecemos position = \"stack\" para que los valores se apilen unos encima de otros.","code":"\n# import the likert survey response data\nlikert_data <- rio::import(\"likert_data.csv\")\nmelted <- likert_data %>% \n  pivot_longer(\n    cols = Q1:Q8,\n    names_to = \"Question\",\n    values_to = \"Response\") %>% \n  mutate(\n    \n    direction = case_when(\n      Response %in% c(\"Poor\",\"Very Poor\")  ~ \"Negative\",\n      Response %in% c(\"Good\", \"Very Good\") ~ \"Positive\",\n      TRUE                                 ~ \"Unknown\"),\n    \n    status = fct_relevel(status, \"Junior\", \"Intermediate\", \"Senior\"),\n    \n    # must reverse 'Very Poor' and 'Poor' for ordering to work\n    Response = fct_relevel(Response, \"Very Good\", \"Good\", \"Very Poor\", \"Poor\")) \n\n# get largest value for scale limits\nmelted_max <- melted %>% \n  count(status, Question) %>% # get counts\n  pull(n) %>%                 # column 'n'\n  max(na.rm=T)                # get max\n# make plot\nggplot()+\n     \n  # bar graph of the \"negative\" responses \n     geom_bar(\n       data = melted %>% filter(direction == \"Negative\"),\n       mapping = aes(\n         x = status,\n         y = ..count..*(-1),    # counts inverted to negative\n         fill = Response),\n       color = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # bar graph of the \"positive responses\n     geom_bar(\n       data = melted %>% filter(direction == \"Positive\"),\n       mapping = aes(\n         x = status,\n         fill = Response),\n       colour = \"black\",\n       closed = \"left\",\n       position = \"stack\")+\n     \n     # flip the X and Y axes\n     coord_flip()+\n  \n     # Black vertical line at 0\n     geom_hline(yintercept = 0, color = \"black\", size=1)+\n     \n    # convert labels to all positive numbers\n    scale_y_continuous(\n      \n      # limits of the x-axis scale\n      limits = c(-ceiling(melted_max/10)*11,    # seq from neg to pos by 10, edges rounded outward to nearest 5\n                 ceiling(melted_max/10)*10),   \n      \n      # values of the x-axis scale\n      breaks = seq(from = -ceiling(melted_max/10)*10,\n                   to = ceiling(melted_max/10)*10,\n                   by = 10),\n      \n      # labels of the x-axis scale\n      labels = abs(unique(c(seq(-ceiling(melted_max/10)*10, 0, 10),\n                            seq(0, ceiling(melted_max/10)*10, 10))))) +\n     \n    # color scales manually assigned \n    scale_fill_manual(\n      values = c(\"Very Good\"  = \"green4\", # assigns colors\n                \"Good\"      = \"green3\",\n                \"Poor\"      = \"yellow\",\n                \"Very Poor\" = \"red3\"),\n      breaks = c(\"Very Good\", \"Good\", \"Poor\", \"Very Poor\"))+ # orders the legend\n     \n    \n     \n    # facet the entire plot so each question is a sub-plot\n    facet_wrap( ~ Question, ncol = 3)+\n     \n    # labels, titles, caption\n    labs(\n      title = str_glue(\"Likert-style responses\\nn = {nrow(likert_data)}\"),\n      x = \"Respondent status\",\n      y = \"Number of responses\",\n      fill = \"\")+\n\n     # display adjustments \n     theme_minimal()+\n     theme(axis.text = element_text(size = 12),\n           axis.title = element_text(size = 14, face = \"bold\"),\n           strip.text = element_text(size = 14, face = \"bold\"),  # facet sub-titles\n           plot.title = element_text(size = 20, face = \"bold\"),\n           panel.background = element_rect(fill = NA, color = \"black\")) # black box around each facet"},{"path":"demographic-pyramids-and-likert-scales.html","id":"resources-26","chapter":"33 Pirámides de población y escalas de Likert","heading":"33.5 Recursos","text":"documentación de apyramide","code":""},{"path":"heat-plots.html","id":"heat-plots","chapter":"34 Gráficos de calor","heading":"34 Gráficos de calor","text":"Los gráficos de calor, también conocidos como “Heatmaps”, o mapas de calor” o “mosaicos de calor”, pueden ser visualizaciones útiles cuando se trata de mostrar 3 variables (eje-x, eje-y y relleno). continuación mostramos dos ejemplos:Una matriz visual de eventos de transmisión por edad (“quién infectó quién”)Seguimiento de las métricas de información en muchas instalaciones/jurisdicciones lo largo del tiempo","code":""},{"path":"heat-plots.html","id":"preparation-25","chapter":"34 Gráficos de calor","heading":"34.1 Preparación","text":"","code":""},{"path":"heat-plots.html","id":"cargar-paquetes-22","chapter":"34 Gráficos de calor","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.Conjuntos de datosEsta página utiliza los casos de linelist un brote simulado para la sección de la matriz de transmisión, y unos datos separados de recuentos diarios de casos de malaria por instalación para la sección de seguimiento de métricas. Se cargan y limpian en sus secciones individuales.","code":"\npacman::p_load(\n  tidyverse,       # data manipulation and visualization\n  rio,             # importing data \n  lubridate        # working with dates\n  )"},{"path":"heat-plots.html","id":"transmission-matrix","chapter":"34 Gráficos de calor","heading":"34.2 Matriz de transmisión","text":"Los mapas de calor pueden ser útiles para visualizar matrices. Un ejemplo es la visualización de “quién-infectó-quién” en un brote. Esto supone que se tiene información sobre los eventos de transmisión.Ten en cuenta que la página Rastreo de contactos contiene otro ejemplo de elaboración de una matriz de contactos del mapa de calor, utilizando unos datos diferentes (quizás más sencillo) en el que las edades de los casos y sus fuentes están perfectamente alineadas en la misma fila del dataframe. Estos mismos datos se utilizan para hacer un mapa de densidad en la página Consejos de ggplot. Este ejemplo comienza partir de linelist y, por lo tanto, implica una considerable manipulación de los datos antes de lograr un dataframe ploteable. Así que hay muchos escenarios para elegir…Partimos de la lista de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (acepta muchos tipos de archivos como .xlsx, .rds, .csv - vea la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado para su demostración:En este linelist:Hay una fila por caso, identificada por case_idHay una columna posterior infector que contiene el case_id del infector, que también es un caso en linelist","code":"\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"heat-plots.html","id":"preparación-de-los-datos","chapter":"34 Gráficos de calor","heading":"Preparación de los datos","text":"Objetivo: Necesitamos conseguir un dataframe de estilo “largo” que contenga una fila por cada posible ruta de transmisión edad--edad, con una columna numérica que contenga la proporción de esa fila de todos los eventos de transmisión observados en linelist.Esto requerirá varios pasos de manipulación de datos para lograrlo:","code":""},{"path":"heat-plots.html","id":"hacer-el-dataframe-de-casos","chapter":"34 Gráficos de calor","heading":"Hacer el dataframe de casos","text":"Para empezar, creamos un dataframe de los casos, sus edades y sus infectadores - llamamos al dataframe case_ages. Las primeras 50 filas se muestran continuación.","code":"\ncase_ages <- linelist %>% \n  select(case_id, infector, age_cat) %>% \n  rename(\"case_age_cat\" = \"age_cat\")"},{"path":"heat-plots.html","id":"hacer-un-dataframe-de-infectores","chapter":"34 Gráficos de calor","heading":"Hacer un dataframe de infectores","text":"continuación, creamos un dataframe de los infectores, que por el momento consta de una sola columna. Se trata de las identificaciones de los infectores del listado. todos los casos tienen un infector conocido, por lo que eliminamos los valores que faltan. continuación se muestran las primeras 50 filas.continuación, utilizamos las uniones para obtener las edades de los infectores. Esto es sencillo, ya que en linelist, las edades de los infectores aparecen como tales. Conseguimos este resultado uniendo los casos de linelist con los infectores. Comenzamos con los infectores, y left_join() (añadimos) linelist de tal manera que la columna de ID del infector del lado izquierdo del dataframe “base” se une la columna case_id en el dataframe linelist en el lado derecho.Así, los datos del registro de casos del infector en linelist(incluida la edad) se añaden la fila del infector. continuación se muestran las 50 primeras filas.continuación, combinamos los casos y sus edades con los infectores y sus edades. Cada uno de estos dataframes tiene la columna infector, por lo que se utiliza para la unión. Las primeras filas se muestran continuación:continuación, una simple tabulación cruzada de los recuentos entre los grupos de edad de los casos y de los infectantes. Se añaden etiquetas para mayor claridad.Podemos convertir esta tabla en un dataframe con data.frame() de R base, que también la convierte automáticamente al formato “long”, que es el deseado por ggplot(). Las primeras filas se muestran continuación.Ahora hacemos lo mismo, pero aplicamos prop.table() de R base la tabla para que en lugar de recuentos obtengamos proporciones del total. Las primeras 50 filas se muestran continuación.","code":"\ninfectors <- linelist %>% \n  select(infector) %>% \n  drop_na(infector)\ninfector_ages <- infectors %>%             # begin with infectors\n  left_join(                               # add the linelist data to each infector  \n    linelist,\n    by = c(\"infector\" = \"case_id\")) %>%    # match infector to their information as a case\n  select(infector, age_cat) %>%            # keep only columns of interest\n  rename(\"infector_age_cat\" = \"age_cat\")   # rename for clarity\nages_complete <- case_ages %>%  \n  left_join(\n    infector_ages,\n    by = \"infector\") %>%        # each has the column infector\n  drop_na()                     # drop rows with any missing data\ntable(cases = ages_complete$case_age_cat,\n      infectors = ages_complete$infector_age_cat)##        infectors\n## cases   0-4 5-9 10-14 15-19 20-29 30-49 50-69 70+\n##   0-4   105 156   105   114   143   117    13   0\n##   5-9   102 132   110   102   117    96    12   5\n##   10-14 104 109    91    79   120    80    12   4\n##   15-19  85 105    82    39    75    69     7   5\n##   20-29 101 127   109    80   143   107    22   4\n##   30-49  72  97    56    54    98    61     4   5\n##   50-69   5   6    15     9     7     5     2   0\n##   70+     1   0     2     0     0     0     0   0\nlong_counts <- data.frame(table(\n    cases     = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat))\nlong_prop <- data.frame(prop.table(table(\n    cases = ages_complete$case_age_cat,\n    infectors = ages_complete$infector_age_cat)))"},{"path":"heat-plots.html","id":"crear-un-gráfico-de-calor","chapter":"34 Gráficos de calor","heading":"Crear un gráfico de calor","text":"Ahora, finalmente, podemos crear el gráfico de calor con el paquete ggplot2, utilizando la función geom_tile(). Consulta la página Consejos de ggplot para conocer más ampliamente las escalas de color/relleno, especialmente la función scale_fill_gradient().En la estética aes() de geom_tile() establece la x y la y como la edad del caso y la edad del infectorTambién en aes() establece el argumento fill = en la columna Freq - este es el valor que se convertirá en un color de mosaicoEstablece un color de escala con scale_fill_gradient() - puedes especificar los colores high/low\nTen en cuenta que scale_color_gradient() es diferente. En este caso quieres que rellene\nTen en cuenta que scale_color_gradient() es diferente. En este caso quieres que relleneDado que el color se hace través de “fill”, puedes utilizar el argumento fill = en labs() para cambiar el título de la leyenda","code":"\nggplot(data = long_prop)+       # use long data, with proportions as Freq\n  geom_tile(                    # visualize it in tiles\n    aes(\n      x = cases,         # x-axis is case age\n      y = infectors,     # y-axis is infector age\n      fill = Freq))+            # color of the tile is the Freq column in the data\n  scale_fill_gradient(          # adjust the fill color of the tiles\n    low = \"blue\",\n    high = \"orange\")+\n  labs(                         # labels\n    x = \"Case age\",\n    y = \"Infector age\",\n    title = \"Who infected whom\",\n    subtitle = \"Frequency matrix of transmission events\",\n    fill = \"Proportion of all\\ntranmsission events\"     # legend title\n  )"},{"path":"heat-plots.html","id":"reporting-metrics-over-time","chapter":"34 Gráficos de calor","heading":"34.3 Informar sobre las métricas a lo largo del tiempo","text":"menudo, en el ámbito de la salud pública, uno de los objetivos es evaluar las tendencias lo largo del tiempo de muchas entidades (instalaciones, jurisdicciones, etc.). Una forma de visualizar esas tendencias lo largo del tiempo es un gráfico de calor en el que el eje de abscisas es el tiempo y en el eje de ordenadas están las numerosas entidades.","code":""},{"path":"heat-plots.html","id":"preparación-de-los-datos-1","chapter":"34 Gráficos de calor","heading":"Preparación de los datos","text":"Comenzamos importando unos datos de informes diarios sobre la malaria procedentes de muchos centros. Los informes contienen una fecha, una provincia, un distrito y el recuento de paludismo. Consulta la página Descargando el manual y los datos para saber cómo descargar estos datos. continuación se muestran las primeras 30 filas:","code":"\nfacility_count_data <- import(\"malaria_facility_count_data.rds\")"},{"path":"heat-plots.html","id":"agregar-y-resumir","chapter":"34 Gráficos de calor","heading":"Agregar y resumir","text":"El objetivo de este ejemplo es transformar los recuentos diarios del total de casos de malaria del centro (vistos en la sección anterior) en estadísticas resumidas semanales de la declaración de cada centro, en este caso la proporción de días por semana en que el centro notificó algún dato. Para este ejemplo mostraremos los datos sólo para el distrito de Spring.Para ello, realizaremos los siguientes pasos de gestión de datos:Filtrar los datos según convenga (por lugar, fecha)Filtrar los datos según convenga (por lugar, fecha)Crear una columna de semana utilizando floor_date() del paquete lubridate \nEsta función devuelve la fecha de inicio de la semana de una fecha dada, utilizando una fecha de inicio especificada de cada semana (por ejemplo, “onday”)\nCrear una columna de semana utilizando floor_date() del paquete lubridate Esta función devuelve la fecha de inicio de la semana de una fecha dada, utilizando una fecha de inicio especificada de cada semana (por ejemplo, “onday”)Los datos se agrupan por las columnas “location” y “week” para crear unidades de análisis de “instalación-semana”Los datos se agrupan por las columnas “location” y “week” para crear unidades de análisis de “instalación-semana”La función summarise() crea nuevas columnas para reflejar las estadísticas resumidas por grupo de facility-week:\nNúmero de días por semana (7 - un valor estático)\nNúmero de informes recibidos de la semana de la instalación (¡podrían ser más de 7!)\nSuma de los casos de paludismo notificados por el centro-semana (sólo por interés)\nNúmero de días únicos en la semana de la instalación para los que hay datos reportados\nPorcentaje de los 7 días por instalación-semana para los que se comunicaron datos\nLa función summarise() crea nuevas columnas para reflejar las estadísticas resumidas por grupo de facility-week:Número de días por semana (7 - un valor estático)Número de informes recibidos de la semana de la instalación (¡podrían ser más de 7!)Suma de los casos de paludismo notificados por el centro-semana (sólo por interés)Número de días únicos en la semana de la instalación para los que hay datos reportadosPorcentaje de los 7 días por instalación-semana para los que se comunicaron datosEl dataframe se une con right_join() una lista exhaustiva de todas las posibles combinaciones de semanas de instalaciones, para que el conjunto de datos esté completo. La matriz de todas las combinaciones posibles se crea aplicando expand() esas dos columnas del dataframe tal y como se encuentra en ese momento en la cadena de pipes (representada por .). Como se utiliza un right_join(), se mantienen todas las filas del dataframe de expand() y se añaden agg_weeks si es necesario. Estas nuevas filas aparecen con valores resumidos NA (missing).continuación lo mostramos paso paso:Ahora el conjunto de datos tiene nrow(agg_weeks) filas, cuando antes tenía nrow(facility_count_data).continuación creamos una columna week que refleje la fecha de inicio de la semana para cada registro. Esto se consigue con la función floor_date() del paquete lubridate, que se establece como “week” y para que las semanas comiencen los lunes (día 1 de la semana - los domingos serían 7). continuación se muestran las filas superiores.La nueva columna week puede verse en el extremo derecho del dataframeAhora agrupamos los datos en semanas de instalaciones y los resumimos para producir estadísticas por facility-week. Consulta la página sobre tablas descriptivas para obtener consejos. La agrupación en sí misma cambia el dataframe, pero afecta la forma en que se calculan las estadísticas de resumen posteriores.continuación se muestran las filas superiores. Observa cómo las columnas han cambiado completamente para reflejar las estadísticas de resumen deseadas. Cada fila refleja una facility-week.Por último, ejecutamos el siguiente comando para asegurarnos que TODAS las semanas posibles de las instalaciones están presentes en los datos, incluso si antes estaban.Estamos utilizando un right_join() sobre sí mismo (el conjunto de datos está representado por “.”) pero habiéndose expandido para incluir todas las combinaciones posibles de las columnas week y location_name. Véase la documentación sobre la función expand() en la página sobre Pivotar datos. Antes de ejecutar este código, el conjunto de datos contiene nrow(agg_weeks) filas.Aquí está expanded_weeks:Antes de ejecutar este código, agg_weeks contiene nrow(agg_weeks) filas.Después de ejecutar este código, agg_weeks contiene nrow(agg_weeks) filas.","code":"\n# Create weekly summary dataset\nagg_weeks <- facility_count_data %>% \n  \n  # filter the data as appropriate\n  filter(\n    District == \"Spring\",\n    data_date < as.Date(\"2020-08-01\")) \nagg_weeks <- agg_weeks %>% \n  # Create week column from data_date\n  mutate(\n    week = lubridate::floor_date(                     # create new column of weeks\n      data_date,                                      # date column\n      unit = \"week\",                                  # give start of the week\n      week_start = 1))                                # weeks to start on Mondays \nagg_weeks <- agg_weeks %>%   \n\n  # Group into facility-weeks\n  group_by(location_name, week) %>%\n  \n  # Create summary statistics columns on the grouped data\n  summarize(\n    n_days          = 7,                                          # 7 days per week           \n    n_reports       = dplyr::n(),                                 # number of reports received per week (could be >7)\n    malaria_tot     = sum(malaria_tot, na.rm = T),                # total malaria cases reported\n    n_days_reported = length(unique(data_date)),                  # number of unique days reporting per week\n    p_days_reported = round(100*(n_days_reported / n_days))) %>%  # percent of days reporting\n  ungroup(location_name, week)\n# Create data frame of every possible facility-week\nexpanded_weeks <- agg_weeks %>% \n  tidyr::expand(location_name, week)  # expand data frame to include all possible facility-week combinations\n# Use a right-join with the expanded facility-week list to fill-in the missing gaps in the data\nagg_weeks <- agg_weeks %>%      \n  right_join(expanded_weeks) %>%                            # Ensure every possible facility-week combination appears in the data\n  mutate(p_days_reported = replace_na(p_days_reported, 0))  # convert missing values to 0                           ## Joining, by = c(\"location_name\", \"week\")"},{"path":"heat-plots.html","id":"crear-un-gráfico-de-calor-1","chapter":"34 Gráficos de calor","heading":"Crear un gráfico de calor","text":"ggplot() se realiza utilizando geom_tile() del paquete ggplot2:Las semanas en el eje-x se transforman en fechas, lo que permite utilizar scale_x_date()location_name en el eje y mostrará todos los nombres de las instalacionesfill (relleno) es p_days_reported, el rendimiento para ese establecimiento-semana (numérico)scale_fill_gradient() se utiliza en el relleno numérico, especificando los colores para el alto, el bajo y NAscale_x_date() se utiliza en el eje x especificando las etiquetas cada 2 semanas y su formatoLos temas de visualización y las etiquetas pueden ajustarse según sea necesario","code":""},{"path":"heat-plots.html","id":"básico","chapter":"34 Gráficos de calor","heading":"Básico","text":"continuación se produce un gráfico de calor básico, utilizando los colores, escalas, etc., por defecto. Como se ha explicado anteriormente, dentro de aes() para geom_tile() debes proporcionar una columna del eje-x, una columna del eje-y y una columna para fill =. El relleno es el valor numérico que se presenta como color del mosaico.","code":"\nggplot(data = agg_weeks)+\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported))"},{"path":"heat-plots.html","id":"gráfico-limpio","chapter":"34 Gráficos de calor","heading":"Gráfico limpio","text":"Podemos hacer que este gráfico se vea mejor añadiendo funciones adicionales de ggplot2, como se muestra continuación. Consulta la página Consejos de ggplot para más detalles.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"eje-y-ordenado","chapter":"34 Gráficos de calor","heading":"Eje-y ordenado","text":"Actualmente, las instalaciones están ordenadas “alfanuméricamente” de abajo arriba. Si deseas ajustar el orden de las instalaciones del eje-y, conviértelas en de tipo factor y proporciona el orden. Consulta la página sobre Factores para obtener consejos.Como hay muchas instalaciones y queremos escribirlas todas, intentaremos otro enfoque: ordenar las instalaciones en un dataframe y utilizar la columna de nombres resultante como orden de los niveles del factor. continuación, la columna location_name se convierte en un factor, y el orden de sus niveles se establece en función del número total de días de notificación presentados por el centro en todo el período de tiempo.Para ello, creamos un dataframe que representa el número total de informes por instalación, ordenados de forma ascendente. Podemos utilizar este vector para ordenar los niveles del factor en el gráfico.Véase el dataframe más abajo:Ahora utiliza una columna del dataframe anterior (facility_order$location_name) para que sea el orden de los niveles del factor location_name en el dataframe agg_weeks:Y ahora los datos se vuelven representar, con location_name como factor ordenado:","code":"\nfacility_order <- agg_weeks %>% \n  group_by(location_name) %>% \n  summarize(tot_reports = sum(n_days_reported, na.rm=T)) %>% \n  arrange(tot_reports) # ascending order\n# load package \npacman::p_load(forcats)\n\n# create factor and define levels manually\nagg_weeks <- agg_weeks %>% \n  mutate(location_name = fct_relevel(\n    location_name, facility_order$location_name)\n    )\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                  # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"mostrar-valores","chapter":"34 Gráficos de calor","heading":"Mostrar valores","text":"Puedes añadir una capa geom_text() encima de los mosaicos, para mostrar los números reales de cada mosaico. Ten en cuenta que esto puede parecer bonito si tiene muchos mosaicos pequeños.Se ha añadido el siguiente código: geom_text(aes(label = p_days_reported)). Esto añade texto en cada mosaico. El texto que se muestra es el valor asignado al argumento label =, que en este caso se ha establecido en la misma columna numérica p_days_reported que también se utiliza para crear el gradiente de color.","code":"\nggplot(data = agg_weeks)+ \n  \n  # show data as tiles\n  geom_tile(\n    aes(x = week,\n        y = location_name,\n        fill = p_days_reported),      \n    color = \"white\")+                 # white gridlines\n  \n  # text\n  geom_text(\n    aes(\n      x = week,\n      y = location_name,\n      label = p_days_reported))+      # add text on top of tile\n  \n  # fill scale\n  scale_fill_gradient(\n    low = \"orange\",\n    high = \"darkgreen\",\n    na.value = \"grey80\")+\n  \n  # date axis\n  scale_x_date(\n    expand = c(0,0),             # remove extra space on sides\n    date_breaks = \"2 weeks\",     # labels every 2 weeks\n    date_labels = \"%d\\n%b\")+     # format is day over month (\\n in newline)\n  \n  # aesthetic themes\n  theme_minimal()+                                    # simplify background\n  \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),           # height of legend key\n    legend.key.width  = grid::unit(0.6,\"cm\"),         # width of legend key\n    \n    axis.text.x = element_text(size=12),              # axis text size\n    axis.text.y = element_text(vjust=0.2),            # axis text alignment\n    axis.ticks = element_line(size=0.4),               \n    axis.title = element_text(size=12, face=\"bold\"),  # axis title size and bold\n    \n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),  # title right-aligned, large, bold\n    plot.caption = element_text(hjust = 0, face = \"italic\")  # caption right-aligned and italic\n    )+\n  \n  # plot labels\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",           # legend title, because legend shows fill\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, May-July 2020\",\n       caption = \"7-day weeks beginning on Mondays.\")"},{"path":"heat-plots.html","id":"resources-25","chapter":"34 Gráficos de calor","heading":"34.4 Recursos","text":"scale_fill_gradient()Galería de gráficos R - mapa de calor","code":""},{"path":"diagrams-and-charts.html","id":"diagrams-and-charts","chapter":"35 Diagramas y gráficos","heading":"35 Diagramas y gráficos","text":"Esta página cubre el código para producir:Diagramas de flujo utilizando DiagrammeR y el lenguaje DOTDiagramas aluviales/Diagramas de SankeyCalendario de eventos","code":""},{"path":"diagrams-and-charts.html","id":"preparation-28","chapter":"35 Diagramas y gráficos","heading":"35.1 Preparación","text":"","code":""},{"path":"diagrams-and-charts.html","id":"cargar-paquetes-23","chapter":"35 Diagramas y gráficos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También es posible cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  DiagrammeR,     # for flow diagrams\n  networkD3,      # For alluvial/Sankey diagrams\n  tidyverse)      # data management and visualization"},{"path":"diagrams-and-charts.html","id":"importar-datos-19","chapter":"35 Diagramas y gráficos","heading":"Importar datos","text":"La mayor parte del contenido de esta página requiere unos datos. Sin embargo, en la sección del diagrama de Sankey, utilizaremos la lista de casos de una epidemia de ébola simulada. Si quieres seguir esta parte, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"diagrams-and-charts.html","id":"flow-diagrams","chapter":"35 Diagramas y gráficos","heading":"35.2 Diagramas de flujo","text":"Se puede utilizar el paquete R DiagrammeR para crear gráficos/gráficos de flujo. Pueden ser estáticos o ajustarse de forma dinámica en función de los cambios en unos datos.HerramientasLa función grViz() se utiliza para crear un diagrama “Graphviz”. Esta función acepta una cadena de caracteres de entrada que contiene las instrucciones para hacer el diagrama. Dentro de esa cadena, las instrucciones están escritas en un lenguaje diferente, llamado DOT - es bastante fácil aprender lo básico.Estructura básicaAbre las instrucciones grViz(\"Especifica la dirección y el nombre del gráfico, y abre los paréntesis, por ejemplo, digraph my_flow_chart {Define los elementos del gráfico (layout, rank direction)Establece los nodos (create nodes)Establece las conexiones entre nodosCierra las instrucciones }\")","code":""},{"path":"diagrams-and-charts.html","id":"ejemplos-sencillos","chapter":"35 Diagramas y gráficos","heading":"Ejemplos sencillos","text":"continuación, dos sencillos ejemplosUn ejemplo mínimo:Un ejemplo con un contexto de salud pública quizás más aplicado:","code":"\n# A minimal plot\nDiagrammeR::grViz(\"digraph {\n  \ngraph[layout = dot, rankdir = LR]\n\na\nb\nc\n\na -> b -> c\n}\")\ngrViz(\"                           # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,\n         overlap = true,\n         fontsize = 10]\n  \n  # nodes\n  #######\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]               # width of circles\n  \n  Primary                         # names of nodes\n  Secondary\n  Tertiary\n\n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer']\n  Secondary -> Tertiary [label = ' case transfer']\n}\n\")"},{"path":"diagrams-and-charts.html","id":"sintaxis","chapter":"35 Diagramas y gráficos","heading":"Sintaxis","text":"Sintaxis básicaLos nombres de los nodos, o las etiquetas de las conexiones (edges), pueden separarse con espacios, punto y coma o nuevas líneas.Dirección del rangoSe puede reorientar un gráfico para que se mueva de izquierda derecha ajustando el argumento rankdir dentro de la sentencia del gráfico. El valor predeterminado es TB (top-bottom, de arriba abajo), pero puede ser LR (Left-Right, de izquierda derecha), RL o BT.Nombres de los nodosLos nombres de los nodos pueden ser palabras sueltas, como en el sencillo ejemplo anterior. Para utilizar nombres con varias palabras o caracteres especiales (por ejemplo, paréntesis, guiones), pon el nombre del nodo entre comillas simples (’ ’). Puede ser más fácil tener un nombre de nodo corto, y asignar una etiqueta como se muestra continuación entre corchetes [ ]. Si quieres tener una nueva línea dentro del nombre del nodo, debes hacerlo través de una etiqueta - utiliza \\n en la etiqueta del nodo entre comillas simples, como se muestra continuación.SubgruposAl definir las conexiones (aristas), se pueden crear subgrupos ambos lados de la arista con corchetes ({ }). La arista se aplica entonces todos los nodos en el corchete - es una forma abreviada.Diseñosdot (establecer rankdir entre TB, LR, RL, BT, )neatotwopicircoNodos - atributos editableslabel (texto, entre comillas simples si es de varias palabras)fillcolor (muchos colores posibles)fontcolor (color de la fuente)alpha (transparencia 0-1)shape (ellipse, oval, diamond, egg, plaintext, point, square, triangle)style (estilo)sides (lados)peripheries (periferia)fixedsize (h x w) (tamaño fijo (alto x ancho))height (alto)width (ancho)distortion (dstorsión)penwidth (ancho del borde de la forma)x (left/right) (desplazamiento la izquierda/derecha)y (/) (desplazamiento arriba/abajo)fontname (nombre de la fuente)fontsize (tamaño de letra)iconConexioness - atributos editablesarrowsize (tamaño de la flecha)arrowhead (normal, box, crow, curve, diamond, dot, inv, none, tee, vee)arrowtail (cola de flecha)dir (dirección, )style (guiones, …)coloralphaheadport (texto delante de la punta de la flecha)tailport (texto detrás de la cola de flecha)fontname (nombre de la fuente)fontsize (tamaño de letra)fontcolor (color de la fuente)penwidth (anchura de la flecha)minlen (longitud mínima)Nombres de los colores: valores hexadecimales o nombres de colores “X11”, véase aquí para los detalles de X11","code":""},{"path":"diagrams-and-charts.html","id":"ejemplos-complejos","chapter":"35 Diagramas y gráficos","heading":"Ejemplos complejos","text":"El siguiente ejemplo amplía el surveillance_diagram, añadiendo nombres de nodos complejos, conexiones agrupadas, colores y estilosAgrupaciones de subgráficosPara agrupar los nodos en clústeres de cajas, ponlos dentro del mismo subgrafo (subgraph name {}). Para que cada subgrafo se identifique dentro de una caja delimitadora, comienza el nombre del subgrafo con “cluster”, como se muestra con las 4 cajas de abajo.Formas de los nodosEl siguiente ejemplo, tomado de este tutorial, muestra las formas de los nodos aplicados y una abreviatura de las conexiones de los bordes en serie","code":"DiagrammeR::grViz(\"               # All instructions are within a large character string\ndigraph surveillance_diagram {    # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            # layout top-to-bottom\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,           # shape = circle\n       fixedsize = true\n       width = 1.3]                      \n  \n  Primary   [label = 'Primary\\nFacility'] \n  Secondary [label = 'Secondary\\nFacility'] \n  Tertiary  [label = 'Tertiary\\nFacility'] \n  SC        [label = 'Surveillance\\nCoordination',\n             fontcolor = darkgreen] \n  \n  # edges\n  #######\n  Primary   -> Secondary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  Secondary -> Tertiary [label = ' case transfer',\n                          fontcolor = red,\n                          color = red]\n  \n  # grouped edge\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting',\n                                      fontcolor = darkgreen,\n                                      color = darkgreen,\n                                      style = dashed]\n}\n\")DiagrammeR::grViz(\"             # All instructions are within a large character string\ndigraph surveillance_diagram {  # 'digraph' means 'directional graph', then the graph name \n  \n  # graph statement\n  #################\n  graph [layout = dot,\n         rankdir = TB,            \n         overlap = true,\n         fontsize = 10]\n  \n\n  # nodes (circles)\n  #################\n  node [shape = circle,                  # shape = circle\n       fixedsize = true\n       width = 1.3]                      # width of circles\n  \n  subgraph cluster_passive {\n    Primary   [label = 'Primary\\nFacility'] \n    Secondary [label = 'Secondary\\nFacility'] \n    Tertiary  [label = 'Tertiary\\nFacility'] \n    SC        [label = 'Surveillance\\nCoordination',\n               fontcolor = darkgreen] \n  }\n  \n  # nodes (boxes)\n  ###############\n  node [shape = box,                     # node shape\n        fontname = Helvetica]            # text font in node\n  \n  subgraph cluster_active {\n    Active [label = 'Active\\nSurveillance'] \n    HCF_active [label = 'HCF\\nActive Search']\n  }\n  \n  subgraph cluster_EBD {\n    EBS [label = 'Event-Based\\nSurveillance (EBS)'] \n    'Social Media'\n    Radio\n  }\n  \n  subgraph cluster_CBS {\n    CBS [label = 'Community-Based\\nSurveillance (CBS)']\n    RECOs\n  }\n\n  \n  # edges\n  #######\n  {Primary Secondary Tertiary} -> SC [label = 'case reporting']\n\n  Primary   -> Secondary [label = 'case transfer',\n                          fontcolor = red]\n  Secondary -> Tertiary [label = 'case transfer',\n                          fontcolor = red]\n  \n  HCF_active -> Active\n  \n  {'Social Media' Radio} -> EBS\n  \n  RECOs -> CBS\n}\n\")\n\nDiagrammeR::grViz(\"digraph {\n\ngraph [layout = dot, rankdir = LR]\n\n# define the global styles of the nodes. We can override these in box if we wish\nnode [shape = rectangle, style = filled, fillcolor = Linen]\n\ndata1 [label = 'Dataset 1', shape = folder, fillcolor = Beige]\ndata2 [label = 'Dataset 2', shape = folder, fillcolor = Beige]\nprocess [label =  'Process \\n Data']\nstatistical [label = 'Statistical \\n Analysis']\nresults [label= 'Results']\n\n# edge definitions with the node IDs\n{data1 data2}  -> process -> statistical -> results\n}\")"},{"path":"diagrams-and-charts.html","id":"salidas","chapter":"35 Diagramas y gráficos","heading":"Salidas","text":"Cómo manejar y guardar las salidasLas salidas aparecerán en el panel del Visor de RStudio, por defecto en la parte inferior derecha junto Files, Plots, Packages, y Help.Para exportarlos puedes “Save image” o “Copy clipboard” desde el Visor. El gráfico se ajustará al tamaño especificado.","code":""},{"path":"diagrams-and-charts.html","id":"figuras-parametrizadas","chapter":"35 Diagramas y gráficos","heading":"Figuras parametrizadas","text":"Esta es una cita este tutorial: https://mikeyharper.uk/flowcharts--r-using-diagrammer/“Figuras parametrizadas”: Una gran ventaja de diseñar figuras dentro de R es que podemos conectar las figuras directamente con nuestro análisis leyendo los valores de R directamente en nuestros diagramas de flujo. Por ejemplo, imagina que creado un proceso de filtrado que elimina valores después de cada etapa de un proceso, puedes hacer que una figura muestre el número de valores que quedan en el conjunto de datos después de cada etapa de su proceso. Para hacer esto, puedes utilizar el símbolo @@X directamente dentro de la figura, y luego hacer referencia esto en el pie de página del gráfico utilizando [X]:, donde X es el índice numérico único”.Te animamos revisar este tutorial si te interesa la parametrización.","code":""},{"path":"diagrams-and-charts.html","id":"alluvialsankey-diagrams","chapter":"35 Diagramas y gráficos","heading":"35.3 Diagramas Aluviales/Sankey","text":"","code":""},{"path":"diagrams-and-charts.html","id":"cargar-paquetes-24","chapter":"35 Diagramas y gráficos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.Cargamos el paquete networkD3 para producir el diagrama, y también tidyverse para los pasos de preparación de datos.","code":"\npacman::p_load(\n  networkD3,\n  tidyverse)"},{"path":"diagrams-and-charts.html","id":"trazado-desde-los-datos","chapter":"35 Diagramas y gráficos","heading":"Trazado desde los datos","text":"Trazado de las conexiones en unos datos. continuación mostramos el uso de este paquete con linelist Aquí hay un tutorial en línea.Comenzamos obteniendo los recuentos de casos para cada combinación única de categoría de edad y hospital. Hemos eliminado los valores con categoría de edad ausente para mayor claridad. También reetiquetamos las columnas hospital y age_cat como source y target respectivamente. Estos serán los dos lados del diagrama aluvial.El conjunto de datos tiene ahora este aspecto:Ahora creamos un dataframe de todos los nodos del diagrama, bajo la columna name. Esto consiste en todos los valores de hospital y age_cat. Observa que nos aseguramos de que todos son de tipo carácter antes de combinarlos. Ajustamos las columnas ID para que sean números en lugar de etiquetas:continuación editamos el dataframe links, que hemos creado anteriormente con count(). Añadimos dos columnas numéricas IDsource e IDtarget que reflejarán/crearán los enlaces entre los nodos. Estas columnas contendrán los números de ruta (posición) de los nodos de origen y destino. Se resta 1 para que estos números de posición comiencen en 0 (en 1).El conjunto de datos links tiene ahora este aspecto:Ahora traza el diagrama Sankey con sankeyNetwork(). Puedes leer más sobre cada argumento ejecutando ?sankeyNetwork en la consola. Ten en cuenta que menos que establezcas iterations = 0 el orden de los nodos puede ser el esperado.Este es un ejemplo en el que también se incluye el resultado del paciente. Obsérva que en el paso de preparación de los datos tenemos que calcular los recuentos de casos entre la edad y el hospital, y por separado entre el hospital y el resultado - y luego unir todos estos recuentos con bind_rows().https://www.displayr.com/sankey-diagrams-r/","code":"\n# counts by hospital and age category\nlinks <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = hospital,\n         target = age_cat)\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\nnodes  # print##                                    name\n## 1                      Central Hospital\n## 2                     Military Hospital\n## 3                               Missing\n## 4                                 Other\n## 5                         Port Hospital\n## 6  St. Mark's Maternity Hospital (SMMH)\n## 7                                   0-4\n## 8                                   5-9\n## 9                                 10-14\n## 10                                15-19\n## 11                                20-29\n## 12                                30-49\n## 13                                50-69\n## 14                                  70+\n# match to numbers, not names\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n# plot\n######\np <- sankeyNetwork(\n  Links = links,\n  Nodes = nodes,\n  Source = \"IDsource\",\n  Target = \"IDtarget\",\n  Value = \"n\",\n  NodeID = \"name\",\n  units = \"TWh\",\n  fontSize = 12,\n  nodeWidth = 30,\n  iterations = 0)        # ensure node order is as in data\np\n# counts by hospital and age category\nage_hosp_links <- linelist %>% \n  drop_na(age_cat) %>% \n  select(hospital, age_cat) %>%\n  count(hospital, age_cat) %>% \n  rename(source = age_cat,          # re-name\n         target = hospital)\n\nhosp_out_links <- linelist %>% \n    drop_na(age_cat) %>% \n    select(hospital, outcome) %>% \n    count(hospital, outcome) %>% \n    rename(source = hospital,       # re-name\n           target = outcome)\n\n# combine links\nlinks <- bind_rows(age_hosp_links, hosp_out_links)\n\n# The unique node names\nnodes <- data.frame(\n  name=c(as.character(links$source), as.character(links$target)) %>% \n    unique()\n  )\n\n# Create id numbers\nlinks$IDsource <- match(links$source, nodes$name)-1 \nlinks$IDtarget <- match(links$target, nodes$name)-1\n\n# plot\n######\np <- sankeyNetwork(Links = links,\n                   Nodes = nodes,\n                   Source = \"IDsource\",\n                   Target = \"IDtarget\",\n                   Value = \"n\",\n                   NodeID = \"name\",\n                   units = \"TWh\",\n                   fontSize = 12,\n                   nodeWidth = 30,\n                   iterations = 0)\np"},{"path":"diagrams-and-charts.html","id":"event-timelines","chapter":"35 Diagramas y gráficos","heading":"35.4 Calendario de eventos","text":"Para hacer una línea de tiempo que muestre eventos específicos, puedes utilizar el paquete vistime.Mira esta viñetaEste es el conjunto de datos de eventos con el que comenzamos:","code":"\n# load package\npacman::p_load(vistime,  # make the timeline\n               plotly    # for interactive visualization\n               )\np <- vistime(data)    # apply vistime\n\nlibrary(plotly)\n\n# step 1: transform into a list\npp <- plotly_build(p)\n\n# step 2: Marker size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"markers\") pp$x$data[[i]]$marker$size <- 10\n}\n\n# step 3: text size\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textfont$size <- 10\n}\n\n\n# step 4: text position\nfor(i in 1:length(pp$x$data)){\n  if(pp$x$data[[i]]$mode == \"text\") pp$x$data[[i]]$textposition <- \"right\"\n}\n\n#print\npp"},{"path":"diagrams-and-charts.html","id":"dags","chapter":"35 Diagramas y gráficos","heading":"35.5 DAGs","text":"Puedes construir un DAG manualmente utilizando el paquete DiagammeR y el lenguaje DOT como se ha descrito anteriormente.Como alternativa, existen paquetes como ggdag y daggityViñeta de Introducción los DAGs ggdagInferencia causal con dags en R","code":""},{"path":"diagrams-and-charts.html","id":"resources-28","chapter":"35 Diagramas y gráficos","heading":"35.6 Recursos","text":"Gran parte de lo anterior sobre el lenguaje DOT está adaptado del tutorial de este sitioOtro tutorial más detallado sobre DiagammeREsta página sobre los diagramas de Sankey","code":""},{"path":"combinations-analysis.html","id":"combinations-analysis","chapter":"36 Análisis de combinaciones","heading":"36 Análisis de combinaciones","text":"Este análisis representa la frecuencia de diferentes combinaciones de valores/respuestas. En este ejemplo, se representa la frecuencia con la que los casos mostraron varias combinaciones de síntomas.Este análisis también se suele llamar:“Análisis de respuesta múltiple”“Análisis de conjuntos”“Análisis de combinaciones”En el ejemplo del gráfico anterior, se muestran cinco síntomas. Debajo de cada barra vertical hay una línea y puntos que indican la combinación de síntomas que refleja la barra de arriba. la derecha, las barras horizontales reflejan la frecuencia de cada síntoma individual.El primer método que mostramos utiliza el paquete ggupset, y el segundo utiliza el paquete UpSetR.","code":""},{"path":"combinations-analysis.html","id":"preparation-29","chapter":"36 Análisis de combinaciones","heading":"36.1 Preparación","text":"","code":""},{"path":"combinations-analysis.html","id":"cargar-paquetes-25","chapter":"36 Análisis de combinaciones","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  tidyverse,     # data management and visualization\n  UpSetR,        # special package for combination plots\n  ggupset)       # special package for combination plots"},{"path":"combinations-analysis.html","id":"importar-datos-20","chapter":"36 Análisis de combinaciones","heading":"Importar datos","text":"Para empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio”, (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - ver la página de importación y exportación para más detalles).Linelist incluye cinco variables “yes/” sobre los síntomas declarados. Tendremos que transformar un poco estas variables para utilizar el paquete ggupset para hacer nuestro gráfico. Para ver los datos desplázate la derecha para ver las variables de los síntomas).","code":"\n# import case linelist \nlinelist_sym <- import(\"linelist_cleaned.rds\")"},{"path":"combinations-analysis.html","id":"reformular-los-valores","chapter":"36 Análisis de combinaciones","heading":"Reformular los valores","text":"Para alinearse con el formato esperado por ggupset, convertimos el “yes” y el “” en el nombre real del síntoma, utilizando case_when() de dplyr. Si “”, establecemos el valor en blanco, por lo que los valores son NA o el síntoma.Ahora hacemos dos columnas finales:Concatenando (pegar) todos los síntomas del paciente (una columna de caracteres)Conviertiendo la columna anterior en una de tipo list, para que pueda ser aceptada por ggupset para hacer la tramaConsulta la página sobre Caracteres y cadenas para saber más sobre la función unite() de stringrEn los datos nuevos observa las dos columnas del extremo derecho: los valores combinados pegados y la lista","code":"\n# create column with the symptoms named, separated by semicolons\nlinelist_sym_1 <- linelist_sym %>% \n    # convert the \"yes\" and \"no\" values into the symptom name itself\n    # if old value is \"yes\", new value is \"fever\", otherwise set to missing (NA)\n     mutate(fever = ifelse(fever == \"yes\", \"fever\", NA), \n            chills = ifelse(chills == \"yes\", \"chills\", NA),\n            cough = ifelse(cough == \"yes\", \"cough\", NA),\n            aches = ifelse(aches == \"yes\", \"aches\", NA),\n            vomit = ifelse(vomit == \"yes\", \"vomit\", NA))\nlinelist_sym_1 <- linelist_sym_1 %>% \n  unite(col = \"all_symptoms\",\n        c(fever, chills, cough, aches, vomit), \n        sep = \"; \",\n        remove = TRUE,\n        na.rm = TRUE) %>% \n  mutate(\n    # make a copy of all_symptoms column, but of class \"list\" (which is required to use ggupset() in next step)\n    all_symptoms_list = as.list(strsplit(all_symptoms, \"; \"))\n    )"},{"path":"combinations-analysis.html","id":"ggupset","chapter":"36 Análisis de combinaciones","heading":"36.2 ggupset","text":"Carga el paqueteCrear el gráfico. Comenzamos con ggplot() y geom_bar(), pero luego añadimos la función especial scale_x_upset() de ggupset.Puedes encontrar más información sobre ggupset en línea o fuera de línea en la documentación del paquete en su pestaña de Ayuda de RStudio ?ggupset.","code":"\npacman::p_load(ggupset)\nggplot(\n  data = linelist_sym_1,\n  mapping = aes(x = all_symptoms_list)) +\ngeom_bar() +\nscale_x_upset(\n  reverse = FALSE,\n  n_intersections = 10,\n  sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"))+\nlabs(\n  title = \"Signs & symptoms\",\n  subtitle = \"10 most frequent combinations of signs and symptoms\",\n  caption = \"Caption here.\",\n  x = \"Symptom combination\",\n  y = \"Frequency in dataset\")"},{"path":"combinations-analysis.html","id":"upsetr","chapter":"36 Análisis de combinaciones","heading":"36.3 UpSetR","text":"El paquete UpSetR permite una mayor personalización del gráfico, pero puede ser más difícil de ejecutar:Cargar paqueteLimpieza de datosDebemos convertir los valores de los síntomas de linelist en 1 / 0.Si está interesado en un comando más eficiente, puede aprovechar la función +(), que convierte en 1s y 0s basándose en una sentencia lógica. Este comando utiliza la función across() para cambiar varias columnas la vez (lea más en Limpieza de datos y funciones básicas).Ahora haz el gráfico usando la función personalizada upset() - utilizando sólo las columnas de síntomas. Debes designar qué “conjuntos” comparar (los nombres de las columnas de síntomas). Alternativamente, utiliza nsets = y order.= \"freq\" para mostrar sólo las X combinaciones principales.","code":"\npacman::p_load(UpSetR)\nlinelist_sym_2 <- linelist_sym %>% \n     # convert the \"yes\" and \"no\" values into 1s and 0s\n     mutate(fever = ifelse(fever == \"yes\", 1, 0), \n            chills = ifelse(chills == \"yes\", 1, 0),\n            cough = ifelse(cough == \"yes\", 1, 0),\n            aches = ifelse(aches == \"yes\", 1, 0),\n            vomit = ifelse(vomit == \"yes\", 1, 0))\n# Efficiently convert \"yes\" to 1 and 0\nlinelist_sym_2 <- linelist_sym %>% \n  \n  # convert the \"yes\" and \"no\" values into 1s and 0s\n  mutate(across(c(fever, chills, cough, aches, vomit), .fns = ~+(.x == \"yes\")))\n# Make the plot\nlinelist_sym_2 %>% \n  UpSetR::upset(\n       sets = c(\"fever\", \"chills\", \"cough\", \"aches\", \"vomit\"),\n       order.by = \"freq\",\n       sets.bar.color = c(\"blue\", \"red\", \"yellow\", \"darkgreen\", \"orange\"), # optional colors\n       empty.intersections = \"on\",\n       # nsets = 3,\n       number.angles = 0,\n       point.size = 3.5,\n       line.size = 2, \n       mainbar.y.label = \"Symptoms Combinations\",\n       sets.x.label = \"Patients with Symptom\")"},{"path":"combinations-analysis.html","id":"recursos-resources-29","chapter":"36 Análisis de combinaciones","heading":"36.4 Recursos {resources-29}","text":"La página de github de UpSetRUna versión de app Shiny: puedes cargar tus propios datos*documentación - difícil de interpretar","code":""},{"path":"transmission-chains.html","id":"transmission-chains","chapter":"37 Cadenas de transmisión","heading":"37 Cadenas de transmisión","text":"","code":""},{"path":"transmission-chains.html","id":"overview-7","chapter":"37 Cadenas de transmisión","heading":"37.1 Resumen","text":"La principal herramienta para manejar, analizar y visualizar las cadenas de transmisión y los datos de rastreo de contactos es el paquete epicontacts, desarrollado por la gente de RECON. Prueba con el gráfico interactivo que se muestra continuación pasando el cursor por encima de los nodos para obtener más información, arrastrándolos para moverlos y clicando sobre ellos para resaltar los casos posteriores.","code":""},{"path":"transmission-chains.html","id":"preparation-30","chapter":"37 Cadenas de transmisión","heading":"37.2 Preparación","text":"","code":""},{"path":"transmission-chains.html","id":"cargar-paquetes-26","chapter":"37 Cadenas de transmisión","heading":"Cargar paquetes","text":"Primero carga los paquetes estándar necesarios para la importación y manipulación de datos. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También se pueden cargar paquetes con library() desde R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.Necesitarás la versión de desarrollo de epicontacts, que puede instalarse desde github utilizando la función p_install_github() de pacman. Sólo necesitas ejecutar este comando una vez, cada vez que utilizas el paquete (partir de entonces, puedes utilizar sólo p_load()).","code":"\npacman::p_load(\n   rio,          # File import\n   here,         # File locator\n   tidyverse,    # Data management + ggplot2 graphics\n   remotes       # Package installation from github\n)\npacman::p_install_gh(\"reconhub/epicontacts@timeline\")"},{"path":"transmission-chains.html","id":"importar-datos-21","chapter":"37 Cadenas de transmisión","heading":"Importar datos","text":"Importamos el conjunto de datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso paso, consulta las instrucciones en la página de descargando el manual y los datos. El conjunto de datos se importa utilizando la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.continuación se muestran las primeras 50 filas del listado. Son especialmente interesantes las columnas case_id, generation, infector, y source.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.xlsx\")"},{"path":"transmission-chains.html","id":"creación-de-un-objeto-epicontacts","chapter":"37 Cadenas de transmisión","heading":"Creación de un objeto epicontacts","text":"continuación, tenemos que crear un objeto epicontacts, que requiere dos tipos de datos:un listado de casos en los que las columnas son variables y las filas corresponden casos únicosuna lista de bordes que definen los vínculos entre los casos sobre la base de sus identificadores únicos (pueden ser contactos, eventos de transmisión, etc.)Como ya tenemos un listado, sólo tenemos que crear una lista de aristas entre los casos, más concretamente entre sus ID. Podemos extraer los enlaces de transmisión del listado vinculando la columna infector con la columna case_id. En este punto también podemos añadir “propiedades de borde”, con lo que nos referimos cualquier variable que describa el vínculo entre los dos casos, los casos en sí. Por ejemplo, añadiremos una variable location que describa la ubicación del evento de transmisión, y una variable de duración que describa la duración del contacto en días.En el código siguiente, la función transmute() de dplyr es similar mutate, excepto que sólo mantiene las columnas que hemos especificado dentro de la función. La función drop_na filtrará cualquier fila en la que las columnas especificadas tengan un valor NA; en este caso, sólo queremos mantener las filas en las que se conoce el infector.Ahora podemos crear el objeto epicontacts utilizando la función make_epicontacts. Necesitamos especificar qué columna del listado apunta al identificador único del caso, así como qué columnas de los contactos apuntan los identificadores únicos de los casos involucrados en cada enlace. Estos enlaces son direccionales en el sentido de que la infección va del infector al caso, por lo que necesitamos especificar los argumentos y . Por lo tanto, también establecemos el argumento directed TRUE, que afectará las operaciones futuras.Al examinar los objetos epicontacts, podemos ver que la columna case_id del listado ha sido renombrada id y las columnas case_id e infector de los contactos han sido renombradas y . Esto garantiza la coherencia en las operaciones posteriores de manipulación, visualización y análisis.","code":"\n## generate contacts\ncontacts <- linelist %>%\n  transmute(\n    infector = infector,\n    case_id = case_id,\n    location = sample(c(\"Community\", \"Nosocomial\"), n(), TRUE),\n    duration = sample.int(10, n(), TRUE)\n  ) %>%\n  drop_na(infector)\n## generate epicontacts object\nepic <- make_epicontacts(\n  linelist = linelist,\n  contacts = contacts,\n  id = \"case_id\",\n  from = \"infector\",\n  to = \"case_id\",\n  directed = TRUE\n)\n## view epicontacts object\nepic## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 5,888 cases in linelist; 3,800 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 5,888 × 30\n##    id     generation date_infect…¹ date_onset date_hos…² date_out…³ outcome gender   age age_u…⁴ age_y…⁵\n##    <chr>       <dbl> <date>        <date>     <date>     <date>     <chr>   <chr>  <dbl> <chr>     <dbl>\n##  1 5fe599          4 2014-05-08    2014-05-13 2014-05-15 NA         <NA>    m          2 years         2\n##  2 8689b7          4 NA            2014-05-13 2014-05-14 2014-05-18 Recover f          3 years         3\n##  3 11f8ea          2 NA            2014-05-16 2014-05-18 2014-05-30 Recover m         56 years        56\n##  4 b8812a          3 2014-05-04    2014-05-18 2014-05-20 NA         <NA>    f         18 years        18\n##  5 893f25          3 2014-05-18    2014-05-21 2014-05-22 2014-05-29 Recover m          3 years         3\n##  6 be99c8          3 2014-05-03    2014-05-22 2014-05-23 2014-05-24 Recover f         16 years        16\n##  7 07e3e8          4 2014-05-22    2014-05-27 2014-05-29 2014-06-01 Recover f         16 years        16\n##  8 369449          4 2014-05-28    2014-06-02 2014-06-03 2014-06-07 Death   f          0 years         0\n##  9 f393b4          4 NA            2014-06-05 2014-06-06 2014-06-18 Recover m         61 years        61\n## 10 1389ca          4 NA            2014-06-05 2014-06-07 2014-06-09 Death   f         27 years        27\n## # … with 5,878 more rows, 19 more variables: age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>,\n## #   days_onset_hosp <dbl>, and abbreviated variable names ¹​date_infection, ²​date_hospitalisation,\n## #   ³​date_outcome, ⁴​age_unit, ⁵​age_years\n## \n##   // contacts\n## \n## # A tibble: 3,800 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f547d6 5fe599 Community         4\n##  2 f90f5f b8812a Nosocomial        3\n##  3 11f8ea 893f25 Nosocomial        1\n##  4 aec8ec be99c8 Community         1\n##  5 893f25 07e3e8 Community         3\n##  6 133ee7 369449 Nosocomial        1\n##  7 996f3a 2978ac Community         8\n##  8 133ee7 57a565 Community         7\n##  9 37a6f6 fc15ef Community         8\n## 10 9f6884 2eaa9a Community         8\n## # … with 3,790 more rows"},{"path":"transmission-chains.html","id":"handling","chapter":"37 Cadenas de transmisión","heading":"37.3 Manipulación","text":"","code":""},{"path":"transmission-chains.html","id":"subconjunto","chapter":"37 Cadenas de transmisión","heading":"Subconjunto","text":"El método subset() para los objetos epicontacts permite, entre otras cosas, filtrar las redes en función de las propiedades del listado (“atributos de nodos”) y de la base de datos de contactos (“atributos de aristas”). Estos valores deben pasarse como listas con nombre al argumento respectivo. Por ejemplo, en el código que sigue mantenemos en linelist sólo los casos masculinos que tienen una fecha de infección entre abril y julio de 2014 (las fechas se especifican como rangos), y los enlaces de transmisión que se produjeron en el hospital.Podemos utilizar la función thin para filtrar linelist para incluir los casos que se encuentran en los contactos estableciendo el argumento = \"linelist\", o filtrar los contactos para incluir los casos que se encuentran en linelist estableciendo el argumento = \"contacts\". En el código siguiente, filtramos aún más el objeto epicontactos para mantener sólo los enlaces de transmisión que implican los casos masculinos infectados entre abril y julio que habíamos filtrado anteriormente. Podemos ver que sólo dos enlaces de transmisión conocidos se ajustan esa especificación.Además de la subdivisión por atributos de nodos y aristas, las redes pueden podarse para incluir sólo los componentes que están conectados ciertos nodos. El argumento cluster_id toma un vector de IDs de casos y devuelve linelist de individuos que están vinculados, directa o indirectamente, esos IDs. En el código siguiente, podemos ver que un total de 13 casos del listado están involucrados en los clusters que contienen 2ae019 y 71577a.El método subset() para los objetos epicontacts también permite filtrar por tamaño de cluster usando los argumentos cs, cs_min y cs_max. En el código siguiente, estamos manteniendo sólo los casos vinculados clusters de 10 casos o más, y podemos ver que 271 casos del listado están involucrados en tales clusters.","code":"\nsub_attributes <- subset(\n  epic,\n  node_attribute = list(\n    gender = \"m\",\n    date_infection = as.Date(c(\"2014-04-01\", \"2014-07-01\"))\n  ), \n  edge_attribute = list(location = \"Nosocomial\")\n)\nsub_attributes## \n## /// Epidemiological Contacts //\n## \n##   // class: epicontacts\n##   // 69 cases in linelist; 1,903 contacts; directed \n## \n##   // linelist\n## \n## # A tibble: 69 × 30\n##    id     generation date_infect…¹ date_onset date_hos…² date_out…³ outcome gender   age age_u…⁴ age_y…⁵\n##    <chr>       <dbl> <date>        <date>     <date>     <date>     <chr>   <chr>  <dbl> <chr>     <dbl>\n##  1 5fe599          4 2014-05-08    2014-05-13 2014-05-15 NA         <NA>    m          2 years         2\n##  2 893f25          3 2014-05-18    2014-05-21 2014-05-22 2014-05-29 Recover m          3 years         3\n##  3 2978ac          4 2014-05-30    2014-06-06 2014-06-08 2014-06-15 Death   m         12 years        12\n##  4 57a565          4 2014-05-28    2014-06-13 2014-06-15 NA         Death   m         42 years        42\n##  5 fc15ef          6 2014-06-14    2014-06-16 2014-06-17 2014-07-09 Recover m         19 years        19\n##  6 99e8fa          7 2014-06-24    2014-06-28 2014-06-29 2014-07-09 Recover m         19 years        19\n##  7 f327be          6 2014-06-14    2014-07-12 2014-07-13 2014-07-14 Death   m         31 years        31\n##  8 90e5fe          5 2014-06-18    2014-07-13 2014-07-14 2014-07-16 <NA>    m         67 years        67\n##  9 a47529          5 2014-06-13    2014-07-17 2014-07-18 2014-07-26 Death   m         45 years        45\n## 10 da8ecb          5 2014-06-20    2014-07-18 2014-07-20 2014-08-01 <NA>    m         12 years        12\n## # … with 59 more rows, 19 more variables: age_cat <fct>, age_cat5 <fct>, hospital <chr>, lon <dbl>,\n## #   lat <dbl>, infector <chr>, source <chr>, wt_kg <dbl>, ht_cm <dbl>, ct_blood <dbl>, fever <chr>,\n## #   chills <chr>, cough <chr>, aches <chr>, vomit <chr>, temp <dbl>, time_admission <chr>, bmi <dbl>,\n## #   days_onset_hosp <dbl>, and abbreviated variable names ¹​date_infection, ²​date_hospitalisation,\n## #   ³​date_outcome, ⁴​age_unit, ⁵​age_years\n## \n##   // contacts\n## \n## # A tibble: 1,903 × 4\n##    from   to     location   duration\n##    <chr>  <chr>  <chr>         <int>\n##  1 f90f5f b8812a Nosocomial        3\n##  2 11f8ea 893f25 Nosocomial        1\n##  3 133ee7 369449 Nosocomial        1\n##  4 b799eb bc2adf Nosocomial        9\n##  5 beb26e 959170 Nosocomial        1\n##  6 567136 8ebf6e Nosocomial        4\n##  7 894024 e56412 Nosocomial        4\n##  8 a2086d a47529 Nosocomial        5\n##  9 7baf73 67be4e Nosocomial        5\n## 10 312ecf 3ad520 Nosocomial        6\n## # … with 1,893 more rows\nsub_attributes <- thin(sub_attributes, what = \"contacts\")\nnrow(sub_attributes$contacts)## [1] 5\nsub_id <- subset(epic, cluster_id = c(\"2ae019\",\"71577a\"))\nnrow(sub_id$linelist)## [1] 13\nsub_cs <- subset(epic, cs_min = 10)\nnrow(sub_cs$linelist)## [1] 271"},{"path":"transmission-chains.html","id":"acceso-a-los-ids","chapter":"37 Cadenas de transmisión","heading":"Acceso a los IDs","text":"La función get_id() recupera información sobre los ID de los casos en el conjunto de datos, y puede parametrizarse como sigue:linelist: IDs en los datos del listadocontacts: IDs en el conjunto de datos de los contactos (“desde” y “hasta” combinados): IDs en la columna “” de los datos del contactoto los identificadores de la columna “” de los datos de los contactosall: Las identificaciones que aparecen en cualquier parte de cualquiera de los conjuntos de datoscommon: identificaciones que aparecen tanto en el conjunto de datos de contactos como en linelistPor ejemplo, ¿cuáles son las diez primeras identificaciones de los datos de contactos?¿Cuántas identificaciones se encuentran tanto en linelist como en los contactos?","code":"\ncontacts_ids <- get_id(epic, \"contacts\")\nhead(contacts_ids, n = 10)##  [1] \"f547d6\" \"f90f5f\" \"11f8ea\" \"aec8ec\" \"893f25\" \"133ee7\" \"996f3a\" \"37a6f6\" \"9f6884\" \"4802b1\"\nlength(get_id(epic, \"common\"))## [1] 4352"},{"path":"transmission-chains.html","id":"visualization","chapter":"37 Cadenas de transmisión","heading":"37.4 Visualización","text":"","code":""},{"path":"transmission-chains.html","id":"representación-básica","chapter":"37 Cadenas de transmisión","heading":"Representación básica","text":"Todas las visualizaciones de los objetos epicontacts son manejadas por la función plot. En primer lugar, filtraremos el objeto epicontacts para incluir solo los casos con fechas de inicio en junio de 2014 utilizando la función de subconjunto, y solo incluiremos los contactos vinculados esos casos utilizando la función thin.continuación, podemos crear el gráfico básico e interactivo de la siguiente manera:Puedes mover los nodos arrastrándolos, pasar por encima de ellos para obtener más información y clicar sobre ellos para resaltar los casos conectados.Hay un gran número de argumentos para modificar este gráfico. Aquí cubriremos los principales, pero consulta la documentación través de ?vis_epicontacts (la función la que se llama cuando se utiliza plot en un objeto epicontacts) para obtener una descripción completa de los argumentos de la función.","code":"\n## subset epicontacts object\nsub <- epic %>%\n  subset(\n    node_attribute = list(date_onset = c(as.Date(c(\"2014-06-30\", \"2014-06-01\"))))\n  ) %>%\n thin(\"contacts\")\n## plot epicontacts object\nplot(\n  sub,\n  width = 700,\n  height = 700\n)"},{"path":"transmission-chains.html","id":"visualizar-los-atributos-de-los-nodos","chapter":"37 Cadenas de transmisión","heading":"Visualizar los atributos de los nodos","text":"El color, la forma y el tamaño del nodo se pueden asignar una columna determinada en linelist utilizando los argumentos node_color, node_shape y node_size. Esto es similar la sintaxis aes que puede reconocer ggplot2.Los colores, formas y tamaños específicos de los nodos pueden especificarse de la siguiente manera:Colores través del argumento col_pal, ya sea proporcionando una lista de nombres para la especificación manual de cada color como se hace continuación, o proporcionando una función de paleta de colores como colorRampPalette(c(\"black\", \"red\", \"orange\")), que proporcionaría un gradiente de colores entre los especificados.Colores través del argumento col_pal, ya sea proporcionando una lista de nombres para la especificación manual de cada color como se hace continuación, o proporcionando una función de paleta de colores como colorRampPalette(c(\"black\", \"red\", \"orange\")), que proporcionaría un gradiente de colores entre los especificados.Formas pasando una lista con nombre al argumento shapes, especificando una forma para cada elemento único en la columna del listado especificada por el argumento node_shape. Ver en codeawesome las formas disponibles.Formas pasando una lista con nombre al argumento shapes, especificando una forma para cada elemento único en la columna del listado especificada por el argumento node_shape. Ver en codeawesome las formas disponibles.Tamaño pasando un rango de tamaño de los nodos al argumento size_range.Tamaño pasando un rango de tamaño de los nodos al argumento size_range.Aquí un ejemplo, donde el color representa el resultado, la forma el género y el tamaño la edad:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"visualizar-los-atributos-de-los-bordes","chapter":"37 Cadenas de transmisión","heading":"Visualizar los atributos de los bordes","text":"El color, tamaño y el tipo de línea de los bordes pueden asignarse una columna determinada del dataframe de los contactos utilizando los argumentos edge_color, edge_width y edge_linetype. Los colores y tamaño específicos de los bordes se pueden especificar como sigue:Colores través del argumento edge_col_pal, de la misma manera que se utiliza para col_pal.Colores través del argumento edge_col_pal, de la misma manera que se utiliza para col_pal.Tamaño pasando un rango de tamaño de los nodos al argumento width_range.Tamaño pasando un rango de tamaño de los nodos al argumento width_range.Aquí un ejemplo:","code":"\nplot(\n  sub, \n  node_color = \"outcome\",\n  node_shape = \"gender\",\n  node_size = 'age',\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  shapes = c(f = \"female\", m = \"male\"),\n  size_range = c(40, 60),\n  edge_color = 'location',\n  edge_linetype = 'location',\n  edge_width = 'duration',\n  edge_col_pal = c(Community = \"orange\", Nosocomial = \"purple\"),\n  width_range = c(1, 3),\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"eje-temporal","chapter":"37 Cadenas de transmisión","heading":"Eje temporal","text":"También podemos visualizar la red lo largo de un eje temporal asignando el argumento x_axis una columna del listado. En el ejemplo siguiente, el eje-x representa la fecha de inicio de los síntomas. También hemos especificado el argumento arrow_size para asegurarnos que las flechas son demasiado grandes, y hemos establecido label = FALSE para que la figura esté menos recargada.Hay un gran número de argumentos adicionales para especificar aún más cómo se visualiza esta red lo largo de un eje temporal, que puede comprobar través de ?vis_temporal_interactive (la función que se llama cuando se utiliza plot en un objeto epicontacts con el x_axis especificado). continuación veremos algunos.","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"especificar-la-forma-del-árbol-de-transmisión","chapter":"37 Cadenas de transmisión","heading":"Especificar la forma del árbol de transmisión","text":"Hay dos formas principales que puede adoptar el árbol de transmisión, especificadas mediante el argumento network_shape. La primera es una forma ramificada, como se muestra arriba, en la que un borde recto conecta dos nodos cualesquiera. Esta es la representación más intuitiva, pero puede dar lugar la superposición de aristas en una red densamente conectada. La segunda forma es rectangle, que produce un árbol parecido una filogenia. Por ejemplo:cada nodo del caso se le puede asignar una posición vertical única mediante el argumento position_dodge. La posición de los casos conectados (es decir, sin contactos reportados) se especifica utilizando el argumento unlinked_pos.La posición del nodo padre respecto los nodos hijos puede especificarse mediante el argumento parent_pos. La opción por defecto es colocar el nodo padre en el centro, sin embargo puede colocarse en la parte inferior (parent_pos = 'bottom') o en la parte superior (parent_pos = 'top').","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  position_dodge = TRUE,\n  unlinked_pos = \"bottom\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n)"},{"path":"transmission-chains.html","id":"cómo-guardar-gráficos-y-valores","chapter":"37 Cadenas de transmisión","heading":"Cómo guardar gráficos y valores","text":"Puedes guardar un gráfico como un archivo html interactivo y autónomo con la función visSave del paquete VisNetwork:Guardar estas salidas de red como una imagen es desafortunadamente menos fácil y requiere que guardes el archivo como un html y luego tomes una captura de pantalla de este archivo usando el paquete webshot. En el código siguiente, estamos convirtiendo el archivo html guardado anteriormente en un PNG:","code":"\nplot(\n  sub,\n  x_axis = \"date_onset\",\n  network_shape = \"rectangle\",\n  node_color = \"outcome\",\n  col_pal = c(Death = \"firebrick\", Recover = \"green\"),\n  parent_pos = \"top\",\n  arrow_size = 0.5,\n  node_size = 13,\n  label = FALSE,\n  height = 700,\n  width = 700\n) %>%\n  visNetwork::visSave(\"network.html\")\nwebshot(url = \"network.html\", file = \"network.png\")"},{"path":"transmission-chains.html","id":"líneas-de-tiempo","chapter":"37 Cadenas de transmisión","heading":"Líneas de tiempo","text":"También se pueden incluir líneas de tiempo en la red, que se representan en el eje de abscisas de cada caso. Esto puede servir para visualizar la ubicación de los casos, por ejemplo, o el tiempo hasta el resultado. Para generar una línea de tiempo, tenemos que crear un data.frame de al menos tres columnas que indiquen el ID del caso, la fecha de inicio del “evento” y la fecha de finalización del “evento”. También se puede añadir cualquier número de otras columnas que luego se pueden asignar las propiedades de los nodos y aristas de la línea de tiempo. En el código siguiente, generamos una línea de tiempo que va desde la fecha de inicio de los síntomas hasta la fecha del desenlace, y mantenemos las variables de desenlace y hospital que utilizamos para definir la forma y el color de los nodos. Ten en cuenta que puede tener más de una fila/evento de la línea de tiempo por caso, por ejemplo si un caso es transferido entre varios hospitales.continuación, pasamos el elemento de la línea de tiempo al argumento timeline. Podemos mapear los atributos de la línea de tiempo los colores, formas y tamaños de los nodos de la línea de tiempo de la misma manera definida en las secciones anteriores, excepto que tenemos dos nodos: el nodo de inicio y el nodo final de cada línea de tiempo, que tienen argumentos separados. Por ejemplo, tl_start_node_color define qué columna de la línea de tiempo se asigna al color del nodo inicial, mientras que tl_end_node_shape define qué columna de la línea de tiempo se asigna la forma del nodo final. También podemos asignar el color, la anchura, el tipo de línea y las etiquetas al borde de la línea de tiempo mediante los argumentos tl_edge_.Consulta ?vis_temporal_interactive (la función la que se llama cuando se traza un objeto epicontacto) para obtener documentación detallada sobre los argumentos. Cada argumento está anotado también en el código de abajo:","code":"\n## generate timeline\ntimeline <- linelist %>%\n  transmute(\n    id = case_id,\n    start = date_onset,\n    end = date_outcome,\n    outcome = outcome,\n    hospital = hospital\n  )\n## define shapes\nshapes <- c(\n  f = \"female\",\n  m = \"male\",\n  Death = \"user-times\",\n  Recover = \"heartbeat\",\n  \"NA\" = \"question-circle\"\n)\n\n## define colours\ncolours <- c(\n  Death = \"firebrick\",\n  Recover = \"green\",\n  \"NA\" = \"grey\"\n)\n\n## make plot\nplot(\n  sub,\n  ## max x coordinate to date of onset\n  x_axis = \"date_onset\",\n  ## use rectangular network shape\n  network_shape = \"rectangle\",\n  ## mape case node shapes to gender column\n  node_shape = \"gender\",\n  ## we don't want to map node colour to any columns - this is important as the\n  ## default value is to map to node id, which will mess up the colour scheme\n  node_color = NULL,\n  ## set case node size to 30 (as this is not a character, node_size is not\n  ## mapped to a column but instead interpreted as the actual node size)\n  node_size = 30,\n  ## set transmission link width to 4 (as this is not a character, edge_width is\n  ## not mapped to a column but instead interpreted as the actual edge width)\n  edge_width = 4,\n  ## provide the timeline object\n  timeline = timeline,\n  ## map the shape of the end node to the outcome column in the timeline object\n  tl_end_node_shape = \"outcome\",\n  ## set the size of the end node to 15 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## node size)\n  tl_end_node_size = 15,\n  ## map the colour of the timeline edge to the hospital column\n  tl_edge_color = \"hospital\",\n  ## set the width of the timeline edge to 2 (as this is not a character, this\n  ## argument is not mapped to a column but instead interpreted as the actual\n  ## edge width)\n  tl_edge_width = 2,\n  ## map edge labels to the hospital variable\n  tl_edge_label = \"hospital\",\n  ## specify the shape for everyone node attribute (defined above)\n  shapes = shapes,\n  ## specify the colour palette (defined above)\n  col_pal = colours,\n  ## set the size of the arrow to 0.5\n  arrow_size = 0.5,\n  ## use two columns in the legend\n  legend_ncol = 2,\n  ## set font size\n  font_size = 15,\n  ## define formatting for dates\n  date_labels = c(\"%d %b %Y\"),\n  ## don't plot the ID labels below nodes\n  label = FALSE,\n  ## specify height\n  height = 1000,\n  ## specify width\n  width = 1200,\n  ## ensure each case node has a unique y-coordinate - this is very important\n  ## when using timelines, otherwise you will have overlapping timelines from\n  ## different cases\n  position_dodge = TRUE\n)## Warning in assert_timeline(timeline, x, x_axis): 5865 timeline row(s) removed as ID not found in\n## linelist or start/end date is NA"},{"path":"transmission-chains.html","id":"analysis","chapter":"37 Cadenas de transmisión","heading":"37.5 Análisis","text":"","code":""},{"path":"transmission-chains.html","id":"resumiendo","chapter":"37 Cadenas de transmisión","heading":"Resumiendo","text":"Podemos obtener una visión general de algunas de las propiedades de la red utilizando la función summary.Por ejemplo, podemos ver que sólo el 57% de los contactos tienen ambos casos en linelist; esto significa que tenemos datos del listado sobre un número significativo de casos involucrados en estas cadenas de transmisión.","code":"\n## summarise epicontacts object\nsummary(epic)## \n## /// Overview //\n##   // number of unique IDs in linelist: 5888\n##   // number of unique IDs in contacts: 5511\n##   // number of unique IDs in both: 4352\n##   // number of contacts: 3800\n##   // contacts with both cases in linelist: 56.868 %\n## \n## /// Degrees of the network //\n##   // in-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  1.0000  0.5392  1.0000  1.0000 \n## \n##   // out-degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##  0.0000  0.0000  0.0000  0.5392  1.0000  6.0000 \n## \n##   // in and out degree summary:\n##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n##   0.000   1.000   1.000   1.078   1.000   7.000 \n## \n## /// Attributes //\n##   // attributes in linelist:\n##  generation date_infection date_onset date_hospitalisation date_outcome outcome gender age age_unit age_years age_cat age_cat5 hospital lon lat infector source wt_kg ht_cm ct_blood fever chills cough aches vomit temp time_admission bmi days_onset_hosp\n## \n##   // attributes in contacts:\n##  location duration"},{"path":"transmission-chains.html","id":"características-de-los-pares","chapter":"37 Cadenas de transmisión","heading":"Características de los pares","text":"La función get_pairwise() permite procesar la(s) variable(s) del listado según cada par de los datos de contactos. En el siguiente ejemplo, la fecha de inicio de la enfermedad se extrae del listado para calcular la diferencia entre la fecha de inicio de la enfermedad para cada par. El valor que se obtiene de esta comparación representa el intervalo de serie (si).La función get_pairwise() interpretará el tipo de la columna que se utiliza para la comparación, y ajustará su método de comparación de los valores en consecuencia. Para los números y las fechas (como en el ejemplo de si), la función restará los valores. Cuando se aplica columnas que son caracteres o categóricas, get_pairwise() pegará los valores. Dado que la función también permite un procesamiento arbitrario (véase el argumento “f”), estas combinaciones discretas pueden ser fácilmente tabuladas y analizadas.En este caso, se observa una asociación significativa entre los vínculos de transmisión y el género.","code":"\nsi <- get_pairwise(epic, \"date_onset\")   \nsummary(si)##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n##    0.00    5.00    9.00   11.01   15.00   99.00    1820\ntibble(si = si) %>%\n  ggplot(aes(si)) +\n  geom_histogram() +\n  labs(\n    x = \"Serial interval\",\n    y = \"Frequency\"\n  )## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.## Warning: Removed 1820 rows containing non-finite values (`stat_bin()`).\nhead(get_pairwise(epic, \"gender\"), n = 10)##  [1] \"f -> m\" NA       \"m -> m\" NA       \"m -> f\" \"f -> f\" NA       \"f -> m\" NA       \"m -> f\"\nget_pairwise(epic, \"gender\", f = table)##            values.to\n## values.from   f   m\n##           f 464 516\n##           m 510 468\nfisher.test(get_pairwise(epic, \"gender\", f = table))## \n##  Fisher's Exact Test for Count Data\n## \n## data:  get_pairwise(epic, \"gender\", f = table)\n## p-value = 0.03758\n## alternative hypothesis: true odds ratio is not equal to 1\n## 95 percent confidence interval:\n##  0.6882761 0.9892811\n## sample estimates:\n## odds ratio \n##  0.8252575"},{"path":"transmission-chains.html","id":"identificación-de-clusters","chapter":"37 Cadenas de transmisión","heading":"Identificación de clusters","text":"La función get_clusters() puede utilizarse para identificar componentes conectados en un objeto epicontacts. En primer lugar, la utilizamos para recuperar un data.frame que contenga la información de los clusters:Veamos los clusters más grandes. Para ello, añadimos la información de los clústers al objeto epicontacts y luego lo subconjuntamos para mantener sólo los clústers más grandes:","code":"\nclust <- get_clusters(epic, output = \"data.frame\")\ntable(clust$cluster_size)## \n##    1    2    3    4    5    6    7    8    9   10   11   12   13   14 \n## 1536 1680 1182  784  545  342  308  208  171  100   99   24   26   42\nggplot(clust, aes(cluster_size)) +\n  geom_bar() +\n  labs(\n    x = \"Cluster size\",\n    y = \"Frequency\"\n  )\nepic <- get_clusters(epic)\nmax_size <- max(epic$linelist$cluster_size)\nplot(subset(epic, cs = max_size))"},{"path":"transmission-chains.html","id":"cálculo-de-grados","chapter":"37 Cadenas de transmisión","heading":"Cálculo de grados","text":"El grado de un nodo corresponde su número de aristas o conexiones con otros nodos. get_degree() proporciona un método sencillo para calcular este valor para las redes de epicontacts. Un grado alto en este contexto indica un individuo que estuvo en contacto con muchos otros. El argumento type indica que queremos contar tanto el grado de entrada como el de salida, el argumento only_linelist indica que sólo queremos calcular el grado para los casos del listado.¿Qué personas son las que tienen más de 10 contactos?¿Cuál es el número medio de contactos?","code":"\ndeg_both <- get_degree(epic, type = \"both\", only_linelist = TRUE)\nhead(sort(deg_both, decreasing = TRUE), 10)## 916d0a 858426 6833d7 f093ea 11f8ea 3a4372 38fc71 c8c4d5 a127a7 02d8fd \n##      7      6      6      6      5      5      5      5      5      5\nmean(deg_both)## [1] 1.078473"},{"path":"transmission-chains.html","id":"resources-30","chapter":"37 Cadenas de transmisión","heading":"37.6 Recursos","text":"La página de epicontacts ofrece una visión general de las funciones del paquete e incluye algunas viñetas más detalladas.La página de github de epicontacts puede utilizarse para plantear problemas y solicitar funciones.","code":""},{"path":"phylogenetic-trees-1.html","id":"phylogenetic-trees-1","chapter":"38 Árboles filogenéticos","heading":"38 Árboles filogenéticos","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"overview-8","chapter":"38 Árboles filogenéticos","heading":"38.1 Resumen","text":"Los árboles filogenéticos se utilizan para visualizar y describir el parentesco y la evolución de los organismos partir de la secuencia de su código genético.Pueden construirse partir de secuencias genéticas utilizando métodos basados en la distancia (como el método de unión de vecinos) o métodos basados en los caracteres (como el método de máxima verosimilitud y el método Bayesiano Markov Chain Monte Carlo). La secuenciación de nueva generación (NGS, por sus siglas en inglés) se ha vuelto más económica y se está utilizando cada vez más en el área de salud pública para describir los patógenos causantes de enfermedades infecciosas. Los dispositivos de secuenciación portátil reducen el tiempo de respuesta y prometen facilitar los datos en tiempo real y así apoyar la investigación de brotes. Los datos de NGS se pueden utilizar para identificar el origen o la fuente de una cepa de un brote y su propagación, así como para determinar la presencia de genes de resistencia antimicrobiana. Para visualizar el parentesco genético entre muestras biológicas se construye un árbol filogenético.Aquí aprenderemos utilizar el paquete ggtree, que permite la visualización combinada de árboles filogenéticos con datos de muestra adicionales en forma de dataframe. Esto nos permitirá observar patrones y comprender mejor la dinámica de los brotes.","code":""},{"path":"phylogenetic-trees-1.html","id":"preparation-31","chapter":"38 Árboles filogenéticos","heading":"38.2 Preparación","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"cargar-paquetes-27","chapter":"38 Árboles filogenéticos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios. En este manual destacamos ‘p_load()’ de pacman, que instala el paquete si es necesario y lo carga para su uso. También puede cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,             # importa/exportar\n  here,            # rutas de fichero relativas\n  tidyverse,       # manejo general de datos y visualización\n  ape,             # para importar y exportar archivos filogenéticos\n  ggtree,          # para visualizar archivos filogenéticos\n  treeio,          # para visualizar archivos filogenéticos\n  ggnewscale)      # para añadir capas adicionales de esquemas de color"},{"path":"phylogenetic-trees-1.html","id":"importar-datos-22","chapter":"38 Árboles filogenéticos","heading":"Importar datos","text":"Los datos de esta página pueden descargarse con las instrucciones de la página Descargando el manual y los datos.Hay varios formatos diferentes en los que se puede almacenar un árbol filogenético (por ejemplo, Newick, NEXUS, Phylip). Uno de los más comunes es el formato de archivo Newick (.nwk), que es el estándar para representar árboles en forma legible por el ordenador. Esto significa que un árbol completo puede expresarse en un formato de cadena como “((t2:0,04,t1:0,34):0,89,(t5:0,37,(t4:0,03,t3:0,67):0,9):0,59);”, enumerando todos los nodos y puntas, y su relación (longitud de rama) entre sí.Nota: Es importante entender que el archivo del árbol filogenético en sí mismo contiene datos de secuenciación, sino que es simplemente el resultado de las distancias genéticas entre las secuencias. Por lo tanto, podemos extraer datos de secuenciación de un archivo de árbol.En primer lugar, utilizamos la función read.tree() del paquete ape para importar un archivo de árbol filogenético de Newick en formato .txt, y lo almacenamos en un objeto tipo lista llamado “phylo”. Si es necesario, utiliza la función () del paquete para especificar la ruta relativa del archivo.Nota: En este caso el árbol newick se guarda como un archivo .txt para facilitar su manejo y descarga desde Github.Inspeccionamos nuestro objeto árbol (‘tree’) y vemos que contiene 299 puntas (o muestras) y 236 nodos.En segundo lugar, importamos una tabla almacenada en un archivo .csv con información adicional para cada muestra secuenciada, como el sexo, el país de origen y los atributos de resistencia antimicrobiana, utilizando la función import() del paquete rio:continuación se muestran las primeras 50 filas de los datos:","code":"\ntree <- ape::read.tree(\"Shigella_tree.txt\")\ntree## \n## Phylogenetic tree with 299 tips and 236 internal nodes.\n## \n## Tip labels:\n##   SRR5006072, SRR4192106, S18BD07865, S18BD00489, S17BD08906, S17BD05939, ...\n## Node labels:\n##   17, 29, 100, 67, 100, 100, ...\n## \n## Rooted; includes branch lengths.\nsample_data <- import(\"sample_data_Shigella_tree.csv\")"},{"path":"phylogenetic-trees-1.html","id":"limpiar-e-inspeccionar","chapter":"38 Árboles filogenéticos","heading":"Limpiar e inspeccionar","text":"Limpiamos e inspeccionamos nuestros datos: Para asignar los datos de muestra correctos al árbol filogenético, los valores de la columna Sample_ID en el dataframe sample_data deben coincidir con los valores de tip.labels en el archivo tree:Comprobamos el formato de los tip.labels en el archivo de árbol mirando las 6 primeras entradas usando head() de R base.También nos aseguramos de que la primera columna de nuestro dataframe sample_data sea Sample_ID. Miramos los nombres de las columnas de nuestro dataframe utilizando colnames() de R base.Miramos los Sample_IDs en el dataframe para asegurarnos de que el formato es el mismo que en el tip.label (por ejemplo, las letras son todas mayúsculas, hay barras bajas adicionales _ entre las letras y los números, etc.)También podemos comparar si todas las muestras están presentes en el archivo tree y viceversa, generando un vector lógico de TRUE o FALSE donde coinciden o . Estos se imprimen aquí, para simplificar.Podemos utilizar estos vectores para mostrar cualquier ID que esté en el árbol (hay ninguno).Al inspeccionar podemos ver que el formato de Sample_ID en el dataframe corresponde al formato de los nombres de las muestras en el tip.labels. es necesario que estén clasificados en el mismo orden para que coincidan.Estamos listos para empezar!","code":"\nhead(tree$tip.label) ## [1] \"SRR5006072\" \"SRR4192106\" \"S18BD07865\" \"S18BD00489\" \"S17BD08906\" \"S17BD05939\"\ncolnames(sample_data)   ##  [1] \"Sample_ID\"                  \"serotype\"                   \"Country\"                   \n##  [4] \"Continent\"                  \"Travel_history\"             \"Year\"                      \n##  [7] \"Belgium\"                    \"Source\"                     \"Gender\"                    \n## [10] \"gyrA_mutations\"             \"macrolide_resistance_genes\" \"MIC_AZM\"                   \n## [13] \"MIC_CIP\"\nhead(sample_data$Sample_ID) # volvemos a inspeccionar sólo los 6 primeros usando head()## [1] \"S17BD05944\" \"S15BD07413\" \"S18BD07247\" \"S19BD07384\" \"S18BD07338\" \"S18BD02657\"\nsample_data$Sample_ID %in% tree$tip.label\n\ntree$tip.label %in% sample_data$Sample_ID\nsample_data$Sample_ID[!tree$tip.label %in% sample_data$Sample_ID]## character(0)"},{"path":"phylogenetic-trees-1.html","id":"simple-tree-visualization","chapter":"38 Árboles filogenéticos","heading":"38.3 Visualización simple de un árbol","text":"","code":""},{"path":"phylogenetic-trees-1.html","id":"diferentes-configuraciones-de-los-árboles","chapter":"38 Árboles filogenéticos","heading":"Diferentes configuraciones de los árboles","text":"ggtree ofrece varios formatos de presentación y algunos pueden ser más adecuados que otros dependiendo del propósito específico. continuación se muestran algunos ejemplos. Para otras opciones, consulta este libro en línea.continuación, vemos algunos ejemplos de configuración de árboles:","code":"\nggtree(tree)                                            # árbol lineal simple\nggtree(tree,  branch.length = \"none\")                   # árbol lineal simple con todas las puntas alineadas\nggtree(tree, layout=\"circular\")                         # árbol circular simple\nggtree(tree, layout=\"circular\", branch.length = \"none\") # árbol circular simple con todas las puntas alineadas"},{"path":"phylogenetic-trees-1.html","id":"árbol-simple-con-datos-de-muestra","chapter":"38 Árboles filogenéticos","heading":"Árbol simple con datos de muestra","text":"El operador %<+% se utiliza para conectar el dataframe sample_data con el archivo tree. La anotación más sencilla de un árbol es el agregado de los nombres de las muestras en las puntas, así como la coloración de las puntas y, si se desea, de las ramas:Este es un ejemplo de árbol circular:Podes exportar el gráfico de árbol con ggsave() como lo harías con cualquier otro objeto ggplot. Escrito de esta manera, ggsave() guarda la última imagen producida en la ruta de archivo que especifiques. Recordá que podes utilizar () y rutas de archivo relativas para guardar fácilmente en subcarpetas, etc.","code":"\nggtree(tree, layout = \"circular\", branch.length = 'none') %<+% sample_data + # %<+% agrega un dataframe con datos de muestra al árbol\n  aes(color = I(Belgium))+                       # colorea las ramas de acuerdo con una variable en tu dataframe\n  scale_color_manual(\n    name = \"Sample Origin\",                      # nombre de tu esquema de color (aparecerá en la leyenda así) \n    breaks = c(\"Yes\", \"No\"),                     # las diferentes opciones en tu variable\n    labels = c(\"NRCSS Belgium\", \"Other\"),        # cómo quieres que se nombren las diferentes opciones en tu leyenda, permite formatearlas\n    values = c(\"blue\", \"black\"),                 # el color que deseas asignar a la variable  \n    na.value = \"black\") +                        # colorea los valores no disponibles (NA) en negro \n  new_scale_color()+                             # permite añadir un esquema de color adicional para otra variable\n    geom_tippoint(\n      mapping = aes(color = Continent),          # color de la punta por continente Puedes cambiar la forma añadiendo \"shape = \"\n      size = 1.5)+                               # define el tamaño de la punta\n  scale_color_brewer(\n    name = \"Continent\",                    # nombre de tu esquema de color (se mostrará en la leyenda así)\n    palette = \"Set1\",                      # elegimos un conjunto de colores que vienen con el paquete de Brewer\n    na.value = \"grey\") +                    # para los valores NA elegimos el color gris\n  geom_tiplab(                             # añade el nombre de la muestra en la punta de su rama \n    color = 'black',                       # añade tantas líneas de texto como desees con + , pero es posible que tengas que ajustar el valor de desplazamiento para colocarlas una al lado de la otra\n    offset = 1,\n    size = 1,\n    geom = \"text\",\n    #align = TRUE\n    )+    \n  ggtitle(\"Phylogenetic tree of Shigella sonnei\")+       # Nombre del árbol\n  theme(\n    axis.title.x = element_blank(), # elimina el título del eje x\n    axis.title.y = element_blank(), # elimina el título del eje y\n    legend.title = element_text(    # define el tamaño y el formato de la fuente del título de la leyenda\n      face = \"bold\",\n      size = 12),   \n    legend.text=element_text(       # define el tamaño de letra y tipografía de la leyenda\n      face = \"bold\",\n      size = 10),  \n    plot.title = element_text(      # define el tamaño de letra y tipografía del título del gráfico\n      size = 12,\n      face = \"bold\"),  \n    legend.position = \"bottom\",     # define la posición de la leyenda\n    legend.box = \"vertical\",        # define la posición de la leyenda\n    legend.margin = margin())   \nggsave(\"example_tree_circular_1.png\", width = 12, height = 14)"},{"path":"phylogenetic-trees-1.html","id":"tree-manipulation","chapter":"38 Árboles filogenéticos","heading":"38.4 Manipulación de árboles","text":"veces puede tener un árbol filogenético muy grande y sólo le interesa una parte del árbol. Por ejemplo, si ha creado un árbol que incluye muestras históricas o internacionales para obtener una gran visión general sobre como pueden encajar tus datos en esos contextos. Pero luego, para ver más de cerca alguna parte tus datos, tendrás que inspeccionar sólo esa parte del árbol.Dado que el archivo del árbol filogenético es el resultado del análisis de los datos de secuenciación, podemos manipular el orden de los nodos y las ramas en el propio archivo. Estos ya han sido determinados en análisis anteriores partir de los datos NGS en bruto. Sin embargo, podemos ampliar partes, ocultar partes e incluso subdividir partes del árbol.","code":""},{"path":"phylogenetic-trees-1.html","id":"ampliar-el-zoom","chapter":"38 Árboles filogenéticos","heading":"Ampliar el zoom","text":"Si en vez de “cortar” tu árbol, prefieres inspeccionar sólo una parte más de cerca, puedes hacer zoom para ver una parte específica.En primer lugar, trazamos todo el árbol en formato lineal y añadimos etiquetas numéricas cada nodo del árbol.Para hacer zoom en una rama en particular (la que sobresale la derecha), utilizá viewClade() en el objeto ggtree p y proporcioná el número de nodo para verlo más de cerca:","code":"\np <- ggtree(tree,) %<+% sample_data +\n  geom_tiplab(size = 1.5) +                # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n  geom_text2(\n    mapping = aes(subset = !isTip,\n                  label = node),\n    size = 5,\n    color = \"darkred\",\n    hjust = 1,\n    vjust = 1)                            # etiqueta todos los nodos del árbol\n\np  # imprime en pantalla\nviewClade(p, node = 452)"},{"path":"phylogenetic-trees-1.html","id":"ramas-colapsadas","chapter":"38 Árboles filogenéticos","heading":"Ramas colapsadas","text":"Sin embargo, tal vez queramos ignorar esta rama, entonces podemos colapsarla en ese mismo nodo (nodo 452) utilizando collapse(). Definimos este árbol como p_collapsed.Como aclaración, cuando imprimimos p_collapsed, añadimos un geom_point2() (un diamante azul) en el nodo de la rama colapsada.","code":"\np_collapsed <- collapse(p, node = 452)\np_collapsed\np_collapsed + \ngeom_point2(aes(subset = (node == 452)),  # asignamos un símbolo al nodo colapsado\n            size = 5,                     # definimos el tamaño del símbolo\n            shape = 23,                   # definimos la forma del símbolo\n            fill = \"steelblue\")           # definimos el color del símbolo"},{"path":"phylogenetic-trees-1.html","id":"subconjunto-de-un-árbol","chapter":"38 Árboles filogenéticos","heading":"Subconjunto de un árbol","text":"Si queremos hacer un cambio más permanente y crear un nuevo árbol reducido con el que trabajar, podemos subconjuntar parte de él con tree_subset(). Luego podemos guardarlo como un nuevo archivo de árbol newick o archivo .txt.En primer lugar, inspeccionamos los nodos del árbol y las etiquetas de las puntas para decidir qué subconjunto se va seleccionar.Ahora, digamos que hemos decidido crear un un subconjunto del árbol (o sub-árbol) con solo el nodo 528 (manteniendo las puntas dentro de esta rama después del nodo 528) y lo guardamos como un nuevo objeto sub_tree1:Veamos el subconjunto del árbol 1:También podes hacer un subconjunto basado en una muestra en particular, especificando cuántos nodos “hacia atrás” queres incluir. Vamos subconjuntar la misma parte del árbol basándonos en una muestra, en este caso S17BD07692, retrocediendo 9 nodos y lo guardamos como un nuevo objeto sub_tree2:Veamos el subconjunto del árbol 2:También podes guardar tu nuevo sub-árbol como un archivo Newick o incluso un archivo de texto utilizando la función write.tree() del paquete ape:","code":"\nggtree(\n  tree,\n  branch.length = 'none',\n  layout = 'circular') %<+% sample_data +               # añade los datos de la muestra usando el operador %<+%\n  geom_tiplab(size = 1)+                                # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n  geom_text2(\n    mapping = aes(subset = !isTip, label = node),\n    size = 3,\n    color = \"darkred\") +                                # etiqueta todos los nodos del árbol\n theme(\n   legend.position = \"none\",                            # elimina la leyenda\n   axis.title.x = element_blank(),\n   axis.title.y = element_blank(),\n   plot.title = element_text(size = 12, face=\"bold\"))\nsub_tree1 <- tree_subset(\n  tree,\n  node = 528)                                            #Subconjuntamos el árbol en el nodo 528\nggtree(sub_tree1) +\n  geom_tiplab(size = 3) +\n  ggtitle(\"Subset tree 1\")\nsub_tree2 <- tree_subset(\n  tree,\n  \"S17BD07692\",\n  levels_back = 9) # levels back define cuántos nodos hacia atrás quieres ir desde la punta de la muestra\nggtree(sub_tree2) +\n  geom_tiplab(size =3)  +\n  ggtitle(\"Subset tree 2\")\n# para guardar en formato .nwk \nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.nwk')\n\n# para guardar en formato  .txt\nape::write.tree(sub_tree2, file='data/phylo/Shigella_subtree_2.txt')"},{"path":"phylogenetic-trees-1.html","id":"rotación-de-nodos-en-un-árbol","chapter":"38 Árboles filogenéticos","heading":"Rotación de nodos en un árbol","text":"Como ya hemos dicho, podemos cambiar el orden de las puntas o de los nodos en el árbol, ya que éste se basa en su parentesco genético y está sujeto manipulación visual. Pero podemos rotar las ramas alrededor de los nodos si eso facilita la visualización.En primer lugar, trazamos nuestro nuevo sub-árbol 2 con las etiquetas de los nodos para elegir el nodo que queremos manipular y lo almacenamos en un objeto de ggtree plot p.Luego podemos manipular los nodos aplicando ggtree::rotate() o ggtree::flip(): Nota: para ilustrar qué nodos estamos manipulando aplicamos primero la función geom_hilight() de ggtree para resaltar las muestras en los nodos que nos interesan y almacenamos ese objeto gráfico de ggtree en un nuevo objeto p1.Ahora podemos rotar el nodo 37 en el objeto p1 para que las muestras del nodo 38 se muevan hacia abajo. Almacenamos el árbol rotado en un nuevo objeto p2O podemos usar el comando flip para rotar el nodo 36 en el objeto p1 y mover el nodo 37 la parte superior y el nodo 39 la parte inferior. Almacenamos el árbol con nodos rotados como un nuevo objeto p3.","code":"\np <- ggtree(sub_tree2) +  \n  geom_tiplab(size = 4) +\n  geom_text2(aes(subset=!isTip, label=node), # etiqueta todos los nodos del árbol\n             size = 5,\n             color = \"darkred\", \n             hjust = 1, \n             vjust = 1) \np\np1 <- p + geom_hilight(  # resalta el nodo 39 en azul, \"extend =\" permite definir la longitud del bloque de color\n  node = 39,\n  fill = \"steelblue\",\n  extend = 0.0017) +  \ngeom_hilight(            # resalta el nodo 37 en amarillo\n  node = 37,\n  fill = \"yellow\",\n  extend = 0.0017) +               \nggtitle(\"Original tree\")\n\n\np1 # imprime en pantalla\np2 <- ggtree::rotate(p1, 37) + \n      ggtitle(\"Rotated Node 37\")\n\n\np2   # imprime en pantalla\np3 <- ggtree::flip(p1, 39, 37) +\n      ggtitle(\"Rotated Node 36\")\n\n\np3   # imprime en pantalla"},{"path":"phylogenetic-trees-1.html","id":"ejemplo-de-sub-árbol-con-anotación-de-datos","chapter":"38 Árboles filogenéticos","heading":"Ejemplo de sub-árbol con anotación de datos","text":"Digamos que estamos investigando el grupo de casos con expansión clonal que se produjo en 2017 y 2018 representados en el nodo 39 de nuestro sub-árbol. Añadimos el año de aislamiento de la cepa, así como el historial de viajes y coloreamos por país para ver el origen de otras cepas estrechamente relacionadas genéticamente:Nuestra observación apunta un evento de importación de cepas procedentes de Asia, que luego circularon en Bélgica lo largo de los años y parecen haber causado el último brote.","code":"\nggtree(sub_tree2) %<+% sample_data +     # usamos el operador %<+% para enlazar con sample_data\n  geom_tiplab(                          # etiqueta las puntas de todas las ramas del árbol con el nombre de la muestra\n    size = 2.5,\n    offset = 0.001,\n    #align = TRUE\n    ) + \n  theme_tree2()+\n  xlim(0, 0.015)+                       # establece los límites del eje x de nuestro árbol\n  geom_tippoint(aes(color=Country),     # colorea la punta por continente\n                size = 1.5)+ \n  scale_color_brewer(\n    name = \"Country\", \n    palette = \"Set1\", \n    na.value = \"grey\")+\n  geom_tiplab(                         # añade el año de aislamiento como etiqueta de texto en las puntas\n    aes(label = Year),\n    color = 'blue',\n    offset = 0.0045,\n    size = 3,\n    linetype = \"blank\" ,\n    geom = \"text\",\n    #align = TRUE\n    )+ \n  geom_tiplab(                          # añade el historial de viajes como una etiqueta de texto en las puntas, en color rojo\n    aes(label = Travel_history),\n    color = 'red',\n    offset = 0.006,\n    size = 3,\n    linetype = \"blank\",\n    geom = \"text\",\n    #align = TRUE\n    )+ \n  ggtitle(\"Phylogenetic tree of Belgian S. sonnei strains with travel history\")+  # añade el título del árbol\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+                   # añade una etiqueta en el eje x\n \n  theme(\n    axis.title.x = element_text(size = 10),\n    axis.title.y = element_blank(),\n    legend.title = element_text(face = \"bold\", size = 12),\n    legend.text = element_text(face = \"bold\", size = 10),\n    plot.title = element_text(size = 12, face = \"bold\"))"},{"path":"phylogenetic-trees-1.html","id":"more-complex-trees-adding-heatmaps-of-sample-data","chapter":"38 Árboles filogenéticos","heading":"38.5 Árboles más complejos: añadir mapas térmicos de datos de muestra","text":"Podemos añadir información más compleja, como la presencia categórica de genes de resistencia antimicrobiana y valores numéricos de resistencia realmente medida contra agentes antimicrobianos en forma de mapa de calor utilizando la función ggtree::gheatmap().Primero necesitamos graficar nuestro árbol (puede ser lineal o circular) y almacenarlo en un nuevo objeto ggtree p: Utilizaremos el sub-árbol de la parte 3).En segundo lugar, preparamos nuestros datos. Para visualizar las diferentes variables con nuevos esquemas de color, realizamos un subconjunto de nuestro dataframe la variable deseada. Es importante añadir el Sample_ID como nombre de fila (rownames) de lo contrario los datos coinciden con los tip.labels del árbol.En nuestro ejemplo, queremos ver el género y las mutaciones que podrían conferir resistencia la ciprofloxacina, un importante antibiótico de primera línea utilizado para tratar las infecciones por Shigella.Creamos un dataframe para el género:Creamos un dataframe para las mutaciones en el gen gyrA, que confieren resistencia la ciprofloxacina:Creamos un dataframe para la concentración inhibitoria mínima (CIM) medida en laboratorio para la ciprofloxacina:Creamos un primer gráfico añadiendo un mapa de calor binario para el género al árbol filogenético y almacenándolo en un nuevo objeto de gráfico ggtree h1:continuación, añadimos información sobre las mutaciones en el gen gyrA, que confieren resistencia la ciprofloxacina:Nota: La presencia de mutaciones cromosómicas puntuales en los datos de secuenciación del genoma completo (WGS) se determinó previamente utilizando la herramienta PointFinder desarrollada por Zankari et al. (ver la sección de referencias adicionales)En primer lugar, asignamos un nuevo esquema de colores nuestro objeto gráfico h1 y lo almacenamos en un objeto llamado h2. Esto nos permite definir y cambiar los colores para nuestra segunda variable en el mapa de calor.continuación, añadimos la segunda capa del mapa de calor h2 y almacenamos los gráficos combinados en un nuevo objeto h3:Repetimos el proceso anterior, añadiendo primero una nueva capa de escala de colores nuestro objeto existente h3, y luego añadiendo los datos continuos sobre la concentración inhibitoria mínima (CIM) de ciprofloxacina para cada cepa al objeto resultante h4 para producir el objeto final h5:Podemos hacer el mismo ejercicio para un árbol lineal:Primero añadimos el género:continuación, añadimos las mutaciones de resistencia la ciprofloxacina después de añadir otra capa de colores representando los genes que confieren resistencia antimicrobiana:continuación, añadimos en forma de mapa de calor la concentración mínima inhibitoria determinada por el laboratorio (MIC):","code":"\np <- ggtree(sub_tree2, branch.length='none', layout='circular') %<+% sample_data +\n  geom_tiplab(size =3) + \n theme(\n   legend.position = \"none\",\n    axis.title.x = element_blank(),\n    axis.title.y = element_blank(),\n    plot.title = element_text(\n      size = 12,\n      face = \"bold\",\n      hjust = 0.5,\n      vjust = -15))\np\ngender <- data.frame(\"gender\" = sample_data[,c(\"Gender\")])\nrownames(gender) <- sample_data$Sample_ID\ncipR <- data.frame(\"cipR\" = sample_data[,c(\"gyrA_mutations\")])\nrownames(cipR) <- sample_data$Sample_ID\nMIC_Cip <- data.frame(\"mic_cip\" = sample_data[,c(\"MIC_CIP\")])\nrownames(MIC_Cip) <- sample_data$Sample_ID\nh1 <-  gheatmap(p, gender,                            # añadimos al árbol una capa de mapa de calor para el género del dataframe\n                offset = 10,                          # offset desplaza el mapa de calor a la derecha\n                width = 0.10,                         # width define el ancho de la columna del mapa de calor\n                color = NULL,                         # color define el borde de las columnas del mapa de calor\n         colnames = FALSE) +                          # oculta los nombres de las columnas del mapa de calor\n  scale_fill_manual(name = \"Gender\",                  # define el esquema de colores y la leyenda para el género\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill() \nh3 <- gheatmap(h2, cipR,         # añade la segunda capa del mapa de calor que describe las mutaciones de resistencia a la ciprofloxacina\n               offset = 12, \n               width = 0.10, \n               colnames = FALSE) +\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\")) +\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh3\n# Primero añadimos el nuevo esquema de colores:\nh4 <- h3 + new_scale_fill()\n\n# luego combinamos los dos en una nueva gráfica:\nh5 <- gheatmap(h4, MIC_Cip,  \n               offset = 14, \n               width = 0.10,\n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",  # aquí definimos un esquema de color de gradiente para la variable continua MIC\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0, 0.50, 1.00),\n                      na.value = \"white\") +\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5\np <- ggtree(sub_tree2) %<+% sample_data +\n  geom_tiplab(size = 3) + # etiqueta las puntas\n  theme_tree2()+\n  xlab(\"genetic distance (0.001 = 4 nucleotides difference)\")+\n  xlim(0, 0.015)+\n theme(legend.position = \"none\",\n      axis.title.y = element_blank(),\n      plot.title = element_text(size = 12, \n                                face = \"bold\",\n                                hjust = 0.5,\n                                vjust = -15))\np\nh1 <-  gheatmap(p, gender, \n                offset = 0.003,\n                width = 0.1, \n                color=\"black\", \n         colnames = FALSE)+\n  scale_fill_manual(name = \"Gender\",\n                    values = c(\"#00d1b1\", \"purple\"),\n                    breaks = c(\"Male\", \"Female\"),\n                    labels = c(\"Male\", \"Female\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh1\nh2 <- h1 + new_scale_fill()\nh3 <- gheatmap(h2, cipR,   \n               offset = 0.004, \n               width = 0.1,\n               color = \"black\",\n                colnames = FALSE)+\n  scale_fill_manual(name = \"Ciprofloxacin resistance \\n conferring mutation\",\n                    values = c(\"#fe9698\",\"#ea0c92\"),\n                    breaks = c( \"gyrA D87Y\", \"gyrA S83L\"),\n                    labels = c( \"gyrA d87y\", \"gyrA s83l\"))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 12),\n        legend.text = element_text(size = 10),\n        legend.box = \"vertical\", legend.margin = margin())+\n  guides(fill = guide_legend(nrow = 2,byrow = TRUE))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\n h3\nh4 <- h3 + new_scale_fill()\nh5 <- gheatmap(h4, MIC_Cip, \n               offset = 0.005,  \n               width = 0.1,\n               color = \"black\", \n                colnames = FALSE)+\n  scale_fill_continuous(name = \"MIC for Ciprofloxacin\",\n                      low = \"yellow\", high = \"red\",\n                      breaks = c(0,0.50,1.00),\n                      na.value = \"white\")+\n   guides(fill = guide_colourbar(barwidth = 5, barheight = 1))+\n   theme(legend.position = \"bottom\",\n        legend.title = element_text(size = 10),\n        legend.text = element_text(size = 8),\n        legend.box = \"horizontal\", legend.margin = margin())+\n  guides(shape = guide_legend(override.aes = list(size = 2)))## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for fill is already present.\n## Adding another scale for fill, which will replace the existing scale.\nh5"},{"path":"phylogenetic-trees-1.html","id":"resources-29","chapter":"38 Árboles filogenéticos","heading":"38.6 Recursos","text":"http://hydrodictyon.eeb.uconn.edu/eebedia/index.php/Ggtree# Clade_Colorshttps://bioconductor.riken.jp/packages/3.2/bioc/vignettes/ggtree/inst/doc/treeManipulation.htmlhttps://guangchuangyu.github.io/ggtree-book/chapter-ggtree.htmlhttps://bioconductor.riken.jp/packages/3.8/bioc/vignettes/ggtree/inst/doc/treeManipulation.htmlEa Zankari, Rosa Allesøe, Katrine G Joensen, Lina M Cavaco, Ole Lund, Frank M Aarestrup, PointFinder: una novedosa herramienta web para la detección basada en WGS de la resistencia los antimicrobianos asociada mutaciones puntuales cromosómicas en patógenos bacterianos, Journal Antimicrobial Chemotherapy, Volume 72, Issue 10, October 2017, Pages 2764-2768, https://doi.org/10.1093/jac/dkx217","code":""},{"path":"interactive-plots.html","id":"interactive-plots","chapter":"39 Gráficos interactivos","heading":"39 Gráficos interactivos","text":"Últimamente es cada vez más común la necesidad de que la visualización de datos sea interactiva para el público. Por ello, es cada vez más habitual la realización de gráficos interactivos. Hay varias formas de realizarlos, pero las dos más comunes son empleando plotly y shiny.En esta página nos centraremos en como convertir un gráfico ggplot() existente en un gráfico interactivo con plotly. Puedes leer más sobre shiny en la página Dashboards con Shiny. Antes de comenzar, merece la pena mencionar que los gráficos interactivos sólo se pueden utilizar en documentos R markdown en formato HTML, en documentos PDF o Word.continuación se muestra una curva epidémica que se ha transformado en interactiva utilizando la integración de ggplot2 y plotly (pasa el cursor por encima del gráfico, amplía la imagen o clica en los elementos de la leyenda para comprobarlo).","code":""},{"path":"interactive-plots.html","id":"preparation-32","chapter":"39 Gráficos interactivos","heading":"39.1 Preparación","text":"","code":""},{"path":"interactive-plots.html","id":"cargar-paquetes-28","chapter":"39 Gráficos interactivos","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library(). Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,       # importación/exportación\n  here,      # rutas de archivos\n  lubridate, # lubridate\n  plotly,    # gráficos interactivos\n  scales,    # porcentajes rápidos\n  tidyverse  # gestión y visualización de datos\n  ) "},{"path":"interactive-plots.html","id":"comienza-con-un-ggplot","chapter":"39 Gráficos interactivos","heading":"Comienza con un ggplot()","text":"En esta página asumimos que comienzas con un gráfico ggplot() que deseas convertir en interactivo. Construiremos varios de estos gráficos en esta página, utilizando la base de datos linelist, la cual es ampliamente utilizada en este manual.","code":""},{"path":"interactive-plots.html","id":"importar-datos-23","chapter":"39 Gráficos interactivos","heading":"Importar datos","text":"Para empezar, importamos la lista de casos limpia de una epidemia de ébola simulada. Si quieres seguir el proceso, clica aquí para descargar linelist “limpio” (como archivo .rds). Importae los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - consulta la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas de la base de datos.","code":"\n# Importar base de datos linelist \nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"interactive-plots.html","id":"plot-with-ggplotly","chapter":"39 Gráficos interactivos","heading":"39.2 Trazar con ggplotly()","text":"La función ggplotly() del paquete plotly facilita la conversión de un ggplot() para que sea interactivo. Simplemente guarda tu ggplot() y luego pásaselo la función ggplotly().continuación, trazamos una línea simple que representa la proporción de casos que murieron en una semana determinada.Comenzamos creando unos datos resumidos de cada semana epidemiológica y el porcentaje de casos con resultado conocido que murieron.Aquí están las primeras 50 filas de los datos weekly_deaths.Luego creamos el gráfico con ggplot2, utilizando geom_line().Podemos convertirlo en interactivo simplemente pasando este gráfico mediante un “pipe” ggplotly(), como se muestra abajo. Pasa el cursor por encima de la línea para mostrar los valores x e y. Puedes ampliar el gráfico y arrastrarlo. También puedes ver los iconos en la parte superior derecha del gráfico. En orden, estos botones permiten:Descargar la vista actual como imagen PNGAcercarse con un cuadro de selección“Pan”, o moverse través de la gráfica clicando y arrastrando la gráficaAcercar, alejar o volver al zoom por defectoRestablecer los ejes por defectoActivar/desactivar las “líneas en pico” que son líneas punteadas desde el punto interactivo que se extienden los ejes x e yAjustes para que los datos se muestren cuando se está sobre la líneaLos datos agrupados también funcionan con ggplotly(). continuación, realizaremos una curva epidemica semanal agrupada por resultado. Las barras apiladas son interactivas. Prueba clicar en los diferentes elementos de la leyenda (aparecerán/desaparecerán).","code":"\nweekly_deaths <- linelist %>%\n  group_by(epiweek = floor_date(date_onset, \"week\")) %>%  # crear y agrupar los datos por la columna epiweek\n  summarise(                                              # crear nuevo dataframe descriptivo \n    n_known_outcome = sum(!is.na(outcome), na.rm=T),      # número de casos por grupo con resultado conocido\n    n_death  = sum(outcome == \"Death\", na.rm=T),          # número de casos por grupo que murieron\n    pct_death = 100*(n_death / n_known_outcome)           # porcentaje de casos con resultado conocido que murieron\n  )\ndeaths_plot <- ggplot(data = weekly_deaths)+            # comenzar introduciendo los datos de  weekly deaths \n  geom_line(mapping = aes(x = epiweek, y = pct_death))  # hacer un gráfico de línea\n\ndeaths_plot   # imprimir\ndeaths_plot %>% plotly::ggplotly()\n# Hacer curva epidémica con el paquete incidence2\np <- incidence2::incidence(\n  linelist,\n  date_index = date_onset,\n  interval = \"weeks\",\n  groups = outcome) %>% plot(fill = outcome)\n# Hacer interactivo\np %>% plotly::ggplotly()"},{"path":"interactive-plots.html","id":"modifications","chapter":"39 Gráficos interactivos","heading":"39.3 Modificaciones","text":"","code":""},{"path":"interactive-plots.html","id":"tamaño-del-archivo","chapter":"39 Gráficos interactivos","heading":"Tamaño del archivo","text":"Cuando se exportan imagenes en un HTML generado por R Markdown (¡como este libro!) es deseable que el gráfico tenga el menor tamaño de datos posible (y siempre que se pueda, evitar que esto tenga repercusiones negativas). Para ello, sólo hay que realizar “pipe” desde el gráfico interactivo partial_bundle(), de plotly.","code":"\np <- p %>% \n  plotly::ggplotly() %>%\n  plotly::partial_bundle()"},{"path":"interactive-plots.html","id":"botones","chapter":"39 Gráficos interactivos","heading":"Botones","text":"Algunos de los botones de un plotly estándar son superfluos y pueden distraer, por lo que, si quieres, puedes eliminarlos. Puedes hacer esto simplemente canalizando la haz pipe hacia config() de plotly y especifican qué botones eliminar. En el siguiente ejemplo especificamos por adelantado los nombres de los botones eliminar, y los especificamos en el argumento modeBarButtonsToRemove =. También establecemos displaylogo = FALSE para eliminar el logo de plotly.","code":"\n## estos botones distraen y queremos eliminarlos\nplotly_buttons_remove <- list('zoom2d','pan2d','lasso2d', 'select2d','zoomIn2d',\n                              'zoomOut2d','autoScale2d','hoverClosestCartesian',\n                              'toggleSpikelines','hoverCompareCartesian')\n\np <- p %>%            # redefinir el gráfico  interactivo sin estos botones\n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"heat-tiles","chapter":"39 Gráficos interactivos","heading":"39.4 Gráficos de calor","text":"Puedes hacer que casi cualquier gráfico de ggplot() sea interactivo, incluidos los gráficos de calor. En la página sobre gráficos de calor puede leer cómo hacer el siguiente gráfico, que muestra la proporción de días la semana en que determinados centros comunicaron datos su provincia.Aquí está el código, aunque en este capítulo describiremos en profundidad como realizarlo.continuación, lo convertimos en interactivo y lo modificamos para que los botones sean sencillos y disminuya el tamaño del archivo.–>\n","code":"\n# importar datos\nfacility_count_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\"))\n\n# datos agregados en semanas para el distrito de Spring\nagg_weeks <- facility_count_data %>% \n  filter(District == \"Spring\",\n         data_date < as.Date(\"2020-08-01\")) %>% \n  mutate(week = aweek::date2week(\n    data_date,\n    start_date = \"Monday\",\n    floor_day = TRUE,\n    factor = TRUE)) %>% \n  group_by(location_name, week, .drop = F) %>%\n  summarise(\n    n_days          = 7,\n    n_reports       = n(),\n    malaria_tot     = sum(malaria_tot, na.rm = T),\n    n_days_reported = length(unique(data_date)),\n    p_days_reported = round(100*(n_days_reported / n_days))) %>% \n  ungroup(location_name, week) %>% \n  right_join(tidyr::expand(., week, location_name)) %>% \n  mutate(week = aweek::week2date(week))\n\n# crear plot\nmetrics_plot <- ggplot(agg_weeks,\n       aes(x = week,\n           y = location_name,\n           fill = p_days_reported))+\n  geom_tile(colour=\"white\")+\n  scale_fill_gradient(low = \"orange\", high = \"darkgreen\", na.value = \"grey80\")+\n  scale_x_date(expand = c(0,0),\n               date_breaks = \"2 weeks\",\n               date_labels = \"%d\\n%b\")+\n  theme_minimal()+ \n  theme(\n    legend.title = element_text(size=12, face=\"bold\"),\n    legend.text  = element_text(size=10, face=\"bold\"),\n    legend.key.height = grid::unit(1,\"cm\"),\n    legend.key.width  = grid::unit(0.6,\"cm\"),\n    axis.text.x = element_text(size=12),\n    axis.text.y = element_text(vjust=0.2),\n    axis.ticks = element_line(size=0.4),\n    axis.title = element_text(size=12, face=\"bold\"),\n    plot.title = element_text(hjust=0,size=14,face=\"bold\"),\n    plot.caption = element_text(hjust = 0, face = \"italic\")\n    )+\n  labs(x = \"Week\",\n       y = \"Facility name\",\n       fill = \"Reporting\\nperformance (%)\",\n       title = \"Percent of days per week that facility reported data\",\n       subtitle = \"District health facilities, April-May 2019\",\n       caption = \"7-day weeks beginning on Mondays.\")\n\nmetrics_plot # imprimir\nmetrics_plot %>% \n  plotly::ggplotly() %>% \n  plotly::partial_bundle() %>% \n  plotly::config(displaylogo = FALSE, modeBarButtonsToRemove = plotly_buttons_remove)"},{"path":"interactive-plots.html","id":"resources-32","chapter":"39 Gráficos interactivos","heading":"39.5 Recursos","text":"Plotly es sólo para R, también funciona bien con Python (y realmente con cualquier lenguaje de ciencia de datos, ya que está construido en JavaScript). Puedes leer más sobre él en el sitio web de plotly","code":""},{"path":"reports-with-r-markdown.html","id":"reports-with-r-markdown","chapter":"40 Informes con R Markdown","heading":"40 Informes con R Markdown","text":"R Markdown es una herramienta ampliamente utilizada para crear documentos de salida automatizados, reproducibles y dignos de compartir, como por ejemplo, informes. Podés generar resultados estáticos o interactivos en Word, pdf, html, powerpoint y otros formatos.Un script de R Markdown intercala código R y texto de tal manera que el script se convierte en tu documento de salida. Puedes crear un documento completo con formato, incluyendo texto narrativo (el texto puede ser dinámico y cambiar en función de sus datos), tablas, figuras, viñetas/números, bibliografías, etc.Estos documentos pueden producirse para ser actualizados de forma rutinaria (por ejemplo, informes de vigilancia diarios) y/o ejecutarse sobre subconjuntos de datos (por ejemplo, informes para cada jurisdicción).Otras páginas de este manual amplían este tema:La página Organización de informes rutinarios muestra cómo “rutinizar” la producción de informes con carpetas autogeneradas con marca de tiempo.La página Dashboards con R Markdown explica cómo formatear un informe de R Markdown como un cuadro de mando o tablero de control.Cabe destacar que el proyecto R4Epis ha desarrollado plantillas de scripts R Markdown para los escenarios de brotes y encuestas de uso frcuente en lugares en donde MSF maneja proyectos.","code":""},{"path":"reports-with-r-markdown.html","id":"preparation-33","chapter":"40 Informes con R Markdown","heading":"40.1 Preparación","text":"Antecedentes de R MarkdownExplicamos algunos de los conceptos y paquetes involucrados:Markdown es un “lenguaje” que permite escribir un documento en texto plano, que se puede convertir html y otros formatos. es específico de R. Los archivos escritos en Markdown tienen una extensión ‘.md’.R Markdown: es una variación de markdown que es específica de R - te permite escribir un documento usando markdown para producir texto y para integrar código R y mostrar sus resultados. Los archivos R Markdown tienen la extensión ‘.Rmd’.rmarkdown - el paquete: Usado por R para convertir el archivo .Rmd en el tipo de documento de salida deseado. Su objetivo es convertir la sintaxis markdown (texto), por lo que también necesitamos…knitr: Este paquete de R leerá los trozos de código, los ejecutará y los “tejerá” dentro del documento. Así es como se incluyen las tablas y los gráficos junto al texto.Pandoc: Por último, pandoc convierte el documento de salida en word/pdf/powerpoint, etc. Es un software independiente de R, y viene instalado automáticamente con RStudio.En resumen, el proceso que ocurre en segundo plano (¡es necesario que conozcas todos estos pasos!) consiste en alimentar el archivo .Rmd knitr, que ejecuta los trozos de código R y crea un nuevo archivo .md (markdown) que incluye el código R y su salida renderizada. El archivo .md es entonces procesado por pandoc para crear el producto final: un documento de Microsoft Word, un archivo HTML, un documento powerpoint, un pdf, etc.(fuente: https://rmarkdown.rstudio.com/authoring_quick_tour.html):InstalaciónPara crear una salida de R Markdown, necesitas tener instalado lo siguiente:El paquete rmarkdown (knitr también se instalará automáticamente)Pandoc, que debería venir instalado con RStudio. Si utilizas RStudio, podés descargar Pandoc aquí: http://pandoc.org .Si querés generar una salida en PDF (un poco más complicado), necesitarás instalar LaTeX. Para los usuarios de R Markdown que hayan instalado LaTeX antes, recomendamos que instalen TinyTeX (https://yihui.name/tinytex/)https://yihui.name/tinytex/). Puedes utilizar los siguientes comandos:","code":"\npacman::p_load(tinytex)     # install tinytex package\ntinytex::install_tinytex()  # R command to install TinyTeX software"},{"path":"reports-with-r-markdown.html","id":"getting-started","chapter":"40 Informes con R Markdown","heading":"40.2 Cómo empezar","text":"","code":""},{"path":"reports-with-r-markdown.html","id":"instalar-el-paquete-r-rmarkdown","chapter":"40 Informes con R Markdown","heading":"Instalar el paquete R rmarkdown","text":"Instalá el paquete R rmarkdown. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y ademas lo carga para su uso. También podés cargar los paquetes instalados con library() de R base. Consultá la página sobre fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(rmarkdown)"},{"path":"reports-with-r-markdown.html","id":"iniciar-un-nuevo-archivo-rmd","chapter":"40 Informes con R Markdown","heading":"Iniciar un nuevo archivo Rmd","text":"En RStudio, abrí un nuevo archivo R markdown, comenzando con ‘File’, luego ‘New file’ luego ‘R markdown…’.R Studio te dará algunas opciones de salida para elegir. En el ejemplo siguiente seleccionamos “HTML” porque queremos crear un documento html. El título y los nombres de los autores son importantes. Si el tipo de documento de salida que desea es uno de estos, te preocupes - podés elegir cualquiera y cambiarlo en el script más tarde.Esto abrirá un nuevo script .Rmd.","code":""},{"path":"reports-with-r-markdown.html","id":"es-importante-saber","chapter":"40 Informes con R Markdown","heading":"Es importante saber","text":"El directorio de trabajoEl directorio de trabajo de un archivo markdown es el lugar donde se guarda el propio archivo Rmd. Por ejemplo, si el proyecto R está dentro de ~/Documents/projectX y el archivo Rmd en sí está en una subcarpeta ~/Documents/projectX/markdownfiles/markdown.Rmd, el código read.csv(\"data.csv\") dentro del markdown buscará un archivo csv en la carpeta markdownfiles, y en la carpeta raíz del proyecto donde los scripts dentro de los proyectos normalmente buscarían archivos de manera automática.Para referirse archivos en otro lugar, tendrá que utilizar la ruta completa del archivo o utilizar el paquete . El paquete establece el directorio de trabajo en la carpeta raíz del proyecto R y se explica en detalle en las páginas de proyectos R e importación y exportación de este manual. Por ejemplo, para importar un archivo llamado “data.csv” desde la carpeta projectX, el código sería import((\"data.csv\")).Ten en cuenta que se recomienda el uso de setwd() en los scripts de R Markdown - sólo se aplica al trozo de código en el que está escrito.Trabajar en una unidad versus tu ordenadorDebido que R Markdown puede tener problemas con pandoc cuando se ejecuta en una unidad de red compartida, se recomienda que la carpeta esté ubicada en tu máquina local, por ejemplo, en un proyecto dentro de ‘Mis Documentos’. Si utilizas Git (¡super recomendable!), esto te resultará familiar. Para más detalles, consulta las páginas del manual sobre R en unidades de red y Errores y ayuda.","code":""},{"path":"reports-with-r-markdown.html","id":"r-markdown-components","chapter":"40 Informes con R Markdown","heading":"40.3 Componentes de R Markdown","text":"Un documento R Markdown puede ser editado en RStudio igual que un script estándar de R. Cuando se inicia un nuevo script de R Markdown, RStudio intenta ayudarnos mostrando una plantilla que explica las diferentes secciones de un script de R Markdown.Lo que aparece continuación es lo que veremos al iniciar un nuevo script Rmd destinado producir un documento de salida en html (según la sección anterior).Como puedes ver, hay tres componentes básicos en un archivo Rmd: YAML, texto Markdown y trozos de código R.Estos crearán y se convertirán en la salida de su documento. Consulta el siguiente diagrama:","code":""},{"path":"reports-with-r-markdown.html","id":"metadatos-yaml","chapter":"40 Informes con R Markdown","heading":"Metadatos YAML","text":"Denominado ‘metadatos YAML’ o simplemente ‘YAML’, se encuentra en la parte superior del documento R Markdown. Esta sección del script le dirá su archivo Rmd qué tipo de salida producir, preferencias de formato y otros metadatos como el título del documento, el autor y la fecha. Hay otros usos que se mencionan aquí (pero los que se hace referencia en ‘Producción del documento de salida’). Ten en cuenta que la sangría es importante; los tabuladores se aceptan, pero los espacios sí.Esta sección debe comenzar con una línea que contenga sólo tres guiones --- y debe cerrar con una línea que contenga sólo tres guiones ---. Los parámetros YAML vienen en pares key:value. La colocación de los dos puntos en YAML es importante - los pares key:value están separados por dos puntos (¡por signos de igualdad!).El YAML debe comenzar con los metadatos del documento. El orden de estos parámetros YAML primarios (sin sangría) importa. Por ejemplo:Puedes utilizar código R en valores YAML escribiéndolo como código en línea (precedido por r entre comillas) pero también entre comillas (véase el ejemplo anterior para date:).En la imagen de arriba, porque hemos seleccionado el tipo de documento de salida como html, podemos ver que el YAML dice output: html_document. Sin embargo, también podemos cambiar esto escribir powerpoint_presentation o word_document o incluso pdf_document.","code":"title: \"My document\"\nauthor: \"Me\"\ndate: \"2022-11-22\""},{"path":"reports-with-r-markdown.html","id":"texto","chapter":"40 Informes con R Markdown","heading":"Texto","text":"Esta es la narrativa de t u documento, incluyendo los títulos y encabezados. Está escrito en el lenguaje “markdown”, que se utiliza en muchos otros programas.continuación se presentan las formas principales de escribir este texto. Podés consultar material de referencia más detallado disponible en R Markdown “cheatsheet” en el sitio web de RStudio.","code":""},{"path":"reports-with-r-markdown.html","id":"nuevas-líneas","chapter":"40 Informes con R Markdown","heading":"Nuevas líneas","text":"En R Markdown, para iniciar una nueva línea, introducí *dos espacios** al final de la línea anterior y luego Enter/Return. Esto es una particularidad de R Markdown.","code":""},{"path":"reports-with-r-markdown.html","id":"formato-de-texto","chapter":"40 Informes con R Markdown","heading":"Formato de texto","text":"Rodea el texto normal con estos caracteres para cambiar su apariencia en la salida.Guiones bajos (_texto_) o un asterisco simple (*texto*) para poner en cursiva (itálica)Doble asterisco (**texto**) para el texto en negritaComillas invertidas (texto) para mostrar el texto como códigoEl aspecto real de la fuente puede establecerse utilizando plantillas específicas (especificadas en los metadatos YAML; ver sub-secciones de este capitulo).","code":""},{"path":"reports-with-r-markdown.html","id":"color","chapter":"40 Informes con R Markdown","heading":"Color","text":"existe un mecanismo sencillo para cambiar el color del texto en R Markdown. Como solución, si tu salida es un archivo HTML, es añadir una línea de codigo HTML en el texto de Markdown. El siguiente código HTML imprimirá una línea de texto en negrita roja.PELIGRO: Esto es una advertencia.","code":"<span style=\"color: red;\">**_PELIGRO:_** Esto es una advertencia.<\/span>  "},{"path":"reports-with-r-markdown.html","id":"títulos-y-encabezamientos","chapter":"40 Informes con R Markdown","heading":"Títulos y encabezamientos","text":"Un símbolo de almohadilla (hash #) delante de un texto en un script de R Markdown crea un encabezado. Esto es diferente que en un trozo de código R en el script, en el que un símbolo de almohadilla permite comentar/anotar/desactivar, como en un script normal de R.Los distintos niveles de encabezamiento se establecen con diferentes números de símbolos de almohadilla al comienzo de una nueva línea. Un solo símbolo de almohadilla genera un título o encabezamiento primario. Dos símbolos hash generan un encabezamiento de segundo nivel. Los encabezamientos de tercer y cuarto nivel pueden hacerse con más símbolos hash sucesivamente.","code":"# Encabezamiento / título de primer nivel\n\n## Encabezamiento de segundo nivel\n\n### Encabezamiento de tercer nivel"},{"path":"reports-with-r-markdown.html","id":"viñetas-y-numeración","chapter":"40 Informes con R Markdown","heading":"Viñetas y numeración","text":"Utilizá asteriscos (*) para crear una lista de viñetas. Completá la frase anterior, introducí dos espacios, presioná Enter/Return dos veces, y luego comenzá tus viñetas. Incluí un espacio entre el asterisco y el texto de tu viñeta. Después de cada viñeta, introducí dos espacios y luego presioná Enter/Return. Las sub-viñetas funcionan de la misma manera pero con sangría. Los números funcionan de la misma manera, pero en lugar de un asterisco, escribí 1), 2), etc. El texto de tu script de R Markdown se vería como mostramos continuación.","code":"Aquí están mis viñetas (hay dos espacios después de los dos puntos):\n\n* Viñeta 1 (seguida de dos espacios y Enter/Return)\n* Viñeta 2 (seguida de dos espacios y Enter/Return)\n  * Sub-viñeta 1 (seguida de dos espacios y Enter/Return)\n  * Sub-viñeta 2 (seguida de dos espacios y Enter/Return)\n* Subbalanceo 2 (seguido de dos espacios y Enter/Return)"},{"path":"reports-with-r-markdown.html","id":"comentar-el-texto","chapter":"40 Informes con R Markdown","heading":"Comentar el texto","text":"Puedes desactivar o “esconder” el texto de R Markdown del mismo modo que puede utilizar el “#” para desactivar una línea de código en un chunk de R. Simplemente resalta el texto y clica Ctrl+Mayús+c (Cmd+Mayús+c para Mac). El texto aparecerá rodeado de flechas y se volverá verde. aparecerá en tu salida.","code":""},{"path":"reports-with-r-markdown.html","id":"trozos-de-código-chunks","chapter":"40 Informes con R Markdown","heading":"Trozos de código (chunks)","text":"Las secciones del script que se dedican ejecutar el código R se denominan “chunks” o trozos. Aquí es donde se pueden cargar paquetes, importar datos y realizar la gestión y visualización de datos propiamente dicha. Puede haber muchos trozos de código, por lo que puede ser de ayuda organizar tu código R en partes, quizás intercaladas con texto. Para tener en cuenta: estos trozos tendrán un color de fondo ligeramente diferente al de la parte narrativa del documento.Cada trozo se abre con una línea que comienza con tres comillas invertidas y corchetes que contienen parámetros para el trozo ({ }). El trozo termina con otras tres comillas invertidas.Puedes crear un nuevo fragmento escribiendo tú mismo las marcas, utilizando el atajo de teclado “Ctrl + Alt + ” (o Cmd + Shift + r en Mac), o clicando en el icono verde ‘insert new code chunk’ en la parte superior de tu editor de scripts.Algunas notas sobre el contenido de las corchetes { }:Empiezan con una “r” para indicar que el nombre del idioma dentro del chunk es RDespués de la r puedes asignarle un “nombre” al chunk - es necesario pero puede ayudarte organizar tu trabajo. Ten en cuenta que si nombras tus chunks, debes usar SIEMPRE nombres únicos o de lo contrario R se quejará cuando intentes procesarlos.Los corchetes pueden incluir también otras opciones, escritas como tag=value, como por ejemploeval = FALSE para ejecutar el código R\necho = FALSE para imprimir o esconder el código fuente de R del chunk en el documento de salida\nwarning = FALSE para imprimir las advertencias producidas por el código R\nmessage = FALSE para imprimir ningún mensaje producido por el código R\ninclude = TRUE/FALSE para incluir (o ) los resultados generados por los trozos (por ejemplo, los gráficos) en el documento de salida\n.width = y .height = - asigna proporciones de ancho y largo, por ejemplo .width = \"75%\"\nfig.align = \"center\" ajusta cómo se alinea una figura en la página\nfig.show = 'hold' si tu chunk imprime múltiples figuras y querés imprimirlas una al lado de la otra usá también la funciónout.width = c(\"33%\", \"67%\"). También podés establecer como fig.show='asis' para mostrarlas debajo del código que las genera, 'hide' para ocultarlas, o 'animate' para concatenar varias figuras en una animación.\necho = FALSE para imprimir o esconder el código fuente de R del chunk en el documento de salidawarning = FALSE para imprimir las advertencias producidas por el código Rmessage = FALSE para imprimir ningún mensaje producido por el código Rinclude = TRUE/FALSE para incluir (o ) los resultados generados por los trozos (por ejemplo, los gráficos) en el documento de salidaout.width = y .height = - asigna proporciones de ancho y largo, por ejemplo .width = \"75%\"fig.align = \"center\" ajusta cómo se alinea una figura en la páginafig.show = 'hold' si tu chunk imprime múltiples figuras y querés imprimirlas una al lado de la otra usá también la funciónout.width = c(\"33%\", \"67%\"). También podés establecer como fig.show='asis' para mostrarlas debajo del código que las genera, 'hide' para ocultarlas, o 'animate' para concatenar varias figuras en una animación.La cabecera de un trozo debe escribirse en una sola líneaIntentá evitar puntos, barras bajas y espacios. Utiliza guiones ( - ) en su lugar si necesitas un separador.Leé más extensamente sobre las opciones de knitr aquí.Algunas de estas opciones pueden configurarse usando los botones de configuración situados en la parte superior derecha del chunk. Aquí puedes especificar qué partes del chunk quieres incluir en el documento renderizado, es decir, el código, las salidas generadas y las advertencias. Estas preferencias aparecerán escritas como código dentro de los corchetes, por ejemplo, si especificás que querés mostrar sólo la salida (‘Show output ’) aparecerá echo=FALSE entre los corchetes.También hay dos flechas en la parte superior derecha de cada trozo, que son útiles para ejecutar el código dentro de un trozo, o todo el código en trozos anteriores. Pasa el cursor por encima de estos iconos para ver lo que hacen.Para que las opciones globales se apliquen todos los chunks del script, podés configurar esto dentro del primer chunk de código R en el script. Por ejemplo, para sólo muestrar las salidas generadas por cada trozo de código y el propio código, podés incluir este comando en el trozo de código R:","code":"\nknitr::opts_chunk$set(echo = FALSE) "},{"path":"reports-with-r-markdown.html","id":"código-r-en-el-texto","chapter":"40 Informes con R Markdown","heading":"Código R en el texto","text":"También se puede insertar un mínimo de código R entre comillas invertidas (back ticks) intercalado entre el texto narrativo. Dentro de las comillas invertidas, comenzá el código con la letra “r” y un espacio, para que RStudio sepa que debe evaluar el código como código R. Ver el siguiente ejemplo.El ejemplo siguiente muestra múltiples niveles de encabezamiento, viñetas, y utiliza el código (Sys.Date()) para obtener y mostrar la fecha actual.El ejemplo anterior es sencillo (muestra la fecha actual), pero utilizando la misma sintaxis puede mostrar valores producidos por un código R más complejo (por ejemplo, para calcular el mínimo, la mediana o el máximo de una columna). También podés integrar objetos R o valores que han sido creados en trozos de código R anteriores.Como ejemplo, el siguiente script calcula la proporción de casos que tienen menos de 18 años, utilizando funciones tidyverse, y crea los objetos less18, total y less18prop. Este valor dinámico se inserta en el texto narrativo. Vemos cómo queda cuando se teje en un documento de Word.","code":""},{"path":"reports-with-r-markdown.html","id":"imágenes","chapter":"40 Informes con R Markdown","heading":"Imágenes","text":"Hay dos maneras de incluir imágenes en R Markdown:Si el código anterior funciona, probá utilizar knitr::include_graphics()(recordá que podes declarar la ruta de tu archivo usando el paquete )","code":"![](\"path/to/image.png\")  \nknitr::include_graphics(\"path/to/image.png\")\nknitr::include_graphics(here::here(\"path\", \"to\", \"image.png\"))"},{"path":"reports-with-r-markdown.html","id":"tablas","chapter":"40 Informes con R Markdown","heading":"Tablas","text":"Creá una tabla utilizando guiones ( - ) y barras ( | ). El número de guiones entre las barras determina el número de espacios en la celda patrir del cual el texto comienza envolverse.El código anterior produce la siguiente tabla:","code":"Column  1 |Column   2 |Column 3\n----------|-----------|--------\nCell A    |Cell B     |Cell C\nCell D    |Cell E     |Cell F"},{"path":"reports-with-r-markdown.html","id":"secciones-con-pestañas","chapter":"40 Informes con R Markdown","heading":"Secciones con pestañas","text":"Para las salidas HTML, podés organizar las secciones con “pestañas”. Basta con añadir .tabset entre las llaves { } que se colocan después de un encabezamiento. Todos los subtítulos debajo de ese encabezado (hasta el próximo encabezado del mismo nivel) aparecerán como pestañas en las que el usuario puedes clicar. Lee más aquíPuedes añadir una opción adicional .tabset-pills después de .tabset para dar las pestañas una apariencia “en forma de píldora”. Ten en cuenta que al ver la salida HTML con etiquetas, la funcionalidad de búsqueda Ctrl+f sólo buscará en las etiquetas “activas”, en las ocultas.","code":""},{"path":"reports-with-r-markdown.html","id":"file-structure","chapter":"40 Informes con R Markdown","heading":"40.4 Estructura de los archivos","text":"Hay varias maneras de estructurar el archivo de R Markdown y sus scripts de R asociados. Cada una tiene sus ventajas y desventajas:R Markdown autónomo - todo lo necesario para el informe se importa o se crea dentro del R Markdown\nUbicar otros archivos - Podés ejecutar scripts R externos con el comando source() y utilizar sus salidas en el Rmd\nScripts hijos - un mecanismo alternativo para source()\nUbicar otros archivos - Podés ejecutar scripts R externos con el comando source() y utilizar sus salidas en el RmdScripts hijos - un mecanismo alternativo para source()Utilizar un “archivo de ejecución” - Ejecutar comandos en un script R antes de renderizar el R Markdown","code":""},{"path":"reports-with-r-markdown.html","id":"rmd-autónomo","chapter":"40 Informes con R Markdown","heading":"Rmd autónomo","text":"Para un informe relativamente sencillo, puedes optar por organizar tu script de R Markdown de manera que sea “autosuficiente” y implique utilizar ningún script externo.Todo lo que se necesite para ejecutar el R Markdown se importa o se crea dentro del archivo Rmd, incluyendo todos los trozos de código y la carga de paquetes. Este enfoque “autosuficiente” es apropiado cuando necesitás hacer mucho procesamiento de datos (por ejemplo, cuando se importa un archivo de datos limpio o semilimpio) y el procesamiento del R Markdown tomará demasiado tiempo.En este escenario, una organización lógica del script de R Markdown podría ser:Establecer las opciones globales de knitrCargar paquetesImportar los datosProcesar los datosGenerar resultados (tablas, gráficos, etc.)Guardar los resultados, si es el caso (.csv, .png, etc.)","code":""},{"path":"reports-with-r-markdown.html","id":"obtener-otros-archivos","chapter":"40 Informes con R Markdown","heading":"Obtener otros archivos","text":"Una variación del enfoque “autocontenido” es hacer que los trozos de código R Markdown busquen (ejecuten) scripts de R externos. Esto puede hacer que tu script de R Markdown sea menos desordenado, más simple y más fácil de organizar. También puede ayudar si quieres mostrar las cifras finales al principio del informe. En este enfoque, el script de R Markdown final simplemente combina las salidas preprocesadas en un documento.Una forma de hacerlo es proporcionando los scripts de R (ruta del archivo y nombre con extensión) al comando source() R base.Tené en cuenta que cuando utilizás source() dentro de R Markdown, los archivos externos se ejecutarán durante el curso del procesamiento de tu archivo Rmd. Por lo tanto, cada script se ejecuta cada vez que se procesa el informe. Por lo tanto, utilizar comandos source() dentro del R Markdown acelera el tiempo de ejecución, ni ayuda mucho la depuración, ya que el error producido todavía se imprimirá al producir el R Markdown.Una alternativa es utilizar la opción child = knitr. #EXPLICAR MÁS PARA HACERDebes ser consciente de los distintos entornos de R. Los objetos creados dentro de un entorno estarán necesariamente disponibles para el entorno utilizado por R Markdown.","code":"\nsource(\"your-script.R\", local = knitr::knit_global())\n# or sys.source(\"your-script.R\", envir = knitr::knit_global())"},{"path":"reports-with-r-markdown.html","id":"ejecutar-archivo","chapter":"40 Informes con R Markdown","heading":"Ejecutar archivo","text":"Este enfoque implica utilizar el script de R que contiene el comando(s) render() para preprocesar los objetos que se introducen en el R markdown.Por ejemplo, podés cargar los paquetes, cargar y limpiar los datos, e incluso crear los gráficos de interés antes de ejecutarrender(). Estos pasos pueden ocurrir en el script de R, o en otros scripts que se convocan. Siempre y cuando estos comandos ocurran en la misma sesión de RStudio y los objetos se guarden en el entorno, los objetos pueden ser convocados dentro del contenido de Rmd. Entonces R markdown sólo se utilizará para el paso final, es decir, para producir la salida con todos los objetos pre-procesados. Esto es mucho más fácil de depurar si se genera algún error.Este enfoque es útil por las siguientes razones:Mensajes de error más informativos - estos mensajes serán generados por el script de R, por el R Markdown. Los errores de R Markdown tienden informar qué trozo tuvo un problema, pero te dirán qué línea.Si ejecutás muchos pasos de procesamiento antes de usar el comando render() - se ejecutarán sólo una vez.En el ejemplo siguiente, tenemos un script de R en el que preprocesamos el objeto data en el entorno de R y luego procesamos “create_output.Rmd” usando render().","code":"\ndata <- import(\"datafile.csv\") %>%       # Cargar datos y guardarlos en el entorno\n  select(age, hospital, weight)          # Seleccionar columnas\n\nrmarkdown::render(input = \"create_output.Rmd\")   # Crear archivo Rmd "},{"path":"reports-with-r-markdown.html","id":"estructura-de-carpetas","chapter":"40 Informes con R Markdown","heading":"Estructura de carpetas","text":"El flujo de trabajo también se refiere la estructura general de las carpetas, como tener una carpeta de ‘salida’ para los documentos y figuras creados, y carpetas de ‘datos’ o ‘entradas’ para los datos depurados. entramos en más detalles aquí, pero echa un vistazo la página de organización de informes rutinarios.","code":""},{"path":"reports-with-r-markdown.html","id":"producing-the-document","chapter":"40 Informes con R Markdown","heading":"40.5 Producir el documento","text":"Puedes generar el documento de las siguientes maneras:Manualmente haciendo click sobre el botón “Knit” en la parte superior del editor de scripts de RStudio (rápido y fácil)Ejecutando el comando render() (ejecutado fuera del script de R Markdown)","code":""},{"path":"reports-with-r-markdown.html","id":"opción-1-botón-knit","chapter":"40 Informes con R Markdown","heading":"Opción 1: botón “Knit”","text":"Cuando tengas el archivo Rmd abierto, cliqueá el botón ‘Knit’ en la parte superior del archivo.R Studio te mostrará el progreso dentro de una pestaña ‘R Markdown’ cerca de la consola R. El documento se abrirá automáticamente cuando esté completo.El documento se guardará en la misma carpeta que tu script de R markdown, y con el mismo nombre de archivo (excepto la extensión). Obviamente, esto es ideal para el control de versiones (se sobreescribirá cada vez que se haga un knit, menos que se mueva manualmente), ya que entonces puede que tengas que renombrar el archivo (por ejemplo, añadir una fecha).Este es el botón de acceso directo de RStudio para la función render() de rmarkdown. Este enfoque sólo es compatible con un R markdown autocontenido, donde todos los componentes necesarios existen o se convocan dentro del archivo.","code":""},{"path":"reports-with-r-markdown.html","id":"opción-2-comando-render","chapter":"40 Informes con R Markdown","heading":"Opción 2: comando render()","text":"Otra forma de producir el documento de salida de R Markdown es ejecutar la función render() (del paquete rmarkdown). Debés ejecutar este comando fuera del script de R Markdown, ya sea en un script de R separado (menudo llamado “archivo de ejecución”), o como un comando independiente en la consola de R.Al igual que con “knit”, la configuración predeterminada guardará la salida Rmd en la misma carpeta que el script Rmd, con el mismo nombre de archivo (excepto la extensión del archivo). Por ejemplo, “mi_informe.Rmd” cuando se procese creará “mi_informe.docx” si se procesa un documento de Word. Sin embargo, al usar render() existe la opción de usar diferentes configuraciones. render() puede aceptar argumentos que incluyen:output_format = Este es el formato del documento salida al que se va convertir (por ejemplo, \"html_document\", \"pdf_document\", \"word_document\", o \"\"). Esto también se puede especificar en el YAML dentro del script de R Markdown.output_file = Este es el nombre del archivo de salida (y la ruta del archivo). Se puede crear través de funciones de R como () o str_glue() como se demuestra continuación.output_dir =Este es un directorio de salida (carpeta) para guardar el archivo. Esto te permite elegir un directorio distinto en el que se guarda el archivo Rmd.output_options = Podés proporcionar una lista de opciones que anulen las del YAML del scriptoutput_yaml = Podés proporcionar la ruta un archivo .yml que contenga las especificaciones YAMLparams = Ver la sección de parámetros más abajoVer la lista completa aquíComo ejemplo, para mejorar el control de versiones, el siguiente comando guardará el archivo de salida dentro de una subcarpeta ‘outputs’, con la fecha actual en el nombre del archivo. Para crear el nombre del archivo, se utiliza la función str_glue() del paquete stringr para “pegar” las cadenas estáticas (escritas sin formato) con el código dinámico de R (escrito entre corchetes). Por ejemplo, si es 10 de abril de 2021, el nombre del archivo será “Informe_2021-04-10.docx”. Consultá la página sobre Caracteres y cadenas para obtener más detalles sobre str_glue().medida que el archivo se procesa, la consola de RStudio mostrará el progreso hasta el 100%, y un mensaje final para indicar que la renderización se ha completado.","code":"\nrmarkdown::render(input = \"my_report.Rmd\")\nrmarkdown::render(\n  input = \"create_output.Rmd\",\n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\")) "},{"path":"reports-with-r-markdown.html","id":"opción-3-paquete-reportfactory","chapter":"40 Informes con R Markdown","heading":"Opción 3: paquete reportfactory","text":"El paquete de R reportfactory ofrece un método alternativo de organización y compilación de informes R Markdown para situaciones en las que se ejecutan informes de forma rutinaria (por ejemplo, diariamente, semanalmente…). Facilita la compilación de múltiples archivos R Markdown y la organización de sus resultados. En esencia, proporciona una “fábrica” desde la que se pueden ejecutar los informes R Markdown, obtener automáticamente carpetas con fecha y hora para los resultados, y tener un control de versiones “ligero”.Leé más sobre este flujo de trabajo en la página sobre la organización de informes rutinarios.","code":""},{"path":"reports-with-r-markdown.html","id":"parameterised-reports","chapter":"40 Informes con R Markdown","heading":"40.6 Informes parametrizados","text":"Podés utilizar la parametrización para generar informes dinámicos, de forma que pueda ejecutarse con una configuración específica (por ejemplo, una fecha o lugar concretos o con determinadas opciones de procesamiento). continuación, nos centramos en los aspectos básicos, pero hay más detalles en línea sobre los informes parametrizados.Utilizando el listado de casos de Ébola como ejemplo, digamos que queremos ejecutar un informe de diario vigilancia estándar para cada hospital. Mostramos cómo se puede hacer esto usando parámetros.Importante: los informes dinámicos también son posibles sin la estructura formal de parámetros (sin params:), utilizando simples objetos R en un script adyacente. Esto se explica al final de esta sección.","code":""},{"path":"reports-with-r-markdown.html","id":"establecer-parámetros-1","chapter":"40 Informes con R Markdown","heading":"Establecer parámetros","text":"Existen varias opciones para especificar los valores de los parámetros para tu documento de salida de R Markdown.","code":""},{"path":"reports-with-r-markdown.html","id":"opción-1-establecer-parámetros-dentro-de-yaml","chapter":"40 Informes con R Markdown","heading":"Opción 1: Establecer parámetros dentro de YAML","text":"Editá el YAML para incluir una opción params:, con declaraciones indentadas para cada parámetro definir. En este ejemplo creamos los parámetros date y hospital, y especificamos sus valores. Estos valores están sujetos cambios cada vez que se ejecuta el informe. Si utilizás el botón “Knit” para producir la salida, los parámetros estarán predeterminados por estos valores. Del mismo modo, si utilizás render() los parámetros tendrán estos valores por defecto menos que se especifiquen de otra manera en el comando render().En un segundo plano, los valores de los parámetros están contenidos en una lista de sólo lectura llamada params. Así, puedes insertar los valores de los parámetros en el código de R como lo harías con otro objeto/valor de R en tu entorno. Simplemente escriba params$ seguido del nombre del parámetro. Por ejemplo params$hospital para representar el nombre del hospital (“Hospital Central” por defecto).Tené en cuenta que los parámetros también pueden tener valores true o false, y por lo tanto estos pueden ser incluidos en sus opciones de knitr dentro de un chunk de R. Por ejemplo, puedes establecer {r, eval=params$run} en lugar de {r, eval=FALSE}, y ahora si el chunk se ejecuta o depende del valor de un parámetro run:.Los parámetros que son fechas, serán introducidos como una cadena. Por lo tanto, para que params$date se interprete en el código de R, es probable que tenga que ser envuelto con .Date() o una función similar para convertir al tipo Date.","code":"---\ntitle: Informe de vigilancia\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: Hospital Central\n---"},{"path":"reports-with-r-markdown.html","id":"opción-2-establecer-los-parámetros-dentro-de-render","chapter":"40 Informes con R Markdown","heading":"Opción 2: Establecer los parámetros dentro de render()","text":"Como se ha mencionado anteriormente, como alternativa cliquear el botón “Knit” para producir la salida es ejecutar la función render() desde un script independiente. En este último caso, se pueden especificar los parámetros utilizar con el argumento params = de render().Hay que tener en cuenta que los valores de los parámetros asignados aquí sobrescribirán sus valores predeterminados si aparacen el YAML. Escribimos los valores entre comillas ya que en este caso deben ser definidos como valores de carácter/cadena.El siguiente comando genera “surveillance_report.Rmd”, especifica un nombre dinámico para el archivo de salida y una carpeta, y proporciona un list() de dos parámetros y sus valores al argumento params =.","code":"\nrmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = list(date = \"2021-04-10\", hospital  = \"Central Hospital\"))"},{"path":"reports-with-r-markdown.html","id":"opción-3-establecer-los-parámetros-mediante-una-interfaz-gráfica-de-usuario","chapter":"40 Informes con R Markdown","heading":"Opción 3: Establecer los parámetros mediante una interfaz gráfica de usuario","text":"Para obtener una experiencia más interactiva, se puede utilizar la interfaz gráfica de usuario (GUI, por sus siglas en ingles) para seleccionar manualmente los valores de los parámetros. Para ello, podemos clicar en el menú desplegable situado junto al botón ‘Knit’ y elegir ‘Knit parameters’.Aparecerá una ventana que te permitirá introducir los valores de los parámetros establecidos en el YAML del documento.Se puede lograr lo mismo través del comando render() especificando params = \"ask\", como se demuestra continuación.Sin embargo, la asignación de valores en esta ventana emergente está sujeta errores y faltas de ortografía. Es posible añadir restricciones los valores que se pueden introducir través de los menús desplegables. Podés hacerlo añadiendo en el YAML especificaciones para cada entrada params:.label: es el título para ese menú desplegable en particularvalue: es el valor predeterminado (inicial)input: establecer select para utilizar un menú desplegablechoices: Indique los valores opcionales en el menú desplegableA continuación, estas especificaciones están escritas para el parámetro hospitalAl procesarlo (con el botón ‘knit parameters’ o con render(), la ventana emergente tendrá opciones desplegables para seleccionarlos.","code":"rmarkdown::render(\n  input = \"surveillance_report.Rmd\",  \n  output_file = stringr::str_glue(\"outputs/Report_{Sys.Date()}.docx\"),\n  params = “ask”)---\ntitle: Surveillance report\noutput: html_document\nparams:\n date: 2021-04-10\n hospital: \n  label: “Town:”\n  value: Central Hospital\n  input: select\n  choices: [Central Hospital, Military Hospital, Port Hospital, St. Mark's Maternity Hospital (SMMH)]\n---"},{"path":"reports-with-r-markdown.html","id":"ejemplo-parametrizado","chapter":"40 Informes con R Markdown","heading":"Ejemplo parametrizado","text":"El siguiente código crea parámetros para date y hospital, que se utilizan en el R Markdown como params$date y params$hospital, respectivamente.En la salida del informe resultante, los datos se filtran al hospital específico, y el título del gráfico se refiere al hospital y la fecha correctos. En este caso utilizamos el archivo “linelist_cleaned.rds”, pero sería especialmente adecuado que la propia lista de casos tuviera también un sello de fecha para alinearse con la fecha parametrizada.Si se procesa esto se obtiene la salida final con la fuente y el diseño predeterminados.","code":""},{"path":"reports-with-r-markdown.html","id":"parametrización-sin-parámetros","chapter":"40 Informes con R Markdown","heading":"Parametrización sin parámetros","text":"Si estás procesando un archivo R Markdown con render() desde un script independiente, puede crear el mismo efecto de parametrización sin usar la funcionalidad params:.Por ejemplo, en el script de R que contiene el comando render(), podés simplemente definir hospital y date como dos objetos R (valores) antes del comando render(). En el R Markdown, sería necesario tener una sección params: en el YAML, y nos referiríamos al objeto date en lugar de params$date y hospital en lugar de params$hospital.Este enfoque significa que se puede procesar con “knit parameters”, ni utilizar la interfaz gráfica, ni incluir opciones de procesamiento dentro de los parámetros. Sin embargo, permite simplificar el código, lo cual puede resultar ventajoso.","code":"\n# This is a R script that is separate from the R Markdown\n\n# define R objects\nhospital <- \"Central Hospital\"\ndate <- \"2021-04-10\"\n\n# Render the R markdown\nrmarkdown::render(input = \"create_output.Rmd\") "},{"path":"reports-with-r-markdown.html","id":"looping-reports","chapter":"40 Informes con R Markdown","heading":"40.7 Informes en bucle","text":"Es posible que queramos ejecutar un informe varias veces, variando los parámetros de entrada, para producir un informe para cada jurisdicción/unidad. Esto puede hacerse utilizando herramientas para la iteración, que se explican en detalle en la página sobre Iteración, bucles y listas. Las opciones incluyen el paquete purrr, o el uso de un loop como se explica continuación.continuación, utilizamos un simple loop para generar un informe de vigilancia para todos los hospitales de interés. Esto se hace con un solo comando (en lugar de cambiar manualmente el parámetro del hospital uno por uno). El comando para generar los informes debe existir en un script separado fuera del informe Rmd. Este script también contendrá objetos definidos para “hacer un bucle” - la fecha de hoy, y un vector de nombres de hospitales para hacer un bucle.continuación, introducimos estos valores uno uno en el comando render() mediante un bucle, que ejecuta el comando una vez por cada valor del vector hospitales. La letra “” representa la posición del índice (del 1 al 4) del hospital que se está utilizando en esa iteración, de modo que “lista_de_hospitales[1]sería \"Hospital Central\". Esta información se suministra en dos lugares en el comandorender()`:Al nombre del archivo, de forma que el nombre del archivo de la primera iteración, si se produce el 10 de abril de 2021, sería “Informe_Hospital Central_2021-04-10.docx”, guardado en la subcarpeta ‘output’ del directorio de trabajo.params = de forma que el Rmd utilice el nombre del hospital internamente siempre que se llame al valor params$hospital (por ejemplo, para filtrar los datos sólo un hospital determinado). En este ejemplo, se crearían cuatro archivos, uno por cada hospital.","code":"\nhospitals <- c(\"Central Hospital\",\n                \"Military Hospital\", \n                \"Port Hospital\",\n                \"St. Mark's Maternity Hospital (SMMH)\") \nfor(i in 1:length(hospitals)){\n  rmarkdown::render(\n    input = \"surveillance_report.Rmd\",\n    output_file = str_glue(\"output/Report_{hospitals[i]}_{Sys.Date()}.docx\"),\n    params = list(hospital  = hospitals[i]))\n}       "},{"path":"reports-with-r-markdown.html","id":"templates","chapter":"40 Informes con R Markdown","heading":"40.8 Plantillas","text":"Utilizando un documento de plantilla que contenga cualquier formato deseado, podés ajustar la estética del archivo de salida Rmd. Podés crear, por ejemplo, un archivo de MS Word o Powerpoint que contenga páginas/diapositivas con las dimensiones, marcas de agua, fondos y fuentes deseadas.","code":""},{"path":"reports-with-r-markdown.html","id":"documentos-en-word","chapter":"40 Informes con R Markdown","heading":"Documentos en Word","text":"Para crear una plantilla, iniciá un nuevo documento de Word (o utiliza uno ya existente con el formato deseado), y editá las fuentes definiendo los Estilos. En el Estilo, los encabezados 1, 2 y 3 se refieren los distintos niveles de encabezado de markdown (# Header 1, ## Header 2 ### Header 3, respectivamente). Cliqueá con el botón derecho en el estilo y selectioná ‘modificar’ para cambiar el formato de la fuente, así como el párrafo (por ejemplo, podés introducir saltos de página antes de ciertos estilos que pueden ayudar con el espaciado). Otros aspectos del documento de Word, como los márgenes, el tamaño de la página, los encabezados, etc., pueden modificarse como un documento de Word normal en el que se trabaja directamente.","code":""},{"path":"reports-with-r-markdown.html","id":"documentos-en-powerpoint","chapter":"40 Informes con R Markdown","heading":"Documentos en Powerpoint","text":"Como en el caso anterior, creá un nuevo conjunto de diapositivas o utiliza un archivo PowerPoint existente con el formato deseado. Para seguir editando, cliqueá en “Ver” y “Patrón de diapositivas”. Desde aquí se puede cambiar la apariencia de la diapositiva “maestra” editando el formato del texto en los cuadros de texto, así como el fondo y las dimensiones del página.Desgraciadamente, la edición de archivos PowerPoint es un poco menos flexible:Un encabezado de primer nivel (# Header 1) se convertirá automáticamente en el título de una nueva diapositiva,El texto del # Header 2 aparecerá como subtítulo, sino como texto dentro del cuadro de texto principal de la diapositiva (menos que encuentre una manera de manipular la vista del Patrón).Los gráficos y las tablas resultantes irán automáticamente nuevas diapositivas. Tendrás que combinarlos, por ejemplo con la función patchwork para combinar ggplots, para que aparezcan en la misma página. Esta entrada del blog trata el uso del paquete patchwork para colocar múltiples imágenes en una diapositiva.En el paquete oficcer  encontrarás una herramienta para trabajar más fondo con las presentaciones de PowerPoint.","code":""},{"path":"reports-with-r-markdown.html","id":"integración-de-plantillas-en-el-yaml","chapter":"40 Informes con R Markdown","heading":"Integración de plantillas en el YAML","text":"Una vez preparada la plantilla, el detalle de la misma puede añadirse en el YAML del Rmd debajo de la línea ‘output’ y debajo de donde se especifica el tipo de documento (que va una línea aparte). Para las plantillas de diapositivas de PowerPoint se puede utilizar reference_doc.Lo más fácil es guardar la plantilla en la misma carpeta en la que está el archivo Rmd (como en el ejemplo siguiente), o en una subcarpeta dentro de ella.","code":"---\ntitle: Surveillance report\noutput: \n word_document:\n  reference_docx: \"template.docx\"\nparams:\n date: 2021-04-10\n hospital: Central Hospital\ntemplate:\n \n---"},{"path":"reports-with-r-markdown.html","id":"formateo-de-archivos-html","chapter":"40 Informes con R Markdown","heading":"Formateo de archivos HTML","text":"Los archivos HTML utilizan plantillas, pero pueden tener los estilos configurados dentro del YAML. Los HTML son documentos interactivos y particularmente flexibles. Aquí cubrimos algunas opciones básicas.Tabla de contenidos: Podemos añadir una tabla de contenidos con toc: true, y también especificar que permanezca visible (“flotante”) al desplazarse, con toc_float: true.Tabla de contenidos: Podemos añadir una tabla de contenidos con toc: true, y también especificar que permanezca visible (“flotante”) al desplazarse, con toc_float: true.Temas: Nos referimos algunos temas prearmados, que provienen de una biblioteca de temas de Bootswatch. En el siguiente ejemplo utilizamos cerulean. Otras opciones son: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex y yeti.Temas: Nos referimos algunos temas prearmados, que provienen de una biblioteca de temas de Bootswatch. En el siguiente ejemplo utilizamos cerulean. Otras opciones son: journal, flatly, darkly, readable, spacelab, united, cosmo, lumen, paper, sandstone, simplex y yeti.Resaltar: Configurando esto se cambia el aspecto del texto resaltado (por ejemplo, el código dentro de los trozos que se muestran). Los estilos disponibles son default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark y textmate.Resaltar: Configurando esto se cambia el aspecto del texto resaltado (por ejemplo, el código dentro de los trozos que se muestran). Los estilos disponibles son default, tango, pygments, kate, monochrome, espresso, zenburn, haddock, breezedark y textmate.aquí un ejemplo de cómo integrar las opciones anteriores en el YAML.continuación se muestran dos ejemplos de salidas HTML ambas con tablas de contenido flotantes pero con diferentes estilos de tema y resaltado seleccionados:","code":"---\ntitle: \"HTML example\"\noutput:\n  html_document:\n    toc: true\n    toc_float: true\n    theme: cerulean\n    highlight: kate\n    \n---"},{"path":"reports-with-r-markdown.html","id":"dynamic-content","chapter":"40 Informes con R Markdown","heading":"40.9 Contenido dinámico","text":"En una salida HTML, el contenido de tu informe puede ser dinámico. continuación, veremos algunos ejemplos:","code":""},{"path":"reports-with-r-markdown.html","id":"tablas-1","chapter":"40 Informes con R Markdown","heading":"Tablas","text":"En un informe HTML, se puede imprimir un dataframe / tibble de manera que el contenido sea dinámico, con filtros y barras de desplazamiento. Hay varios paquetes que ofrecen esta capacidad.Para hacer esto con el paquete DT, como se utiliza en este manual, se puede insertar un trozo de código como este:La función datatable() imprimirá el dataframe proporcionado como una tabla dinámica para el lector. Puedes establecer rownames = FALSE para simplificar el extremo izquierdo de la tabla. filter = \"top\" proporciona un filtro sobre cada columna. En el argumento options() proporciona una lista de otras especificaciones. continuación incluimos dos: pageLength = 5 determina que el número de filas mostrar sea 5 (las filas restantes se pueden ver paginando través de flechas), y scrollX=TRUE habilita una barra de desplazamiento en la parte inferior de la tabla (para visualizar las columnas que se extienden la extrema derecha).Si tu conjunto de datos es muy grande, considerá mostrar sólo las filas superiores envolviendo los datos en head().","code":""},{"path":"reports-with-r-markdown.html","id":"widgets-html","chapter":"40 Informes con R Markdown","heading":"Widgets HTML","text":"Los widgets HTML para R son un tipo especial de paquetes de R que permiten una mayor interactividad utilizando bibliotecas de JavaScript. Puedes incorporarlos en salidas HTML R Markdown.Algunos ejemplos comunes de estos widgets son:Plotly (utilizado en la página de este manual y en la página de Gráficos interactivosvisNetwork (utilizado en la página de Cadenas de transmisión de este manual)Leaflet (Folleto) (utilizado en la página Conceptos básicos de los SIG de este manual)dygraphs (útil para mostrar interactivamente los datos de las series temporales)DT (datatable()) (se utiliza para mostrar tablas dinámicas con filtro, ordenación, etc.)La función ggplotly() de plotly es particularmente fácil de usar. Consúltalo en la sección en la página de Gráficos interactivos.","code":""},{"path":"reports-with-r-markdown.html","id":"resources-33","chapter":"40 Informes con R Markdown","heading":"40.10 Recursos","text":"Podés encontrar más información en:https://bookdown.org/yihui/rmarkdown/https://rmarkdown.rstudio.com/articles_intro.htmlAquí encontras una buena explicación de markdown vs knitr vs Rmarkdown: https://stackoverflow.com/questions/40563479/relationship--r-markdown-knitr-pandoc--bookdown","code":""},{"path":"organizing-routine-reports.html","id":"organizing-routine-reports","chapter":"41 Organización de informes rutinarios","heading":"41 Organización de informes rutinarios","text":"Esta página cubre el paquete reportfactory, que es un complemento para el uso de R Markdown para los informes.Este paquete facilita la ejecucion de reportes de rutina, especialmente la compilación de múltiples archivos R Markdown y la organización de sus resultados. En esencia, proporciona una “fábrica” desde la que se pueden ejecutar los informes R Markdown, obtener automáticamente carpetas con fecha y hora para guardar los archivos de salida, y generar un control de versiones “ligero”.reportfactory es uno de los paquetes desarrollados por RECON (R Epidemics Consortium). Aquí está su sitio web y su Github.","code":""},{"path":"organizing-routine-reports.html","id":"preparation-34","chapter":"41 Organización de informes rutinarios","heading":"41.1 Preparación","text":"","code":""},{"path":"organizing-routine-reports.html","id":"cargar-paquetes-29","chapter":"41 Organización de informes rutinarios","heading":"Cargar paquetes","text":"En RStudio, instalá la última versión del paquete reportfactory desde Github.Podés hacerlo través del paquete pacman con p_load_current_gh() que forzará la instalación de la última versión desde Github. Proporcioná la cadena de caracteres “reconverse/reportfactory”, que especifica la organización de Github (reconverse) y el repositorio (reportfactory). También puede utilizar install_github() del paquete remotes, como alternativa.","code":"\n# Instalá y cargá la última versión del paquete desde Github\npacman::p_load_current_gh(\"reconverse/reportfactory\")\n#remotes::install_github(\"reconverse/reportfactory\") # alternativa"},{"path":"organizing-routine-reports.html","id":"new-factory","chapter":"41 Organización de informes rutinarios","heading":"41.2 Nueva fábrica","text":"Para crear una nueva fábrica, ejecutá la función new_factory(). Esto creará una nueva carpeta de proyecto R autocontenida con las siguientes características predeterminadas:La fábrica se añadirá tu directorio de trabajoEl nombre del proyecto R de la fábrica será “new_factory.Rproj”Tu sesión de RStudio se “trasladará” este proyecto RMirando dentro de la fábrica, se puede ver que las subcarpetas y algunos archivos se han creado de manera automática.La carpeta report_sources contendrá tus scripts R Markdown, que generan sus informesLa carpeta de outputs contendrá el informe de salida (por ejemplo, HTML, Word, PDF, etc.)La carpeta de scripts puede utilizarse para guardar otros scripts de R (por ejemplo, los que se convican en tus scripts de Rmd)La carpeta de data puede utilizarse para guardar tus datos (se incluyen las subcarpetas “raw” (datos brutos) y “clean” (datos limpios))Un archivo ., para que puedas utilizar el paquete para convocar los archivos de las subcarpetas gracias su relación con esta carpeta raíz (véase la página de proyectos en R para más detalles)Se ha creado un archivo gitignore en caso de que se vincule este proyecto R un repositorio de Github (ver [Control de versiones y colaboración con Github])Un archivo README vacío, en caso de que uses un repositorio de GithubPRECAUCIÓN:: dependiendo de la configuración de tu ordenador, los archivos como “.” pueden existir pero estar ocultos.continuación mencionamos configuraciones predeterminadas que tal vez quieras ajustar con el comando new_factory():factory = Proporciona un nombre para la carpeta de fábrica (por defecto es “new_factory”)path = Designa una ruta de archivo para la nueva fábrica (por defecto es el directorio de trabajo)report_sources = Proporciona un nombre alternativo para la subcarpeta que contiene los scripts R Markdown (por defecto es “report_sources”)outputs = Proporciona un nombre alternativo para la carpeta que contiene los resultados del informe (por defecto es “outputs”)Ver ?new_factory para ver una lista completa de los argumentos.Cuando creás la nueva fábrica, tu sesión de R se transfiere al nuevo proyecto R, por lo que debés cargar de nuevo el paquete reportfactory.Ahora podés ejecutar el comando factory_overview() para ver la estructura interna (todas las carpetas y archivos) de la fábrica.El siguiente “árbol” de las carpetas y archivos de la fábrica se imprime en la consola de R. Fijáte que en la carpeta “data” hay subcarpetas para los datos “raw” y “clean”, y datos CSV de ejemplo. También hay “example_report.Rmd” en la carpeta “report_sources”.","code":"\n# Este comando creará una fabrica en el directorio de trabajo\nnew_factory()\npacman::p_load(reportfactory)\nfactory_overview()            # muestra la estructura de la fábrica en la consola"},{"path":"organizing-routine-reports.html","id":"create-a-report","chapter":"41 Organización de informes rutinarios","heading":"41.3 Crear un informe","text":"Desde la fábrica del proyecto R, creá un informe R Markdown como lo harías normalmente, y guardálo en la carpeta “report_sources”. Consultá la página de R Markdown para obtener instrucciones. modo de ejemplo, hemos añadido lo siguiente la fábrica:Un nuevo script de R markdown titulado “daily_sitrep.Rmd”, guardado dentro de la carpeta “report_sources”.Datos para el informe (“linelist_cleaned.rds”) guardados en la subcarpeta “clean” dentro de la carpeta “data”Ejecutando factory_overview() podemos ver el archivo R Markdown en la carpeta “report_sources” y el archivo de datos en la carpeta de datos “clean” (resaltado):continuación mostramos una captura de pantalla del comienzo del archivo de Markdown “daily_sitrep.Rmd”. Podés ver que el formato de salida está configurado para ser HTML, través de la cabecera YAML output: html_document.En este sencillo script, hay comandos para:Cargar los paquetes necesariosImportar los datos del listado de casos utilizando una ruta de archivo del paquete (lea más en la página sobre Importación y exportación)Imprimir una tabla de resumen de casos, y exportarla con export() como un archivo .csvImprimir una epicurva, y exportarla con ggsave() como un archivo .pngPodés revisar la lista de informes R Markdown en la carpeta “report_sources” con este comando:","code":"\nlinelist <- import(here(\"data\", \"clean\", \"linelist_cleaned.rds\"))\nlist_reports()"},{"path":"organizing-routine-reports.html","id":"compile","chapter":"41 Organización de informes rutinarios","heading":"41.4 Compilar","text":"En una fábrica de informes, “compilar” un informe de R Markdown implica que se ejecutará el script .Rmd y se producirá la salida (como se especifica en el script YAML, por ejemplo, como HTML, Word, PDF, etc.).La fábrica creará automáticamente una carpeta con fecha y hora para las salidas en la carpeta “outputs”.El informe de salida y los archivos generados por el script (por ejemplo, csv, png, xlsx) se guardarán en esta carpeta. Además, el propio script Rmd se guardará en esta carpeta, así tendrás un registro de esa versión del script.Esto contrasta con el comportamiento normal de un R Markdown “tejido”, que guarda las salidas en la ubicación del script Rmd. Este comportamiento por defecto puede resultar en carpetas abarrotadas y desordenadas. El objetivo de la fábrica es mejorar la organización de archivos cuando uno necesita ejecutar informes con frecuencia.","code":""},{"path":"organizing-routine-reports.html","id":"compilar-por-nombre","chapter":"41 Organización de informes rutinarios","heading":"Compilar por nombre","text":"Podés compilar un informe específico ejecutando compile_reports() y proporcionando el nombre del script Rmd (sin la extensión .Rmd) reports =. Para simplificar, podés omitir reports = y simplemente escribir el nombre R Markdown entre comillas, como se indica continuación.Este comando compilaría sólo el informe “daily_sitrep.Rmd”, guardando el informe de HTML, y las exportaciones de la tabla de .csv y la epicurva de .png en una subcarpeta con fecha y hora específicas, dentro de la carpeta “outputs”.Tené en cuenta que si proporcionás la extensión .Rmd, debés escribir la extensión tal como aparece en el nombre del archivo (.rmd vs. .Rmd).También hay que tener en cuenta que, al compilar, es posible que aparezcan temporariamente varios archivos en la carpeta “report_sources”, pero pronto desaparecerán al ser transferidos la carpeta “outputs”.","code":""},{"path":"organizing-routine-reports.html","id":"compilación-por-número","chapter":"41 Organización de informes rutinarios","heading":"Compilación por número","text":"También se puede especificar el script Rmd compilar proporcionando un número o vector de números reports =. Los números deben alinearse con el orden en que aparecen los informes cuando se ejecuta list_reports().","code":"\n# Compilar el segundo y el cuarto Rmd en la carpeta \"report_sources\"\ncompile_reports(reports = c(2, 4))"},{"path":"organizing-routine-reports.html","id":"compilar-todos","chapter":"41 Organización de informes rutinarios","heading":"Compilar todos","text":"Puedes compilar todos los informes R Markdown en la carpeta “report_sources” usando el argumento reports = TRUE.","code":""},{"path":"organizing-routine-reports.html","id":"compilar-desde-la-subcarpeta","chapter":"41 Organización de informes rutinarios","heading":"Compilar desde la subcarpeta","text":"Podés añadir subcarpetas la carpeta “report_sources”. Para ejecutar un informe R Markdown desde una subcarpeta, simplemente proporcioná el nombre de la carpeta subfolder =. continuación se muestra un ejemplo de código para compilar un informe Rmd localizado en una subcarpeta de “report_sources”.Podés compilar todos los informes Rmd dentro de una subcarpeta proporcionando el nombre de la subcarpeta reports =, con una barra al final, como se indica continuación.","code":"\ncompile_reports(\n     reports = \"summary_for_partners.Rmd\",\n     subfolder = \"for_partners\")\ncompile_reports(reports = \"for_partners/\")"},{"path":"organizing-routine-reports.html","id":"parametrización","chapter":"41 Organización de informes rutinarios","heading":"Parametrización","text":"Como indicamos en la página sobre Informes con R Markdown, podés ejecutar informes con parámetros especificados. Podés pasar estos parámetros como una lista compile_reports() través del argumento params =. Por ejemplo, en este informe ficticio hay tres parámetros proporcionados los informes de R Markdown.","code":"\ncompile_reports(\n  reports = \"daily_sitrep.Rmd\",\n  params = list(most_recent_data = TRUE,\n                region = \"NORTHERN\",\n                rates_denominator = 10000),\n  subfolder = \"regional\"\n)"},{"path":"organizing-routine-reports.html","id":"utilizar-un-run-file","chapter":"41 Organización de informes rutinarios","heading":"Utilizar un “run-file”","text":"Si tenés que ejecutar varios informes, podés crear un script de R que contenga todos los comandos compile_reports(). Un usuario puede simplemente ejecutar todos los comandos en este script de R y todos los informes se compilarán. Puedes guardar este “archivo de ejecución” (run file) en la carpeta “scripts”.","code":""},{"path":"organizing-routine-reports.html","id":"outputs-1","chapter":"41 Organización de informes rutinarios","heading":"41.5 Salidas","text":"Después de haber compilado los informes unas cuantas veces, la carpeta “outputs” tendría este aspecto (los resaltados se han añadido para mayor claridad):Dentro de “outputs”, se han creado subcarpetas para cada informe RmdDentro de ellas, se han creado otras subcarpetas para cada compilación única\nEstán marcados con fecha y hora (“2021-04-23_T11-07-36” significa 23 de abril de 2021 las 11:07:36)\nPodés editar el formato de la fecha/hora. Ver ?compile_reports\nEstán marcados con fecha y hora (“2021-04-23_T11-07-36” significa 23 de abril de 2021 las 11:07:36)Podés editar el formato de la fecha/hora. Ver ?compile_reportsDentro de cada carpeta compilada de fecha/hora, se almacena el resultado del informe (por ejemplo, HTML, PDF, Word) junto con el script Rmd (¡control de versiones!) y cualquier otro archivo exportado (por ejemplo, table.csv, epidemic_curve.png)Esta es una vista dentro de una de las carpetas con fecha/hora, para el informe “daily_sitrep”. La ruta del archivo está resaltada en amarillo para enfatizar.Por último, continuación mostramos una captura de pantalla del informe de salida de HTML .Podés utilizar list_outputs() para ver una lista de las salidas.","code":""},{"path":"organizing-routine-reports.html","id":"miscellaneous-1","chapter":"41 Organización de informes rutinarios","heading":"41.6 Miscelánea","text":"","code":""},{"path":"organizing-routine-reports.html","id":"knit","chapter":"41 Organización de informes rutinarios","heading":"Knit","text":"Si querés “procesar” uno de tus informes R Markdown cliqueando el botón “Knit” podés hacerlo. En este caso, por defecto, las salidas aparecerán en la carpeta donde se guarda el Rmd - la carpeta “report_sources”. En versiones anteriores de reportfactory, la presencia de cualquier archivo que sea Rmd en la carpeta “report_sources” impediría la compilación, pero esto ya es así. Es posible ejecutar compile_reports() y se producirá ningún error.","code":""},{"path":"organizing-routine-reports.html","id":"scripts-1","chapter":"41 Organización de informes rutinarios","heading":"Scripts","text":"Te recomendamos utilizar la carpeta “scripts” para almacenar “archivos de ejecución” o scripts .R que se originan en tus scripts .Rmd. Consultá la página sobre R Markdown para obtener consejos sobre cómo estructurar tu código en varios archivos.","code":""},{"path":"organizing-routine-reports.html","id":"extras","chapter":"41 Organización de informes rutinarios","heading":"Extras","text":"Con reportfactory, podés utilizar la función list_deps() para listar todos los paquetes requeridos en todos los informes de toda la fábrica.Con reportfactory, podés utilizar la función list_deps() para listar todos los paquetes requeridos en todos los informes de toda la fábrica.Hay un paquete de acompañamiento en desarrollo llamado rfextras que ofrece más funciones de ayuda para asistirte en la construcción de informes, tales como:\nload_scripts() - carga todos los scripts .R en una carpeta determinada (la carpeta “scripts” por defecto)\nfind_latest()- encuentra la última versión de un archivo (por ejemplo, el último conjunto de datos)\nHay un paquete de acompañamiento en desarrollo llamado rfextras que ofrece más funciones de ayuda para asistirte en la construcción de informes, tales como:load_scripts() - carga todos los scripts .R en una carpeta determinada (la carpeta “scripts” por defecto)find_latest()- encuentra la última versión de un archivo (por ejemplo, el último conjunto de datos)","code":""},{"path":"organizing-routine-reports.html","id":"resources-34","chapter":"41 Organización de informes rutinarios","heading":"41.7 Recursos","text":"Consultá la página de Github del paquete reportfactoryConsultá la página de Github del paquete rfextras","code":""},{"path":"dashboards-with-r-markdown.html","id":"dashboards-with-r-markdown","chapter":"42 Dashboards con R Markdown","heading":"42 Dashboards con R Markdown","text":"Esta página cubrirá el uso básico del paquete flexdashboard. Este paquete permite formatear fácilmente la salida de R Markdown como un dashboard (panel de control o cuadro de mandos) y páginas. El contenido del panel puede ser texto, figuras/tablas estáticas o gráficos interactivos.Ventajas de flexdashboard:Requiere una codificación mínima de R estándar - con muy poca práctica puedes crear rápidamente un panel de controlEl Dashboard puede enviarse por correo electrónico los compañeros como un archivo HTML autónomo, sin necesidad de servidorPuedes combinar flexdashboard con shiny, ggplotly y otros “widgets html” para añadir interactividadDesventajas de flexdashboard:Menos personalización en comparación con el uso de Shiny para crear un panel de controlEn la sección de Recursos se pueden encontrar tutoriales muy completos sobre el uso de flexdashboard que sirvieron de base esta página. continuación describimos las características principales y damos un ejemplo de construcción de un dashboard para explorar un brote, utilizando los datos de linelist.","code":""},{"path":"dashboards-with-r-markdown.html","id":"preparation-35","chapter":"42 Dashboards con R Markdown","heading":"42.1 Preparación","text":"","code":""},{"path":"dashboards-with-r-markdown.html","id":"cargar-paquetes-30","chapter":"42 Dashboards con R Markdown","heading":"Cargar paquetes","text":"En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.","code":"\npacman::p_load(\n  rio,             # data import/export     \n  here,            # locate files\n  tidyverse,       # data management and visualization\n  flexdashboard,   # dashboard versions of R Markdown reports\n  shiny,           # interactive figures\n  plotly           # interactive figures\n)"},{"path":"dashboards-with-r-markdown.html","id":"importar-datos-24","chapter":"42 Dashboards con R Markdown","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si quieres seguir el proceso, clica para descargar linelist “limpio” (como archivo .rds). Importa los datos con la función import() del paquete rio (maneja muchos tipos de archivos como .xlsx, .csv, .rds - mira la página de importación y exportación para más detalles).continuación se muestran las primeras 50 filas del listado.","code":"\n# import the linelist\nlinelist <- import(\"linelist_cleaned.rds\")"},{"path":"dashboards-with-r-markdown.html","id":"create-new-r-markdown","chapter":"42 Dashboards con R Markdown","heading":"42.2 Crear un nuevo R Markdown","text":"Una vez instalado el paquete, crea un nuevo archivo R Markdown clicando en File > New file > R Markdown.En la ventana que se abre, selecciona “Template” y selecciona la plantilla “Flex Dashboard”. continuación, pedirá que nombres el documento. En el ejemplo de esta página, nombraremos nuestro R Markdown como “outbreak_dashboard.Rmd”.","code":""},{"path":"dashboards-with-r-markdown.html","id":"the-script","chapter":"42 Dashboards con R Markdown","heading":"42.3 El script","text":"El script es un script de R Markdown, y por lo tanto tiene los mismos componentes y organización que se describen en la página sobre Informes con R Markdown. Volvemos revisar brevemente estos y destacamos las diferencias con otros formatos de salida de R Markdown.","code":""},{"path":"dashboards-with-r-markdown.html","id":"yaml","chapter":"42 Dashboards con R Markdown","heading":"YAML","text":"En la parte superior del script está la cabecera “YAML”. Esta debe comenzar con tres guiones --- y debe cerrarse con tres guiones ---. Los parámetros YAML vienen en pares key:value. La sangría y la colocación de los dos puntos en YAML es importante - los pares key:value están separados por dos puntos (¡por signos de igualdad!).El YAML debe comenzar con los metadatos del documento. El orden de estos parámetros YAML primarios (sin sangría) importa. Por ejemplo:Puedes utilizar código R en los valores YAML poniéndolo como código en línea (precedido por r entre comillas) pero también entre comillas (véase más arriba para la fecha).Un parámetro YAML necesario es output:, que especifica el tipo de archivo que se producirá (por ejemplo, html_document, pdf_document, word_document, o powerpoint_presentation). En el caso de flexdashboard el valor de este parámetro es un poco confuso - debe establecerse como output:flexdashboard::flex_dashboard. Ten en cuenta los dos puntos simples y dobles, y el guión bajo. Este parámetro de salida YAML suele ir seguido de dos puntos adicionales y de subparámetros con sangría (ver parámetros orientation: y vertical_layout: más abajo).Como se muestra arriba, se utilizan sangrías (2 espacios) para los subparámetros. En este caso, olvides poner dos puntos adicionales después del primario, como key:value:.Si procede, los valores lógicos deben indicarse en YAML en minúsculas (true, false, null). Si los dos puntos forman parte del valor (por ejemplo, en el título), escribe el valor entre comillas. Revisa los ejemplos en las secciones siguientes.","code":"\ntitle: \"My document\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\ntitle: \"My dashboard\"\nauthor: \"Me\"\ndate: \"`r Sys.Date()`\"\noutput:\n  flexdashboard::flex_dashboard:\n    orientation: rows\n    vertical_layout: scroll"},{"path":"dashboards-with-r-markdown.html","id":"trozos-de-código","chapter":"42 Dashboards con R Markdown","heading":"Trozos de código","text":"Un script de R Markdown puede contener múltiples “trozos” de código (Chunk) - estas son áreas del script donde se puede escribir código R de varias líneas y funcionan como mini scripts R.Los trozos de código se crean con tres signos de acento grave (```) y corchetes con una “r” minúscula dentro. El fragmento se cierra con otros tres acentos graves (acento atrás). Puedes crear un nuevo fragmento escribiéndolo tú mismo, utilizando el atajo de teclado “Ctrl + Alt + ” (o Cmd + Shift + r en Mac), o clicando en el icono verde ‘insertar un nuevo fragmento de código’ en la parte superior de tu editor de scripts. continuación se ofrecen muchos ejemplos.","code":""},{"path":"dashboards-with-r-markdown.html","id":"texto-narrativo","chapter":"42 Dashboards con R Markdown","heading":"Texto narrativo","text":"Fuera de un “trozo” de código R, puedes escribir texto narrativo. Como se describe en la página sobre Informes con R Markdown, puedes poner el texto en cursiva rodeándolo con un asterisco (*), o en negrita rodeándolo con dos asteriscos (**). Recuerda que las viñetas y los esquemas de numeración son sensibles las nuevas líneas, la sangría y terminar una línea con dos espacios.También puedes insertar código R en línea en el texto, como se describe en la página Informes con R Markdown, rodeando el código con puntos suspensivos y comenzando el comando con “r”: ` 1+1` (véase el ejemplo con la fecha anterior).","code":""},{"path":"dashboards-with-r-markdown.html","id":"encabezados","chapter":"42 Dashboards con R Markdown","heading":"Encabezados","text":"Los diferentes niveles de encabezamiento se establecen con diferentes números de símbolos hash, como se describe en la página Informes con R Markdown.En flexdashboard, un encabezado primario (#) crea una “página” del dashboard. Los encabezados de segundo nivel (##) crean una columna o una fila dependiendo de su parámetro orientation: (ver detalles más abajo). Los encabezados de tercer nivel (###) crean paneles para gráficos, diagramas, tablas, texto, etc.","code":"# Título de primer nivel (página)\n\n## Título de segundo nivel (fila o columna)\n\n### Título de tercer nivel (panel para gráfico, diagrama, etc.)"},{"path":"dashboards-with-r-markdown.html","id":"section-attributes","chapter":"42 Dashboards con R Markdown","heading":"42.4 Atributos de la sección","text":"Al igual que en un R Markdown normal, puedes especificar los atributos que se aplicarán las partes del cuadro de mando incluyendo las opciones key=value después de un encabezado, entre llaves { }. Por ejemplo, en un típico informe HTML R Markdown podrías organizar los sub-encabezados en pestañas con ## heading {.tabset}.Ten en cuenta que estos atributos se escriben después de un título en una parte de texto del script. Son diferentes las opciones de knitr insertadas dentro en la parte superior de los trozos de código R, como .height =.Los atributos de sección específicos de flexdashboard incluyen:{data-orientation=} Establece la orientación de las filas rows o de las columnas columns.{orientación de los datos=} . Si tu dashboard tiene varias páginas, añade este atributo cada una de ellas para indicar la orientación (se explica con más detalle en la sección de diseño).{data-width=} y {data-height=} establecen el tamaño relativo de los gráficos, columnas y filas dispuestos en la misma dimensión (horizontal o vertical). Los tamaños absolutos se ajustan para llenar mejor el espacio en cualquier dispositivo de visualización gracias al motor flexbox.\nLa altura de las figuras también depende de si se establece el parámetro YAML vertical_layout: fill vertical_layout: scroll. Si se establece en scroll, la altura de la figura reflejará la opción tradicional fig.height = en el fragmento de código de R.\nConsulta la documentación completa sobre el tamaño en el sitio web de flexdashboard\nLa altura de las figuras también depende de si se establece el parámetro YAML vertical_layout: fill vertical_layout: scroll. Si se establece en scroll, la altura de la figura reflejará la opción tradicional fig.height = en el fragmento de código de R.Consulta la documentación completa sobre el tamaño en el sitio web de flexdashboard{.hidden} Utiliza esto para excluir una página específica de la barra de navegación{data-navbar=} Utilízalo en un encabezado nivel de página para anidarlo dentro de un menú desplegable de la barra de navegación. Indica el nombre (entre comillas) del menú desplegable. Véase el ejemplo siguiente.","code":""},{"path":"dashboards-with-r-markdown.html","id":"layout","chapter":"42 Dashboards con R Markdown","heading":"42.5 Diseño","text":"Ajusta el diseño de tu panel de control de las siguientes maneras:Añadir páginas, columnas/filas y gráficos con encabezados R Markdown (por ejemplo, #, ## o ###)Ajustar la orientación de los parámetros YAML: orientation: rows o columnsEspecificar si el diseño llena el navegador o permite el desplazamientoAñadir pestañas un título de sección concreto","code":""},{"path":"dashboards-with-r-markdown.html","id":"páginas","chapter":"42 Dashboards con R Markdown","heading":"Páginas","text":"Los encabezados de primer nivel (#) en el R Markdown representarán las “páginas” del cuadro de mando. Por defecto, las páginas aparecerán en una barra de navegación lo largo de la parte superior del dashboard.Puedes agrupar las páginas en un “menú” dentro de la barra de navegación superior añadiendo el atributo {data-navmenu=} al título de la página. Ten cuidado: incluyas espacios alrededor del signo de igualdad, de lo contrario funcionará.Esto es lo que produce el script:También puedes convertir una página o una columna en una “barra lateral” en el lado izquierdo del panel de control añadiendo el atributo {.sidebar}. Puede contener texto (visible desde cualquier página) o, si integrado una interactividad Shiny, puede ser útil para contener controles de entrada del usuario, como deslizadores o menús desplegables.Esto es lo que produce el script:","code":""},{"path":"dashboards-with-r-markdown.html","id":"orientación","chapter":"42 Dashboards con R Markdown","heading":"Orientación","text":"Añade el parámetro orientation: yaml para indicar cómo deben interpretarse los encabezados de segundo nivel (##) de R Markdown - como orientation: columns o orientation: rows.Los encabezados de segundo nivel (##) se interpretarán como nuevas columnas o filas en función de este ajuste de orientación.Si estableces orientation: columns, las cabeceras de segundo nivel crearán nuevas columnas en el dashboard. El siguiente dashboard tiene una página, que contiene dos columnas, con un total de tres paneles. Puedes ajustar el ancho relativo de las columnas con {data-width=} como se muestra continuación.Esto es lo que produce el script:Si estableces orientation: rows, los encabezados de segundo nivel crearán nuevas filas en lugar de columnas. continuación se muestra el mismo script que el anterior, pero con orientation: rows para que los encabezados de segundo nivel produzcan filas en lugar de columnas. Puedes ajustar la altura relativa de las filas con {data-height=} como se muestra continuación.Esto es lo que produce el script:Si tu dashboard tiene varias páginas, puedes designar la orientación para cada página específica añadiendo el atributo {data-orientation=} la cabecera de cada página (especifica rows o columns sin comillas).","code":""},{"path":"dashboards-with-r-markdown.html","id":"pestañas","chapter":"42 Dashboards con R Markdown","heading":"Pestañas","text":"Puedes dividir el contenido en pestañas con el atributo {.tabset}, como en otras salidas HTML R Markdown.Simplemente añade este atributo después del título deseado. Los subtítulos bajo ese encabezado se mostrarán como pestañas. Por ejemplo, en el script de ejemplo que aparece continuación, la columna 2 de la derecha (##) se modifica para que la curva epidémica y los paneles de la tabla (###) se muestren en pestañas.Puedes hacer lo mismo con las filas si su orientación es de filas.Esto es lo que produce el script:","code":""},{"path":"dashboards-with-r-markdown.html","id":"adding-content","chapter":"42 Dashboards con R Markdown","heading":"42.6 Añadir contenido","text":"Comencemos construir un panel de control. Nuestro sencillo panel de control tendrá 1 página, 2 columnas y 4 paneles. Construiremos los paneles pieza por pieza para la demostración.Puedes incluir fácilmente salidas estándar de R, como texto, ggplots y tablas (véase la página Tablas para presentaciones). Simplemente codifícalos dentro de un fragmento de código R como lo harías con cualquier otro script de R Markdown.Nota: puedes descargar el script Rmd terminado y el resultado del Dashboard en HTML - ver la página descargando el manual y los datos.","code":""},{"path":"dashboards-with-r-markdown.html","id":"texto-1","chapter":"42 Dashboards con R Markdown","heading":"Texto","text":"Puedes escribir el texto de Markdown e incluir el código en línea como para cualquier otra salida de R Markdown. Consulta la página Informes con R Markdown para obtener más detalles.En este dashboard incluimos un panel de texto resumido que incluye un texto dinámico que muestra la última fecha de hospitalización y el número de casos notificados en el brote.","code":""},{"path":"dashboards-with-r-markdown.html","id":"tablas-2","chapter":"42 Dashboards con R Markdown","heading":"Tablas","text":"Puedes incluir trozos de código R que impriman salidas como tablas. Pero la salida se verá mejor y responderá al tamaño de la ventana si utilizas la función kable() de knitr para mostrar las tablas. Las funciones de flextable pueden producir tablas acortadas / cortadas.Por ejemplo, continuación alimentamos linelist() través de un comando count() para producir una tabla resumen de casos por hospital. Finalmente, la tabla se enlaza knitr::kable() y el resultado tiene una barra de desplazamiento la derecha. Puedes leer más sobre la personalización de la tabla con kable() y kableExtra aquí.Esto es lo que produce el script:Si deseas mostrar una tabla dinámica que permita al usuario filtrar, ordenar y/o clicar través de las “páginas” del dataframe, utiliza el paquete DT y su función datatable(), como en el código siguiente.En el código de ejemplo que sigue, se imprime linelist del dataframe. Se puede establecer rownames = FALSE para conservar el espacio horizontal, y filter = \"top\" para tener filtros en la parte superior de cada columna. Se puede proporcionar una lista de otras especificaciones options =. continuación, establecemos pageLength = para que aparezcan 5 filas y scrollX = para que el usuario pueda utilizar una barra de desplazamiento en la parte inferior para desplazarse horizontalmente. El argumento class = 'white-space: nowrap' asegura que cada fila sea sólo una línea (varias líneas). Puedes consultar otros argumentos y valores posibles aquí o introduciendo ?datatable","code":"\nDT::datatable(linelist, \n              rownames = FALSE, \n              options = list(pageLength = 5, scrollX = TRUE), \n              class = 'white-space: nowrap' )"},{"path":"dashboards-with-r-markdown.html","id":"gráficos","chapter":"42 Dashboards con R Markdown","heading":"Gráficos","text":"Puedes imprimir gráficos en un panel de control como lo harías en un script de R. En nuestro ejemplo, utilizamos el paquete incidence2 para crear una “epicurva” por grupo de edad con dos simples comandos (véase la página de curvas epidémicas). Sin embargo, podrías utilizar ggplot() e imprimir un gráfico de la misma manera.Esto es lo que produce el script:","code":""},{"path":"dashboards-with-r-markdown.html","id":"gráficos-interactivos","chapter":"42 Dashboards con R Markdown","heading":"Gráficos interactivos","text":"También puedes pasar un ggplot estándar u otro objeto de gráfico ggplotly() del paquete plotly (véase la página de gráficos interactivos). Esto hará que el gráfico sea interactivo, permitirá al lector hacer un “zoom”, y mostrará sobre el dashboard el valor de cada punto de datos (en este escenario el número de casos por semana y el grupo de edad en la curva).Esto es lo que parece en el dashboard (gif). Esta funcionalidad interactiva seguirá funcionando incluso si envías por correo electrónico el Dashboard como un archivo estático (en línea en un servidor).","code":"\nage_outbreak <- incidence(linelist, date_onset, \"week\", groups = age_cat)\nplot(age_outbreak, fill = age_cat, col_pal = muted, title = \"\") %>% \n  plotly::ggplotly()"},{"path":"dashboards-with-r-markdown.html","id":"widgets-html-1","chapter":"42 Dashboards con R Markdown","heading":"Widgets HTML","text":"Los widgets HTML para R son un tipo especial de paquetes R que aumentan la interactividad utilizando bibliotecas JavaScript. Se pueden incrustar en salidas R Markdown (como un flexdashboard) y en dashboards de Shiny.Algunos ejemplos comunes de estos widgets son:Plotly (utilizado en la página de este manual y en la página de Plots interativos)visNetwork (utilizado en la página de cadenas de transmisión de este manual)Leaflet (utilizado en la página conceptos básicos de los SIG de este manual)dygraphs (útil para mostrar interactivamente los datos de las series temporales)DT (datatable()) (utilizado para mostrar tablas dinámicas con filtro, ordenación, etc.)continuación mostramos la adición de una cadena de transmisión de epidemias que utiliza visNetwork al dashboard. El guión muestra sólo el nuevo código añadido la sección “Columna 2” del script R Markdown. Puedes encontrar el código en la página de cadenas de transmisión de este manual.Esto es lo que produce el script:","code":""},{"path":"dashboards-with-r-markdown.html","id":"code-organization","chapter":"42 Dashboards con R Markdown","heading":"42.7 Organización del código","text":"Puedes elegir tener todo el código dentro del script de R Markdown flexdashboard. Alternativamente, para tener un script de dashboard más limpio y conciso, puedes elegir llamar al código/figuras que están alojadas o creadas en scripts R externos. Esto se describe con mayor detalle en la página Informes con R Markdown.","code":""},{"path":"dashboards-with-r-markdown.html","id":"shiny-1","chapter":"42 Dashboards con R Markdown","heading":"42.8 Shiny","text":"La integración del paquete R shiny puede hacer que tus Dashboards sean aún más reactivos la entrada del usuario. Por ejemplo, puedes hacer que el usuario selecciona una jurisdicción, o un rango de fechas, y hacer que los paneles reaccionen su elección (por ejemplo, filtrar los datos mostrados). Para incrustar la reactividad de shiny en el flexdashboard, sólo tienes que hacer unos pocos cambios en tu script de R Markdown en el flexdashboard.También se puede utilizar shiny para producir aplicaciones/dashboards sin flexdashboard. La página del manual sobre Dashboards con Shiny ofrece una visión general de este enfoque, incluyendo consejos sobre la sintaxis de Shiny, la estructura de los archivos de la aplicación y las opciones para compartir/publicar (incluyendo opciones de servidor gratuito). Esta sintaxis y los consejos generales se traducen también en el contexto de flexdashboard.La incrustación de shiny en el flexdashboard supone, sin embargo, un cambio fundamental en tu flexdashboard. Ya producirá una salida HTML que puedas enviar por correo electrónico y que cualquiera puede abrir y ver. En su lugar, será una “aplicación”. El botón “Knit” en la parte superior del script será reemplazado por un icono “Run document”, que abrirá una instancia del dashboard interactivo localmente en tu ordenador.Para compartir tu panel de control, ahora será necesario que:Enviar el script Rmd al espectador, ellos lo abren en R en su ordenador, y ejecutan la aplicación, oEnviar el script Rmd al espectador, ellos lo abren en R en su ordenador, y ejecutan la aplicación, oLa aplicación/dashboard se aloja en un servidor accesible para el espectadorLa aplicación/dashboard se aloja en un servidor accesible para el espectadorPor lo tanto, la integración de shiny tiene ventajas, pero también complicaciones. Si la facilidad de compartir por correo electrónico es una prioridad y necesitas las capacidades reactivas de shiny, considera la reducida interactividad que ofrece ggplotly() como se ha demostrado anteriormente.continuación damos un ejemplo muy sencillo utilizando el mismo “outbreak_dashboard.Rmd” que el anterior. Una amplia documentación sobre la integración de Shiny en flexdashboard está disponible en línea aquí.","code":""},{"path":"dashboards-with-r-markdown.html","id":"ajustes-2","chapter":"42 Dashboards con R Markdown","heading":"Ajustes","text":"Habilitar shiny en un flexdashboard añadiendo el parámetro YAML runtime: shiny en el mismo nivel de sangría que output:, como se indica continuación:También es conveniente habilitar una “barra lateral” para albergar los widgets de entrada de Shiny que recogerán la información del usuario. Como se explicó anteriormente, crea una columna e indica la opción {.sidebar} para crear una barra lateral en el lado izquierdo. Dentro de esta columna se pueden añadir trozos de texto R que contengan los comandos input de shiny.Si tu aplicación/panel está alojado en un servidor y puede tener varios usuarios simultáneos, nombra el primer trozo de código R como global. Incluye los comandos para importar/cargar tus datos en este chunk. Este chunk con nombre especial es tratado de manera diferente, y los datos importados dentro de él sólo se importan una vez (continuamente) y están disponibles para todos los usuarios. Esto mejora la velocidad de arranque de la aplicación.","code":"---\ntitle: \"Dashboard del brote (demo Shiny)\"\noutput: \n  flexdashboard::flex_dashboard:\n    orientation: columns\n    vertical_layout: fill\nruntime: shiny\n---"},{"path":"dashboards-with-r-markdown.html","id":"ejemplo-trabajado","chapter":"42 Dashboards con R Markdown","heading":"Ejemplo trabajado","text":"Aquí adaptamos el script flexdashboard “outbreak_dashboard.Rmd” para incluir shiny. Añadiremos la capacidad de que el usuario seleccione un hospital de un menú desplegable, y que la curva epidémica refleje sólo los casos de ese hospital, con un título de gráfico dinámico. Hacemos lo siguiente:Añadir runtime: shiny al YAMLRenombrar el chunk de configuración como globalCrear una barra lateral que contenga:\nCódigo para crear un vector de nombres únicos de hospitales\nUn comando selectInput() (menú desplegable Shiny) con la elección de los nombres de los hospitales. La selección se guarda como hospital_choice, la que se puede hacer referencia en código posterior como input$hospital_choice\nCódigo para crear un vector de nombres únicos de hospitalesUn comando selectInput() (menú desplegable Shiny) con la elección de los nombres de los hospitales. La selección se guarda como hospital_choice, la que se puede hacer referencia en código posterior como input$hospital_choiceEl código de la curva epidémica (columna 2) está envuelto dentro de renderPlot({ }), incluyendo:\nUn filtro en los datos que restringe la columna hospital al valor actual de input$hospital_choice\nUn título de gráfico dinámico que incorpora input$hospital_choice\nUn filtro en los datos que restringe la columna hospital al valor actual de input$hospital_choiceUn título de gráfico dinámico que incorpora input$hospital_choiceTen en cuenta que cualquier código que haga referencia un valor de input$ debe estar dentro de una función render({}) (para ser reactiva).Aquí está la parte superior del script, incluyendo el YAML, el chunk global y la barra lateral:Aquí está la Columna 2, con el gráfico de la epicurva reactiva:Y aquí está el Dashboard:","code":""},{"path":"dashboards-with-r-markdown.html","id":"otros-ejemplos","chapter":"42 Dashboards con R Markdown","heading":"Otros ejemplos","text":"Para leer un ejemplo relacionado con la salud de un Shiny-flexdashboard que utiliza la interactividad de Shiny y el widget de mapeo leaflet, consulta este capítulo del libro en línea Geospatial Health Data: Modeling Visualization R-INLA Shiny.","code":""},{"path":"dashboards-with-r-markdown.html","id":"sharing","chapter":"42 Dashboards con R Markdown","heading":"42.9 Compartir","text":"Los Dashboards que contengan elementos Shiny producirán un archivo HTML (.html), que puede enviarse por correo electrónico (si el tamaño lo permite). Esto es útil, ya que puedes enviar el informe del “dashboard” y tener que configurar un servidor para alojarlo como un sitio web.Si incrustado shiny, podrás enviar una salida por correo electrónico, pero puedes enviar el propio script un usuario de R, o alojar el Dashboard en un servidor como se ha explicado anteriormente.","code":""},{"path":"dashboards-with-r-markdown.html","id":"resources-35","chapter":"42 Dashboards con R Markdown","heading":"42.10 Recursos","text":"continuación se pueden encontrar excelentes tutoriales que informaron esta página. Si los revisas, lo más probable es que en una hora puedas tener tu propio Dashboard.https://bookdown.org/yihui/rmarkdown/dashboards.htmlhttps://rmarkdown.rstudio.com/flexdashboard/https://pkgs.rstudio.com/flexdashboard/articles/using.htmlhttps://pkgs.rstudio.com/flexdashboard/articles/examples.html","code":""},{"path":"dashboards-with-shiny.html","id":"dashboards-with-shiny","chapter":"43 Dashboards con Shiny","heading":"43 Dashboards con Shiny","text":"Los Dashboards (cuadros de mando o tableros de control) suelen ser una buena forma de compartir los resultados de los análisis con otras personas. Elaborar un cuadro de mando con shiny requiere un conocimiento relativamente avanzado del lenguaje R, pero ofrece una personalización y unas posibilidades increíbles.Se recomienda que alguien que esté aprendiendo usar Dashboards con shiny tenga buenos conocimientos de transformación y visualización de datos, y se sienta cómodo depurando código y escribiendo funciones. Trabajar con dashboards es intuitivo cuando se empieza, y es difícil de entender veces, pero es una gran habilidad para aprender y se hace mucho más fácil con la práctica.Esta página dará una breve visión general de cómo hacer Dashboards con shiny y sus extensiones. Para un método alternativo de hacer dashboards que es más rápido, más fácil, pero quizás menos personalizable, ver la página sobre flextable (Dashboards R Markdown).","code":""},{"path":"dashboards-with-shiny.html","id":"preparation-36","chapter":"43 Dashboards con Shiny","heading":"43.1 Preparación","text":"","code":""},{"path":"dashboards-with-shiny.html","id":"cargar-paquetes-31","chapter":"43 Dashboards con Shiny","heading":"Cargar paquetes","text":"En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página Fundamentos de R para obtener más información sobre los paquetes de R.Comenzamos instalando el paquete R Shiny:","code":"\npacman::p_load(\"shiny\")"},{"path":"dashboards-with-shiny.html","id":"importar-datos-25","chapter":"43 Dashboards con Shiny","heading":"Importar datos","text":"Si quieres seguir esta página, consulta esta sección del Manual de descarga y datos. Hay enlaces para descargar los scripts de R y los archivos de datos que producen la aplicación final de Shiny.Si intentas reconstruir la aplicación utilizando estos archivos, ten en cuenta la estructura de carpetas del proyecto R que se crea en el transcurso de la demostración (por ejemplo, carpetas para “data” y para “funcs”).","code":""},{"path":"dashboards-with-shiny.html","id":"the-structure-of-a-shiny-app","chapter":"43 Dashboards con Shiny","heading":"43.2 Estructura de una app Shiny","text":"","code":""},{"path":"dashboards-with-shiny.html","id":"estructuras-básicas-de-archivos","chapter":"43 Dashboards con Shiny","heading":"Estructuras básicas de archivos","text":"Para entender Shiny, primero tenemos que entender cómo funciona la estructura de archivos de una aplicación. Deberíamos crear un nuevo directorio antes de empezar. Esto puede hacerse más fácil eligiendo Nuevo proyecto en Rstudio, y eligiendo Aplicación Web Shiny. Esto creará la estructura básica de una aplicación shiny para ti.Al abrir este proyecto, notarás que ya hay un archivo .R llamado app.R. Es esencial que tengamos una de las dos estructuras básicas de archivos:Un archivo llamado app.R, oDos archivos, uno llamado ui.R y el otro server.REn esta página, utilizaremos el primer enfoque de tener un archivo llamado app.R. Aquí hay un script de ejemplo:Si abres este archivo, te darás cuenta de que hay dos objetos definidos: uno llamado ui (interfaz de usuario) y otro llamado server (servidor). Estos objetos deben ser definidos en todas las aplicaciones shiny y son fundamentales para la estructura de la propia aplicación. De hecho, la única diferencia entre las dos estructuras de archivos descritas anteriormente es que en la estructura 1, tanto ui como server están definidos en un solo archivo, mientras que en la estructura 2 están definidos en archivos separados. Nota: también podemos (y deberíamos si tenemos una aplicación más grande) tener otros archivos .R en nuestra estructura que podemos llamar con source() desde nuestra aplicación.","code":"\n# an example of app.R\n\nlibrary(shiny)\n\nui <- fluidPage(\n\n    # Application title\n    titlePanel(\"My app\"),\n\n    # Sidebar with a slider input widget\n    sidebarLayout(\n        sidebarPanel(\n            sliderInput(\"input_1\")\n        ),\n\n        # Show a plot \n        mainPanel(\n           plotOutput(\"my_plot\")\n        )\n    )\n)\n\n# Define server logic required to draw a histogram\nserver <- function(input, output) {\n     \n     plot_1 <- reactive({\n          plot_func(param = input_1)\n     })\n     \n    output$my_plot <- renderPlot({\n       plot_1()\n    })\n}\n\n\n# Run the application \nshinyApp(ui = ui, server = server)"},{"path":"dashboards-with-shiny.html","id":"el-servidor-y-la-interfaz-de-usuario-ui","chapter":"43 Dashboards con Shiny","heading":"El servidor y la Interfaz de Usuario (ui)","text":"continuación, tenemos que entender lo que hacen realmente los objetos server y ui. En pocas palabras, se trata de dos objetos que interactúan entre sí cada vez que el usuario interactúa con la app shiny.El elemento de interfaz de usuario de una aplicación Shiny es, en un nivel básico, el código R que crea una interfaz HTML. Esto significa todo lo que se muestra en la UI de una app. Esto generalmente incluye:“Widgets” - menús desplegables, casillas de verificación, deslizadores, etc. con los que puede interactuar el usuarioGráficos, tablas, etc. - resultados que se generan con el código RAspectos de la navegación de una aplicación: pestañas, paneles, etc.Texto genérico, hipervínculos, etc.Elementos HTML y CSS (abordados más adelante)Lo más importante que hay que entender sobre la UI es que recibe entradas del usuario y muestra salidas del servidor. hay código activo que se ejecute en la UI en ningún momento - todos los cambios que se ven en la UI pasan por el servidor (más o menos). Así que tenemos que hacer nuestros gráficos, descargas, etc en el servidorEl servidor de la app shiny es donde se ejecuta todo el código una vez que la aplicación se inicia. La forma en que esto funciona es un poco confusa. La función del servidor reaccionará efectivamente la interfaz del usuario con la UI, y ejecutará trozos de código en respuesta. Si las cosas cambian en el servidor, estas serán pasadas de vuelta la UI, donde pueden verse los cambios. Es importante destacar que el código en el servidor se ejecutará de forma consecutiva (o es mejor pensarlo así). Básicamente, cada vez que una entrada de la ui afecte un trozo de código en el servidor, éste se ejecutará automáticamente, y se producirá y mostrará esa salida.Probablemente todo esto suene muy abstracto por ahora, así que tendremos que sumergirnos en algunos ejemplos para tener una idea clara de cómo funciona realmente.","code":""},{"path":"dashboards-with-shiny.html","id":"antes-de-empezar-a-crear-una-app","chapter":"43 Dashboards con Shiny","heading":"Antes de empezar a crear una app","text":"Antes de empezar construir una aplicación, es muy útil saber qué quieres construir. Dado que tu interfaz de usuario estará escrita en código, puedes visualizar realmente lo que estás construyendo menos que tengas como objetivo algo específico. Por esta razón, es inmensamente útil mirar muchos ejemplos de aplicaciones Shiny para tener una idea de lo que puedes hacer - ¡incluso mejor si puedes mirar el código fuente detrás de estas aplicaciones! Algunos de los mejores recursos para ello son:La galería de aplicaciones de RstudioUna vez que tengas una idea de lo que es posible, también es útil hacer un mapa de cómo quieres que sea la tuya; puedes hacerlo en papel o en cualquier software de dibujo (PowerPoint, MS paint, etc.). Es útil empezar con algo sencillo para tu primera aplicación. Tampoco hay que avergonzarse de utilizar el código que encuentres en Internet de una buena aplicación como plantilla para tu trabajo: es mucho más fácil que construir algo desde cero.","code":""},{"path":"dashboards-with-shiny.html","id":"building-a-ui","chapter":"43 Dashboards con Shiny","heading":"43.3 Construir una interfaz de usuario","text":"Cuando construimos nuestra aplicación, es más fácil trabajar en la interfaz de usuario (UI) primero para que podamos ver lo que estamos haciendo, y arriesgarnos que la aplicación falle debido cualquier error del servidor. Como se mencionó anteriormente, menudo es bueno utilizar una plantilla cuando se trabaja en la interfaz de usuario. Hay una serie de diseños estándar que se pueden utilizar con shiny que están disponibles en el paquete base de shiny, pero vale la pena señalar que también hay una serie de extensiones del paquete como shinydashboard. Utilizaremos un ejemplo del paquete shiny básico para empezar.Una interfaz de usuario Shiny se define generalmente como una serie de funciones anidadas, en el siguiente ordenUna función que define el diseño general (la más básica es fluidPage(), pero hay más disponibles)Paneles dentro del diseño como:\nuna barra lateral (sidebarPanel())\nun panel “principal” (mainPanel())\nuna pestaña (tabPanel())\nuna “columna” genérica (column())\nuna barra lateral (sidebarPanel())un panel “principal” (mainPanel())una pestaña (tabPanel())una “columna” genérica (column())Widgets y salidas: pueden conferir entradas al servidor (widgets) o salidas del servidor (salidas)\nLos widgets suelen tener el estilo de xxxInput(), por ejemplo, selectInput()\nLas salidas suelen tener el estilo de xxxOutput(), por ejemplo, plotOutput()\nLos widgets suelen tener el estilo de xxxInput(), por ejemplo, selectInput()Las salidas suelen tener el estilo de xxxOutput(), por ejemplo, plotOutput()Vale la pena repetir que estos datos se pueden visualizar fácilmente de forma abstracta, por lo que es mejor ver un ejemplo. Consideremos la posibilidad de crear una aplicación básica que visualice nuestros datos de recuento de instalaciones de malaria por distrito. Estos datos tienen muchos parámetros diferentes, por lo que sería estupendo que el usuario final pudiera aplicar algunos filtros para ver los datos por grupo de edad/distrito según su criterio. Podemos utilizar un diseño Shiny muy simple para empezar - el diseño de la barra lateral. Se trata de un diseño en el que los widgets se colocan en una barra lateral la izquierda, y el gráfico se coloca la derecha.Planifiquemos nuestra aplicación: podemos empezar con un selector que nos permita elegir el distrito donde queremos visualizar los datos, y otro que nos permita visualizar el grupo de edad que nos interesa. Con estos filtros pretendemos mostrar una epicurva que refleje estos parámetros. Para ello necesitamos:Dos menús desplegables que nos permiten elegir el distrito que queremos y el grupo de edad que nos interesa.Un área donde podemos mostrar nuestra epicurva resultante.Esto podría ser algo así:Cuando se ejecuta app.R con el código de interfaz de usuario anterior (sin código activo en la parte del server de app.R), el diseño aparece con el siguiente aspecto: ten en cuenta que habrá ningún gráfico si hay un servidor que lo represente, ¡pero nuestras entradas están funcionando!Esta es una buena oportunidad para discutir cómo funcionan los widgets - nota que cada widget está aceptando un inputId, una label (etiqueta), y una serie de otras opciones que son específicas para el tipo de widget. Este inputId es extremadamente importante - estos son los IDs que se utilizan para pasar la información de la UI al servidor. Por esta razón, deben ser únicos. Deberías hacer un esfuerzo para denominarlos con algo sensato, y específico lo que están interactuando en casos de aplicaciones más grandes.Deberías leer la documentación cuidadosamente para conocer todos los detalles sobre lo que hace cada uno de estos widgets. Los widgets pasarán tipos específicos de datos al servidor dependiendo del tipo de widget, y esto debe entenderse completamente. Por ejemplo, selectInput() pasará un dato de tipo carácter al servidor:Si seleccionamos Spring para el primer widget aquí, pasará el objeto carácter \"Spring\" al servidor.Si seleccionamos dos elementos del menú desplegable, aparecerán como un vector de caracteres (por ejemplo, c(\"Primavera\", \"Bolo\")).Otros widgets pasarán diferentes tipos de objetos al servidor. Por ejemplo:numericInput() pasará un objeto de tipo numérico al servidorcheckboxInput() pasará un objeto de tipo lógico al servidor (TRUE o FALSE)También vale la pena tener en cuenta el nombre del vector que usaremos para los datos de edad aquí. Para muchos widgets, el uso de un vector para las opciones mostrará los nombres del vector como las opciones de visualización, pero pasará el valor seleccionado del vector al servidor. Por ejemplo, aquí alguien puede seleccionar “15+” en el menú desplegable, y la interfaz de usuario pasará \"malaria_rdt_15\" al servidor, que resulta ser el nombre de la columna que nos interesa.Hay un montón de widgets que puedes utilizar para hacer muchas cosas con tu aplicación. Los widgets también permiten cargar archivos en la aplicación y descargar resultados. También hay algunas excelentes extensiones de shiny que te dan acceso más widgets que el shiny básico - el paquete shinyWidgets es un gran ejemplo de esto. Para ver algunos ejemplos puedes consultar los siguientes enlaces:Galería de widgets de ShinyGalería de shinyWidgets","code":"\nlibrary(shiny)\n\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)"},{"path":"dashboards-with-shiny.html","id":"loading-data-into-our-app","chapter":"43 Dashboards con Shiny","heading":"43.4 Cargar datos en nuestra app","text":"El siguiente paso en el desarrollo de nuestra aplicación es poner en marcha el servidor. Para ello, sin embargo, tenemos que conseguir algunos datos en nuestra aplicación, y averiguar todos los cálculos que vamos hacer. Una aplicación Shiny es fácil de depurar, ya que menudo está claro de dónde provienen los errores, por lo que es ideal desarrollar el código todo nuestro procesamiento de datos y visualización antes de empezar hacer el propio servidor.Así que dado que queremos hacer una aplicación que muestre epicurvas que cambien en base la entrada del usuario, deberíamos pensar en qué código necesitaríamos para ejecutar esto en un script normal de R. Necesitaremos:Cargar nuestros paquetesCargar nuestros datosTransformar nuestros datosDesarrollar una función para visualizar nuestros datos en función de las entradas del usuarioEsta lista es bastante sencilla, y debería ser demasiado difícil de hacer. Ahora es importante pensar qué partes de este proceso deben hacerse una sola vez y qué partes deben ejecutarse en respuesta las entradas del usuario. Esto se debe que las aplicaciones Shiny generalmente ejecutan algún código antes de ejecutarse, que sólo se realiza una vez. Ayudará al rendimiento de nuestra aplicación si la mayor parte de nuestro código puede ser trasladado esta sección. Para este ejemplo, sólo necesitamos cargar nuestros datos/paquetes y hacer transformaciones básicas una vez, así que podemos poner ese código fuera del servidor. Esto significa que lo único que necesitaremos en el servidor es el código para visualizar nuestros datos. Vamos desarrollar todos estos componentes en un script primero. Sin embargo, ya que estamos visualizando nuestros datos con una función, también podemos poner el código de la función fuera del servidor para que nuestra función esté en el entorno cuando la aplicación se ejecute.Primero vamos cargar nuestros datos. Ya que estamos trabajando con un nuevo proyecto, y queremos limpiarlo, podemos crear un nuevo directorio llamado data, y añadir nuestros datos de malaria allí. Podemos ejecutar este código de abajo en un script de prueba que eventualmente borraremos cuando limpiemos la estructura de nuestra aplicación.Será más fácil trabajar con estos datos si utilizamos estándares de datos ordenados, por lo que también debemos transformarlos en un formato de datos más largo, donde el grupo de edad es una columna, y los casos son otra columna. Podemos hacer esto fácilmente usando lo que hemos aprendido en la página de Pivotar datos.Y con esto hemos terminado de preparar nuestros datos! Esto tacha los puntos 1, 2 y 3 de nuestra lista de cosas desarrollar para nuestro “script de prueba de R”. La última tarea, y la más difícil, será construir una función para producir una epicurva basada en parámetros definidos por el usuario. Como se mencionó anteriormente, se recomienda encarecidamente que cualquier persona que aprenda shimy primero mire la sección sobre la programación funcional (Escribir funciones) para entender cómo funciona esto!Al definir nuestra función, puede ser difícil pensar en los parámetros que queremos incluir. Para la programación funcional con shiny, cada parámetro relevante tendrá generalmente un widget asociado él, así que pensar en esto suele ser bastante fácil. Por ejemplo, en nuestra aplicación actual, queremos ser capaces de filtrar por distrito, y tener un widget para ello, por lo que podemos añadir un parámetro de distrito para reflejar esto. tenemos ninguna funcionalidad de la aplicación para filtrar por centro (por ahora), así que necesitamos añadir esto como parámetro. Empecemos haciendo una función con tres parámetros:Los datos básicosEl distrito de elecciónEl grupo de edad elegidoNo entraremos en grandes detalles sobre esta función, ya que su funcionamiento es relativamente sencillo. Una cosa tener en cuenta, sin embargo, es que debemos gestionar los errores devolviendo NULL cuando de otro modo daría un error. Esto se debe que cuando un servidor Shiny produce un objeto NULL en lugar de un objeto gráfico, ¡se mostrará nada en la interfaz de usuario! Esto es importante, ya que de lo contrario los errores menudo harán que la aplicación deje de funcionar.Otra cosa tener en cuenta es el uso del operador %% cuando se evalúa la entrada del district. Como se mencionó anteriormente, esto podría llegar como un vector de caracteres con múltiples valores, por lo que el uso de %% es más flexible que, por ejemplo, ==.Vamos probar nuestra función!Con nuestra función ya trabajando, ahora tenemos que entender cómo va encajar todo esto en nuestra aplicación Shiny. Hemos mencionado el concepto de código de inicio antes, pero vamos ver cómo podemos incorporar esto en la estructura de nuestra aplicación. Hay dos maneras de hacerlo.Escribe este código en tu archivo app.R al principio del script (por encima de la interfaz de usuario), oCrea un nuevo archivo en el directorio de tu aplicación llamado global.R, y pon el código de inicio en él.Vale la pena señalar en este punto que generalmente es más fácil, especialmente con aplicaciones más grandes, utilizar la segunda estructura de archivos, ya que permite separar su estructura de una manera sencilla. Vamos desarrollar completamente este script global.R ahora. Esto es lo que podría parecer:Fácil! Una gran característica es qe shiny entenderá para qué sirven los archivos llamados app.R, server.R, ui.R y global.R, por lo que es necesario conectarlos entre sí mediante ningún código. Así que sólo con tener este código en global.R en el directorio adecuado se ejecutará antes de que iniciemos nuestra app!También debemos tener en cuenta que mejoraría la organización de nuestra aplicación si movemos la función de dibujar su propio archivo - esto será especialmente útil medida que las aplicaciones se hacen más grandes. Para hacer esto, podríamos hacer otro directorio llamado funcs, y poner esta función en un archivo llamado plot_epicurve.R. Podríamos entonces leer esta función través del siguiente comando en global.RTen en cuenta que siempre debes especificar local = TRUE en las aplicaciones shiny, ya que afectará la obtención de recursos cuando/si la aplicación se publica en un servidor.","code":"\npacman::p_load(\"tidyverse\", \"lubridate\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\nprint(malaria_data)## # A tibble: 3,038 × 10\n##    location_name data_date  submitted_date Province District malaria_rdt…¹ malar…² malar…³ malar…⁴ newid\n##    <chr>         <date>     <date>         <chr>    <chr>            <int>   <int>   <int>   <int> <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring              11      12      23      46     1\n##  2 Facility 2    2020-08-11 2020-08-12     North    Bolo                11      10       5      26     2\n##  3 Facility 3    2020-08-11 2020-08-12     North    Dingo                8       5       5      18     3\n##  4 Facility 4    2020-08-11 2020-08-12     North    Bolo                16      16      17      49     4\n##  5 Facility 5    2020-08-11 2020-08-12     North    Bolo                 9       2       6      17     5\n##  6 Facility 6    2020-08-11 2020-08-12     North    Dingo                3       1       4       8     6\n##  7 Facility 6    2020-08-10 2020-08-12     North    Dingo                4       0       3       7     6\n##  8 Facility 5    2020-08-10 2020-08-12     North    Bolo                15      14      13      42     5\n##  9 Facility 5    2020-08-09 2020-08-12     North    Bolo                11      11      13      35     5\n## 10 Facility 5    2020-08-08 2020-08-12     North    Bolo                19      15      15      49     5\n## # … with 3,028 more rows, and abbreviated variable names ¹​`malaria_rdt_0-4`, ²​`malaria_rdt_5-14`,\n## #   ³​malaria_rdt_15, ⁴​malaria_tot\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\nprint(malaria_data)## # A tibble: 12,152 × 7\n##    location_name data_date  submitted_date Province District age_group        cases_reported\n##    <chr>         <date>     <date>         <chr>    <chr>    <chr>                     <int>\n##  1 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_0-4              11\n##  2 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_5-14             12\n##  3 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_rdt_15               23\n##  4 Facility 1    2020-08-11 2020-08-12     North    Spring   malaria_tot                  46\n##  5 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_0-4              11\n##  6 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_5-14             10\n##  7 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_rdt_15                5\n##  8 Facility 2    2020-08-11 2020-08-12     North    Bolo     malaria_tot                  26\n##  9 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_0-4               8\n## 10 Facility 3    2020-08-11 2020-08-12     North    Dingo    malaria_rdt_5-14              5\n## # … with 12,142 more rows\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Bolo\", agegroup = \"malaria_rdt_0-4\")\n# global.R script\n\npacman::p_load(\"tidyverse\", \"lubridate\", \"shiny\")\n\n# read data\nmalaria_data <- rio::import(here::here(\"data\", \"malaria_facility_count_data.rds\")) %>% \n  as_tibble()\n\n# clean data and pivot longer\nmalaria_data <- malaria_data %>%\n  select(-newid) %>%\n  pivot_longer(cols = starts_with(\"malaria_\"), names_to = \"age_group\", values_to = \"cases_reported\")\n\n\n# define plotting function\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\") {\n  \n  # create plot title\n  if (!(\"All\" %in% district)) {            \n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  # filter to age group\n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nsource(here(\"funcs\", \"plot_epicurve.R\"), local = TRUE)"},{"path":"dashboards-with-shiny.html","id":"developing-an-app-server","chapter":"43 Dashboards con Shiny","heading":"43.5 Desarrollar un servidor de app","text":"Ahora que tenemos la mayor parte de nuestro código, sólo tenemos que desarrollar nuestro servidor. Esta es la pieza final de nuestra aplicación, y es probablemente la más difícil de entender. El servidor es una gran función de R, pero es útil pensar en él como una serie de funciones más pequeñas, o tareas que la aplicación puede realizar. Es importante entender que estas funciones se ejecutan en un orden lineal. Hay un orden en ellas, pero es necesario entenderlo del todo cuando se empieza con Shiny. un nivel muy básico, estas tareas o funciones se activarán cuando haya un cambio en las entradas del usuario que las afecte, menos que el desarrollador las haya configurado para que se comporten de forma diferente. De nuevo, todo esto es bastante abstracto, pero vamos repasar primero los tres tipos básicos de objetos shinyFuentes reactivas - este es otro término para las entradas del usuario. El servidor shiny tiene acceso las salidas de la UI través de los widgets que hemos programado. Cada vez que los valores de estos se cambian, esto se pasa al servidor.Fuentes reactivas - este es otro término para las entradas del usuario. El servidor shiny tiene acceso las salidas de la UI través de los widgets que hemos programado. Cada vez que los valores de estos se cambian, esto se pasa al servidor.Conductores reactivos - estos son objetos que existen sólo dentro del servidor Shiny. En realidad los necesitamos para aplicaciones simples, pero producen objetos que sólo pueden ser vistos dentro del servidor, y utilizados en otras operaciones. Generalmente dependen de fuentes reactivas.Conductores reactivos - estos son objetos que existen sólo dentro del servidor Shiny. En realidad los necesitamos para aplicaciones simples, pero producen objetos que sólo pueden ser vistos dentro del servidor, y utilizados en otras operaciones. Generalmente dependen de fuentes reactivas.Puntos finales: son las salidas que se pasan del servidor la interfaz de usuario. En nuestro ejemplo, esto sería la epicurva que estamos produciendo.Puntos finales: son las salidas que se pasan del servidor la interfaz de usuario. En nuestro ejemplo, esto sería la epicurva que estamos produciendo.Con esto en mente vamos construir nuestro servidor paso paso. Vamos mostrar nuestro código de interfaz de usuario de nuevo aquí sólo para referencia:De este código UI tenemos:Dos entradas:\nSelector de distrito (con un inputId de select_district)\nSelector de grupo de edad (con un inputId de select_agegroup)\nSelector de distrito (con un inputId de select_district)Selector de grupo de edad (con un inputId de select_agegroup)Una salida:\nLa epicurva (con un outputId de malaria_epicurve)\nLa epicurva (con un outputId de malaria_epicurve)Como hemos dicho anteriormente, estos nombres únicos que hemos asignado nuestras entradas y salidas son cruciales. Deben ser únicos y se utilizan para pasar información entre la ui y el servidor. En nuestro servidor, accedemos nuestras entradas través de la sintaxis input$inputID y las salidas y las pasamos la ui través de la sintaxis output$output_name ¡Veamos un ejemplo, porque de nuevo esto es difícil de entender de otra manera!El servidor para una aplicación simple como esta es en realidad bastante sencillo. Te darás cuenta de que el servidor es una función con tres parámetros - input, output, session - esto es tan importante para entender por ahora, pero es importante seguir esta configuración. En nuestro servidor sólo tenemos una tarea - esta procesa un gráfico basado en la función que hicimos antes, y las entradas del servidor. Fíjate en que los nombres de los objetos de entrada y salida se corresponden exactamente con los de la interfaz de usuario.Para entender los fundamentos de cómo el servidor reacciona las entradas del usuario, debes tener en cuenta que la salida sabrá (través del paquete subyacente) cuando las entradas cambian, y volver ejecutar esta función para crear un gráfico cada vez que cambian. Ten en cuenta que aquí también utilizamos la función renderPlot() - esta es de una familia de funciones específicas del tipo que pasan esos objetos una salida ui. Hay una serie de funciones que se comportan de manera similar, pero hay que asegurarse de que la función utilizada coincide con el tipo de objeto que se está pasando la ui. Por ejemplo:renderText() - enviar texto la uirenderDataTable - envía una tabla interactiva la ui.Recuerda que estos también necesitan coincidir con la función de salida utilizada en la ui - así que renderPlot() se empareja con plotOutput(), y renderText() se empareja con textOutput().Así que finalmente hemos hecho una aplicación que funciona! Podemos ejecutarla clicando el botón Ejecutar aplicación en la parte superior derecha de la ventana de script en Rstudio. Debes tener en cuenta que puedes elegir ejecutar tu aplicación en tu navegador por defecto (en lugar de Rstudio), lo que reflejará con mayor precisión el aspecto que tendrá la aplicación para otros usuarios.¡Es divertido observar que en la consola R, la aplicación está “escuchando”. Hablando de reactividad!","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\")\n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n}"},{"path":"dashboards-with-shiny.html","id":"adding-more-functionality","chapter":"43 Dashboards con Shiny","heading":"43.6 Añadir más funcionalidad","text":"En este punto tenemos finalmente una aplicación en funcionamiento, pero tenemos muy poca funcionalidad. Tampoco hemos rascado la superficie de lo que shiny puede hacer, ¡así que hay mucho más que aprender! Vamos seguir construyendo nuestra aplicación actual añadiendo algunas características adicionales. Algunas cosas que podría ser bueno añadir:Algunos textos explicativosUn botón de descarga para nuestra gráfica - esto proporcionaría al usuario una versión de alta calidad de la imagen que está generando en la aplicaciónUn selector de instalaciones específicasOtra página del panel de control: podría mostrar una tabla con nuestros datos.Esto es mucho para agregar, pero podemos usarlo para aprender en el camino un montón de diferentes características de Shiny. Hay mucho que aprender sobre Shiny (puede ser muy avanzado, pero es de esperar que una vez que los usuarios tienen una mejor idea de cómo usarlo pueden llegar ser más cómodo usando fuentes de aprendizaje externas también).","code":""},{"path":"dashboards-with-shiny.html","id":"añadir-texto-estático","chapter":"43 Dashboards con Shiny","heading":"Añadir texto estático","text":"Vamos hablar primero de la adición de texto estático nuestra aplicación Shiny. Añadir texto nuestra aplicación es extremadamente fácil, una vez que se tiene un conocimiento básico de la misma. Dado que el texto estático cambia en la aplicación shiny (si quieres que cambie, puedes utilizar las funciones de procesado de texto en el servidor), todo el texto estático de shiny se añade generalmente en la interfaz de usuario de la aplicación. vamos entrar en detalles, pero puedes añadir un número de elementos diferentes su ui (e incluso personalizados) mediante la interfaz de R con HTML y css.HTML y css son lenguajes que intervienen explícitamente en el diseño de la interfaz de usuario. es necesario entenderlos demasiado bien, pero HTML crea objetos en la interfaz de usuario (como un cuadro de texto, o una tabla), y css se utiliza generalmente para cambiar el estilo y la estética de esos objetos. Shiny tiene acceso una gran variedad de etiquetas HTML - éstas están presentes para los objetos que se comportan de una manera específica, como los encabezados, los párrafos de texto, los saltos de línea, las tablas, etc. Podemos utilizar algunos de estos ejemplos así:h1() - esta es una etiqueta de encabezado, que hará que el texto adjunto sea automáticamente más grande, y cambiará los valores predeterminados en cuanto la fuente, el color, etc. (dependiendo del tema general de tu aplicación). Puedes acceder subtítulos cada vez más pequeños con h2() hasta h6() también. El uso es así:\nh1(\"mi cabecera - sección 1\")\nh1() - esta es una etiqueta de encabezado, que hará que el texto adjunto sea automáticamente más grande, y cambiará los valores predeterminados en cuanto la fuente, el color, etc. (dependiendo del tema general de tu aplicación). Puedes acceder subtítulos cada vez más pequeños con h2() hasta h6() también. El uso es así:h1(\"mi cabecera - sección 1\")p() - esta es una etiqueta de párrafo, que hará que el texto encerrado sea similar al texto de un cuerpo de texto. Este texto se envolverá automáticamente, y será de un tamaño relativamente pequeño (los pies de página podrían ser más pequeños, por ejemplo). Piensa en ello como el cuerpo de texto de un documento de Word. El uso es así:\np(\"Este es un cuerpo de texto más grande donde explico la función de mi aplicación\")\np() - esta es una etiqueta de párrafo, que hará que el texto encerrado sea similar al texto de un cuerpo de texto. Este texto se envolverá automáticamente, y será de un tamaño relativamente pequeño (los pies de página podrían ser más pequeños, por ejemplo). Piensa en ello como el cuerpo de texto de un documento de Word. El uso es así:p(\"Este es un cuerpo de texto más grande donde explico la función de mi aplicación\")tags$b() ytags$() - se utilizan para poner tags$b() en negrita (bold) y tags$() en cursiva el texto que se incluya entre los paréntesis.tags$b() ytags$() - se utilizan para poner tags$b() en negrita (bold) y tags$() en cursiva el texto que se incluya entre los paréntesis.tags$ul(), tags$ol() y tags$li() - son etiquetas utilizadas para crear listas. Todas ellas se utilizan dentro de la sintaxis siguiente, y permiten al usuario crear una lista ordenada (tags$ol(); es decir, numerada) o desordenada (tags$ul(), es decir, con viñetas). tags$li() se utiliza para marcar los elementos de la lista, independientemente del tipo de lista que se utilice. p. ej:tags$ul(), tags$ol() y tags$li() - son etiquetas utilizadas para crear listas. Todas ellas se utilizan dentro de la sintaxis siguiente, y permiten al usuario crear una lista ordenada (tags$ol(); es decir, numerada) o desordenada (tags$ul(), es decir, con viñetas). tags$li() se utiliza para marcar los elementos de la lista, independientemente del tipo de lista que se utilice. p. ej:br() y hr() - estas etiquetas crean saltos de línea y líneas horizontales (con un salto de línea) respectivamente. Utilízalas para separar las secciones de tu aplicación y el texto. es necesario pasar ningún elemento estas etiquetas (los paréntesis pueden permanecer vacíos).br() y hr() - estas etiquetas crean saltos de línea y líneas horizontales (con un salto de línea) respectivamente. Utilízalas para separar las secciones de tu aplicación y el texto. es necesario pasar ningún elemento estas etiquetas (los paréntesis pueden permanecer vacíos).div() - esta es una etiqueta genérica que puede contener cualquier cosa, y puede tener cualquier nombre. Una vez que avances en el diseño de la interfaz de usuario, puedes utilizarlas para compartimentar tu interfaz de usuario, dar estilos específicos determinadas secciones y crear interacciones entre el servidor y los elementos de la interfaz de usuario. vamos entrar en detalles, pero vale la pena conocerlos.div() - esta es una etiqueta genérica que puede contener cualquier cosa, y puede tener cualquier nombre. Una vez que avances en el diseño de la interfaz de usuario, puedes utilizarlas para compartimentar tu interfaz de usuario, dar estilos específicos determinadas secciones y crear interacciones entre el servidor y los elementos de la interfaz de usuario. vamos entrar en detalles, pero vale la pena conocerlos.Ten en cuenta que se puede acceder cada uno de estos objetos través de tags$... o para algunos, sólo la función. Estos son efectivamente sinónimos, pero puede ayudar utilizar el estilo tags$... si prefieres ser más explícito y sobrescribir las funciones accidentalmente. Esta es en absoluto una lista exhaustiva de etiquetas disponibles. Hay una lista completa de todas las etiquetas disponibles en shiny aquí e incluso se pueden utilizar más insertando HTML directamente en su ui!Si te sientes seguro, también puedes añadir cualquier elemento de estilo css tus etiquetas HTML con el argumento style en cualquiera de ellas. vamos entrar en detalles sobre cómo funciona esto, pero un consejo para probar los cambios estéticos en una interfaz de usuario es utilizar el modo de inspector de HTML en Chrome (de tu aplicación Shiny que está ejecutando en el navegador), y editar el estilo de los objetos tu mismo!Vamos añadir algo de texto nuestra aplicación","code":"\ntags$ol(\n  \n  tags$li(\"Item 1\"),\n  \n  tags$li(\"Item 2\"),\n  \n  tags$li(\"Item 3\")\n  \n)\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         h4(\"Options\"),\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = TRUE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n    tags$ul(\n      tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n      tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n      tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n      tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n      tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n      tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n      tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n    )\n    \n  )\n)\n)"},{"path":"dashboards-with-shiny.html","id":"añadir-un-enlace","chapter":"43 Dashboards con Shiny","heading":"Añadir un enlace","text":"Para añadir un enlace una página web, utiliza tags$() con el enlace y el texto mostrar como se muestra continuación. Para tener como un párrafo independiente, escríbelo dentro de p(). Para tener sólo algunas palabras de una frase enlazada, divide la frase en partes y utiliza tags$() para la parte hipervinculada. Para que el enlace se abra en una nueva ventana del navegador, añade target = \"_blank\" como argumento.","code":"\ntags$a(href = \"www.epiRhandbook.com\", \"Visit our website!\")"},{"path":"dashboards-with-shiny.html","id":"añadir-un-botón-de-descarga","chapter":"43 Dashboards con Shiny","heading":"Añadir un botón de descarga","text":"Pasemos la segunda de las tres características. Un botón de descarga es una cosa bastante común para añadir una aplicación y es bastante fácil de hacer. Tenemos que añadir otro Widget nuestra ui, y tenemos que añadir otra salida nuestro servidor para adjuntarlo. También podemos introducir conductores reactivos en este ejemplo!Vamos actualizar nuestra interfaz de usuario primero - esto es fácil ya que Shiny viene con un widget llamado downloadButton() - vamos darle un inputId y una label (etiqueta).Observa que también hemos añadido una etiqueta hr() - esto añade una línea horizontal que separa nuestros widgets de control de nuestros widgets de descarga. Esta es otra de las etiquetas HTML que hemos discutido anteriormente.Ahora que tenemos nuestra ui lista, necesitamos añadir el componente del servidor. Las descargas se realizan en el servidor con la función downloadHandler(). De manera similar nuestra trama, necesitamos adjuntarla una salida que tenga el mismo inputId que el botón de descarga. Esta función toma dos argumentos - filename y content - ambos son funciones. Como podrás adivinar, filename se utiliza para especificar el nombre del archivo descargado, y content se utiliza para especificar lo que debe ser descargado. content contiene una función que usarías para guardar los datos localmente - así que si estuvieras descargando un archivo csv podrías usar rio::export(). Como estamos descargando un gráfico, usaremos ggplot2::ggsave(). Veamos cómo programaríamos esto (aún lo añadiremos al servidor).Observa que la función content siempre toma un argumento file, que ponemos donde se especifica el nombre del archivo de salida. También puedes notar que estamos repitiendo código aquí - estamos usando nuestra función plot_epicurve() dos veces en este servidor, una para la descarga y otra para la imagen mostrada en la aplicación. Aunque esto afecta masivamente al rendimiento, significa que el código para generar este gráfico tendrá que ejecutarse cuando el usuario cambie los widgets que especifican el distrito y el grupo de edad, y de nuevo cuando quiera descargar el gráfico. En aplicaciones más grandes, decisiones subóptimas como ésta ralentizarán cada vez más las cosas, así que es bueno aprender hacer nuestra aplicación más eficiente en este sentido. Lo que tendría más sentido es si tuviéramos una forma de ejecutar el código de la epicurva cuando los distritos/grupos de edad cambien, y dejar que eso sea utilizado por las funciones renderPlot() y downloadHandler(). Aquí es donde entran los conductores reactivos!Los conductores reactivos son objetos que se crean en el servidor shiny de forma reactiva, pero se emiten - sólo pueden ser utilizados por otras partes del servidor. Hay varios tipos de conductores reactivos, pero vamos repasar los dos básicos.reactive() - este es el conductor reactivo más básico - reaccionará siempre que cualquier entrada utilizada dentro de él cambie (por nuestros widgets de distrito/grupo de edad)eventReactive() - este conductor rectivo funciona igual que reactive(), excepto que el usuario puede especificar qué entradas hacen que se vuelva ejecutar. Esto es útil si tu conductor reactivo tarda mucho en procesar, pero esto se explicará más adelante.Veamos los dos ejemplos:Cuando usamos la configuración de eventReactive(), podemos especificar qué entradas hacen que se ejecute este trozo de código - esto nos es muy útil por el momento, así que podemos dejarlo por ahora. Ten en cuenta que puedes incluir múltiples entradas con c()Veamos cómo podemos integrar esto en el código de nuestro servidor:Puedes ver que sólo estamos llamando la salida del reactivo que hemos definido en nuestras funciones de descarga y representación gráfica. Una cosa que hay que tener en cuenta y que suele confundir la gente es que hay que utilizar las salidas de los reactivos como si fueran funciones, por lo que hay que añadir paréntesis vacíos al final de los mismos (es decir, malaria_plot() es correcto, y malaria_plot lo es). Ahora que hemos añadido esta solución nuestra aplicación es un poco más ordenada, más rápida y más fácil de cambiar ya que todo el código que ejecuta la función epicurve está en un solo lugar.","code":"\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = c(\n                   \"All\",\n                   \"Spring\",\n                   \"Bolo\",\n                   \"Dingo\",\n                   \"Barnard\"\n              ),\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nserver <- function(input, output, session) {\n  \n  output$malaria_epicurve <- renderPlot(\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}\nmalaria_plot_r <- reactive({\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\n\n\n# only runs when the district selector changes!\nmalaria_plot_er <- eventReactive(input$select_district, {\n  \n  plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup)\n  })\n  \n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n}"},{"path":"dashboards-with-shiny.html","id":"añadir-un-selector-de-instalaciones","chapter":"43 Dashboards con Shiny","heading":"Añadir un selector de instalaciones","text":"Pasemos nuestra siguiente función: un selector para instalaciones específicas. Implementaremos otro parámetro en nuestra función para poder pasarlo como argumento desde nuestro código. Vamos ver cómo hacer esto primero - sólo funciona con los mismos principios que los otros parámetros que hemos establecido. Actualicemos y probemos nuestra función.Vamos probarlo:Con todas las instalaciones en nuestros datos, está muy claro qué instalaciones corresponden qué distritos, y el usuario final tampoco lo sabrá. Esto puede hacer que el uso de la aplicación sea poco intuitivo. Por esta razón, debemos hacer que las opciones de instalaciones en la interfaz de usuario cambien dinámicamente medida que el usuario cambia de distrito, de modo que una filtra la otra. Dado que tenemos tantas variables que estamos utilizando en las opciones, también podríamos querer generar algunas de nuestras opciones para la ui en nuestro archivo global.R partir de los datos. Por ejemplo, podemos añadir este trozo de código global.R después de haber leído nuestros datos:Vamos verlos:Podemos pasar estas nuevas variables la ui sin ningún problema, ya que son visibles globalmente tanto por el servidor como por la ui. Actualicemos nuestra UI:Fíjate en que ahora pasamos variables para nuestras elecciones en lugar de codificarlas en la interfaz de usuario. Esto también puede hacer que nuestro código sea más compacto. Por último, tendremos que actualizar el servidor. Será fácil actualizar nuestra función para incorporar nuestra nueva entrada (sólo tenemos que pasarla como argumento nuestro nuevo parámetro), pero debemos recordar que también queremos que la ui se actualice dinámicamente cuando el usuario cambie el distrito seleccionado. Es importante entender aquí que podemos cambiar los parámetros y el comportamiento de los widgets mientras la aplicación se está ejecutando, pero esto debe hacerse en el servidor. Tenemos que entender una nueva forma de salida al servidor para aprender hacer esto.Las funciones que necesitamos para entender cómo hacer esto se conocen como funciones de observador, y son similares las funciones reactivas en cuanto su comportamiento. Sin embargo, tienen una diferencia clave:Las funciones reactivas afectan directamente las salidas, y producen objetos que pueden verse en otros lugares del servidorLas funciones reactivas afectan directamente las salidas, y producen objetos que pueden verse en otros lugares del servidorLas funciones de los observadores pueden afectar las salidas del servidor, pero lo hacen través de los efectos secundarios de otras funciones. (También pueden hacer otras cosas, pero esta es su función principal en la práctica)Las funciones de los observadores pueden afectar las salidas del servidor, pero lo hacen través de los efectos secundarios de otras funciones. (También pueden hacer otras cosas, pero esta es su función principal en la práctica)Al igual que las funciones reactivas, hay dos tipos de funciones de observador, y se dividen por la misma lógica que divide las funciones reactivas:observe() - esta función se ejecuta cada vez que cambian las entradas utilizadas dentro de ellaobserveEvent() - esta función se ejecuta cuando cambia una entrada especificada por el usuarioTambién necesitamos entender las funciones proporcionadas por Shiny que actualizan los widgets. Estas son bastante sencillas de ejecutar - primero toman el objeto session de la función del servidor (esto necesita ser entendido por ahora), y luego el inputId de la función ser cambiada. Luego pasamos las nuevas versiones de todos los parámetros que ya son tomados por selectInput() - estos serán actualizados automáticamente en el widget.Veamos un ejemplo aislado de cómo podríamos utilizar esto en nuestro servidor. Cuando el usuario cambia de distrito, queremos filtrar nuestra lista de instalaciones por distrito, y actualizar las opciones para que sólo reflejen las que están disponibles en ese distrito (y una opción para todas las instalaciones)Y ya está, podemos añadirlo nuestro servidor, y ese comportamiento ya funcionará. Este es el aspecto que debería tener nuestro nuevo servidor:","code":"\nplot_epicurve <- function(data, district = \"All\", agegroup = \"malaria_tot\", facility = \"All\") {\n  \n  if (!(\"All\" %in% district)) {\n    data <- data %>%\n      filter(District %in% district)\n    \n    plot_title_district <- stringr::str_glue(\"{paste0(district, collapse = ', ')} districts\")\n    \n  } else {\n    \n    plot_title_district <- \"all districts\"\n    \n  }\n  \n  # si no hay datos restantes, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  data <- data %>%\n    filter(age_group == agegroup)\n  \n  \n  # si no hay datos restantes, devuelve NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n  \n  if (agegroup == \"malaria_tot\") {\n      agegroup_title <- \"All ages\"\n  } else {\n    agegroup_title <- stringr::str_glue(\"{str_remove(agegroup, 'malaria_rdt')} years\")\n  }\n  \n    if (!(\"All\" %in% facility)) {\n    data <- data %>%\n      filter(location_name == facility)\n    \n    plot_title_facility <- facility\n    \n  } else {\n    \n    plot_title_facility <- \"all facilities\"\n    \n  }\n  \n  # if no remaining data, return NULL\n  if (nrow(data) == 0) {\n    \n    return(NULL)\n  }\n\n  \n  \n  ggplot(data, aes(x = data_date, y = cases_reported)) +\n    geom_col(width = 1, fill = \"darkred\") +\n    theme_minimal() +\n    labs(\n      x = \"date\",\n      y = \"number of cases\",\n      title = stringr::str_glue(\"Malaria cases - {plot_title_district}; {plot_title_facility}\"),\n      subtitle = agegroup_title\n    )\n  \n  \n  \n}\nplot_epicurve(malaria_data, district = \"Spring\", agegroup = \"malaria_rdt_0-4\", facility = \"Facility 1\")\nall_districts <- c(\"All\", unique(malaria_data$District))\n\n# data frame of location names by district\nfacility_list <- malaria_data %>%\n  group_by(location_name, District) %>%\n  summarise() %>% \n  ungroup()\nall_districts## [1] \"All\"     \"Spring\"  \"Bolo\"    \"Dingo\"   \"Barnard\"\nfacility_list## # A tibble: 65 × 2\n##    location_name District\n##    <chr>         <chr>   \n##  1 Facility 1    Spring  \n##  2 Facility 10   Bolo    \n##  3 Facility 11   Spring  \n##  4 Facility 12   Dingo   \n##  5 Facility 13   Bolo    \n##  6 Facility 14   Dingo   \n##  7 Facility 15   Barnard \n##  8 Facility 16   Barnard \n##  9 Facility 17   Barnard \n## 10 Facility 18   Bolo    \n## # … with 55 more rows\nui <- fluidPage(\n\n  titlePanel(\"Malaria facility visualisation app\"),\n\n  sidebarLayout(\n\n    sidebarPanel(\n         # selector for district\n         selectInput(\n              inputId = \"select_district\",\n              label = \"Select district\",\n              choices = all_districts,\n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for age group\n         selectInput(\n              inputId = \"select_agegroup\",\n              label = \"Select age group\",\n              choices = c(\n                   \"All ages\" = \"malaria_tot\",\n                   \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                   \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                   \"15+ yrs\" = \"malaria_rdt_15\"\n              ), \n              selected = \"All\",\n              multiple = FALSE\n         ),\n         # selector for facility\n         selectInput(\n           inputId = \"select_facility\",\n           label = \"Select Facility\",\n           choices = c(\"All\", facility_list$location_name),\n           selected = \"All\"\n         ),\n         \n         # horizontal line\n         hr(),\n         downloadButton(\n           outputId = \"download_epicurve\",\n           label = \"Download plot\"\n         )\n\n    ),\n\n    mainPanel(\n      # epicurve goes here\n      plotOutput(\"malaria_epicurve\"),\n      br(),\n      hr(),\n      p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n      tags$ul(\n        tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n        tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n        tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n        tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n        tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n        tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n        tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n      )\n      \n    )\n    \n  )\n)\nobserve({\n  \n  if (input$select_district == \"All\") {\n    new_choices <- facility_list$location_name\n  } else {\n    new_choices <- facility_list %>%\n      filter(District == input$select_district) %>%\n      pull(location_name)\n  }\n  \n  new_choices <- c(\"All\", new_choices)\n  \n  updateSelectInput(session, inputId = \"select_facility\",\n                    choices = new_choices)\n  \n})\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  \n  \n}"},{"path":"dashboards-with-shiny.html","id":"añadir-otra-pestaña-con-una-tabla","chapter":"43 Dashboards con Shiny","heading":"Añadir otra pestaña con una tabla","text":"Ahora pasaremos al último componente que queremos añadir nuestra aplicación. Querremos separar nuestra ui en dos pestañas, una de las cuales tendrá una tabla interactiva donde el usuario podrá ver los datos con los que está haciendo la curva epidémica. Para ello, podemos utilizar los elementos de ui empaquetados que vienen con shiny relevantes para las pestañas. En un nivel básico, podemos encerrar la mayor parte de nuestro panel principal en esta estructura general:Apliquemos esto nuestra ui. También vamos querer utilizar el paquete DT aquí - este es un gran paquete para hacer tablas interactivas partir de datos preexistentes. Podemos ver que se utiliza para DT::datatableOutput() en este ejemplo.Ahora nuestra aplicación está organizada en pestañas! Hagamos también las modificaciones necesarias en el servidor. Dado que necesitamos manipular nuestro conjunto de datos antes de procesarlo, esto es muy sencillo: ¡sólo tenemos que procesar los datos malaria_data través de DT::renderDT() en la interfaz de usuario!","code":"\n# ... the rest of ui\n\nmainPanel(\n  \n  tabsetPanel(\n    type = \"tabs\",\n    tabPanel(\n      \"Epidemic Curves\",\n      ...\n    ),\n    tabPanel(\n      \"Data\",\n      ...\n    )\n  )\n)\nui <- fluidPage(\n     \n     titlePanel(\"Malaria facility visualisation app\"),\n     \n     sidebarLayout(\n          \n          sidebarPanel(\n               # selector for district\n               selectInput(\n                    inputId = \"select_district\",\n                    label = \"Select district\",\n                    choices = all_districts,\n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for age group\n               selectInput(\n                    inputId = \"select_agegroup\",\n                    label = \"Select age group\",\n                    choices = c(\n                         \"All ages\" = \"malaria_tot\",\n                         \"0-4 yrs\" = \"malaria_rdt_0-4\",\n                         \"5-14 yrs\" = \"malaria_rdt_5-14\",\n                         \"15+ yrs\" = \"malaria_rdt_15\"\n                    ), \n                    selected = \"All\",\n                    multiple = FALSE\n               ),\n               # selector for facility\n               selectInput(\n                    inputId = \"select_facility\",\n                    label = \"Select Facility\",\n                    choices = c(\"All\", facility_list$location_name),\n                    selected = \"All\"\n               ),\n               \n               # horizontal line\n               hr(),\n               downloadButton(\n                    outputId = \"download_epicurve\",\n                    label = \"Download plot\"\n               )\n               \n          ),\n          \n          mainPanel(\n               tabsetPanel(\n                    type = \"tabs\",\n                    tabPanel(\n                         \"Epidemic Curves\",\n                         plotOutput(\"malaria_epicurve\")\n                    ),\n                    tabPanel(\n                         \"Data\",\n                         DT::dataTableOutput(\"raw_data\")\n                    )\n               ),\n               br(),\n               hr(),\n               p(\"Welcome to the malaria facility visualisation app! To use this app, manipulate the widgets on the side to change the epidemic curve according to your preferences! To download a high quality image of the plot you've created, you can also download it with the download button. To see the raw data, use the raw data tab for an interactive form of the table. The data dictionary is as follows:\"),\n               tags$ul(\n                    tags$li(tags$b(\"location_name\"), \" - the facility that the data were collected at\"),\n                    tags$li(tags$b(\"data_date\"), \" - the date the data were collected at\"),\n                    tags$li(tags$b(\"submitted_daate\"), \" - the date the data were submitted at\"),\n                    tags$li(tags$b(\"Province\"), \" - the province the data were collected at (all 'North' for this dataset)\"),\n                    tags$li(tags$b(\"District\"), \" - the district the data were collected at\"),\n                    tags$li(tags$b(\"age_group\"), \" - the age group the data were collected for (0-5, 5-14, 15+, and all ages)\"),\n                    tags$li(tags$b(\"cases_reported\"), \" - the number of cases reported for the facility/age group on the given date\")\n               )\n               \n               \n          )\n     )\n)\nserver <- function(input, output, session) {\n  \n  malaria_plot <- reactive({\n    plot_epicurve(malaria_data, district = input$select_district, agegroup = input$select_agegroup, facility = input$select_facility)\n  })\n  \n  \n  \n  observe({\n    \n    if (input$select_district == \"All\") {\n      new_choices <- facility_list$location_name\n    } else {\n      new_choices <- facility_list %>%\n        filter(District == input$select_district) %>%\n        pull(location_name)\n    }\n    \n    new_choices <- c(\"All\", new_choices)\n    \n    updateSelectInput(session, inputId = \"select_facility\",\n                      choices = new_choices)\n    \n  })\n  \n  \n  output$malaria_epicurve <- renderPlot(\n    malaria_plot()\n  )\n  \n  output$download_epicurve <- downloadHandler(\n    \n    filename = function() {\n      stringr::str_glue(\"malaria_epicurve_{input$select_district}.png\")\n    },\n    \n    content = function(file) {\n      ggsave(file, \n             malaria_plot(),\n             width = 8, height = 5, dpi = 300)\n    }\n    \n  )\n  \n  # render data table to ui\n  output$raw_data <- DT::renderDT(\n    malaria_data\n  )\n  \n  \n}"},{"path":"dashboards-with-shiny.html","id":"sharing-shiny-apps","chapter":"43 Dashboards con Shiny","heading":"43.7 Compartir apps Shiny","text":"Ahora que desarrollado tu aplicación, probablemente quieras compartirla con los demás, ¡al fin y al cabo esta es la principal ventaja de shiny! Podemos hacerlo compartiendo el código directamente, o podemos publicarlo en un servidor. Si compartimos el código, otros podrán ver lo que hecho y construir sobre él, pero esto anulará una de las principales ventajas de shiny: puede eliminar la necesidad de que los usuarios finales mantengan una instalación de R. Por esta razón, si estás compartiendo tu aplicación con usuarios que se sienten cómodos con R, es mucho más fácil compartir una aplicación que ha sido publicada en un servidor.Si prefieres compartir el código, puedes hacer un archivo .zip de la aplicación, o mejor aún, publicar tu aplicación en github y añadir colaboradores. Puedes consultar la sección de github para más información aquí.Sin embargo, si vamos publicar la aplicación en línea, tenemos que hacer un poco más de trabajo. En última instancia, queremos que se pueda acceder tu aplicación través de una URL web para que otros puedan acceder ella de forma rápida y sencilla. Desafortunadamente, para publicar tu aplicación en un servidor, necesitas tener acceso un servidor donde publicarla. Hay varias opciones de alojamiento en este sentido:shinyapps.io: es el lugar más sencillo para publicar aplicaciones shiny, ya que es el que menos trabajo de configuración necesita, y tiene algunas licencias gratuitas, pero limitadas.shinyapps.io: es el lugar más sencillo para publicar aplicaciones shiny, ya que es el que menos trabajo de configuración necesita, y tiene algunas licencias gratuitas, pero limitadas.RStudio Connect: es una versión mucho más potente de un servidor de R, que puede realizar muchas operaciones, incluida la publicación de aplicaciones Shinys. Sin embargo, es más difícil de usar y menos recomendable para los usuarios noveles.RStudio Connect: es una versión mucho más potente de un servidor de R, que puede realizar muchas operaciones, incluida la publicación de aplicaciones Shinys. Sin embargo, es más difícil de usar y menos recomendable para los usuarios noveles.Para los propósitos de este documento, utilizaremos shinyapps.io, ya que es más fácil para los usuarios noveles. Puedes hacer una cuenta gratuita aquí para empezar - también hay diferentes planes de precios para las licecias de los servidores si es necesario. Cuantos más usuarios esperes tener, más caro tendrá que ser tu plan de precios, así que tenlo en cuenta. Si quieres crear algo para un pequeño grupo de personas, una licencia gratuita puede ser perfectamente adecuada, pero una aplicación de cara al público puede necesitar más licencias.Primero debemos asegurarnos de que nuestra aplicación es adecuada para publicar en un servidor. En tu aplicación, debes reiniciar tu sesión de R, y asegurarte de que se ejecuta sin ejecutar ningún código extra. Esto es importante, ya que una aplicación que requiere la carga de paquetes, o la lectura de datos definidos en el código de tu aplicación se ejecutará en un servidor. También ten en cuenta que puedes tener rutas de archivo explícitas en tu aplicación - éstas serán inválidas en la configuración del servidor - el uso del paquete resuelve muy bien este problema. Por último, si estás leyendo datos de una fuente que requiere autenticación de usuario, como los servidores de tu organización, esto funcionará generalmente en un servidor. Tendrás que ponerte en contacto con tu departamento de TI para averiguar cómo poner en la lista blanca el Shiny servidor.registro de la cuentaUna vez que tengas tu cuenta, puedes navegar la página de tokens en Accounts. Aquí querrás añadir un nuevo token, que se utilizará para desplegar tu aplicación.partir de aquí, debes tener en cuenta que la url de tu cuenta reflejará el nombre de tu app - así que si tu app se llama mi_app, la url se añadirá como xxx.io/mi_app/. Elige bien el nombre de tu aplicación. Ahora que está todo listo, clica en desplegar - si tiene éxito esto ejecutará tu aplicación en la url web elegida.¿algo sobre la creación de aplicaciones en documentos?","code":""},{"path":"dashboards-with-shiny.html","id":"further-reading","chapter":"43 Dashboards con Shiny","heading":"43.8 Más información","text":"Hasta ahora, hemos cubierto muchos aspectos de shiny, y apenas hemos arañado la superficie de lo que ofrece shiny. Aunque esta guía sirve de introducción, hay mucho más que aprender para entender completamente shiny. Deberías empezar crear aplicaciones y añadir gradualmente más y más funcionalidad","code":""},{"path":"dashboards-with-shiny.html","id":"recommended-extension-packages","chapter":"43 Dashboards con Shiny","heading":"43.9 Paquetes de extensión recomendados","text":"continuación se presenta una selección de extensiones de shiny de alta calidad que pueden ayudarte sacar mucho más provecho de shiny. Sin ningún orden en particular:shinyWidgets - este paquete ofrece muchos más widgets que pueden ser utilizados en tu aplicación. Ejecuta shinyWidgets::shinyWidgetsGallery() para ver una selección de los widgets disponibles con este paquete. Mira los ejemplos aquíshinyWidgets - este paquete ofrece muchos más widgets que pueden ser utilizados en tu aplicación. Ejecuta shinyWidgets::shinyWidgetsGallery() para ver una selección de los widgets disponibles con este paquete. Mira los ejemplos aquíshinyjs - este es un excelente paquete que da al usuario la capacidad de ampliar en gran medida la utilidad de shiny través de una serie de javascript. Las aplicaciones de este paquete van desde las más sencillas hasta las más avanzadas, pero es posible que quieras utilizarlo primero para manipular la interfaz de usuario de forma sencilla, como ocultar/mostrar elementos, o activar/desactivar botones. Para más información, consulta aquishinyjs - este es un excelente paquete que da al usuario la capacidad de ampliar en gran medida la utilidad de shiny través de una serie de javascript. Las aplicaciones de este paquete van desde las más sencillas hasta las más avanzadas, pero es posible que quieras utilizarlo primero para manipular la interfaz de usuario de forma sencilla, como ocultar/mostrar elementos, o activar/desactivar botones. Para más información, consulta aquishinydashboard - este paquete expande masivamente la ui disponible que puede ser usada en shiny, específicamente permitiendo al usuario crear un dashboard complejo con una variedad de diseños complejos. Consulta más aquíshinydashboard - este paquete expande masivamente la ui disponible que puede ser usada en shiny, específicamente permitiendo al usuario crear un dashboard complejo con una variedad de diseños complejos. Consulta más aquíshinydashboardPlus: ¡aún más funciones del marco de trabajo de shinydashboard! Puedes ver más aquíshinydashboardPlus: ¡aún más funciones del marco de trabajo de shinydashboard! Puedes ver más aquíshinythemes - ¡cambia el tema css por defecto de tu app shiny con una amplia gama de plantillas preestablecidas! Más aquíshinythemes - ¡cambia el tema css por defecto de tu app shiny con una amplia gama de plantillas preestablecidas! Más aquíTambién hay una serie de paquetes que pueden utilizarse para crear resultados interactivos compatibles con Shiny.DT está semi-incorporado en shinybásico, pero proporciona un gran conjunto de funciones para crear tablas interactivas.DT está semi-incorporado en shinybásico, pero proporciona un gran conjunto de funciones para crear tablas interactivas.plotly es un paquete para crear gráficos interactivos que el usuario puede manipular en la aplicación. También puede convertir sus gráficos en versiones interactivas mediante plotly::ggplotly(). Como alternativas, dygraphs y highcharter son también excelentes.plotly es un paquete para crear gráficos interactivos que el usuario puede manipular en la aplicación. También puede convertir sus gráficos en versiones interactivas mediante plotly::ggplotly(). Como alternativas, dygraphs y highcharter son también excelentes.","code":""},{"path":"dashboards-with-shiny.html","id":"recommended-resources","chapter":"43 Dashboards con Shiny","heading":"43.10 Recursos recomendados","text":"","code":""},{"path":"writing-functions-1.html","id":"writing-functions-1","chapter":"44 Escribir funciones","heading":"44 Escribir funciones","text":"","code":""},{"path":"writing-functions-1.html","id":"preparation-37","chapter":"44 Escribir funciones","heading":"44.1 Preparación","text":"","code":""},{"path":"writing-functions-1.html","id":"cargar-paquetes-32","chapter":"44 Escribir funciones","heading":"Cargar paquetes","text":"Este trozo de código muestra la carga de los paquetes necesarios para los análisis. En este manual destacamos p_load() de pacman, que instala el paquete si es necesario y lo carga para su uso. También puedes cargar los paquetes instalados con library() de R base. Consulta la página fundamentos de R para obtener más información sobre los paquetes de R.","code":""},{"path":"writing-functions-1.html","id":"importar-datos-26","chapter":"44 Escribir funciones","heading":"Importar datos","text":"Importamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso paso, consulta las instrucciones en la página [Descargar libro y datos]. Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos.También utilizaremos en la última parte de esta página algunos datos sobre la gripe H7N9 de 2013.","code":""},{"path":"writing-functions-1.html","id":"functions-2","chapter":"44 Escribir funciones","heading":"44.2 Funciones","text":"Las funciones son útiles en la programación, ya que permiten hacer códigos más fáciles de entender, de alguna manera más cortos y menos propensos errores (dado que hay errores en la propia función).Si llegado hasta este manual, significa que te encontrado con un sinfín de funciones ya que en R, cada operación es una llamada una función +, , , [, $, { …. Por ejemplo, x + y es lo mismo que'+'(x, y)R es uno de los lenguajes que más posibilidades ofrece para trabajar con funciones y da suficientes herramientas al usuario para escribirlas fácilmente. debemos pensar en las funciones como algo fijo en la cima o al final de la cadena de programación, R ofrece la posibilidad de utilizarlas como si fueran vectores e incluso utilizarlas dentro de otras funciones, listas…Existen muchos recursos muy avanzados sobre programación funcional y aquí sólo daremos una visión para ayudarte empezar con la programación de funciones con breves ejemplos prácticos. Te animamos visitar los enlaces de las referencias para leer más sobre el tema.","code":""},{"path":"writing-functions-1.html","id":"why-would-you-use-a-function","chapter":"44 Escribir funciones","heading":"44.3 ¿Por qué utilizar una función?","text":"Antes de responder esta pregunta, es importante tener en cuenta que ya tenido consejos para llegar escribir tus primeras funciones R en la página sobre Iteración, bucles y listas de este manual. De hecho, el uso de “/else” y bucles suele ser una parte fundamental de muchas de nuestras funciones, ya que ayudan fácilmente ampliar la aplicación de nuestro código permitiendo múltiples condiciones o iterar códigos para repetir tareas.¿Estoy repitiendo varias veces el mismo bloque de código para aplicarlo una variable o dato diferente?¿Estoy repitiendo varias veces el mismo bloque de código para aplicarlo una variable o dato diferente?Deshacerse de él, ¿acortará sustancialmente mi código general y hará que se ejecute más rápido?Deshacerse de él, ¿acortará sustancialmente mi código general y hará que se ejecute más rápido?¿Es posible que el código que escrito se utilice de nuevo pero con un valor diferente en muchos lugares del código?¿Es posible que el código que escrito se utilice de nuevo pero con un valor diferente en muchos lugares del código?Si la respuesta una de las preguntas anteriores es “SÍ”, es probable que tenga que escribir una función.","code":""},{"path":"writing-functions-1.html","id":"how-does-r-build-functions","chapter":"44 Escribir funciones","heading":"44.4 ¿Cómo construye R las funciones?","text":"Las funciones en R tienen tres componentes principales:las formals() que es la lista de argumentos que controla cómo podemos llamar la funciónlas formals() que es la lista de argumentos que controla cómo podemos llamar la funciónel body() que es el código dentro de la función, es decir, dentro de los paréntesis o después del paréntesis, dependiendo de cómo lo escribamosel body() que es el código dentro de la función, es decir, dentro de los paréntesis o después del paréntesis, dependiendo de cómo lo escribamosy,el environment() que ayudará localizar las variables de la función y determina cómo encuentra la función el valor.Una vez que hayas creado tu función, puedes verificar cada uno de estos componentes llamando la función asociada.","code":""},{"path":"writing-functions-1.html","id":"basic-syntax-and-structure","chapter":"44 Escribir funciones","heading":"44.5 Sintaxis y estructura básica","text":"Una función tendrá que ser nombrada adecuadamente para que su trabajo sea fácilmente comprensible tan pronto como leamos su nombre. En realidad, este es el caso de la mayoría de la arquitectura básica de R. Funciones como mean(), print(), summary() tienen nombres muy sencillosUna función tendrá que ser nombrada adecuadamente para que su trabajo sea fácilmente comprensible tan pronto como leamos su nombre. En realidad, este es el caso de la mayoría de la arquitectura básica de R. Funciones como mean(), print(), summary() tienen nombres muy sencillosUna función necesitará argumentos, como los datos sobre los que trabajar y otros objetos que pueden ser valores estáticos entre otras opcionesUna función necesitará argumentos, como los datos sobre los que trabajar y otros objetos que pueden ser valores estáticos entre otras opcionesY finalmente una función producirá una salida basada en su tarea principal y en los argumentos que se le han dado. Normalmente utilizaremos las funciones incorporadas como print(), return()… para producir la salida. La salida puede ser un valor lógico, un número, un carácter, un dataframe… en definitiva cualquier tipo de objeto de R.Y finalmente una función producirá una salida basada en su tarea principal y en los argumentos que se le han dado. Normalmente utilizaremos las funciones incorporadas como print(), return()… para producir la salida. La salida puede ser un valor lógico, un número, un carácter, un dataframe… en definitiva cualquier tipo de objeto de R.Básicamente se trata de la composición de una función:Podemos crear nuestra primera función que se llamará contain_covid19().continuación, podemos verificar los componentes de nuestra función recién creada.Ahora vamos probar nuestra función. Para llamar nuestra función escrita, la usas como usas todas las funciones de R, es decir, escribiendo el nombre de la función y añadiendo los argumentos necesarios.Podemos volver escribir el nombre de cada argumento por precaución. Pero sin especificarlos, el código debería funcionar ya que R tiene en memoria la posición de cada argumento. Así que mientras pongas los valores de los argumentos en el orden correcto, puedes omitir escribir los nombres de los argumentos al llamar las funciones.continuación, veamos qué ocurre si uno de los valores es \"\" o \"yes\".Si proporcionamos un argumento que es reconocido, se producirá un error:Error en contain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", : se pudo encontrar la función \"contain_covid19\"NOTA: Algunas funciones (la mayoría de las veces muy cortas y sencillas) pueden necesitar un nombre y pueden ser utilizadas directamente en una línea de código o dentro de otra función para realizar una tarea rápida. Se llaman funciones anónimas.Por ejemplo, continuación se muestra una primera función anónima que mantiene sólo las variables de carácter de los datos.continuación, otra función que selecciona una de cada dos observaciones de nuestro conjunto de datos (puede ser relevante cuando tenemos datos longitudinales con muchos registros por paciente, por ejemplo, después de haber ordenado por fecha o visita). En este caso, la función adecuada que se escribe fuera de dplyr sería function (x) (x%2 == 0) para aplicarla al vector que contiene todos los números de fila.Un posible código para la misma tarea sería:PRECAUCIÓN: Aunque es cierto que el uso de funciones puede ayudarnos con nuestro código, puede llevar mucho tiempo escribir algunas funciones o arreglar una si ha sido pensada fondo, escrita adecuadamente y está devolviendo errores como resultado. Por esta razón, menudo se recomienda escribir primero el código en R, asegurarse de que hace lo que pretendemos, y luego transformarlo en una función con sus tres componentes principales, como se ha indicado anteriormente.","code":"\nfunction_name <- function(argument_1, argument_2, argument_3){\n  \n           function_task\n  \n           return(output)\n}\ncontain_covid19 <- function(barrier_gest, wear_mask, get_vaccine){\n  \n                            if(barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \"yes\" ) \n       \n                            return(\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\nformals(contain_covid19)## $barrier_gest\n## \n## \n## $wear_mask\n## \n## \n## $get_vaccine\nbody(contain_covid19)## {\n##     if (barrier_gest == \"yes\" & wear_mask == \"yes\" & get_vaccine == \n##         \"yes\") \n##         return(\"success\")\n##     else (\"please make sure all are yes, this pandemic has to end!\")\n## }\nenvironment(contain_covid19)## <environment: R_GlobalEnv>\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"yes\")## [1] \"success\"\ncontain_covid19(\"yes\", \"yes\", \"yes\")## [1] \"success\"\ncontain_covid19(barrier_gest = \"yes\", wear_mask = \"yes\", get_vaccine = \"no\")## [1] \"please make sure all are yes, this pandemic has to end!\"\ncontain_covid19(barrier_gest = \"sometimes\", wear_mask = \"yes\", get_vaccine = \"no\")\nlinelist %>% \n  dplyr::slice_head(n=10) %>%  #equivalente a la función de R base \"head\" que retorna las n primeras observaciones de un conjunto de datos.\n  select(function(x) is.character(x)) \nlinelist %>%   \n   slice_head(n=20) %>% \n   tibble::rownames_to_column() %>% # agregue índices de cada obs como rownames para ver claramente la selección final\n   filter(row_number() %%2 == 0)\nlinelist_firstobs <- head(linelist, 20)\n\nlinelist_firstobs[base::Filter(function(x) (x%%2 == 0), seq(nrow(linelist_firstobs))),]"},{"path":"writing-functions-1.html","id":"examples-2","chapter":"44 Escribir funciones","heading":"44.6 Ejemplos","text":"","code":""},{"path":"writing-functions-1.html","id":"devuelve-tablas-de-proporciones-para-varias-columnas","chapter":"44 Escribir funciones","heading":"Devuelve tablas de proporciones para varias columnas","text":"Sí, ya disponemos de bonitas funciones en muchos paquetes que permiten resumir la información de una manera muy fácil y agradable. Pero aún así intentaremos hacer las nuestras, en nuestros primeros pasos para acostumbrarnos escribir funciones.En este ejemplo queremos mostrar cómo la escritura de una función simple te evitaría copiar y pegar el mismo código varias veces.CONSEJO: Como se ha indicado anteriormente, es muy importante comentar las funciones como se haría en la programación general. Ten en cuenta que el objetivo de una función es hacer un código fácil de leer, más corto y más eficiente. Entonces uno debería ser capaz de entender lo que hace la función con sólo leer su nombre y debería tener más detalles leyendo los comentarios.Una segunda opción es utilizar esta función en otra través de un bucle para hacer el proceso la vez:Una forma más sencilla podría ser utilizar la base R “apply” en lugar de un “bucle ” como se expresa continuación:CONSEJO: R se define menudo como un lenguaje de programación funcional y casi siempre que ejecutas una línea de código estás utilizando algunas funciones incorporadas. Un buen hábito para sentirse más cómodo con la escritura de funciones es echar menudo un vistazo interno cómo están construidas las funciones básicas que utiliza diario. El atajo para hacerlo es seleccionar el nombre de la función y luego clicar en Ctrl+F2 o fn+F2 o Cmd+F2 (dependiendo de tu ordenador).","code":"\nproptab_multiple <- function(my_data, var_to_tab){\n  \n  #imprime el nombre de cada variable de interés antes de realizar la tabulación\n  print(var_to_tab)\n\n  with(my_data,\n       rbind( #enlazar por filas los resultados de las siguientes dos funciones \n        #tabular la variable de interés: da solo números\n          table(my_data[[var_to_tab]], useNA = \"no\"),\n          #calcular la proporción de cada variable de interés y redondear el valor a 2 decimales\n         round(prop.table(table(my_data[[var_to_tab]]))*100,2)\n         )\n       )\n}\n\n\nproptab_multiple(linelist, \"gender\")## [1] \"gender\"##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\nproptab_multiple(linelist, \"age_cat\")## [1] \"age_cat\"##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\nproptab_multiple(linelist, \"outcome\")## [1] \"outcome\"##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44\nfor(var_to_tab in c(\"gender\",\"age_cat\",  \"outcome\")){\n  \n  print(proptab_multiple(linelist, var_to_tab))\n  \n}## [1] \"gender\"\n##            f       m\n## [1,] 2807.00 2803.00\n## [2,]   50.04   49.96\n## [1] \"age_cat\"\n##          0-4     5-9  10-14  15-19   20-29 30-49 50-69 70+\n## [1,] 1095.00 1095.00 941.00 743.00 1073.00   754 95.00 6.0\n## [2,]   18.87   18.87  16.22  12.81   18.49    13  1.64 0.1\n## [1] \"outcome\"\n##        Death Recover\n## [1,] 2582.00 1983.00\n## [2,]   56.56   43.44"},{"path":"writing-functions-1.html","id":"using-purrr-writing-functions-that-can-be-iteratively-applied","chapter":"44 Escribir funciones","heading":"44.7 Uso de purrr: escribir funciones que se pueden aplicar de forma iterativa","text":"","code":""},{"path":"writing-functions-1.html","id":"modificar-el-tipo-de-múltiples-columnas-en-unos-datos","chapter":"44 Escribir funciones","heading":"Modificar el tipo de múltiples columnas en unos datos","text":"Digamos que muchas variables de carácter en los datos originales de linelist necesitan ser cambiadas “factor” para propósitos de análisis y trazado. En lugar de repetir el paso varias veces, podemos utilizar simplemente lapply() para realizar la transformación de todas las variables afectadas en una sola línea de código.PRECAUCIÓN: lapply() devuelve una lista, por lo que su uso puede requerir una modificación adicional como último paso.El mismo paso puede realizarse utilizando la función map_if() del paquete purrr","code":"\nlinelist_factor2 <- linelist %>%\n  purrr::map_if(is.character, as.factor)\n\n\nlinelist_factor2 %>%\n        glimpse()## List of 30\n##  $ case_id             : Factor w/ 5888 levels \"00031d\",\"00086d\",..: 2134 3022 396 4203 3084 4347 179 1241 5594 430 ...\n##  $ generation          : num [1:5888] 4 4 2 3 3 3 4 4 4 4 ...\n##  $ date_infection      : Date[1:5888], format: \"2014-05-08\" NA NA ...\n##  $ date_onset          : Date[1:5888], format: \"2014-05-13\" \"2014-05-13\" \"2014-05-16\" ...\n##  $ date_hospitalisation: Date[1:5888], format: \"2014-05-15\" \"2014-05-14\" \"2014-05-18\" ...\n##  $ date_outcome        : Date[1:5888], format: NA \"2014-05-18\" \"2014-05-30\" ...\n##  $ outcome             : Factor w/ 2 levels \"Death\",\"Recover\": NA 2 2 NA 2 2 2 1 2 1 ...\n##  $ gender              : Factor w/ 2 levels \"f\",\"m\": 2 1 2 1 2 1 1 1 2 1 ...\n##  $ age                 : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_unit            : Factor w/ 2 levels \"months\",\"years\": 2 2 2 2 2 2 2 2 2 2 ...\n##  $ age_years           : num [1:5888] 2 3 56 18 3 16 16 0 61 27 ...\n##  $ age_cat             : Factor w/ 8 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 7 4 1 4 4 1 7 5 ...\n##  $ age_cat5            : Factor w/ 18 levels \"0-4\",\"5-9\",\"10-14\",..: 1 1 12 4 1 4 4 1 13 6 ...\n##  $ hospital            : Factor w/ 6 levels \"Central Hospital\",..: 4 3 6 5 2 5 3 3 3 3 ...\n##  $ lon                 : num [1:5888] -13.2 -13.2 -13.2 -13.2 -13.2 ...\n##  $ lat                 : num [1:5888] 8.47 8.45 8.46 8.48 8.46 ...\n##  $ infector            : Factor w/ 2697 levels \"00031d\",\"002e6c\",..: 2594 NA NA 2635 180 1799 1407 195 NA NA ...\n##  $ source              : Factor w/ 2 levels \"funeral\",\"other\": 2 NA NA 2 2 2 2 2 NA NA ...\n##  $ wt_kg               : num [1:5888] 27 25 91 41 36 56 47 0 86 69 ...\n##  $ ht_cm               : num [1:5888] 48 59 238 135 71 116 87 11 226 174 ...\n##  $ ct_blood            : num [1:5888] 22 22 21 23 23 21 21 22 22 22 ...\n##  $ fever               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ chills              : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ cough               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 2 ...\n##  $ aches               : Factor w/ 2 levels \"no\",\"yes\": 1 NA NA 1 1 1 NA 1 1 1 ...\n##  $ vomit               : Factor w/ 2 levels \"no\",\"yes\": 2 NA NA 1 2 2 NA 2 2 1 ...\n##  $ temp                : num [1:5888] 36.8 36.9 36.9 36.8 36.9 37.6 37.3 37 36.4 35.9 ...\n##  $ time_admission      : Factor w/ 1072 levels \"00:10\",\"00:29\",..: NA 308 746 415 514 589 609 297 409 387 ...\n##  $ bmi                 : num [1:5888] 117.2 71.8 16.1 22.5 71.4 ...\n##  $ days_onset_hosp     : num [1:5888] 2 1 2 2 1 1 2 1 1 2 ..."},{"path":"writing-functions-1.html","id":"elaborar-de-forma-iterativa-gráficos-para-diferentes-niveles-de-una-variable","chapter":"44 Escribir funciones","heading":"Elaborar de forma iterativa gráficos para diferentes niveles de una variable","text":"Produciremos aquí un gráfico circular para ver la distribución del resultado de los pacientes en China durante el brote de H7N9 para cada provincia. En lugar de repetir el código para cada una de ellas, nos limitaremos aplicar una función que crearemos.","code":"\n#precisar opciones para el uso de highchart\noptions(highcharter.theme =   highcharter::hc_theme_smpl(tooltip = list(valueDecimals = 2)))\n\n\n#Cree una función llamada \"chart_outcome_province\" que tome como argumento el conjunto de datos y el nombre de la provincia para la cual plotear la distribución del resultado.\n\nchart_outcome_province <- function(data_used, prov){\n  \n  tab_prov <- data_used %>% \n    filter(province == prov,\n           !is.na(outcome))%>% \n    group_by(outcome) %>% \n    count() %>%\n    adorn_totals(where = \"row\") %>% \n    adorn_percentages(denominator = \"col\", )%>%\n    mutate(\n        perc_outcome= round(n*100,2))\n  \n  \n  tab_prov %>%\n    filter(outcome != \"Total\") %>% \n  highcharter::hchart(\n    \"pie\", hcaes(x = outcome, y = perc_outcome),\n    name = paste0(\"Distibution of the outcome in:\", prov)\n    )\n  \n}\n\nchart_outcome_province(flu_china, \"Shanghai\")\nchart_outcome_province(flu_china,\"Zhejiang\")\nchart_outcome_province(flu_china,\"Jiangsu\")"},{"path":"writing-functions-1.html","id":"producir-iterativamente-tablas-para-diferentes-niveles-de-una-variable","chapter":"44 Escribir funciones","heading":"Producir iterativamente tablas para diferentes niveles de una variable","text":"Aquí crearemos tres indicadores para resumirlos en una tabla y nos gustaría elaborar esta tabla para cada una de las provincias. Nuestros indicadores son el retraso entre el inicio y la hospitalización, el porcentaje de recuperación y la edad media de los casos.Indicateurs pour la province de: ShanghaiIndicateursEstimationMean delay onset-hosp4.0Percentage recovery46.7Median age cases67.0Indicateurs pour la province de: JiangsuIndicateursEstimationMean delay onset-hosp6.0Percentage recovery71.4Median age cases55.0","code":"\nindic_1 <- flu_china %>% \n  group_by(province) %>% \n  mutate(\n    date_hosp= strptime(date_of_hospitalisation, format = \"%m/%d/%Y\"),\n    date_ons= strptime(date_of_onset, format = \"%m/%d/%Y\"), \n    delay_onset_hosp= as.numeric(date_hosp - date_ons)/86400,\n    mean_delay_onset_hosp = round(mean(delay_onset_hosp, na.rm=TRUE ), 0)) %>%\n  select(province, mean_delay_onset_hosp)  %>% \n  distinct()\n     \n\nindic_2 <-  flu_china %>% \n            filter(!is.na(outcome)) %>% \n            group_by(province, outcome) %>% \n            count() %>%\n            pivot_wider(names_from = outcome, values_from = n) %>% \n    adorn_totals(where = \"col\") %>% \n    mutate(\n        perc_recovery= round((Recover/Total)*100,2))%>% \n  select(province, perc_recovery)\n    \n    \n    \nindic_3 <-  flu_china %>% \n            group_by(province) %>% \n            mutate(\n                    median_age_cases = median(as.numeric(age), na.rm = TRUE)\n            ) %>% \n  select(province, median_age_cases)  %>% \n  distinct()## Warning in median(as.numeric(age), na.rm = TRUE): NAs introduced by coercion\n#unir los indicadores de los tres conjuntos de datos\n\ntable_indic_all <- indic_1 %>% \n  dplyr::left_join(indic_2, by = \"province\") %>% \n        left_join(indic_3, by = \"province\")\n\n\n#imprimir los indicadores en una flextable\n\n\nprint_indic_prov <-  function(table_used, prov){\n  \n  #first transform a bit the dataframe for printing ease\n  indic_prov <- table_used %>%\n    filter(province==prov) %>%\n    pivot_longer(names_to = \"Indicateurs\", cols = 2:4) %>% \n   mutate( indic_label = factor(Indicateurs,\n   levels= c(\"mean_delay_onset_hosp\",\"perc_recovery\",\"median_age_cases\"),\n   labels=c(\"Mean delay onset-hosp\",\"Percentage of recovery\", \"Median age of the cases\"))\n   ) %>% \n    ungroup(province) %>% \n    select(indic_label, value)\n  \n\n    tab_print <- flextable(indic_prov)  %>%\n    theme_vanilla() %>% \n    flextable::fontsize(part = \"body\", size = 10) \n    \n    \n     tab_print <- tab_print %>% \n                  autofit()   %>%\n                  set_header_labels( \n                indic_label= \"Indicateurs\", value= \"Estimation\") %>%\n    flextable::bg( bg = \"darkblue\", part = \"header\") %>%\n    flextable::bold(part = \"header\") %>%\n    flextable::color(color = \"white\", part = \"header\") %>% \n    add_header_lines(values = paste0(\"Indicateurs pour la province de: \", prov)) %>% \nbold(part = \"header\")\n \n tab_print <- set_formatter_type(tab_print,\n   fmt_double = \"%.2f\",\n   na_str = \"-\")\n\ntab_print \n    \n}\n\n\n\n\nprint_indic_prov(table_indic_all, \"Shanghai\")\nprint_indic_prov(table_indic_all, \"Jiangsu\")"},{"path":"writing-functions-1.html","id":"tips-and-best-practices-for-well-functioning-functions","chapter":"44 Escribir funciones","heading":"44.8 Consejos y buens prácticas para el buen funcionamiento de las funciones","text":"La programación funcional está pensada para aliviar el código y facilitar su lectura. Podría producir lo contrario. Los siguientes consejos le ayudarán tener un código limpio y fácil de leer.","code":""},{"path":"writing-functions-1.html","id":"nombres-y-sintaxis","chapter":"44 Escribir funciones","heading":"Nombres y sintaxis","text":"Evitar el uso de caracteres que podrían haber sido fácilmente tomados por otras funciones ya existentes en su entornoEvitar el uso de caracteres que podrían haber sido fácilmente tomados por otras funciones ya existentes en su entornoSe recomienda que el nombre de la función sea corto y sencillo de entender para otro lectorSe recomienda que el nombre de la función sea corto y sencillo de entender para otro lectorEs preferible utilizar verbos como nombre de la función y sustantivos para los nombres de los argumentos.Es preferible utilizar verbos como nombre de la función y sustantivos para los nombres de los argumentos.","code":""},{"path":"writing-functions-1.html","id":"nombres-de-columnas-y-evaluación-ordenada","chapter":"44 Escribir funciones","heading":"Nombres de columnas y evaluación ordenada","text":"Si quiere saber cómo referenciar nombres de columnas que se proporcionan su código como argumentos, lea esta guía de programación de tidyverse. Entre los temas tratados están la evaluación ordenada y el uso del abrazo con {{ }} “llaves dobles”Por ejemplo, aquí hay un esqueleto rápido de código de plantilla del tutorial de la página mencionada anteriormente:","code":"\nvar_summary <- function(data, var) {\n  data %>%\n    summarise(n = n(), min = min({{ var }}), max = max({{ var }}))\n}\nmtcars %>% \n  group_by(cyl) %>% \n  var_summary(mpg)"},{"path":"writing-functions-1.html","id":"pruebas-y-tratamiento-de-errores","chapter":"44 Escribir funciones","heading":"Pruebas y tratamiento de errores","text":"Cuanto más complicada sea la tarea de una función, mayor será la posibilidad de errores. Por lo tanto, veces es necesario añadir alguna verificación dentro de la función para ayudar entender rápidamente de dónde proviene el error y encontrar una manera de solucionarlo.Puede ser más que recomendable introducir una comprobación sobre la ausencia de un argumento utilizando missing(argumento). Esta simple comprobación puede devolver el valor “TRUE” o “FALSE”.Utiliza stop() para errores más detectables.Como vemos cuando ejecutamos la mayoría de las funciones incorporadas, hay mensajes y advertencias que pueden aparecer en ciertas condiciones. Podemos integrarlos en nuestras funciones escritas utilizando las funciones message() y warning().Como vemos cuando ejecutamos la mayoría de las funciones incorporadas, hay mensajes y advertencias que pueden aparecer en ciertas condiciones. Podemos integrarlos en nuestras funciones escritas utilizando las funciones message() y warning().También podemos manejar los errores usando safely() que toma una función como argumento y la ejecuta de forma segura. De hecho, la función se ejecutará sin detenerse si encuentra un error. safely() devuelve como salida una lista con dos objetos que son los resultados y el error que se ha “saltado”.También podemos manejar los errores usando safely() que toma una función como argumento y la ejecuta de forma segura. De hecho, la función se ejecutará sin detenerse si encuentra un error. safely() devuelve como salida una lista con dos objetos que son los resultados y el error que se ha “saltado”.Podemos verificarlo ejecutando primero la mean() como función, y luego ejecutarla con safely().Como se ha dicho anteriormente, comentar bien nuestros códigos ya es una buena forma de tener documentación en nuestro trabajo.","code":"\ncontain_covid19_missing <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if (missing(barrier_gest)) (print(\"please provide arg1\"))\n  if (missing(wear_mask)) print(\"please provide arg2\")\n  if (missing(get_vaccine)) print(\"please provide arg3\")\n\n\n  if (!barrier_gest == \"yes\" | wear_mask ==\"yes\" | get_vaccine == \"yes\" ) \n       \n       return (\"you can do better\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_missing(get_vaccine = \"yes\")## [1] \"please provide arg1\"\n## [1] \"please provide arg2\"## Error in contain_covid19_missing(get_vaccine = \"yes\"): argument \"barrier_gest\" is missing, with no default\ncontain_covid19_stop <- function(barrier_gest, wear_mask, get_vaccine){\n  \n  if(!is.character(barrier_gest)) (stop(\"arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\"))\n  \n  if (barrier_gest == \"yes\" & wear_mask ==\"yes\" & get_vaccine == \"yes\" ) \n       \n       return (\"success\")\n  \n  else(\"please make sure all are yes, this pandemic has to end!\")\n}\n\n\ncontain_covid19_stop(barrier_gest=1, wear_mask=\"yes\", get_vaccine = \"no\")## Error in contain_covid19_stop(barrier_gest = 1, wear_mask = \"yes\", get_vaccine = \"no\"): arg1 should be a character, please enter the value with `yes`, `no` or `sometimes\nmap(linelist, mean)## $case_id\n## [1] NA\n## \n## $generation\n## [1] 16.56165\n## \n## $date_infection\n## [1] NA\n## \n## $date_onset\n## [1] NA\n## \n## $date_hospitalisation\n## [1] \"2014-11-03\"\n## \n## $date_outcome\n## [1] NA\n## \n## $outcome\n## [1] NA\n## \n## $gender\n## [1] NA\n## \n## $age\n## [1] NA\n## \n## $age_unit\n## [1] NA\n## \n## $age_years\n## [1] NA\n## \n## $age_cat\n## [1] NA\n## \n## $age_cat5\n## [1] NA\n## \n## $hospital\n## [1] NA\n## \n## $lon\n## [1] -13.23381\n## \n## $lat\n## [1] 8.469638\n## \n## $infector\n## [1] NA\n## \n## $source\n## [1] NA\n## \n## $wt_kg\n## [1] 52.64487\n## \n## $ht_cm\n## [1] 124.9633\n## \n## $ct_blood\n## [1] 21.20686\n## \n## $fever\n## [1] NA\n## \n## $chills\n## [1] NA\n## \n## $cough\n## [1] NA\n## \n## $aches\n## [1] NA\n## \n## $vomit\n## [1] NA\n## \n## $temp\n## [1] NA\n## \n## $time_admission\n## [1] NA\n## \n## $bmi\n## [1] 46.89023\n## \n## $days_onset_hosp\n## [1] NA\nsafe_mean <- safely(mean)\nlinelist %>% \n  map(safe_mean)## $case_id\n## $case_id$result\n## [1] NA\n## \n## $case_id$error\n## NULL\n## \n## \n## $generation\n## $generation$result\n## [1] 16.56165\n## \n## $generation$error\n## NULL\n## \n## \n## $date_infection\n## $date_infection$result\n## [1] NA\n## \n## $date_infection$error\n## NULL\n## \n## \n## $date_onset\n## $date_onset$result\n## [1] NA\n## \n## $date_onset$error\n## NULL\n## \n## \n## $date_hospitalisation\n## $date_hospitalisation$result\n## [1] \"2014-11-03\"\n## \n## $date_hospitalisation$error\n## NULL\n## \n## \n## $date_outcome\n## $date_outcome$result\n## [1] NA\n## \n## $date_outcome$error\n## NULL\n## \n## \n## $outcome\n## $outcome$result\n## [1] NA\n## \n## $outcome$error\n## NULL\n## \n## \n## $gender\n## $gender$result\n## [1] NA\n## \n## $gender$error\n## NULL\n## \n## \n## $age\n## $age$result\n## [1] NA\n## \n## $age$error\n## NULL\n## \n## \n## $age_unit\n## $age_unit$result\n## [1] NA\n## \n## $age_unit$error\n## NULL\n## \n## \n## $age_years\n## $age_years$result\n## [1] NA\n## \n## $age_years$error\n## NULL\n## \n## \n## $age_cat\n## $age_cat$result\n## [1] NA\n## \n## $age_cat$error\n## NULL\n## \n## \n## $age_cat5\n## $age_cat5$result\n## [1] NA\n## \n## $age_cat5$error\n## NULL\n## \n## \n## $hospital\n## $hospital$result\n## [1] NA\n## \n## $hospital$error\n## NULL\n## \n## \n## $lon\n## $lon$result\n## [1] -13.23381\n## \n## $lon$error\n## NULL\n## \n## \n## $lat\n## $lat$result\n## [1] 8.469638\n## \n## $lat$error\n## NULL\n## \n## \n## $infector\n## $infector$result\n## [1] NA\n## \n## $infector$error\n## NULL\n## \n## \n## $source\n## $source$result\n## [1] NA\n## \n## $source$error\n## NULL\n## \n## \n## $wt_kg\n## $wt_kg$result\n## [1] 52.64487\n## \n## $wt_kg$error\n## NULL\n## \n## \n## $ht_cm\n## $ht_cm$result\n## [1] 124.9633\n## \n## $ht_cm$error\n## NULL\n## \n## \n## $ct_blood\n## $ct_blood$result\n## [1] 21.20686\n## \n## $ct_blood$error\n## NULL\n## \n## \n## $fever\n## $fever$result\n## [1] NA\n## \n## $fever$error\n## NULL\n## \n## \n## $chills\n## $chills$result\n## [1] NA\n## \n## $chills$error\n## NULL\n## \n## \n## $cough\n## $cough$result\n## [1] NA\n## \n## $cough$error\n## NULL\n## \n## \n## $aches\n## $aches$result\n## [1] NA\n## \n## $aches$error\n## NULL\n## \n## \n## $vomit\n## $vomit$result\n## [1] NA\n## \n## $vomit$error\n## NULL\n## \n## \n## $temp\n## $temp$result\n## [1] NA\n## \n## $temp$error\n## NULL\n## \n## \n## $time_admission\n## $time_admission$result\n## [1] NA\n## \n## $time_admission$error\n## NULL\n## \n## \n## $bmi\n## $bmi$result\n## [1] 46.89023\n## \n## $bmi$error\n## NULL\n## \n## \n## $days_onset_hosp\n## $days_onset_hosp$result\n## [1] NA\n## \n## $days_onset_hosp$error\n## NULL"},{"path":"writing-functions-1.html","id":"resources-36","chapter":"44 Escribir funciones","heading":"44.9 Recursos","text":"Funciones en R Data Science en españolCheatsheet advanzado de programación de RCheatsheet del paquete purrVídeo-ACM charla de Hadley Wickham: La alegría de la programación funcional (cómo funciona map_dbl)","code":""},{"path":"directory-interactions.html","id":"directory-interactions","chapter":"45 Interacciones con directorios","heading":"45 Interacciones con directorios","text":"En esta página cubrimos los escenarios comunes en los que se crea, se interactúa, se guarda y se importa con directorios (carpetas).","code":""},{"path":"directory-interactions.html","id":"preparation-38","chapter":"45 Interacciones con directorios","heading":"45.1 Preparación","text":"","code":""},{"path":"directory-interactions.html","id":"paquete-fs","chapter":"45 Interacciones con directorios","heading":"Paquete fs","text":"El paquete fs es un paquete tidyverse que facilita las interacciones con los directorios, mejorando algunas de las funciones de R base. En las secciones siguientes utilizaremos menudo funciones de fs.","code":"\npacman::p_load(\n  fs,             # file/directory interactions\n  rio,            # import/export\n  here,           # relative file pathways\n  tidyverse)      # data management and visualization"},{"path":"directory-interactions.html","id":"imprimir-el-directorio-como-un-árbol-de-dendrogramas","chapter":"45 Interacciones con directorios","heading":"Imprimir el directorio como un árbol de dendrogramas","text":"Utiliza la función dir_tree() de fs.Proporciona la ruta de la carpeta path = y decide si quieres mostrar sólo un nivel (recurse = FALSE) o todos los archivos en todos los subniveles (recurse = TRUE). continuación utilizamos () como abreviatura del proyecto R y especificamos su subcarpeta “data”, que contiene todos los datos utilizados para este manual de R. Lo configuramos para que muestre todos los archivos dentro de “data” y sus subcarpetas (por ejemplo, “cache”, “epidemic models”, “population”, “shp” y “weather”).","code":"\nfs::dir_tree(path = here(\"data\"), recurse = TRUE)## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_es/data\n## ├── cache\n## │   └── epidemic_models\n## │       ├── 2015-04-30\n## │       │   ├── estimated_reported_cases_samples.rds\n## │       │   ├── estimate_samples.rds\n## │       │   ├── latest_date.rds\n## │       │   ├── reported_cases.rds\n## │       │   ├── summarised_estimated_reported_cases.rds\n## │       │   ├── summarised_estimates.rds\n## │       │   └── summary.rds\n## │       ├── epinow_res.rds\n## │       ├── epinow_res_small.rds\n## │       ├── generation_time.rds\n## │       └── incubation_period.rds\n## ├── case_linelists\n## │   ├── cleaning_dict.csv\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── linelist_cleaned.rds\n## │   └── linelist_raw.xlsx\n## ├── example\n## │   ├── Central Hospital.csv\n## │   ├── district_weekly_count_data.xlsx\n## │   ├── fluH7N9_China_2013.csv\n## │   ├── hospital_linelists.xlsx\n## │   ├── linelists\n## │   │   ├── 20201007linelist.csv\n## │   │   ├── case_linelist20201006.csv\n## │   │   ├── case_linelist_2020-10-02.csv\n## │   │   ├── case_linelist_2020-10-03.csv\n## │   │   ├── case_linelist_2020-10-04.csv\n## │   │   ├── case_linelist_2020-10-05.csv\n## │   │   └── case_linelist_2020-10-08.xlsx\n## │   ├── Military Hospital.csv\n## │   ├── Missing.csv\n## │   ├── Other.csv\n## │   ├── Port Hospital.csv\n## │   └── St. Mark's Maternity Hospital (SMMH).csv\n## ├── flexdashboard\n## │   ├── outbreak_dashboard.html\n## │   ├── outbreak_dashboard.Rmd\n## │   ├── outbreak_dashboard_shiny.Rmd\n## │   ├── outbreak_dashboard_test.html\n## │   └── outbreak_dashboard_test.Rmd\n## ├── gis\n## │   ├── africa_countries.geo.json\n## │   ├── covid_incidence.csv\n## │   ├── covid_incidence_map.R\n## │   ├── linelist_cleaned_with_adm3.rds\n## │   ├── population\n## │   │   ├── sle_admpop_adm3_2020.csv\n## │   │   └── sle_population_statistics_sierraleone_2020.xlsx\n## │   └── shp\n## │       ├── README.txt\n## │       ├── sle_adm3.CPG\n## │       ├── sle_adm3.dbf\n## │       ├── sle_adm3.prj\n## │       ├── sle_adm3.sbn\n## │       ├── sle_adm3.sbx\n## │       ├── sle_adm3.shp\n## │       ├── sle_adm3.shp.xml\n## │       ├── sle_adm3.shx\n## │       ├── sle_hf.CPG\n## │       ├── sle_hf.dbf\n## │       ├── sle_hf.prj\n## │       ├── sle_hf.sbn\n## │       ├── sle_hf.sbx\n## │       ├── sle_hf.shp\n## │       └── sle_hf.shx\n## ├── godata\n## │   ├── cases_clean.rds\n## │   ├── contacts_clean.rds\n## │   ├── followups_clean.rds\n## │   └── relationships_clean.rds\n## ├── likert_data.csv\n## ├── linelist_cleaned.xlsx\n## ├── make_evd_dataset.R\n## ├── malaria_app\n## │   ├── app.R\n## │   ├── data\n## │   │   └── facility_count_data.rds\n## │   ├── funcs\n## │   │   └── plot_epicurve.R\n## │   ├── global.R\n## │   ├── malaria_app.Rproj\n## │   ├── server.R\n## │   └── ui.R\n## ├── malaria_facility_count_data.rds\n## ├── phylo\n## │   ├── sample_data_Shigella_tree.csv\n## │   ├── Shigella_subtree_2.nwk\n## │   ├── Shigella_subtree_2.txt\n## │   └── Shigella_tree.txt\n## ├── rmarkdown\n## │   ├── outbreak_report.docx\n## │   ├── outbreak_report.html\n## │   ├── outbreak_report.pdf\n## │   ├── outbreak_report.pptx\n## │   ├── outbreak_report.Rmd\n## │   ├── report_tabbed_example.html\n## │   └── report_tabbed_example.Rmd\n## ├── standardization\n## │   ├── country_demographics.csv\n## │   ├── country_demographics_2.csv\n## │   ├── deaths_countryA.csv\n## │   ├── deaths_countryB.csv\n## │   └── world_standard_population_by_sex.csv\n## ├── surveys\n## │   ├── population.xlsx\n## │   ├── survey_data.xlsx\n## │   └── survey_dict.xlsx\n## └── time_series\n##     ├── campylobacter_germany.xlsx\n##     └── weather\n##         ├── germany_weather2002.nc\n##         ├── germany_weather2003.nc\n##         ├── germany_weather2004.nc\n##         ├── germany_weather2005.nc\n##         ├── germany_weather2006.nc\n##         ├── germany_weather2007.nc\n##         ├── germany_weather2008.nc\n##         ├── germany_weather2009.nc\n##         ├── germany_weather2010.nc\n##         └── germany_weather2011.nc"},{"path":"directory-interactions.html","id":"list-files-in-a-directory","chapter":"45 Interacciones con directorios","heading":"45.2 Listar los archivos de un directorio","text":"Para listar sólo los nombres de los archivos de un directorio puedes utilizar dir() de R base. Por ejemplo, este comando lista los nombres de los archivos de la subcarpeta “population” de la carpeta “data” en un proyecto R. La ruta relativa de los archivos se proporciona utilizando () (sobre la que puede leer más en la página de importación y exportación).Para listar las rutas completas de los archivos del directorio, puedes utilizar dir_ls() de fs. Una alternativa de R base es list.files().Para obtener toda la información de los metadatos de cada archivo en un directorio, (por ejemplo, la ruta, la fecha de modificación, etc.) puedes utilizar dir_info() de fs.Esto puede ser especialmente útil si quieres extraer la última hora de modificación del archivo, por ejemplo si quieres importar la versión más reciente de un archivo. Para ver un ejemplo de esto, consulta la página de importación y exportación.Aquí está el dataframe devuelto. Desplázate la derecha para ver todas las columnas.","code":"\n# file names\ndir(here(\"data\", \"gis\", \"population\"))## [1] \"sle_admpop_adm3_2020.csv\"                        \"sle_population_statistics_sierraleone_2020.xlsx\"\n# file paths\ndir_ls(here(\"data\", \"gis\", \"population\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_es/data/gis/population/sle_admpop_adm3_2020.csv\n## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_es/data/gis/population/sle_population_statistics_sierraleone_2020.xlsx\n# file info\ndir_info(here(\"data\", \"gis\", \"population\"))"},{"path":"directory-interactions.html","id":"file-information","chapter":"45 Interacciones con directorios","heading":"45.3 Información sobre el archivo","text":"Para extraer información de metadatos sobre un archivo específico, puedes utilizar file_info() de fs (o file.info() de R base).Aquí usamos $ para indexar el resultado y devolver sólo el valor de modification_time.","code":"\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))\nfile_info(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))$modification_time## [1] \"2022-11-22 14:52:20 CET\""},{"path":"directory-interactions.html","id":"check-if-exists","chapter":"45 Interacciones con directorios","heading":"45.4 Comprobar si existe","text":"","code":""},{"path":"directory-interactions.html","id":"objetos-r","chapter":"45 Interacciones con directorios","heading":"Objetos R","text":"Puedes utilizar exists() de R base para comprobar si un objeto R existe dentro de R (escribe el nombre del objeto entre comillas).Ten en cuenta que algunos paquetes de R base utilizan nombres de objetos genéricos como “data” entre bastidores, que aparecerán como TRUE menos que se especifique inherit = FALSE. Esta es una razón para nombrar tu conjunto de datos como “data”.Si estás escribiendo una función, deberías utilizar missing() de R base para comprobar si un argumento está presente o , en lugar de exists().","code":"\nexists(\"linelist\")## [1] TRUE\nexists(\"data\")## [1] TRUE\nexists(\"data\", inherit = FALSE)## [1] FALSE"},{"path":"directory-interactions.html","id":"directorios","chapter":"45 Interacciones con directorios","heading":"Directorios","text":"Para comprobar si un directorio existe, escribe la ruta del archivo (y el nombre del archivo) is_dir() de fs. Desplázate la derecha para ver que se imprime TRUE.Una alternativa de R base es file.exists().","code":"\nis_dir(here(\"data\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_es/data \n##                                                            TRUE"},{"path":"directory-interactions.html","id":"files","chapter":"45 Interacciones con directorios","heading":"Files","text":"Para comprobar si un archivo específico existe, utiliza is_file() de fs. Desplázate la derecha para ver que se imprime TRUE.Una alternativa de R base es file.exists().","code":"\nis_file(here(\"data\", \"case_linelists\", \"linelist_cleaned.rds\"))## C:/Users/neale/Documents/Applied Epi/repos/epiRhandbook_es/data/case_linelists/linelist_cleaned.rds \n##                                                                                                TRUE"},{"path":"directory-interactions.html","id":"create","chapter":"45 Interacciones con directorios","heading":"45.5 Crear","text":"","code":""},{"path":"directory-interactions.html","id":"directorios-1","chapter":"45 Interacciones con directorios","heading":"Directorios","text":"Para crear un nuevo directorio (carpeta) puede utilizar dir_create() de fs. Si el directorio ya existe, se sobrescribirá y se devolverá ningún error.Una alternativa es dir.create() de R base, que mostrará un error si el directorio ya existe. En cambio, dir_create() en este escenario será silencioso.","code":"\ndir_create(here(\"data\", \"test\"))"},{"path":"directory-interactions.html","id":"archivos","chapter":"45 Interacciones con directorios","heading":"Archivos","text":"Puedes crear un archivo (vacío) con file_create() de fs. Si el archivo ya existe, se sobreescribirá ni se modificará.Una alternativa de R base es file.create(). Pero si el archivo ya existe, esta opción lo truncará. Si se utiliza file_create() el archivo se dejará sin cambios","code":"\nfile_create(here(\"data\", \"test.rds\"))"},{"path":"directory-interactions.html","id":"crear-si-no-existe","chapter":"45 Interacciones con directorios","heading":"Crear si no existe","text":"EN CONSTRUCCIÓN","code":""},{"path":"directory-interactions.html","id":"delete","chapter":"45 Interacciones con directorios","heading":"45.6 Borrar","text":"","code":""},{"path":"directory-interactions.html","id":"objetos-r-1","chapter":"45 Interacciones con directorios","heading":"Objetos R","text":"Utiliza rm() de R base para eliminar un objeto R.","code":""},{"path":"directory-interactions.html","id":"directorios-2","chapter":"45 Interacciones con directorios","heading":"Directorios","text":"Utiliza dir_delete() de fs.","code":""},{"path":"directory-interactions.html","id":"archivos-1","chapter":"45 Interacciones con directorios","heading":"Archivos","text":"Puedes eliminar archivos con file_delete() de fs.","code":""},{"path":"directory-interactions.html","id":"running-other-files","chapter":"45 Interacciones con directorios","heading":"45.7 Ejecución de otros archivos","text":"","code":""},{"path":"directory-interactions.html","id":"source","chapter":"45 Interacciones con directorios","heading":"source()","text":"Para ejecutar un script de R desde otro script de R, puedes utilizar el comando source() (de R base).Esto equivale ver el script de R anterior y clicar en el botón “Source” en la parte superior derecha del script. Esto ejecutará el script pero lo hará de forma silenciosa (sin salida la consola de R) menos que se pretenda específicamente. Consulta la página sobre [Consola interactiva] para ver ejemplos de uso de source() para interactuar con un usuario través de la consola de R en modo de pregunta y respuesta.","code":"\nsource(here(\"scripts\", \"cleaning_scripts\", \"clean_testing_data.R\"))"},{"path":"directory-interactions.html","id":"render","chapter":"45 Interacciones con directorios","heading":"render()","text":"render() es una variación de source() que se utiliza más menudo para los scripts de R markdown. Tu pescribes input = que es el archivo R markdown, y también output_format = (“html_document”, “pdf_document”, “word_document”, ““)Mira la página sobre Informes con R Markdown para más detalles. También consulta la documentación de render() aquí o escribiendo ?render.","code":""},{"path":"directory-interactions.html","id":"ejecutar-archivos-en-un-directorio","chapter":"45 Interacciones con directorios","heading":"Ejecutar archivos en un directorio","text":"Puedes crear un bucle y utilizarlo para source() cada archivo en un directorio, identificado con dir().Si sólo quieres ejecutar determinados scripts, puedes identificarlos por su nombre de la siguiente manera:Aquí puedes ver una comparación de las funciones fs y R base.","code":"\nfor(script in dir(here(\"scripts\"), pattern = \".R$\")) {   # for each script name in the R Project's \"scripts\" folder (with .R extension)\n  source(here(\"scripts\", script))                        # source the file with the matching name that exists in the scripts folder\n}\nscripts_to_run <- c(\n     \"epicurves.R\",\n     \"demographic_tables.R\",\n     \"survival_curves.R\"\n)\n\nfor(script in scripts_to_run) {\n  source(here(\"scripts\", script))\n}"},{"path":"directory-interactions.html","id":"importar-archivos-en-un-directorio","chapter":"45 Interacciones con directorios","heading":"Importar archivos en un directorio","text":"Consulta la página sobre importación y exportación para importar y exportar archivos individuales.Consulta también la página de importación y exportación para conocer los métodos para importar automáticamente el archivo más reciente, basándose en una fecha del nombre del archivo o mirando los metadatos del mismo.Consulta la página sobre Iteración, bucles y listas para ver un ejemplo con el paquete purrr demostrando:Dividir un dataframe y guardarlo como múltiples archivos CSVDividir un dataframe y guardar cada parte como una hoja separada dentro de un libro de ExcelImportar varios archivos CSV y combinarlos en un dataframeImportar un libro de Excel con varias hojas y combinarlas en un dataframe","code":""},{"path":"directory-interactions.html","id":"base-r-4","chapter":"45 Interacciones con directorios","heading":"45.8 R base","text":"Mira continuación las funciones list.files() y dir(), que realizan la misma operación de listar archivos dentro de un directorio especificado. Puedes especificar ignore.case = o un patrón específico para buscar.Si un archivo está actualmente “abierto”, se mostrará en su carpeta con una tilde delante, como “~$hospital_linelists.xlsx”.","code":"\nlist.files(path = here(\"data\"))\n\nlist.files(path = here(\"data\"), pattern = \".csv\")\n# dir(path = here(\"data\"), pattern = \".csv\")\n\nlist.files(path = here(\"data\"), pattern = \"evd\", ignore.case = TRUE)"},{"path":"directory-interactions.html","id":"resources-37","chapter":"45 Interacciones con directorios","heading":"45.9 Recursos","text":"https://cran.r-project.org/web/packages/fs/vignettes/function-comparisons.html","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"version-control-and-collaboration-with-git-and-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46 Control de versiones y colaboración con Git y Github","text":"Este capítulo presenta una visión general del uso de Git para colaborar con otros. Puedes encontrar tutoriales más extensos al final, en la sección de Recursos.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"what-is-git","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.1 ¿Qué es Git?","text":"Git es un software de control de versiones que permite seguir los cambios realizados en una carpeta. Se puede utilizar como la opción “control de cambios” de Word, LibreOffice o Google docs, pero para todo tipo de archivos. Es una de las opciones más potentes y más utilizadas para el control de versiones.¿Por qué nunca oído hablar de Git? - Mientras que las personas con formación como desarrollador aprenden habitualmente utilizar un software de control de versiones (Git, Mercurial, Subversion u otros), pocas personas de las disciplinas cuantitativas se nos enseñan estas habilidades. En consecuencia, la mayoría de profesionales de la epidemiología nunca hemos oído hablar sobre esto en sus estudios, y tenemos que aprenderlo sobre la marcha.Espera, oído hablar de Github, ¿es lo mismo? - exactamente, pero menudo se utilizan juntos, y veremos aquí cómo hacerlo. En resumen:Git es el sistema de control de versiones, una pieza de software. Se puede utilizar localmente en el ordenador o para sincronizar una carpeta con un sitio web anfitrión. Por defecto, se utiliza una ventana de terminal para escribir las instrucciones de Git en la línea de comandos.Git es el sistema de control de versiones, una pieza de software. Se puede utilizar localmente en el ordenador o para sincronizar una carpeta con un sitio web anfitrión. Por defecto, se utiliza una ventana de terminal para escribir las instrucciones de Git en la línea de comandos.Se puede utilizar un cliente/interfaz Git para evitar la línea de comandos y realizar las mismas acciones (al menos para las más sencillas y supercomunes).Se puede utilizar un cliente/interfaz Git para evitar la línea de comandos y realizar las mismas acciones (al menos para las más sencillas y supercomunes).Si se quiere almacenar una carpeta en un sitio web para colaborar con otros, se puede utilizar una cuenta en Github, Gitlab, Bitbucket u otros.Si se quiere almacenar una carpeta en un sitio web para colaborar con otros, se puede utilizar una cuenta en Github, Gitlab, Bitbucket u otros.Se puede utilizar el cliente/interfaz Github Desktop, que utiliza Git en segundo plano para gestionar los archivos, tanto localmente en el ordenador, como remotamente en un servidor de Github.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"why-use-the-combo-git-and-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.2 ¿Por qué utilizar la combinación de Git y Github?","text":"El uso de Git facilita:Almacenar versiones de archivos con cambios incrementales de forma que permite volver fácilmente cualquier estado anteriorMantener ramas paralelas, es decir, versiones de desarrollo/“trabajo” que más adelante pueden integrar los cambios después de su revisiónEsto también se puede hacer localmente en tu ordenador, incluso si colaboras con otras personas. Alguna vez ….:¿te arrepentido de haber eliminado una sección de código, para darte cuenta dos meses después de que realmente la necesitabas?¿te arrepentido de haber eliminado una sección de código, para darte cuenta dos meses después de que realmente la necesitabas?¿vuelto un proyecto que había estado en pausa e intentado recordar si habías hecho esa complicada modificación en uno de los modelos?¿vuelto un proyecto que había estado en pausa e intentado recordar si habías hecho esa complicada modificación en uno de los modelos?¿tenías un archivo modelo_1.R y otro archivo modelo_1_prueba.R y un archivo modelo_1_no_funciona.R para probar las cosas?¿tenías un archivo modelo_1.R y otro archivo modelo_1_prueba.R y un archivo modelo_1_no_funciona.R para probar las cosas?¿tenías un archivo report.Rmd, un archivo report_full.Rmd, un archivo report_true_final.Rmd, un archivo report_final_20210304.Rmd, un archivo report_final_20210402.Rmd y maldecías tus habilidades de almacenamiento?¿tenías un archivo report.Rmd, un archivo report_full.Rmd, un archivo report_true_final.Rmd, un archivo report_final_20210304.Rmd, un archivo report_final_20210402.Rmd y maldecías tus habilidades de almacenamiento?Git puede ayudar con todo eso, y vale la pena aprenderlo sólo por eso.Sin embargo, se vuelve aún más potente cuando se utiliza con un repositorio en línea como Github para apoyar proyectos de colaboración. Esto facilita:Colaboración: otros pueden revisar, comentar y aceptar o rechazar los cambiosColaboración: otros pueden revisar, comentar y aceptar o rechazar los cambiosCompartir el código, los datos y los resultados, e invitar hacer comentarios al público (o en privado, con tu equipo)Compartir el código, los datos y los resultados, e invitar hacer comentarios al público (o en privado, con tu equipo)y evitar:“Uy, olvidé de enviar la última versión y ahora tienes que rehacer el trabajo de dos días en este nuevo archivo”“Uy, olvidé de enviar la última versión y ahora tienes que rehacer el trabajo de dos días en este nuevo archivo”Mina, Henry y Oumar trabajaron al mismo tiempo en un script y necesitan fusionar manualmente sus cambiosMina, Henry y Oumar trabajaron al mismo tiempo en un script y necesitan fusionar manualmente sus cambiosDos personas intentan modificar el mismo archivo en Dropbox y Sharepoint y esto crea un error de sincronización.Dos personas intentan modificar el mismo archivo en Dropbox y Sharepoint y esto crea un error de sincronización.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"esto-suena-complicado-yo-no-soy-un-programador","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Esto suena complicado, yo no soy un programador","text":"Puede ser. Los ejemplos de usos avanzados pueden ser bastante aterradores. Sin embargo, al igual que ocurre con R, o incluso con Excel, es necesario convertirse en un experto para aprovechar las ventajas de la herramienta. El aprendizaje de un pequeño número de funciones y nociones te permite seguir sus cambios, sincronizar los archivos en un repositorio en línea y colaborar con los colegas en muy poco tiempo.Debido la curva de aprendizaje, el contexto de emergencia puede ser el mejor momento para aprender estas herramientas. Pero el aprendizaje puede hacerse por pasos. Una vez que adquieras un par de nociones, tu flujo de trabajo puede ser bastante eficiente y rápido. Si estás trabajando en un proyecto en el que la colaboración con personas través de Git sea una necesidad, … en realidad es un buen momento para adquirir confianza en su uso en solitario antes de sumergirte en ello en un proyecto colaborativo.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"setup","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.3 Configuración","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"instalar-git","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Instalar Git","text":"Git es el motor que está de este control de cambios la computadora; rastrea los cambios, las ramas (versiones), las fusiones y las reversiones. Primero debes instalar Git desde https://git-scm.com/downloads.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"instalar-una-interfaz-gráfica-opcional-pero-recomendable","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Instalar una interfaz gráfica (opcional pero recomendable)","text":"Git tiene su propio lenguaje de comandos, que se pueden escribir en la línea de comandos de un terminal. Sin embargo, hay muchos clientes/interfaces que proporcionan una buena visualización de las modificaciones de archivos o ramas. Esto es recomendable ya que personas que son desarrolladoras, en su uso diario, rara vez necesitarán interactuar directamente con Git.Existen muchas opciones, en todos los sistemas operativos, desde las amigables para los principiantes hasta las más complejas. Unas buenas opciones para principiantes son el panel Git de RStudio y Github Desktop, que mostraremos en este capítulo. Las opciones intermedias (más potentes, pero más complejas) incluyen Source Tree, Gitkracken, Smart Git y otras.Explicación rápida sobre los clientes Git.Nota: dado que todas las interfaces utilizan Git internamente, puedes probar varias de ellas, cambiar de una otra en un proyecto determinado, utilizar la consola puntualmente para una acción que tu interfaz soporta, o incluso realizar una serie de acciones online en Github.Como se indica más adelante, es posible que ocasionalmente tengas que escribir comandos Git en un terminal como en la pestaña “terminal” de RStudio (una pestaña adyacente la consola de R) o la aplicación de terminal Git Bash.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"cuenta-de-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Cuenta de Github","text":"Regístrate para obtener una cuenta gratuita en github.com.Es posible que se te ofrezca configurar la autenticación de dos pasos con una aplicación en tu teléfono. Lee más en estos documentos de ayuda de Github.Si usas Github Desktop, puedes introducir tus credenciales de Github después de la instalación siguiendo estos pasos. Si lo haces, las credenciales se te pedirán más tarde cuando intentes clonar un proyecto desde Github.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"vocabulary-concepts-and-basic-functions","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.4 Vocabulario, conceptos y funciones básicas","text":"Al igual que cuando se aprende R, hay que recordar un poco de vocabulario para entender Git. Aquí están los conceptos básicos para empezar / tutorial interactivo. En las próximas secciones, mostraremos cómo usar las interfaces, pero es bueno tener el vocabulario y los conceptos en mente, para construir tu modelo mental, ya que lo necesitarás cuando más tarde, aunque uses las interfaces de los programas.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"repositorio","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Repositorio","text":"Un repositorio Git (“repo”) es una carpeta que contiene todas las subcarpetas y archivos de tu proyecto (datos, código, imágenes, etc.) y sus historiales de revisión. Cuando empieces seguir los cambios en el repositorio con él, Git creará una carpeta oculta que contiene toda la información de seguimiento. Un repositorio típico de Git es la carpeta de tu proyecto R (ver la página del manual sobre proyectos R).Mostraremos cómo crear (inicializar) un repositorio Git desde Github, Github Desktop o Rstudio en las siguientes secciones.\nsections.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"commits-consolidaciones","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Commits (Consolidaciones)","text":"Cuando realices un cambio en el proyecto, hay que ejecutar commit para consolidar estos cambios (el delta) realizados en tus archivos. Por ejemplo, quizás hayas editado algunas líneas de código y actualizado unos datos relacionados. Una vez guardados los cambios, puedes agrupar y confirmar estos cambios en un solo “commit”.Cada consolidación (commit) tiene un ID único (un hash). Para el control de versiones, puedes revertir tu proyecto hacia atrás en base estas Consolidaciones, así que es mejor mantenerlas relativamente pequeñas y coherentes. También realizarás una breve descripción de los cambios llamada “commit message (mensaje de consolidación)”. En cierto modo, cada commit es una instantánea del proyecto en un momento dado.¿Cambios por etapas (staged)? Poner etapas en los cambios es añadirlos la zona de preparación para la siguiente consolidación. La idea es que puedas decidir con precisión qué cambios incluir en un determinado commit. Por ejemplo, si trabajas en la especificación del modelo en un script, y más tarde en una figura en otro script, tendría sentido tener dos commits diferentes (sería más fácil en caso de que quisieras revertir los cambios en la figura pero en el modelo).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"ramas-branches","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Ramas (Branches)","text":"Una rama representa una línea independiente de cambios en su repo, una versión paralela y alternativa de los archivos del proyecto.Las ramas son útiles para probar los cambios antes de incorporarlos la rama principal (main, master), que suele ser la versión primaria/final/“viva” de tu proyecto. Cuando termines de experimentar en una rama, puedes incorporar los cambios tu rama principal, fusionándola, o eliminarla, si los cambios fueron tan exitosos.Nota: es necesario colaborar con otras personas para utilizar las ramas, ni es necesario tener un repositorio remoto en línea.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"repositorios-locales-y-remotos","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Repositorios locales y remotos","text":"el repositorio LOCAL en el ordenador físico. Aquí es donde se hacen los cambios reales los archivos/código.el repositorio LOCAL en el ordenador físico. Aquí es donde se hacen los cambios reales los archivos/código.el repositorio REMOTO, en línea: las versiones de los archivos del proyecto en el repositorio Github (o en cualquier otro alojamiento web).el repositorio REMOTO, en línea: las versiones de los archivos del proyecto en el repositorio Github (o en cualquier otro alojamiento web).Para sincronizar estos repositorios, utilizaremos más funciones. En efecto, diferencia de Sharepoint, Dropbox u otro software de sincronización, Git actualiza automáticamente el repositorio local en base lo que está en línea, o viceversa. Tú eliges cuándo y cómo sincronizarlo.FETCH: git fetch descarga los cambios realizados en el repositorio remoto pero cambia el repositorio local. Piensa en ello para una comprobación del estado del repositorio remoto.FETCH: git fetch descarga los cambios realizados en el repositorio remoto pero cambia el repositorio local. Piensa en ello para una comprobación del estado del repositorio remoto.PULL:git pull descarga archivos cambiados en los repositorios remotos y actualiza el repositorio local.PULL:git pull descarga archivos cambiados en los repositorios remotos y actualiza el repositorio local.PUSH: Actualiza el repositorio remoto. Cuando hayas hecho uno o varios commits localmente, puedes hacer git push de los commits al repositorio remoto. Esto envía tus cambios Github para actualizar el repositorio y que otras personas puedan verlos y extraerlos si lo desean.PUSH: Actualiza el repositorio remoto. Cuando hayas hecho uno o varios commits localmente, puedes hacer git push de los commits al repositorio remoto. Esto envía tus cambios Github para actualizar el repositorio y que otras personas puedan verlos y extraerlos si lo desean.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"get-started-create-a-new-repository","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.5 Empezar: crear un nuevo repositorio","text":"Hay muchas formas de crear nuevos repositorios. Puedes hacerlo desde la consola/terminal, desde Github, desde una interfaz gráfica, como Github Desktop o Rstudio->Git.Hay dos enfoques generales para la puesta en marcha:Crear un nuevo proyecto R partir de un repositorio de Github existente o nuevo (preferible para los principiantes), oCrear un repositorio Github para un proyecto R existente","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"archivos-de-inicio","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Archivos de inicio","text":"create new repository, can optionally create\nfiles, can add repository later stage.\ntypically live “root” folder repository.Un archivo README es un archivo que alguien puede leer para entender por qué existe tu proyecto y qué más deben saber para usarlo. Al principio estará vacío, pero deberías completarlo más adelante.Un archivo README es un archivo que alguien puede leer para entender por qué existe tu proyecto y qué más deben saber para usarlo. Al principio estará vacío, pero deberías completarlo más adelante.Un archivo .gitignore es un archivo de texto donde cada línea contendría carpetas o archivos que Git debería ignorar (rastrear los cambios). Lee más sobre esto y mira ejemplos aquí.Un archivo .gitignore es un archivo de texto donde cada línea contendría carpetas o archivos que Git debería ignorar (rastrear los cambios). Lee más sobre esto y mira ejemplos aquí.Puedes elegir un tipo de licencia para el trabajo, de modo que otras personas sepan en qué condiciones pueden utilizar o reproducir tu obra. Para más información, consulta las licencias Creative Commons.Puedes elegir un tipo de licencia para el trabajo, de modo que otras personas sepan en qué condiciones pueden utilizar o reproducir tu obra. Para más información, consulta las licencias Creative Commons.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"crear-un-nuevo-repositorio-en-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Crear un nuevo repositorio en Github","text":"Para crear un nuevo repositorio, entra en Github y busca el botón verde para crear un nuevo repositorio. Este repositorio, ahora vacío, puede ser clonado localmente en tu ordenador (ver la siguiente sección).Debes elegir si quieres que tu repositorio sea público (visible para todo el mundo en Internet) o privado (sólo visible para aquellos con permiso). Esto tiene importantes implicaciones si tus datos son sensibles. Si tu repositorio es privado te encontrarás con algunos límites en circunstancias especiales avanzadas, como por ejemplo si estás usando actions de Github para ejecutar automáticamente tu código en la nube.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"clonar-desde-un-repositorio-de-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Clonar desde un repositorio de Github","text":"Puedes clonar un repositorio de Github existente para crear un nuevo proyecto R local en tu ordenador.El repositorio de Github puede ser uno que ya existe y tiene contenido, o puede ser un repositorio vacío que acabas de crear. En este último caso, básicamente estás creando el repositorio de Github y el proyecto local de R al mismo tiempo (ver las instrucciones anteriores).Nota: si tienes derechos de contribución en un repositorio de Github, es posible primero bifurcar (fork) el repositorio hacia tu perfil, y luego proceder con las otras acciones. La bifurcación se explica al final de este capítulo, pero recomendamos que leas primero las otras secciones.Paso 1: Navega en Github hasta el repositorio, clica en el botón verde “Code” y copia la HTTPS clon URL (ver imagen inferior)El siguiente paso se puede realizar en cualquier interfaz. Lo ilustraremos con Rstudio y Github desktop.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-rstudio","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Rstudio","text":"En RStudio, inicia un nuevo proyecto R clicando en File>New project > Version control > Git) (Archivo > Nuevo proyecto > Control de versiones > Git)Cuando te pida la “URL del repositorio”, pega la URL HTTPS de GithubCuando te pida la “URL del repositorio”, pega la URL HTTPS de GithubAsigna al proyecto R un nombre corto e informativoAsigna al proyecto R un nombre corto e informativoElige dónde se guardará el nuevo proyecto R localmenteElige dónde se guardará el nuevo proyecto R localmenteMarca “Abrir en una nueva sesión” y clica en “Crear proyecto”.Marca “Abrir en una nueva sesión” y clica en “Crear proyecto”.Ahora estás en un nuevo proyecto local de RStudio que es un clon del repositorio de Github. Este proyecto local y el repositorio de Github están ahora vinculados.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"Clica en File>Clone repository (Archivo > Clonar un repositorio)Clica en File>Clone repository (Archivo > Clonar un repositorio)Selecciona la pestaña URLSelecciona la pestaña URLPega la URL HTTPS de Github en la primera casillaPega la URL HTTPS de Github en la primera casillaSelecciona la carpeta en la que deseas tener tu repositorio localSelecciona la carpeta en la que deseas tener tu repositorio localClica en “CLONE”Clica en “CLONE”","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"nuevo-repositorio-de-github-a-partir-de-un-proyecto-r-existente","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Nuevo repositorio de Github a partir de un proyecto R existente","text":"Un escenario alternativo de configuración es que ya tengas un proyecto R con contenido, y quieras crear un repositorio Github para él.Crear un nuevo repositorio de Github vacío para el proyecto (ver instrucciones anteriores)Crear un nuevo repositorio de Github vacío para el proyecto (ver instrucciones anteriores)Clona este repositorio localmente (ver las instrucciones de HTTPS más arriba)Clona este repositorio localmente (ver las instrucciones de HTTPS más arriba)Copia todo el contenido de tu proyecto R preexistente (códigos, datos, etc.) en este nuevo repositorio local vacío (por ejemplo, utiliza copiar y pegar).Copia todo el contenido de tu proyecto R preexistente (códigos, datos, etc.) en este nuevo repositorio local vacío (por ejemplo, utiliza copiar y pegar).Abre tu nuevo proyecto en RStudio, y ve al panel Git. Los nuevos archivos deberían registrarse como cambios de archivo, ahora rastreados por Git. Por lo tanto, puedes agrupar estos cambios bajo un commit y push Github. Una vez hecho push, el repositorio en Github reflejará todos los archivos.Abre tu nuevo proyecto en RStudio, y ve al panel Git. Los nuevos archivos deberían registrarse como cambios de archivo, ahora rastreados por Git. Por lo tanto, puedes agrupar estos cambios bajo un commit y push Github. Una vez hecho push, el repositorio en Github reflejará todos los archivos.Consulta la sección de flujo de trabajo de Github para obtener más detalles sobre este proceso.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"qué-aspecto-tiene-ahora","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"¿Qué aspecto tiene ahora?","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-rstudio-1","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En RStudio","text":"Una vez que hayas clonado un repositorio de Github un nuevo proyecto R, ahora verás en RStudio una pestaña “Git”. Esta pestaña aparece en el mismo panel de RStudio que Environment:Botón commit para consolidar los cambios del archivo guardado en local (se abrirá una nueva ventana para añadir la descripción y confirmarlo)Botón commit para consolidar los cambios del archivo guardado en local (se abrirá una nueva ventana para añadir la descripción y confirmarlo)Flecha azul pull (descarga los cambios realizados en la versión remota/Github de esa rama y actualiza tu versión local de la rama)Flecha azul pull (descarga los cambios realizados en la versión remota/Github de esa rama y actualiza tu versión local de la rama)Flecha verde push (enviar cualquier commits/cambio de tu versión local de la rama y actualiza la versión remota/Github de esa rama)Flecha verde push (enviar cualquier commits/cambio de tu versión local de la rama y actualiza la versión remota/Github de esa rama)La pestaña Git en RStudioLa pestaña Git en RStudioBotón para crear una rama NUEVA dependiente de la rama que se muestra la derecha como base. Casi siempre querrá bifurcarse desde la rama principal (después de haber tirado primero para actualizar la rama principal)Botón para crear una rama NUEVA dependiente de la rama que se muestra la derecha como base. Casi siempre querrá bifurcarse desde la rama principal (después de haber tirado primero para actualizar la rama principal)La Rama en la que trabajas actualmenteLa Rama en la que trabajas actualmenteA continuación aparecerán los cambios que haya realizado en el código o en otros archivosA continuación aparecerán los cambios que haya realizado en el código o en otros archivos","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop-1","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"Github Desktop es una aplicación independiente que te permite gestionar todos tus repositorios. Cuando la abres, la interfaz te permite elegir el repositorio en el que quieres trabajar, y luego realizar acciones básicas de Git desde allí.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"git-github-workflow","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.6 Flujo de trabajo Git + Github","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"resumen-del-proceso","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Resumen del proceso","text":"Una vez que hayas completado la configuración (descrita anteriormente), tendrás un repo de Github que está conectado (clonado) un proyecto local de R. La rama principal (main por defecto) es la llamada versión “viva” de todos los archivos. Cuando quieras hacer modificaciones, es una buena práctica crear una nueva rama partir de la rama principal (como “Hacer una copia”). Este es un flujo de trabajo típico en Git porque crear una rama es fácil y rápido.Un flujo de trabajo típico es el siguiente:Asegúrate de que tu repositorio local está actualizado, actualízalo si es asíAsegúrate de que tu repositorio local está actualizado, actualízalo si es asíVe la rama en la que estabas trabajando anteriormente, o crea una nueva rama para probar algunas cosasVe la rama en la que estabas trabajando anteriormente, o crea una nueva rama para probar algunas cosasTrabaja en los archivos localmente en tu ordenador, haz uno o varios commits en esta ramaTrabaja en los archivos localmente en tu ordenador, haz uno o varios commits en esta ramaActualiza la versión remota de la rama con tus cambios (push)Actualiza la versión remota de la rama con tus cambios (push)Cuando estés satisfecho con tu rama, puedes fusionar la versión en línea de la rama de trabajo con la rama “principal” en línea para transferir los cambiosCuando estés satisfecho con tu rama, puedes fusionar la versión en línea de la rama de trabajo con la rama “principal” en línea para transferir los cambiosOtros miembros del equipo pueden estar haciendo lo mismo con sus propias ramas, o quizás contribuyendo con commits en su rama de trabajo también.continuación, repasamos el proceso anterior paso paso con más detalle. Es un esquema que hemos desarrollado - está en el formato de una tabla de dos x dos, por lo que debería ayudarnos entenderlo.Aquí hay otro diagrama.Nota: hasta hace poco, se utilizaba el término rama “master” (maestra), pero ahora se denomina rama “main” (principal).Fuente de la imagen","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"create-a-new-branch","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.7 Crear una nueva rama","text":"Cuando seleccionas una rama para trabajar, Git restablece tu directorio de trabajo tal y como estaba la última vez que estuviste en esta rama.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-el-panel-git-de-rstudio","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En el panel Git de Rstudio","text":"Asegúrate que te encuentras en la rama “main” (master, principal) y, continuación, clica en el icono morado para crear una nueva rama (véase la imagen anterior).Pedirá un nombre descriptivo para esa rama, de una palabra (se pueden usar barras bajas si es necesario).Verás que localmente, sigues en el mismo proyecto R, pero ya estás trabajando en la rama “main”(principal).Una vez creada, la nueva rama también aparecerá en el sitio web de Github como una rama.Puedes visualizar las ramas en el panel Git de Rstudio tras clicar en “History”","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop-2","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"El proceso es muy similar, se pide que des un nombre tu rama. Después, pedirá que “publique su rama en Github” para que la nueva rama aparezca también en el repositorio remoto.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-la-consola","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En la consola","text":"Lo que realmente ocurre entre bastidores es que creas una nueva rama con git branch, y luego vas la rama con git checkout (es decir, le dices Git que tus próximos commits se producirán allí). Desde tu repositorio git:Para más información sobre el uso de la consola, consulta la sección sobre comandos Git al final.","code":"git branch my-new-branch  # Crea la nueva rama my-new-branch\ngit checkout my-new-branch # Va a la rama\ngit checkout -b my-new-branch # Ambos a la vez (satajo)"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"commit-changes","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.8 Consolidar los cambios (Commit)","text":"Ahora puedes editar el código, añadir nuevos archivos, actualizar conjuntos de datos, etc.Cada uno de tus cambios es rastreado, una vez que el archivo respectivo es guardado. Los archivos modificados aparecerán en la pestaña Git de RStudio, en Github Desktop, o utilizando el comando git status en el terminal (ver más abajo).Siempre que hagas cambios sustanciales (por ejemplo, añadir o actualizar una sección de código), haz una pausa y consolida esos cambios (Commit). Piensa en una Consolidación como un “lote” de cambios relacionados con un propósito común. Siempre puedes seguir revisando un archivo después de haber confirmado los cambios en él.Consejo sobre los commits: en general, es mejor hacer Consolidaciones pequeñas, que puedan revertirse fácilmente si surge un problema, y Consolidar juntas modificaciones relacionadas con un propósito común. Para lograr esto, verás que debes hacer commits menudo. Al principio, es probable que te olvides de hacer commits menudo, pero luego el hábito se impone.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-rstudio-2","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Rstudio","text":"El ejemplo siguiente muestra que, desde la última consolidación, el script de R Markdown “collaboration.Rmd” ha cambiado, y se han añadido varias imágenes PNG.Puede que te preguntes qué representan los cuadrados amarillo, azul, verde y rojo que aparecen junto los nombres de los archivos. Aquí hay una captura de la hoja de trucos de RStudio que explica su significado. Ten en cuenta que los cambios con el amarillo “?” aún pueden ser puestos en escena, confirmados y enviados.Clica el botón “Commit” en la pestaña Git, que abrirá una nueva ventana (mostrada continuación)Clica el botón “Commit” en la pestaña Git, que abrirá una nueva ventana (mostrada continuación)Clica en un nombre de archivo en el cuadro superior izquierdoClica en un nombre de archivo en el cuadro superior izquierdoRevisa los cambios que ha realizado en ese archivo (resaltados en verde o rojo)Revisa los cambios que ha realizado en ese archivo (resaltados en verde o rojo)“Stage” (Poner en etapas) el archivo , lo que incluirá esos cambios en la consolidación. Para ello, marca la casilla situada junto al nombre del archivo. También puedes marcar varios nombres de archivo y clicar en “Stage”.“Stage” (Poner en etapas) el archivo , lo que incluirá esos cambios en la consolidación. Para ello, marca la casilla situada junto al nombre del archivo. También puedes marcar varios nombres de archivo y clicar en “Stage”.Escribe un mensaje de consolidación breve pero descriptivo (obligatorio)Escribe un mensaje de consolidación breve pero descriptivo (obligatorio)Clica el botón “Commit”. Aparecerá un cuadro emergente mostrando el éxito o un mensaje de error.Clica el botón “Commit”. Aparecerá un cuadro emergente mostrando el éxito o un mensaje de error.Ahora puedes hacer más cambios y más commits, tantas veces como quieras","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop-3","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"Puedes ver la lista de los archivos que se han modificado la izquierda. Si seleccionas un archivo de texto, verás en el panel derecho un resumen de las modificaciones que se han hecho (la vista funcionará en archivos más complejos como .docs o .xlsx).Para añadir los cambios, basta con marcar la pequeña casilla situada junto los nombres de los archivos. Cuando hayas seleccionado los archivos que quieres añadir esta consolidación, dale un nombre la consolidación, opcionalmente una descripción y luego clica en el botón de commit.\nbutton.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-la-consola-1","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En la consola","text":"Las dos funciones que se utilizan entre bastidores son git add para seleccionar/poner en escena los archivos y git commit para hacer realmente el commit.","code":"git status # see the changes \n\ngit add new_pages/collaboration.Rmd  # selecciona los ficheros a (= stage los cambioss)\n\ngit commit -m \"Describe commit from Github Desktop\" # commit los cambios con un mensaje\n\ngit log  # ver información sobre los commits anteriores"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"modificar-una-consolidación-anterior","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Modificar una consolidación anterior","text":"¿Qué sucede si confirmas algunos cambios, sigues trabajando y te das cuenta de que hiciste cambios que deberían “pertenecer” la consolidación anterior (en tu opinión)? temas! Puedes añadir estos cambios tu consolidación anterior.En Rstudio, debería ser bastante obvio, ya que hay una casilla “Amend previous commit” (modificar una consolidación anterior) en la misma línea que el botón COMMIT.Por alguna razón poco clara, la funcionalidad se ha implementado como tal en Github Desktop, pero hay una forma (conceptualmente incómoda pero fácil) de hacerlo. Si confirmado pero aún enviado tus cambios, aparece un botón “UNDO” justo debajo del botón COMMIT. Clica en él y revertirá tu consolidación (pero mantendrá sus archivos en etapa y tu mensaje de consolidación). Guarda los cambios, añade nuevos archivos la consolidación si es necesario y vuelva confirmar.En la consola:Note: think modifying commits already public shared collaborators.","code":"git add [YOUR FILES] # Stage your new changes\n\ngit commit --amend  # Amend the previous commit\n\ngit commit --amend -m \"An updated commit message\"  # Amend the previous commit AND update the commit message"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"pull-and-push-changes-up-to-github","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.9 Actualizar los cambios con Github","text":"“Primero PULL (actualizar local), luego PUSH (actualizar reomto)”Es una buena práctica fetch y pull antes de empezar trabajar en tu proyecto, para actualizar la versión de la rama en tu equipo local con los cambios que se han hecho en la versión remota/Github.Pull menudo. dudes. Pull siempre antes de Push.Cuando los cambios estén hechos y confirmados y estés contento con el estado de tu proyecto, puedes enviar (push) tus consolidaciones la versión remota/Github de tu rama.Repite la operación mientras trabajas en el repositorio.Nota: es mucho más fácil revertir los cambios que fueron confirmados pero empujados (es decir, siguen siendo locales) que revertir los cambios que fueron empujados al repositorio remoto (y tal vez ya sacados por otra persona), por lo que es mejor empujar cuando haya terminado de introducir cambios en la tarea en la que estaba trabajando.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-rstudio-3","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Rstudio","text":"PULL - En primer lugar, clica en el icono “Pull” (flecha hacia abajo) que busca y tira al mismo tiempo.PUSH – Clicando en el icono verde “Push” (flecha hacia arriba). Es posible que pida que introduzcas tu nombre de usuario y contraseña de Github. La primera vez que la pida, es posible que tenga que introducir dos líneas de comando Git en el Terminal:git config –global user.email\n“@example.com” (Github\nemail address), andgit config –global user.name “Github username”Para saber más sobre cómo introducir estos comandos, consulta la sección siguiente sobre comandos Git.SUGERENCIA: ¿Te piden la contraseña muy menudo? Consulta los capítulos 10 y 11 de este tutorial para conectarse un repositorio usando una clave SSH (más complicado)","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop-4","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"Clica en el botón “Fetch origin” para comprobar si hay nuevos commits en el repositorio remoto.Si Git encuentra nuevos commits en el repositorio remoto, el botón cambiará un botón “Pull”. Dado que el mismo botón se utiliza para Pull y Push, puedes enviar tus cambios si descargas y actualizas antes.Puedes ir la pestaña “History” (cerca de la pestaña “Changes”) para ver todos los commits (los tuyos y los de los demás). Esta es una buena manera de conocer lo que hicieron tus colaboradores. Puedes leer el mensaje de consolidación, la descripción si la hay, y comparar el código de los dos archivos usando el panel diff.Una vez que se han extraído todos los cambios remotos y se ha consignado al menos un cambio local, se puede empujar clicando en el mismo botón.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"consola","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Consola","text":"Sin sorpresas, las órdenes son fetch, pull y push.","code":"git fetch  # ¿hay nuevos commits en el directorio remoto?\ngit pull   # Trae los commits remotos a tu rama local y la actualiza\ngit push   # Envía los commits locales de esta rama a la rama remota"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"quiero-actualizarme-pero-tengo-trabajo-local","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Quiero actualizarme pero tengo trabajo local","text":"Esto puede ocurrir veces: hecho algunos cambios en tu repositorio local, pero el repositorio remoto tiene consolidaciones que descargado.Git rechazará hacer un pull porque podría sobrescribir tus cambios. Hay varias estrategias para guardar tus cambios, bien descritas en Happy Git R, entre las cuales las dos principales son:\n- Confirmar tus cambios, obtener los cambios remotos, extraerlos, resolver los conflictos si es necesario (ver la sección más abajo), y consolidar todo en línea\n- stash tus cambios, lo que en cierto modo los guarda un lado, pull, unstash (restaurar), y luego confirmar, resolver cualquier conflicto, y push.Si los archivos afectados por los cambios remotos y los archivos afectados por tus cambios locales se solapan, Git puede resolver los conflictos automáticamente.En Github Desktop, esto se puede hacer con botones. Para almacenar, ve Branch > Stash changes.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"merge-branch-into-main","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.10 Combinar la rama con la principal","text":"Si terminado de hacer cambios, puedes comenzar el proceso de fusión de esos cambios en la rama principal. Dependiendo de su situación, esto puede ser rápido, o puede tener pasos deliberados de revisión y aprobación que involucren compañeros de equipo.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"localmente-en-github-desktop","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Localmente en Github Desktop","text":"Se pueden fusionar ramas localmente usando Github Desktop. Primero, ve (checkout) la rama que será la destinataria de los commits, es decir, la rama que quieres actualizar. continuación, clica en el menú Branch > Merge current branch. Un cuadro te permitirá seleccionar la rama desde la que quieres importar.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-la-consola-2","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En la consola","text":"Primero, vuelve la rama que será la destinataria de los cambios. Normalmente es la rama maestra (main), pero puede ser otra rama. Luego fusiona tu rama de trabajo con la maestra.Esta página muestra un ejemplo más avanzado de bifurcación y explica un poco lo que ocurre entre bastidores.","code":"git checkout master  # Go back to master (or to the branch you want to move your )\ngit merge this_fancy_new_branch"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-envío-de-pull-requests","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github: envío de pull requests","text":"Aunque es totalmente posible fusionar dos ramas localmente, o sin informar nadie, una fusión puede ser discutida o investigada por varias personas antes de ser integrada en la rama maestra. Para ayudar en el proceso, Github ofrece algunas funciones de discusión en torno la fusión: el pull request.Un pull request (un “PR”) es una solicitud para fusionar una rama con otra (en otras palabras, una solicitud para que tu rama de trabajo se incorpore la rama “principal”). Una solicitud de extracción suele incluir varias consolidaciones. Un pull request suele iniciar un proceso de conversación y revisión antes de que sea aceptado y la rama sea fusionada. Por ejemplo, puedes leer las discusiones sobre pull requests en el github de dplyr.Puedes enviar una solicitud de extracción (PR) directamente desde el sitio web (como se ilustra continuación) o desde Github Desktop.Ir al repositorio Github (en línea)Ve la pestaña “Pull Requests” y clica en el botón “New pull request”.Selecciona en el menú desplegable para fusionar su rama en la principalEscribe un comentario detallado sobre la solicitud de extracción y clica en “Crear solicitud de extracción”.En la imagen siguiente, se ha seleccionado la rama “forests” para fusionarla con la “principal”:Ahora se debería poder ver el pull request (imagen de ejemplo abajo):Revisa la pestaña “Files changed” (Archivos cambiados) para ver cómo cambiaría la rama “principal” si se fusionara la rama.la derecha, puedes solicitar una revisión los miembros de tu equipo etiquetando su ID de Github. Si quieres, puedes configurar el repositorio para que se requiera una revisión de aprobación para poder fusionarlo con el principal.Una vez aprobada la solicitud de extracción, se activará un botón para “Merge pull request” (fusionar la solicitud de extracción). Clica en él.Una vez completado, elimina tu rama como se explica continuación.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"resolución-de-conflictos","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Resolución de conflictos","text":"Cuando dos personas modifican la(s) misma(s) línea(s) al mismo tiempo, surge un conflicto de fusión. De hecho, Git se niega tomar una decisión sobre qué versión mantener, pero te ayuda encontrar dónde está el conflicto. TE ASUSTES. La mayoría de las veces, es bastante sencillo de resolver.Por ejemplo, en Github:Después de que la fusión haya planteado un conflicto, abre el archivo en tu editor favorito. El conflicto se indicará con una serie de caracteres:El texto entre <<<<<<< HEAD y ======= proviene de tu repositorio local, y el que está entre ======= y >>>>>>> de la otra rama (que puede ser origin, master o cualquier rama de tu elección).Tienes que decidir qué versión del código prefieres (o incluso escribir una tercera, incluyendo los cambios de ambas partes si es pertinente), borrar el resto y eliminar todas las marcas que Git ha añadido (<<<<<<< HEAD, =======, >>>>>>> origin/master/tu_nombre_de_rama).continuación, guarda el archivo, estadíalo y haz un commit: este es el commit que hace que la versión fusionada sea “oficial”. te olvides de hacer push después.Cuanto más menudo hagáis pull y push tú y tus colaboradores, menores serán los conflictos.Nota: Si te sientes cómodo con la consola, existen opciones avanzadas de fusión (por ejemplo, ignorar los espacios en blanco, dar prioridad un colaborador, etc.).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"borrar-tu-rama","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Borrar tu rama","text":"Una vez que una rama se ha fusionado con la maestra y ya es necesaria, puedes eliminarla.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"github-rstudio","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Github + Rstudio","text":"Ve al repositorio en Github y clica en el botón para ver todas las ramas (junto al desplegable para seleccionar ramas). Ahora busca tu rama y clica en el icono de la papelera junto ella. Lee más detalles sobre cómo eliminar una rama aquí.Asegúrate de eliminar también la rama localmente en tu ordenador. Esto ocurrirá automáticamente.Desde RStudio, asegúrese de estar en la rama principalCambia para escribir los comandos Git en la “Terminal” de RStudio (la pestaña adyacente la consola de R), y escribe: git branch -d nombre_de_rama, donde “nombre_de_rama” es el nombre de la rama eliminarActualiza tu pestaña Git y la rama debería desaparecer","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"en-github-desktop-5","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"En Github Desktop","text":"Sólo tienes que comprobar la rama que quieres eliminar, e ir al menú\nBranch > Delete.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"bifurcación","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Bifurcación","text":"Puedes bifurcar (fork) un proyecto si quieres contribuir él pero tienes los derechos para hacerlo, o si sólo quieres modificarlo para tu uso personal. Puedes encontrar una breve descripción de la bifurcación aquí.En Github, clica en el botón “Fork”:Esto clonará el repositorio original, pero en tu propio perfil. Así que ahora hay dos versiones del repositorio en Github: la original, que puedes modificar, y la versión clonada en tu perfil.Entonces, puedes clonar tu versión del repositorio en línea localmente en tu ordenador, utilizando cualquiera de los métodos descritos en las secciones anteriores. Luego, puede crear una nueva rama, hacer cambios, confirmarlos y empujarlos tu repositorio remoto.Una vez que estés contento con el resultado, puedes crear un Pull Request desde Github o Github Desktop para iniciar la conversación con los propietarios/mantenedores del repositorio original.¿Y si necesitas algunos commits más recientes del repositorio oficial?Imagina que alguien hace una modificación crítica en el repositorio oficial, que quieres incluir en tu versión clonada. Es posible sincronizar tu fork con el repositorio oficial. Implica usar el terminal, pero es demasiado complicado. Principalmente necesitas recordar que - upstream = el repositorio oficial, el que podido modificar - origin = tu versión del repositorio en tu perfil de GithubPuedes leer este tutorial o seguirlo continuación:Primero, escribe en tu terminal Git (dentro de tu repo):Si aún configurado el repositorio upstream deberías ver dos líneas, que comienzan por origin. Muestran el repositorio remoto al que apuntan fetch y push. Recuerda que origin es el apodo convencional para tu propia versión del repositorio en Github. Por ejemplo:Ahora, añade un nuevo repositorio remoto:Aquí la dirección es la que genera Github cuando clonas un repositorio (ver sección de clonación). Ahora tendrás cuatro punteros remotos:Ahora que la configuración está hecha, siempre que quieras obtener los cambios del repositorio original (upstream), sólo tienes que ir (checkout) la rama que quieres actualizar y teclear:Si hay conflictos, tendrá que resolverlos, tal y como se explica en la sección Resolución de conflictos.Resumen: forking es clonación, pero en el lado del servidor de Github. El resto de las acciones son las típicas del flujo de trabajo de colaboración (clonar, empujar, tirar, confirmar, fusionar, enviar solicitudes de extracción…).Nota: aunque la bifurcación es un concepto, un comando de Git, también existe en otros hosts web, como Bitbucket.","code":"git remote -vgit remote add upstream https://github.com/epirhandbook/Epi_R_handbook.gitgit fetch upstream # Obtener los nuevos commits del repositorio remoto\ngit checkout the_branch_you_want_to_update\ngit merge upstream/the_branch_you_want_to_update  # Fusiona la rama de upstream en tu rama..\ngit push # Actualiza tu propia versión del repositorio remoto"},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"what-we-learned","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.11 Lo que hemos aprendido","text":"aprendido :Configurar Git para rastrear las modificaciones en tus carpetas,Conectar tu repositorio local un repositorio remoto en línea,Confirmar los cambios,Sincronizar tus repositorios locales y remotos.Todo esto debería ayudar ponerte en marcha y ser suficiente para la mayoría de tus necesidades de análisis epidemiológico. Normalmente tenemos un uso tan avanzado como los desarrolladores.Sin embargo, debes saber que si quieres (o necesitas) ir más allá, Git ofrece más potencia para simplificar los historiales de commit, revertir uno o varios commits, hacer cherry-pick de commits, etc. Algunas cosas pueden parecer pura magia, pero ahora que tienes los fundamentos, es más fácil construir sobre ellos.Ten en cuenta que mientras el panel Git en Rstudio y Github Desktop son buenos para los principiantes / uso diario en nuestra línea de trabajo, ofrecen una interfaz para algunas de las funciones intermedias / avanzadas de Git. Algunas interfaces más completas permiten hacer más cosas con apuntar y clicar (normalmente costa de un diseño más complejo).Recuerda que, dado que puedes utilizar cualquier herramienta en cualquier momento para realizar el seguimiento de tu repositorio, puedes instalar muy fácilmente una interfaz para probarla veces, o para realizar alguna tarea compleja menos común ocasionalmente, mientras prefieres una interfaz simplificada para el resto del tiempo (por ejemplo, utilizando Github Desktop la mayor parte del tiempo, y cambiando SourceTree o Gitbash para algunas tareas específicas).","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"git","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.12 Comandos Git","text":"","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"aprendizaje-recomendado","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Aprendizaje recomendado","text":"Para aprender los comandos de Git en un tutorial interactivo, consulta este sitio web.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"dónde-escribir-los-comandos","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"¿Dónde escribir los comandos?","text":"Se introducen comandos en un entorno Git.Opción 1 Puedes abrir una nueva Terminal en RStudio. Esta pestaña está al lado de la Consola R. Si puedes escribir ningún texto en ella, clica en el menú desplegable debajo de “Terminal” y selecciona “Nueva terminal”. Escribe los comandos en el espacio parpadeante delante del signo de dólar “$”.Opción 2 También puede abrir un shell (un terminal para introducir comandos) clicando en el icono azul de “engranajes” en la pestaña Git (cerca del entorno de RStudio). Selecciona “Shell” en el menú desplegable. Se abrirá una nueva ventana en la que puedes escribir los comandos después del signo de dólar “$”.Opción 3 Clica con el botón derecho para abrir “Git Bash ” que abrirá el mismo tipo de terminal, o abra Git Bash desde tu lista de aplicaciones. Más información para principiantes sobre Git Bash, cómo encontrarlo y algunos comandos bash que necesitarás.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"ejemplos-de-comandos","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"Ejemplos de comandos","text":"continuación presentamos algunos comandos git comunes. Cuando los uses, ten en cuenta qué rama está activa (check-), ¡ya que eso cambiará la acción!En los comandos de abajo, representa un nombre de rama. representa el hash ID de un commit específico. representa un número. escriba los símbolos < o >.","code":""},{"path":"version-control-and-collaboration-with-git-and-github.html","id":"resources-6","chapter":"46 Control de versiones y colaboración con Git y Github","heading":"46.13 Recursos","text":"Gran parte de esta página está inspirada en “Happy Git R”\nwebsite Jenny Bryan. Hay una sección muy útil de este sitio web que te ayuda solucionar errores comunes relacionados con Git y R.La documentación y guía de inicio de Github.com..La hoja de trucos de RStudio “IDE”\ncheatsheet\nque incluye consejos sobre Git con RStudio.https://ohi-science.org/news/github-going-back--timeComandos Git para principiantesUn tutorial interactivo para aprender los comandos de Git.https://www.freecodecamp.org/news/-introduction--git--absolute-beginners-86fa1d32ff71/:\nbueno para aprender los fundamentos absolutos para rastrear los cambios en una carpeta en\nen tu propio ordenador.Buen esquema para entender las ramas:\nhttps://speakerdeck.com/alicebartlett/git--humansTutoriales que cubren temas básicos y más avanzados*https://tutorialzine.com/2016/06/learn-git--30-minuteshttps://dzone.com/articles/git-tutorial-commands--operations--git\nhttps://swcarpentry.github.io/git-novice/ (short course)\nhttps://rsjakob.gitbooks.io/git/content/chapter1.htmlEl libro Pro Git está considerado como una referencia oficial.\nAunque algunos capítulos están bien, suele ser un poco técnico. Probablemente es un buen recurso\nuna vez que hayas usado un poco Git y quieras aprender con un poco más de precisión\nlo que sucede y cómo ir más allá.","code":""},{"path":"common-errors.html","id":"common-errors","chapter":"47 Errores comunes","heading":"47 Errores comunes","text":"Esta página incluye una lista actualizada de los errores más comunes y sugiere soluciones para solucionarlos.","code":""},{"path":"common-errors.html","id":"interpreting-error-messages","chapter":"47 Errores comunes","heading":"47.1 Interpretación de los mensajes de error","text":"Los mensajes de error de R pueden ser crípticos veces, así que Google es tu amigo. Busca el mensaje de error con “R” y busca publicaciones recientes en StackExchange.com, stackoverflow.com, community.rstudio.com, twitter (#rstats) y otros foros utilizados por los programadores para archivar preguntas y respuestas. Intenta encontrar publicaciones recientes que hayan resuelto problemas similares.Si después de mucho buscar encuentras una respuesta tu problema, considera la posibilidad de crear un ejemplo reproducible (“reprex”) y publicar tú mismo la pregunta. Consulta la página sobre Cómo obtener ayuda para obtener consejos sobre cómo crear y publicar un ejemplo reproducible en los foros.","code":""},{"path":"common-errors.html","id":"common-errors-1","chapter":"47 Errores comunes","heading":"47.2 Errores comunes","text":"continuación, enumeramos algunos errores comunes y posibles explicaciones/soluciones. Algunos de ellos se han tomado prestados de Noam Ross, que analizó los mensajes más comunes del foro en Stack Overflow sobre los mensajes de error de R (véase el análisis aquí)","code":""},{"path":"common-errors.html","id":"errores-tipográficos","chapter":"47 Errores comunes","heading":"Errores tipográficos","text":"Si aparece “unexpected symbol” (símbolo inesperado), comprueba si faltan comas","code":"Error: unexpected symbol in:\n\"  geom_histogram(stat = \"identity\")+\n  tidyquant::geom_ma(n=7, size = 2, color = \"red\" lty\""},{"path":"common-errors.html","id":"errores-del-paquete","chapter":"47 Errores comunes","heading":"Errores del paquete","text":"Esto probablemente significa que escrito mal el nombre de la función, o que olvidado instalar o cargar un paquete.Crees que estás usando dplyr::select() pero la función select() ha sido enmascarada por MASS::select() - especifica dplyr:: o reordena la carga de tu paquete para que dplyr esté después de todos los demás.Otros errores de enmascaramiento comunes provienen de: plyr::summarise() y stats::filter(). Considere la posibilidad de utilizar el paquete conflicted.Si recibes un error diciendo que necesitas eliminar un archivo “00LOCK”, ve tu biblioteca “R” en el directorio de tu ordenador (por ejemplo, R/win-library/) y busca una carpeta llamada “00LOCK”. Elimínala manualmente e intenta instalar el paquete de nuevo. Es probable que un proceso de instalación anterior se haya interrumpido, provocando este error.","code":"could not find function \"x\"...Error in select(data, var) : unused argument (var)Error in install.packages : ERROR: failed to lock directory ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0’ for modifying\nTry removing ‘C:\\Users\\Name\\Documents\\R\\win-library\\4.0/00LOCK’"},{"path":"common-errors.html","id":"errores-en-los-objetos","chapter":"47 Errores comunes","heading":"Errores en los objetos","text":"Si ves un error como este cuando intentas exportar o importar: Comprueba la ortografía del archivo y de la ruta de acceso, y si la ruta contiene barras inclinadas, asegúrese de que son hacia delante / y hacia atrás \\. Asegúrate también de que utilizado la extensión de archivo correcta (por ejemplo, .csv, .xlsx).Esto significa que el objeto al que se hace referencia existe. ¿Quizá el código anterior se ha ejecutado correctamente?Esto significa que intentado acceder algo (un elemento de un vector o una lista) que estaba allí.","code":"No such file or directory:object 'x' not found Error in 'x': subscript out of bounds"},{"path":"common-errors.html","id":"errores-de-sintaxis-de-las-funciones","chapter":"47 Errores comunes","heading":"Errores de sintaxis de las funciones","text":"Este error de arriba (argument .x missing, default) es común en mutate() si estás suministrando una función como recode() o replace_na() donde se espera que proporciones el nombre de la columna como primer argumento. Esto es fácil de olvidar.","code":"# ejecuta recode sin reiniciar la variable x en mutate(x = recode(x, OLD = NEW)\nError: Problem with `mutate()` input `hospital`.\nx argument \".x\" is missing, with no default\ni Input `hospital` is `recode(...)`."},{"path":"common-errors.html","id":"errores-lógicos","chapter":"47 Errores comunes","heading":"Errores lógicos","text":"Esto probablemente significa que se aplicó una sentencia algo que era TRUE o FALSE.","code":"Error in if"},{"path":"common-errors.html","id":"errores-de-los-factores","chapter":"47 Errores comunes","heading":"Errores de los factores","text":"Si ves este error sobre niveles de factor válidos, es probable que tengas una columna de tipo Factor (que contiene niveles predefinidos) y hayas intentado añadirle un nuevo valor. Conviértela al tipo Carácter antes de añadir un nuevo valor.","code":"#Trató de añadir un valor (\"Missing\") a un factor (con replace_na operando en un factor)\nProblem with `mutate()` input `age_cat`.\ni invalid factor level, NA generated\ni Input `age_cat` is `replace_na(age_cat, \"Missing\")`.invalid factor level, NA generated"},{"path":"common-errors.html","id":"errores-de-trazado","chapter":"47 Errores comunes","heading":"Errores de trazado","text":"Error: Insufficient values manual scale. 3 needed 2 provided.\nggplot() scale_fill_manual() values = c(“orange”, “purple”) … insuficiente para el número de niveles del factor … considera si NA es ahora un nivel del factor…Probablemente tienes un + extra al final de un comando ggplot que necesitas eliminar.","code":"Can't add x object"},{"path":"common-errors.html","id":"errores-de-r-markdown","chapter":"47 Errores comunes","heading":"Errores de R Markdown","text":"Si el mensaje de error contiene algo como Error en options[sprintf(\"fig.%s\", )]], comprueba que tus opciones knitr en la parte superior de cada chunk utilizan correctamente .width = o .height =y fig.width= y fig.height=.","code":""},{"path":"common-errors.html","id":"miscelánea","chapter":"47 Errores comunes","heading":"Miscelánea","text":"Comprueba si reordenado los verbos dplyr y reemplazado un pipe en el medio, o eliminado un pipe del final después de reordenar.","code":""},{"path":"common-errors.html","id":"resources-39","chapter":"47 Errores comunes","heading":"47.3 Recursos","text":"Esta es otra entrada del blog que enumera los errores comunes de programación en R los que se enfrentan los principiantes","code":""},{"path":"getting-help.html","id":"getting-help","chapter":"48 Cómo obtener ayuda","heading":"48 Cómo obtener ayuda","text":"page covers get help posting Github issue posting reproducible example (“reprex”) online forum.","code":""},{"path":"getting-help.html","id":"github-issues","chapter":"48 Cómo obtener ayuda","heading":"48.1 Issues en Github","text":"Muchos paquetes y proyectos de R tienen su código alojado en el sitio web Github.com. Puedes comunicarte directamente con los autores través de este sitio web publicando un “Issue”.Lee más sobre cómo almacenar tu trabajo en Github en la página Colaboración y Github.En Github, cada proyecto está contenido en un repositorio. Cada repositorio contiene código, datos, resultados, documentación de ayuda, etc. También hay un vehículo para comunicarse con los autores llamado “Issues”.Mira continuación la página de Github del paquete incidence2 (utilizado para hacer curvas epidémicas). Puedes ver la pestaña “Issues” resaltada en amarillo. Puedes ver que hay 5 temas abiertos.Una vez en la pestaña de problemas, podrás ver los problemas abiertos. Revísalas para asegurarte de que tu problema ha sido ya tratado. Puedes abrir una nueva incidencia clicando en el botón verde de la derecha. Necesitarás una cuenta de Github para hacerlo.En tu Issue, sigue las instrucciones que aparecen continuación para proporcionar un ejemplo mínimo y reproducible. Y, por favor, ¡se cortés! La mayoría de las personas que desarrollan paquetes y proyectos de R lo hacen en su tiempo libre (¡como este manual!).Para leer más materiales avanzados sobre el manejo de problemas en tu propio repositorio de Github, consulta su documentación sobre Problemas.","code":""},{"path":"getting-help.html","id":"reproducible-example","chapter":"48 Cómo obtener ayuda","heading":"48.2 Ejemplo reproducible","text":"Proporcionar un ejemplo reproducible (“reprex”) es la clave para obtener ayuda cuando se publica en un foro o en un Issue de Github. La gente quiere ayudarte, pero tienes que darles un ejemplo con el que puedan trabajar en su propio ordenador. El ejemplo debe:Demostrar el problema que encontradoSer mínimo, en el sentido de que incluya sólo los datos y el código necesarios para reproducir el problemaSer reproducible, de manera que se incluyan todos los objetos (por ejemplo, los datos), las llamadas al paquete (por ejemplo, library() o p_load())Además, ¡asegúrese de publicar ningún dato sensible con el reprex! Puedes crear dataframes de ejemplo, o utilizar uno de los dataframes incorporados en R (escribe data() para ver una lista de estos set de datos).","code":""},{"path":"getting-help.html","id":"el-paquete-reprex","chapter":"48 Cómo obtener ayuda","heading":"El paquete reprex","text":"El paquete reprex puede ayudarte crear un ejemplo reproducible:reprex se instala con tidyverse, así que carga cualquiera de los dos paquetesInicia un script de R que cree el problema, paso paso, empezando por la carga de paquetes y datos.Copia todo el código en tu portapapeles y ejecuta el siguiente comando:Verás que aparece una salida HTML en el panel del visor de RStudio. Contendrá todo tu código y cualquier advertencia, error o salida de gráficos. Esta salida también se copia en el portapapeles, por lo que puedes publicarla directamente en un Issue de Github o en un mensaje del foro.Si estableces session_info = TRUE se incluirá la salida de sessioninfo::session_info() con tus versiones de R y del paquete utilizadoPuedes proporcionar un directorio de trabajo con wd =Puedes leer más sobre los argumentos y las posibles variaciones en esta página o introduciendo ?reprexEn el ejemplo anterior, el comando ggplot() se ejecutó porque el argumento date_format = es correcto - debería ser date_labels =.","code":"\n# install/load tidyverse (which includes reprex)\npacman::p_load(tidyverse)\n# cargar paquetes\npacman::p_load(\n     tidyverse,  # gestión y visualización de datos\n     outbreaks)  # datos de ejemplo de brotes\n\n#  lista de casos del brote de gripe\noutbreak_raw <- outbreaks::fluH7N9_china_2013  # obtener datos del paquete de brotes\n\n# Limpiar los datos\noutbreak <- outbreak_raw %>% \n     mutate(across(contains(\"date\"), as.Date))\n\n# Graficar el brote\n\nggplot(data = outbreak)+\n     geom_histogram(\n          mapping = aes(x = date_of_onset),\n          binwidth = 7\n     )+\n  scale_x_date(\n    date_format = \"%d %m\"\n  )\nreprex::reprex()"},{"path":"getting-help.html","id":"datos-mínimos","chapter":"48 Cómo obtener ayuda","heading":"Datos mínimos","text":"Los revisores tienen que ser capaces de utilizar tus datos - idealmente tienen que ser capaces de crearlos con código.Para crear unos datos mínimos, considera la posibilidad de anonimizarlos y utilizar sólo un subconjunto de las observaciones.EN CONSTRUCCIÓN - también puede utilizar la función dput() para crear unos datos mínimo.","code":""},{"path":"getting-help.html","id":"posting-to-a-forum","chapter":"48 Cómo obtener ayuda","heading":"48.3 Publicar en un foro","text":"Lee muchos mensajes de foros. Comprende qué mensajes están bien escritos y cuáles .En primer lugar, decide si vas formular la pregunta. revisado fondo el sitio web del foro, probando con varios términos de búsqueda, para ver si tu pregunta ya ha sido formulada?En primer lugar, decide si vas formular la pregunta. revisado fondo el sitio web del foro, probando con varios términos de búsqueda, para ver si tu pregunta ya ha sido formulada?Dale tu pregunta un título informativo (“¡Ayuda! esto funciona”).Dale tu pregunta un título informativo (“¡Ayuda! esto funciona”).Escribe tu pregunta:Escribe tu pregunta:Presenta la situación y tu problemaEnlaza con posts de temas similares y explica cómo responden tu preguntaIncluye cualquier información relevante para ayudar alguien que conozca el contexto de tu trabajoDa un ejemplo mínimo reproducible con la información de tu sesión de RUtiliza la ortografía, la gramática y la puntuación adecuadas, y divide tu pregunta en párrafos para que sea más fácil de leerSupervisa tu pregunta una vez publicada para responder cualquier solicitud de aclaración. Se cortés y amable: menudo las personas que responden están ofreciendo su tiempo para ayudarte. Si tienes una pregunta de seguimiento, piensa si debe ser una pregunta publicada por separado.Supervisa tu pregunta una vez publicada para responder cualquier solicitud de aclaración. Se cortés y amable: menudo las personas que responden están ofreciendo su tiempo para ayudarte. Si tienes una pregunta de seguimiento, piensa si debe ser una pregunta publicada por separado.Marca la pregunta como respondida, si obtienes una respuesta que satisfaga la petición original. Esto ayuda que otros reconozcan más tarde rápidamente la solución.Marca la pregunta como respondida, si obtienes una respuesta que satisfaga la petición original. Esto ayuda que otros reconozcan más tarde rápidamente la solución.Lee estos posts sobre cómo hacer una buena pregunta el código de conducta de Stack overflow.","code":""},{"path":"getting-help.html","id":"resources-40","chapter":"48 Cómo obtener ayuda","heading":"48.4 Recursos","text":"Página de Tidyverse sobre cómo obtener ayudaConsejos para elaborar unos datos mínimosDocumentación de la función dput","code":""},{"path":"r-on-network-drives.html","id":"r-on-network-drives","chapter":"49 R en redes locales","heading":"49 R en redes locales","text":"","code":""},{"path":"r-on-network-drives.html","id":"overview-9","chapter":"49 R en redes locales","heading":"49.1 Resumen","text":"El uso de R en unidades compartidas de la red o de la “empresa” puede presentar desafíos adicionales. Esta página contiene enfoques, errores comunes y sugerencias sobre la solución de problemas obtenidas partir de nuestra experiencia trabajando con estos problemas. Se incluyen consejos para las situaciones especialmente delicadas relacionadas con R Markdown.Uso de R en unidades de red: Principios generalesDebes tener acceso de administrador tu ordenador. Configura RStudio específicamente para que se ejecute como administrador.Guarda los paquetes en una biblioteca en una unidad con letras (por ejemplo, “C:”) cuando sea posible. Uiliza lo menos posible una biblioteca de paquetes cuya ruta comience por “\\\".El paquete rmarkdown debe estar en una librería de paquetes “\\\", ya que entonces puede conectarse TinyTex o Pandoc.","code":""},{"path":"r-on-network-drives.html","id":"rstudio-as-administrator","chapter":"49 R en redes locales","heading":"49.2 RStudio como administrador","text":"Cuando clicas en el icono de RStudio para abrirlo, hazlo clicando con el botón derecho. Dependiendo de tu máquina, puedes ver una opción para “Ejecutar como administrador”. O si , puedes ver una opción para seleccionar Propiedades (entonces debería aparecer una ventana con la opción “Compatibilidad”, y selecciona una casilla de verificación “Ejecutar como administrador”).","code":""},{"path":"r-on-network-drives.html","id":"useful-commands","chapter":"49 R en redes locales","heading":"49.3 Comandos útiles","text":"continuación se presentan algunos comandos útiles cuando se trata de solucionar problemas utilizando R en unidades de red.Puedes devolver la(s) ruta(s) las bibliotecas de paquetes que R está utilizando. Serán listadas en el orden que R está usando para instalar/cargar/buscar paquetes. Por lo tanto, si quieres que R utilice una biblioteca diferente por defecto, puedes cambiar el orden de estas rutas (ver más abajo).Es posible que desees cambiar el orden de las bibliotecas de paquetes utilizados por R. Por ejemplo, si R está recogiendo una ubicación de la biblioteca que comienza con “\\\" y uno que comienza con una letra, por ejemplo,”D:“. Puedes ajustar el orden de .libPaths() con el siguiente código.Si tienes dificultades para que R Markdown se conecte Pandoc, comienza con este código para averiguar dónde cree RStudio que está tu instalación de Pandoc.Si quieres ver de qué biblioteca se está cargando un paquete, prueba con el siguiente código:","code":"\n# Find libraries\n.libPaths()                   # Your library paths, listed in order that R installs/searches. \n                              # Note: all libraries will be listed, but to install to some (e.g. C:) you \n                              # may need to be running RStudio as an administrator (it won't appear in the \n                              # install packages library drop-down menu) \n# Switch order of libraries\n# this can effect the priority of R finding a package. E.g. you may want your C: library to be listed first\nmyPaths <- .libPaths() # get the paths\nmyPaths <- c(myPaths[2], myPaths[1]) # switch them\n.libPaths(myPaths) # reassign them\n# Find Pandoc\nSys.getenv(\"RSTUDIO_PANDOC\")  # Find where RStudio thinks your Pandoc installation is\n# Find a package\n# gives first location of package (note order of your libraries)\nfind.package(\"rmarkdown\", lib.loc = NULL, quiet = FALSE, verbose = getOption(\"verbose\")) "},{"path":"r-on-network-drives.html","id":"troubleshooting-common-errors","chapter":"49 R en redes locales","heading":"49.4 Solución de errores comunes","text":"“Fallo al compilar…tex en rmarkdown”Comprueba la instalación de TinyTex, o instala TinyTex en la ubicación C:. Consulta la página de fundamentos de R sobre cómo instalar TinyTex.se pueden cargar las rutinas de Internet.Por ejemplo, Error tools::startDynamicHelp() : internet routines loadedIntenta seleccionar la versión de 32 bits de RStudio través de Herramientas/Opciones Globales.\nnota: si la versión de 32 bits aparece en el menú, asegúrate que está utilizando RStudio v1.2.\nnota: si la versión de 32 bits aparece en el menú, asegúrate que está utilizando RStudio v1.2.Alternativamente, intenta desinstalar R y volver instalarlo con una versión de bits diferente (32 en lugar de 64)C: la biblioteca aparece como opción cuando intento instalar los paquetes manualmenteEjecuta RStudio como administrador, entonces aparecerá esta opción.Para configurar RStudio para que se ejecute siempre como administrador (lo que resulta ventajoso cuando se utiliza un proyecto R en el que se clica en el icono de RStudio para abrirlo)… clica con el botón derecho en el icono de RstudioLa imagen siguiente muestra cómo puedes seleccionar manualmente la biblioteca en la que instalar un paquete. Esta ventana aparece cuando se abre el panel de paquetes de RStudio y se clica en “Install”.Error Pandoc 1Si aparece el error “pandoc error 1” al ejecutar R Markdowns scripts en unidades de red:De las múltiples ubicaciones de las bibliotecas, que aparezca en primer lugar la que tenga una unidad de disco con letras (véanse los códigos anteriores)La solución anterior funciona en una unidad de red local, si establece la conexión Internet en la redMira más consejos aquí: https://ciser.cornell.edu/rmarkdown-knit--html-word-pdf/Error Pandoc 83El error será algo así: find file...rmarkdown...lua.... Esto significa que se ha podido encontrar este archivo.Ver https://stackoverflow.com/questions/58830927/rmarkdown-unable--locate-lua-filter--knitting--wordPosibilidades:El paquete Rmarkdown está instaladoEl paquete Rmarkdown se encuentraUn problema de derechos de administración.Es posible que R sea capaz de encontrar el archivo del paquete rmarkdown, así que comprueba en qué biblioteca está el paquete rmarkdown (vearel código anterior). Si el paquete está instalado en una biblioteca inaccesible (por ejemplo, comienza con “\\\") considera moverlo manualmente C: o otra biblioteca con nombre. Ten en cuenta que el paquete rmarkdown tiene que ser capaz de conectarse la instalación de TinyTex, por lo que puede valojarse en una biblioteca en una unidad de red.Error Pandoc 61Por ejemplo: Error: pandoc document conversion failed error 61 o fetch...Prueba ejecutar RStudio como administrador (clica con el botón derecho en el icono, selecciona ejecutar como administrador, vea las instrucciones anteriores)Ver también si el paquete específico que pudo ser alcanzado puede ser movido la biblioteca C:.Error de LaTex (ver más abajo)Un error como: ! Package pdftex.def Error: File 'cict_qm2_2020-06-29_files/figure-latex/unnamed-chunk-5-1.png' found: using draft setting. o Error: LaTeX failed compile file_name.tex.Consulta https://yihui.org/tinytex/r/#debugging para obtener consejos de depuración.Ver file_name.log para más información.Error Pandoc 127Podría tratarse de un problema de RAM (espacio). Reinicia tu sesión de R e inténtelo de nuevo.Asignación de unidades de redMapear una unidad de red puede ser arriesgado. Consulta con tu departamento de TI antes de intentarlo.Un consejo tomado de este foro de discusión:¿Cómo se abre un archivo “través de una unidad de red asignada”?En primer lugar, tendrás que conocer la ubicación de la red la que intentas acceder.continuación, en el administrador de archivos de Windows, deberás clicar con el botón derecho en “Este PC” en el panel de la derecha, y seleccionar “Asignar una unidad de red”.Asigna la ubicación de red como una letra de unidad.Ahora tienes dos maneras de llegar al archivo que estás abriendo. Usar la ruta de la letra de la unidad debería funcionar.Error install.packages()Si obtienes un error que incluya la mención de un directorio de “bloqueo”, por ejemplo Error install.packages : ERROR: failed lock directory...Busca en tu biblioteca de paquetes y verás una carpeta cuyo nombre empieza por “00LOCK”. Prueba los siguientes consejos:Elimina manualmente el directorio de la carpeta “00LOCK” de tu biblioteca de paquetes. Intenta instalar el paquete de nuevo.También puedes probar el comando pacman::p_unlock() (también puedes poner este comando en el Rprofile para que se ejecute cada vez que se abra el proyecto). Luego intenta instalar el paquete de nuevo. Puedes necesitar varios intentos.Prueba ejecutar RStudio en modo de administrador e intenta instalar los paquetes uno por uno.Si todo lo demás falla, instala el paquete en otra biblioteca o carpeta (por ejemplo, Temp) y luego copia manualmente la carpeta del paquete en la biblioteca deseada.","code":"\n# check/install tinytex, to C: location\ntinytex::install_tinytex()\ntinytex:::is_tinytex() # should return TRUE (note three colons)"},{"path":"data-table.html","id":"data-table","chapter":"50 Data Table","heading":"50 Data Table","text":"El manual se centra en las funciones “verbales” de dplyr y en el operador pipe %>% de magrittr como método para limpiar y agrupar datos, pero el paquete data.table ofrece un método alternativo que puedes encontrar en tu recorrido con R.","code":""},{"path":"data-table.html","id":"intro-to-data-tables","chapter":"50 Data Table","heading":"50.1 Introducción a data.table","text":"Una tabla de datos es una estructura de datos bidimensional como un dataframe que permite realizar operaciones de agrupación complejas. La sintaxis de data.table está estructurada de forma que se puedan realizar operaciones sobre filas, columnas y grupos.La estructura es DT[, j, ], separada por 3 partes; los argumentos , j y . El argumento permite subconjuntar las filas necesarias, el argumento j permite operar sobre las columnas y el argumento permite operar sobre las columnas por grupos.En esta página se tratarán los siguientes temas:Importación de datos y uso de fread() y fwrite()Selección y filtrado de filas mediante el argumento iUso de las funciones de ayuda %like%, %chin%, %%Selección y cálculo de columnas con el argumento jCálculo por grupos utilizando el argumento byAñadir y actualizar datos las tablas de datos utilizando :=","code":""},{"path":"data-table.html","id":"load-packages-and-import-data","chapter":"50 Data Table","heading":"50.2 Cargar paquetes e importar datos","text":"","code":""},{"path":"data-table.html","id":"cargar-paquetes-33","chapter":"50 Data Table","heading":"Cargar paquetes","text":"Utilizando la función p_load() de pacman, cargamos (e instalamos si es necesario) los paquetes necesarios para este análisis.","code":"\npacman::p_load(\n  rio,        # to import data\n  data.table, # to group and clean data\n  tidyverse,  # allows use of pipe (%>%) function in this chapter\n  here \n  ) "},{"path":"data-table.html","id":"importar-datos-27","chapter":"50 Data Table","heading":"Importar datos","text":"Esta página explorará algunas de las funciones principales de data.table utilizando la lista de casos referenciados lo largo del manual.Importamos los datos de casos de una epidemia de ébola simulada. Si deseas descargar los datos para seguirlos paso paso, consulta las instrucciones en la página [Descargar libro y datos]. Los datos se importan mediante la función import() del paquete rio. Consulta la página sobre importación y exportación para conocer las distintas formas de importar datos. partir de aquí utilizamos data.table() para convertir el dataframe en una data.table.La función fread() se utiliza para importar directamente archivos delimitados regulares, como los archivos .csv, directamente un formato de tabla de datos. Esta función, y su homóloga, fwrite(), utilizada para escribir tablas de datos como archivos delimitados regulares, son opciones muy rápidas y eficientes desde el punto de vista computacional para bases de datos de gran tamaño.Las primeras 20 filas de linelist:Los comandos de R base, como dim(), que se utilizan para los dataframes, también pueden utilizarse para las tablas de datos","code":"\nlinelist <- rio::import(here(\"data\", \"linelist_cleaned.xlsx\")) %>% data.table()\ndim(linelist) #gives the number of rows and columns in the data table## [1] 5888   30"},{"path":"data-table.html","id":"the-i-argument-selecting-and-filtering-rows","chapter":"50 Data Table","heading":"50.3 El argumento i: seleccionar y filtrar filas","text":"Recordando la estructura **DT*[, j, ], podemos filtrar filas utilizando números de fila o expresiones lógicas. El argumento es el primero; por tanto, se puede utilizar la sintaxis DT[] o DT[,]**.El primer ejemplo muestra las 5 primeras filas de la tabla de datos, el segundo ejemplo los casos de 18 años o más, y el tercer ejemplo los casos de 18 años o más pero diagnosticados en el Central Hospital:El uso de .N en el argumento representa el número total de filas en la tabla de datos. Esto se puede utilizar para subconjuntar los números de las filas:","code":"\nlinelist[1:5] #returns the 1st to 5th row\nlinelist[age >= 18] #subsets cases are equal to or over 18 years\nlinelist[age >= 18 & hospital != \"Central Hospital\"] #subsets cases equal to or over 18 years old but not diagnosed at the Central Hospital\nlinelist[.N] #returns the last row\nlinelist[15:.N] #returns the 15th to the last row"},{"path":"data-table.html","id":"uso-de-funciones-de-ayuda-para-el-filtrado","chapter":"50 Data Table","heading":"Uso de funciones de ayuda para el filtrado","text":"Data table utiliza funciones de ayuda que facilitan el subconjunto de filas. La función %like% se utiliza para coincidir con un patrón en una columna, %chin% se utiliza para coincidir con un carácter específico, y la función de ayuda %% se utiliza para coincidir con columnas numéricas dentro de un rango preestablecido.En los siguientes ejemplos:\n* filtramos las filas en las que la variable hospital contiene “Hospital”\n* filtramos las filas en las que el resultado es “Recover” o “Death”\n* filtramos las filas en el rango de edad 40-60","code":"\nlinelist[hospital %like% \"Hospital\"] #filter rows where the hospital variable contains “Hospital”\nlinelist[outcome %chin% c(\"Recover\", \"Death\")] #filter rows where the outcome is “Recover” or “Death”\nlinelist[age %between% c(40, 60)] #filter rows in the age range 40-60\n\n#%between% must take a vector of length 2, whereas %chin% can take vectors of length >= 1"},{"path":"data-table.html","id":"the-j-argument-selecting-and-computing-on-columns","chapter":"50 Data Table","heading":"50.4 El argumento j: seleccionar y calcular en columnas","text":"Utilizando la estructura DT[, j, ], podemos seleccionar columnas utilizando números o nombres. El argumento j es el segundo; por lo tanto, se utiliza la sintaxis DT[, j]. Para facilitar los cálculos sobre el argumento j, la columna se envuelve utilizando list() o .().","code":""},{"path":"data-table.html","id":"selección-de-columnas","chapter":"50 Data Table","heading":"Selección de columnas","text":"El primer ejemplo recupera la primera, tercera y quinta columnas de la tabla de datos, el segundo ejemplo selecciona todas las columnas excepto las de altura, peso y sexo. El tercer ejemplo utiliza la envoltura .() para seleccionar las columnas case_id y outcome.","code":"\nlinelist[ , c(1,3,5)]\nlinelist[ , -c(\"gender\", \"age\", \"wt_kg\", \"ht_cm\")]\nlinelist[ , list(case_id, outcome)] #linelist[ , .(case_id, outcome)] works just as well"},{"path":"data-table.html","id":"cálculo-en-columnas","chapter":"50 Data Table","heading":"Cálculo en columnas","text":"Combinando los argumentos y j es posible filtrar filas y calcular en sus columnas. El uso de .N en el argumento j también representa el número total de filas en la tabla de datos y puede ser útil para devolver el número de filas después del filtrado de filas.En los siguientes ejemplos:\n* Contar el número de casos que permanecieron más de 7 días en el hospital\n* Calcular la edad media de los casos que murieron en el hospital militar\n* Calcular la desviación estándar, la mediana, la edad media de los casos que se recuperaron en el central hospitalRecuerda que el uso de .() en el argumento j facilita el cálculo, devuelve una tabla de datos y permite nombrar las columnas.","code":"\nlinelist[days_onset_hosp > 7 , .N]## [1] 189\nlinelist[hospital %like% \"Military\" & outcome %chin% \"Death\", .(mean(age, na.rm = T))] #na.rm = T removes N/A values##         V1\n## 1: 15.9084\nlinelist[hospital == \"Central Hospital\" & outcome == \"Recover\", \n                 .(mean_age = mean(age, na.rm = T),\n                   median_age = median(age, na.rm = T),\n                   sd_age = sd(age, na.rm = T))] #this syntax does not use the helper functions but works just as well##    mean_age median_age   sd_age\n## 1: 16.85185         14 12.93857"},{"path":"data-table.html","id":"the-by-argument-computing-by-groups","chapter":"50 Data Table","heading":"50.5 El argumento by: cálculo por grupos","text":"El argumento es el tercer argumento de la estructura DT[, j, ]. El argumento acepta tanto un vector de caracteres como la sintaxis list() o .(). El uso de la sintaxis .() en el argumento permite renombrar las columnas sobre la marcha.En los siguientes ejemplos:\n* agrupamos el número de casos por hospital\n* en los casos de 18 años o más, calculamos la media de altura y peso de los casos según el sexo y si se recuperaron o murieron\n* en los ingresos que duraron más de 7 días, contamos el número de casos según el mes en que ingresaron y el hospital en el que lo hicieronData.table también permite encadenar expresiones de la siguiente manera:En estos ejemplos estamos siguiendo la suposición de que una fila en la tabla de datos es igual un nuevo caso, y por lo tanto podemos utilizar el .N para representar el número de filas en la tabla de datos. Otra función útil para representar el número de casos únicos es uniqueN(), que devuelve el número de valores únicos en una entrada dada. Esto se ilustra aquí:La respuesta es 3, ya que los valores únicos de la columna de género son m, f y N/. Compárelo con la función R base unique(), que devuelve todos los valores únicos en una entrada dada:Para hallar el número de casos únicos en un mes determinado escribiríamos lo siguiente:","code":"\nlinelist[, .N, .(hospital)] #the number of cases by hospital##                                hospital    N\n## 1:                                Other  885\n## 2:                              Missing 1469\n## 3: St. Mark's Maternity Hospital (SMMH)  422\n## 4:                        Port Hospital 1762\n## 5:                    Military Hospital  896\n## 6:                     Central Hospital  454\nlinelist[age > 18, .(mean_wt = mean(wt_kg, na.rm = T),\n                             mean_ht = mean(ht_cm, na.rm = T)), .(gender, outcome)] #NAs represent the categories where the data is missing##    gender outcome  mean_wt  mean_ht\n## 1:      m Recover 71.90227 178.1977\n## 2:      f   Death 63.27273 159.9448\n## 3:      m   Death 71.61770 175.4726\n## 4:      f    <NA> 64.49375 162.7875\n## 5:      m    <NA> 72.65505 176.9686\n## 6:      f Recover 62.86498 159.2996\n## 7:   <NA> Recover 67.21429 175.2143\n## 8:   <NA>   Death 69.16667 170.7917\n## 9:   <NA>    <NA> 70.25000 175.5000\nlinelist[days_onset_hosp > 7, .N, .(month = month(date_hospitalisation), hospital)]##     month                             hospital  N\n##  1:     5                    Military Hospital  3\n##  2:     6                        Port Hospital  4\n##  3:     7                        Port Hospital  8\n##  4:     8 St. Mark's Maternity Hospital (SMMH)  5\n##  5:     8                    Military Hospital  9\n##  6:     8                                Other 10\n##  7:     8                        Port Hospital 10\n##  8:     9                        Port Hospital 28\n##  9:     9                              Missing 27\n## 10:     9                     Central Hospital 10\n## 11:     9 St. Mark's Maternity Hospital (SMMH)  6\n## 12:    10                              Missing  2\n## 13:    10                    Military Hospital  3\n## 14:     3                        Port Hospital  1\n## 15:     4                    Military Hospital  1\n## 16:     5                                Other  2\n## 17:     5                     Central Hospital  1\n## 18:     5                              Missing  1\n## 19:     6                              Missing  7\n## 20:     6 St. Mark's Maternity Hospital (SMMH)  2\n## 21:     6                    Military Hospital  1\n## 22:     7                    Military Hospital  3\n## 23:     7                                Other  1\n## 24:     7                              Missing  2\n## 25:     7 St. Mark's Maternity Hospital (SMMH)  1\n## 26:     8                     Central Hospital  2\n## 27:     8                              Missing  6\n## 28:     9                                Other  9\n## 29:     9                    Military Hospital 11\n## 30:    10                        Port Hospital  3\n## 31:    10                                Other  4\n## 32:    10 St. Mark's Maternity Hospital (SMMH)  1\n## 33:    10                     Central Hospital  1\n## 34:    11                              Missing  2\n## 35:    11                        Port Hospital  1\n## 36:    12                        Port Hospital  1\n##     month                             hospital  N\nlinelist[, .N, .(hospital)][order(-N)][1:3] #1st selects all cases by hospital, 2nd orders the cases in descending order, 3rd subsets the 3 hospitals with the largest caseload##             hospital    N\n## 1:     Port Hospital 1762\n## 2:           Missing 1469\n## 3: Military Hospital  896\nlinelist[, .(uniqueN(gender))] #remember .() in the j argument returns a data table##    V1\n## 1:  3\nlinelist[, .(unique(gender))]##      V1\n## 1:    m\n## 2:    f\n## 3: <NA>\nlinelist[, .(uniqueN(case_id)), .(month = month(date_hospitalisation))]##     month   V1\n##  1:     5   62\n##  2:     6  100\n##  3:     7  198\n##  4:     8  509\n##  5:     9 1170\n##  6:    10 1228\n##  7:    11  813\n##  8:    12  576\n##  9:     1  434\n## 10:     2  310\n## 11:     3  290\n## 12:     4  198"},{"path":"data-table.html","id":"adding-and-updating-to-data-tables","chapter":"50 Data Table","heading":"50.6 Añadir y actualizar a las tablas de datos","text":"El operador := se utiliza para añadir o actualizar datos en una tabla de datos. La adición de columnas la tabla de datos puede hacerse de las siguientes maneras:Las agregaciones más complejas están fuera del alcance de este capítulo introductorio, pero la idea es proporcionar una alternativa popular y viable dplyr para agrupar y limpiar datos. El paquete data.table es un gran paquete que permite un código ordenado y legible.","code":"\nlinelist[, adult := age >= 18] #adds one column\nlinelist[, c(\"child\", \"wt_lbs\") := .(age < 18, wt_kg*2.204)] #to add multiple columns requires c(\"\") and list() or .() syntax\nlinelist[, `:=` (bmi_in_range = (bmi > 16 & bmi < 40),\n                         no_infector_source_data = is.na(infector) | is.na(source))] #this method uses := as a functional operator `:=`\nlinelist[, adult := NULL] #deletes the column"},{"path":"data-table.html","id":"resources-36","chapter":"50 Data Table","heading":"50.7 Recursos","text":"continuación, algunos recursos útiles para obtener más información:\n* https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html\n* https://github.com/Rdatatable/data.table\n* https://s3.amazonaws.com/assets.datacamp.com/img/blog/data+table+cheat+sheet.pdf\n* https://www.machinelearningplus.com/data-manipulation/datatable--r-complete-guide/\n* https://www.datacamp.com/community/tutorials/data-table-r-tutorialPuedes realizar cualquier función de resumen sobre datos agrupados; consulta la hoja de trucos aquí para obtener más información:","code":""}]
